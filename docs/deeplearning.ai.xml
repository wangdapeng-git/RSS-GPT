<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>The Batch - a new weekly newsletter from deeplearning.ai</title>
<link>https://www.deeplearning.ai/the-batch/</link>

<item>
<title>OpenAI Shrinks GPT-4o, Meta Withholds Models From Europe, Investors Hoard GPUs, Synthetic Talking Heads Get Expressive</title>
<link>https://www.deeplearning.ai/the-batch/issue-259</link>
<guid>https://www.deeplearning.ai/the-batch/issue-259</guid>
<content:encoded><![CDATA[
<div> AI应用创业
具体想法
快速得到反馈
可迅速更改方向
提高执行速度
Metaverse
人行模型
欧洲市场隐 私法
风险
调整模型
风险与利益平衡
资本投资
GPU
A16Z
处理能力
资源共享
VASA-1
头部表情
音频
综述

总结：<br><br>AI的具体业务应用对创业公司提供了机遇，快速执行并迅速得到反馈可以帮助发现和解决问题。在欧洲市场，隐私法对AI公司提出要求，调整模型风险与利益需要平衡。资本投资者积累GPU以提供处理能力资源，VASA-1模型通过分离头部表情、音频等元素实现更具表现力的头部生成视频。 <div>
<p>Dear friends,</p><p>AI’s usefulness in a wide variety of applications creates many opportunities for entrepreneurship. In this letter, I’d like to share what might be a counter-intuitive best practice that I’ve learned from leading <a href="http://aifund.ai/?ref=dl-staging-website.ghost.io"><u>AI Fund</u></a>, a venture studio that has built dozens of startups with extraordinary entrepreneurs. When it comes to building AI applications, we strongly prefer to work on a <em>concrete idea</em>, meaning a specific product envisioned in enough detail that we can build it for a specific target user.&nbsp;</p><p>Some design philosophies say you shouldn’t envision a specific product from the start. Instead, they recommend starting with a problem to be solved and then carefully studying the market before you devise a concrete solution. There’s a reason for this: The more concrete or precise your product specification, the more likely it is to be off-target. However, I find that having something specific to execute toward lets you go much faster and discover and fix problems more rapidly along the way. If the idea turns out to be flawed, rapid execution will let you discover the flaws sooner, and this knowledge and experience will help you switch to a different concrete idea.</p><p>One test of concreteness is whether you’ve specified the idea in enough detail that a product/engineering team could build an initial prototype. For example, “AI for livestock farming” is not concrete; it’s vague. If you were to ask an engineer to build this, they would have a hard time knowing what to build.&nbsp; Similarly, “AI for livestock tracking in farming” is still vague. There are so many approaches to this that most reasonable engineers wouldn’t know what to build. But “Apply face recognition to cows so as to recognize individual cows and monitor their movement on a farm” is specific enough that a good engineer could quickly choose from the available options (for example, what algorithm to try first, what camera resolution to use, and so on) to let us relatively efficiently assess:</p><ul><li><strong>Technical feasibility:</strong> For example, do face recognition algorithms developed for human faces work for cows? (It turns out that they do!)&nbsp;</li><li><strong>Business feasibility:</strong> Does the idea add enough value to be worth building? (Talking to farmers might quickly reveal that solutions like RFID are easier and cheaper.)</li></ul><p>Articulating a concrete idea — which is more likely than a vague idea to be wrong — takes more courage. The more specific an idea, the more likely it is to be a bit off, especially in the details. The general area of AI for livestock farming seems promising, and surely there will be good ways to apply AI for livestock. In contrast, specifying a concrete idea, which is much easier to invalidate, is scary.</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--75--1.jpg" width="1200" /></figure><p>The benefit is that the clarity of a specific product vision lets a team execute much faster. One strong predictor of how likely a startup is to succeed is the speed with which it can get stuff done. This is why founders with clarity of vision tend to be desired; clarity helps drive a team in a specific direction. Of course, the vision has to be a good one, and there’s always a risk of efficiently building something that no one wants to buy! But a startup is unlikely to succeed if it meanders for too long without forming a clear, concrete vision.</p><p>Building toward something concrete — if you can do so in a responsible way that doesn’t harm others — lets you get critical feedback more efficiently and, if necessary, switch directions sooner. (See my <a href="https://www.deeplearning.ai/the-batch/how-to-build-ai-products-and-businesses-two-strategies?ref=dl-staging-website.ghost.io"><u>letter</u></a> on when it’s better to go with a “Ready, Fire, Aim” approach to projects.) One factor that favors this approach is the low cost of experimenting and iterating. This is increasingly the case for many AI applications, but perhaps less so for deep-tech AI projects.&nbsp;</p><p>I realize that this advice runs counter to common practice in <a href="https://wind4change.com/design-thinking-d-school-stanford-ideo-approach-methodology/?ref=dl-staging-website.ghost.io"><u>design thinking</u></a>, which warns against leaping to a solution too quickly, and instead advocates spending time understanding end-users, deeply understanding their problems, and brainstorming a wide range of solutions. If you’re starting without any ideas, then such an extended process can be a good way to develop good ideas. Further, keeping ideas open-ended can be good for curiosity-driven research, where investing to pursue deep tech with only a vague direction in mind can pay huge dividends over the long term.&nbsp;</p><p>If you are thinking about starting a new AI project, consider whether you can come up with a concrete vision to execute toward. Even if the initial vision turns out not to be quite right, rapid iteration will let you discover this sooner, and the learnings will let you switch to a different concrete idea.&nbsp;</p><p>Through working with many large corporations, AI Fund has developed best practices for identifying concrete ideas relevant to a business. I’ll share more on this in a later letter.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/intro-to-federated-learning?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-23T084952.204.png" width="1680" /></a></figure><p>Learn how to build secure, privacy-focused federated learning systems using the Flower framework in a new two-part short course. Start with the basics in “Intro to Federated Learning,” and explore advanced techniques in “Federated Fine-tuning of LLMs with Private Data.”&nbsp;<a href="https://www.deeplearning.ai/short-courses/intro-to-federated-learning?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144159.287.gif" width="1200" /></figure><h1 id="mini-but-mighty">Mini but Mighty</h1><p>A slimmed-down version of Open AI’s multimodal flagship packs a low-price punch.</p><p><strong>What’s new:</strong> OpenAI <a href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/?ref=dl-staging-website.ghost.io"><u>released</u></a> GPT-4o mini, a smaller text-image-video-audio generative model that, according to the company, generally outperforms models from Google and Anthropic models of similar size at a lower price for API access. It newly underpins the free version of ChatGPT.</p><p><strong>How it works:</strong> GPT-4o mini currently accepts text and image inputs and outputs text. Image output as well as video and audio input/output are coming soon. OpenAI did not provide information about its architecture or training but <a href="https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?ref=dl-staging-website.ghost.io"><u>told</u></a> <em>TechCrunch</em> it’s roughly the size of Claude 3 Haiku, Gemini 1.5 Flash, and the 8-billion-parameter version of Llama 3. It has a context window of 128,000 tokens and can output up to around 16,400 tokens.&nbsp;</p><ul><li>API access to GPT-4o mini, which <a href="https://openai.com/api/pricing/?ref=dl-staging-website.ghost.io"><u>costs</u></a> $0.15/$0.60 per 1 million input/output tokens. That’s significantly less than the more capable GPT-4o ($5/$15 per 1 million input/output tokens with the same context window). It’s also more cost-effective and significantly better performing than GPT-3.5 Turbo ($0.50/$1.50 per 1 million input/output tokens with a 16,000-token context window).</li><li>On the <a href="https://paperswithcode.com/dataset/mmlu?ref=dl-staging-website.ghost.io"><u>MMLU</u></a> language understanding benchmark, GPT-4o mini beats Gemini 1.5 Flash at a lower cost, according to tests by <a href="https://artificialanalysis.ai/models/gpt-4o-mini?ref=dl-staging-website.ghost.io"><u>Artificial Analysis</u></a>. It’s just behind Llama 3 70B and <a href="https://arxiv.org/abs/2404.12387?ref=dl-staging-website.ghost.io"><u>Reka Core</u></a> but costs around half as much as the former and 1/20th as much as the latter.</li><li>GPT-4o mini (which generates 108 tokens per second) is slower than Llama 3 8B (166 tokens per second), Gemini 1.5 Flash (148 tokens per second), and Claude 3 Haiku (127 tokens per second) according to Artificial Analysis. However, GPT-4o mini speeds past GPT-4o, which produces 63 tokens per second.</li></ul><p><strong>Behind the news:</strong> GPT-4o mini part of a July wave of smaller large language models.&nbsp;</p><ul><li>Mistral and Nvidia jointly <a href="https://mistral.ai/news/mistral-nemo/?ref=dl-staging-website.ghost.io"><u>released</u></a> Mistral NeMo (12 billion parameters). Its context window is 128,000 tokens, equal to GPT-4o mini and larger than most models of its size. It’s available under the Apache 2.0 open source license.</li><li>Hugging Face <a href="https://huggingface.co/blog/smollm?ref=dl-staging-website.ghost.io"><u>debuted</u></a> SmolLM, a family of three even smaller models — 135 million, 362 million, and 1.71 billion parameters — designed to run on mobile devices. The base and instruction-tuned versions including weights are freely available for download with no restrictions on commercial use. SmolLM is licensed under Apache 2.0.</li></ul><p><strong>Why it matters:</strong> Powerful multimodal models are becoming ever more widely available at lower prices, creating opportunities for developers and researchers alike. GPT-4o mini sets a new standard for others to beat. Its price may be especially appealing to developers who aim to build agentic workflows that require models to process large numbers of tokens on their way to producing output.</p><p><strong>We’re thinking:</strong> Not long ago, pushing the edge of large language models meant making them larger, with higher computing costs to drive rising parameter counts. But building bigger models has made it easier to develop smaller models that are more cost-effective and nearly as capable. It’s a virtuous circle: Costs fall and productivity rises to everyone’s benefit.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--76-.jpg" width="1200" /></figure><h1 id="meta-withholds-models-from-europe">M<strong>eta Withholds Models From Europe</strong></h1><p>European users won’t have access to Meta’s multimodal models.&nbsp;</p><p><strong>What’s new:</strong> Meta said it would <a href="https://www.axios.com/2024/07/17/meta-future-multimodal-ai-models-eu?ref=dl-staging-website.ghost.io"><u>withhold</u></a> future multimodal models from the European Union (EU) to avoid being charged, banned, or fined for running afoul of the region’s privacy laws, according to Axios. (The newly released <a href="https://ai.meta.com/blog/meta-llama-3-1/?ref=dl-staging-website.ghost.io"><u>Llama 3.1</u></a> family, which processes text only, will be available to EU users.) <strong>How it works:</strong> EU data regulators have said that Meta may be violating EU privacy laws by training models on data from Facebook, Instagram, and its other properties. Meta’s move in Europe follows its <a href="https://www.reuters.com/technology/artificial-intelligence/meta-decides-suspend-its-generative-ai-tools-brazil-2024-07-17/?ref=dl-staging-website.ghost.io"><u>withdrawal</u></a> of generative models from Brazil, after that country’s national data-protection authority <a href="https://www.reuters.com/technology/artificial-intelligence/brazil-authority-suspends-metas-ai-privacy-policy-seeks-adjustment-2024-07-02/?ref=dl-staging-website.ghost.io"><u>struck down</u></a> the part of Meta’s privacy policy that allowed it to use personal data from users of Meta products to train AI models.&nbsp;</p><ul><li>EU companies will not be able to build applications on future multimodal models from Meta. Companies outside the EU that build products based on these models will not be able to deliver them to EU customers. Text-only versions including Llama 3.1, as well as applications built on them, will continue to be available in the EU.</li><li>In a blog post in May, Meta <a href="https://about.fb.com/news/h/bringing-generative-ai-experiences-to-people-in-europe/?ref=dl-staging-website.ghost.io"><u>announced</u></a> that it would train models on text and images that are publicly visible on Meta-owned services; for example, public Facebook posts and public Instagram photos and their captions. The data-protection authorities of 11 EU member states (including Ireland, where Meta’s European headquarters is located), objected to Meta’s collection of this data from EU users. Meta responded by <a href="https://about.fb.com/news/2024/06/building-ai-technology-for-europeans-in-a-transparent-and-responsible-way/?ref=dl-staging-website.ghost.io"><u>delaying</u></a> its collection of user data in the EU.</li><li>The UK has a nearly <a href="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2024/06/statement-in-response-to-metas-plans-to-train-generative-ai-with-user-data/?ref=dl-staging-website.ghost.io"><u>identical</u></a> data-protection law, but Meta does not plan to restrict its models there. That’s because UK regulators have been clearer than their EU counterparts about the law’s requirements, a Meta representative told Axios.</li></ul><p><strong>Apple and OpenAI in Europe:</strong> Meta is not the only global AI company that’s wary of EU technology regulations.&nbsp;</p><ul><li>In June, Apple <a href="https://www.cnbc.com/2024/06/21/apple-ai-europe-dma-macos.html?ref=dl-staging-website.ghost.io"><u>announced</u></a> it would withhold <a href="https://www.deeplearning.ai/the-batch/apple-unveils-ai-features-in-new-ios-and-macos-update-during-wwdc/?ref=dl-staging-website.ghost.io"><u>generative AI features</u></a> from iOS devices in the EU. Apple said the EU’s <a href="https://digital-markets-act.ec.europa.eu/index_en?ref=dl-staging-website.ghost.io"><u>Digital Markets Act</u></a>, which requires that basic applications like web browsers, search engines, and messaging be able to work together regardless of the operating systems they run on, prevented it from deploying the features to EU customers without compromising user privacy.</li><li>Early in the year, OpenAI <a href="https://www.bbc.com/news/technology-68128396?ref=dl-staging-website.ghost.io"><u>drew</u></a> attention from Italian regulators, who briefly <a href="https://www.deeplearning.ai/the-batch/italy-blocked-chatgpt-for-alleged-privacy-violations/?ref=dl-staging-website.ghost.io"><u>banned</u></a> ChatGPT in 2023 for violating EU law. As of May, a multinational task force was <a href="https://www.edpb.europa.eu/system/files/2024-05/edpb_20240523_report_chatgpt_taskforce_en.pdf?ref=dl-staging-website.ghost.io"><u>investigating</u></a> the matter.&nbsp;</li></ul><p><strong>Why it matters:</strong> Different regions are taking different paths toward regulating AI. The EU is more restrictive than others, creating barriers to AI companies that develop new technology and products. Meta and Apple are taking proactive steps to reduce their risks even if it means foregoing portions of the European market.&nbsp;</p><p><strong>We’re thinking:</strong> We hope regulators everywhere will think hard about how to strike a balance between protecting innovation and other interests. In this instance, the EU’s regulations have prompted Meta to make a decision that likely likely set back European AI while delivering little benefit to citizens.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--77-.jpg" width="1200" /></figure><h1 id="ai-investors-hoard-gpu-power"><strong>AI Investors Hoard GPU Power</strong></h1><p>Investors have been gathering AI chips to attract AI startups.&nbsp;</p><p><strong>What’s new:</strong> Venture-capital firms are stockpiling high-end graphics processing units (GPUs), according to a <a href="https://www.theinformation.com/articles/andreessen-horowitz-is-building-a-stash-of-more-than-20-000-gpus-to-win-ai-deals?ref=dl-staging-website.ghost.io"><u>report</u></a> by <em>The Information</em>. They’re using the hardware to provide processing power to their portfolio companies at reduced or no cost.</p><p><strong>How it works:</strong> Andreessen Horowitz (A16Z), a prominent Silicon Valley venture investment firm, has amassed the largest known stock of GPUs dedicated to venture-funded startups. The firm plans to acquire more than 20,000 GPUs including top-of-the-line Nvidia H100s, which can sell for tens of thousands of dollars each — roughly enough to train a competitive large language model.&nbsp;</p><ul><li>A16Z offers access at below-market rates or in exchange for equity in startups it funds.&nbsp;</li><li>Whether A16Z purchased GPUs or ia paying a third-party cloud provider for access is not clear.&nbsp;</li><li>Luma AI, funded by A16Z, used the venture firm’s compute resources and, in June, released the <a href="https://www.deeplearning.ai/the-batch/claude-3-5-sonnet-is-powerful-inexpensive-and-speedy/?ref=dl-staging-website.ghost.io"><u>Dream Machine</u></a> video generator. Luma AI CEO and co-founder Amit Jain said the company turned down funders who offered more lucrative terms because A16Z offered GPUs.</li></ul><p><strong>Behind the news:</strong> High-end GPUs were in <a href="https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/?ref=dl-staging-website.ghost.io"><u>short supply</u></a> early last year. The shortage has <a href="https://www.tomshardware.com/pc-components/gpus/nvidias-h100-ai-gpu-shortages-ease-as-lead-times-drop-from-up-to-four-months-to-8-12-weeks?ref=dl-staging-website.ghost.io"><u>eased</u></a> significantly, but getting access to enough processing power to train and run large models still isn’t easy. A16Z follows several other investors that have sought to fill the gap for startups.</p><ul><li>Ex-GitHub CEO Nat Friedman and Daniel Gross, who has provided capital to startups including Github, Character.ai, Perplexity.ai, and Uber, <a href="https://www.forbes.com/sites/kenrickcai/2024/02/14/ai-investors-are-wooing-startups-with-massive-computing-clusters/?ref=dl-staging-website.ghost.io"><u>established</u></a> the Andromeda Cluster, a group of supercomputers with more than 4,000 GPUs between them, including over 2,500 H100s. They offer access to startups in their portfolio at below-market rates.</li><li>Last year, Index Ventures <a href="https://techcrunch.com/2023/08/19/how-index-ventures-jumped-to-the-front-of-the-ai-gpu-line/?ref=dl-staging-website.ghost.io"><u>agreed</u></a> to pay Oracle for access to H100 and A100 GPUs. In turn, it made them available to portfolio companies for free.</li><li>Microsoft <a href="https://blogs.microsoft.com/blog/2023/11/07/startups-to-access-high-performance-azure-infrastructure-accelerating-ai-breakthroughs/?ref=dl-staging-website.ghost.io"><u>provides</u></a> free access to GPUs via its Azure cloud service to startups funded by its venture fund M12 and the venture accelerator Y Combinator.</li></ul><p><strong>Yes, but:</strong> David Cahn, a partner at A16Z rival Sequoia Capital, <a href="https://www.sequoiacap.com/article/ais-600b-question/?ref=dl-staging-website.ghost.io"><u>argues</u></a> that stockpiling GPUs is a mistake that could leave venture funds holding large quantities of expensive, rapidly depreciating, hardware. Cahn believes startups and small developers soon may have an easier time getting their hands on the processing power they need. Nvidia recently <a href="https://www.deeplearning.ai/the-batch/all-about-nvidias-new-blackwell-architecture-and-b200-gpu/?ref=dl-staging-website.ghost.io"><u>announced</u></a> its new B100 and B200 GPUs, whose arrival should stanch demand for older units like the H100.</p><p><strong>Why it matters:</strong> AI startups are hot, and venture-capital firms compete for early equity in the most promising ones. In addition to funding, they frequently offer advice, contacts, office support — and now processing power to empower a startup to realize its vision.</p><p><strong>We’re thinking:</strong> Venture investors who use GPUs to sweeten a deal give new meaning to the phrase “bargaining chips.”</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-24T144606.148.gif" width="600" /></figure><h1 id="expressive-synthetic-talking-heads">Expressive Synthetic Talking Heads</h1><p>Previous systems that produce a talking-head video from a photo and a spoken-word audio clip animate the lips and other parts of the face separately. An alternative approach achieves more expressive results by animating the head as a whole.</p><p><strong>What’s new:</strong>&nbsp;Sicheng Xu and colleagues at Microsoft developed&nbsp;<a href="https://arxiv.org/abs/2404.10667?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">VASA-1</a>, a generative system that uses a facial portrait and spoken-word recording to produce a talking-head video with appropriately expressive motion. You can see its output&nbsp;<a href="https://www.microsoft.com/en-us/research/project/vasa-1/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;When a person speaks, the facial expression and head position change over time, while the overall shapes of the face and head don’t. By learning to represent an image via separate embeddings for facial expression and head position — which change — as well as for facial structure in its 2D and 3D aspects — which don’t — a latent diffusion model can focus on the parts of the image that matter most. (<a href="https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">Latent diffusion</a>&nbsp;is a variant of diffusion that saves computation by processing a small, learned vector of an image instead of the image itself.)</p><p><strong>How it works:&nbsp;</strong>VASA-1 comprises four image encoders (three 2D CNNs and one 3D CNN), one image decoder (another 2D CNN),&nbsp;<a href="https://arxiv.org/abs/2006.11477?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">Wav2Vec 2.0</a>, and a latent diffusion image generator. The authors trained the system, given an image of a face and a recorded voice, to generate a series of video frames that conform to the voice. The training set was&nbsp;<a href="https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">VoxCeleb2</a>, which includes over 1 million short videos of celebrities talking. The authors added labels for gaze direction, head-to-camera distance, and an emotional intensity score computed&nbsp;<a href="https://link.springer.com/article/10.3758/s13428-018-1133-5?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">by</a>&nbsp;<a href="https://arxiv.org/abs/1903.08527?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">separate</a>&nbsp;<a href="https://github.com/av-savchenko/face-emotion-recognition?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">systems</a>.</p><ul><li>Given an image of a face, the encoders&nbsp;<a href="https://arxiv.org/pdf/2207.07621?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">learned</a>&nbsp;to generate embeddings that represented the 2D facial structure (which the authors call “identity”), 3D contours (“appearance”), head position, and facial expression. Given the embeddings, the decoder reconstructed the image. The authors trained the encoders and decoder together using eight loss terms. For instance, one loss term encouraged the system to reconstruct the image. Another encouraged the system, when it processes a different image of the same person (with different head positions and facial expressions), to produce a similar identity embedding.</li><li>Given a video, the trained encoders produced a sequence of paired head-position and facial-expression embeddings, which the authors call a “motion sequence.”</li><li>Given the accompanying voice recording, a pretrained Wav2Vec2&nbsp; produced a sequence of audio embeddings.&nbsp;</li><li>Given the audio embeddings that correspond to a series of consecutive frames, the latent diffusion model learned to generate the corresponding embeddings in the motion sequence. It also received other inputs including previous audio and motion sequence embeddings, gaze direction, head-to-camera distances, and emotional-intensity scores.</li><li>At inference, given an arbitrary image of a face and an audio clip, VASA produced the appearance and identity embeddings. Then it produced audio embeddings and motion-sequence embeddings. It generated the final video by feeding the appearance, identity, and motion sequence embeddings to its decoder.</li></ul><p><strong>Results:</strong>&nbsp;The authors measured their results by training a model similar to&nbsp;<a href="https://arxiv.org/abs/2103.00020?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">CLIP</a>&nbsp;that produces a similarity score on how well spoken audio matches a video of a person speaking (higher is better). On the VoxCeleb2 test set, their approach produced a similarity score of 0.468 compared to 0.588 for real video. The nearest contender,&nbsp;<a href="https://arxiv.org/abs/2211.12194?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8OoaVbeFiA37CM2V562ImHCQXdzrwmyJLBKHMJ4NEeKMWV0bCbzhf33oJ8SNplfek6VHaf" rel="noopener">SadTalker</a>, which generates lip, eye, and head motions separately, achieved a similarity score of 0.441.</p><p><strong>Why it matters:</strong>&nbsp;By learning to embed different aspects of a face separately, the system maintained the face’s distinctive, unchanging features while generating appropriate motions. This also made the system more flexible at inference: The authors demonstrated its ability to extract a video’s facial expressions and head movements and apply them to different faces.</p><p><strong>We’re thinking:</strong>&nbsp;Never again will we take talking-head videos at face value!</p><hr /><h2 id="a-message-from-workera">A MESSAGE FROM WORKERA</h2><figure class="kg-card kg-image-card"><a href="https://workera.ai/try-for-free?utm_source=pressrelease&amp;utm_medium=paidsocial&amp;utm_campaign=TryForFree&amp;utm_term=TheBatch&amp;utm_content=TheBatch"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-23T090621.368.png" width="1200" /></a></figure><p>Test, benchmark, and grow your skills with new assessments from Workera! Available domains include AI Foundations, Machine Learning, GenAI, and MLOps.&nbsp;<a href="https://workera.ai/try-for-free?utm_source=pressrelease&amp;utm_medium=paidsocial&amp;utm_campaign=TryForFree&amp;utm_term=TheBatch&amp;utm_content=TheBatch" rel="noreferrer">Try Workera today for $0!</a></p>
]]></content:encoded>
<pubDate>Wed, 24 Jul 2024 19:51:25 GMT</pubDate>
<pubDate>Wed, 24 Jul 2024 19:51:25 GMT</pubDate>
</item>

<item>
<title>Hallucination Detector, Battle of the Image Generators, How Open Are Open Models?, Copyright Claim Fails Against GitHub</title>
<link>https://www.deeplearning.ai/the-batch/issue-258</link>
<guid>https://www.deeplearning.ai/the-batch/issue-258</guid>
<content:encoded><![CDATA[
<div> 关键词: 民主、技术、AI、开放性、幻觉检测

总结:<br /><br />民主是一种脆弱而重要的制度，被Churchill称为“除了其他制度外最糟糕的政府形式”。政治暴力事件对民主过程的干扰是不可容忍的，AI可以在加强民主机制方面发挥作用。技术对民主有积极和消极影响，广泛普及技术有助于增强民主。法院驳回了针对GitHub等的版权诉讼，涉及AI模型的版权纠纷受到关注。开放性对于创新至关重要，调查显示一些AI模型表现开放性较差。通过幻觉检测方法，可以准确识别大型语言模型的虚构回答。 <div>
<p>Dear friends,</p><p>“Democracy is the worst form of government, except for all the others,” said Winston Churchill. Last week’s shocking attempt to assassinate former President Trump was a reminder that democracy is fragile.</p><p>Democracy lets citizens argue with each other via words and votes. While imperfect, it is a powerful force for making sure that people are governed by leaders of their own choosing, and that these leaders are accountable to making people better off.&nbsp;</p><p>That’s why attempts to disrupt the democratic process, such as assassinating a political candidate or attempting to disrupt a peaceful handover of power to a newly elected government, are despicable: They attack a fundamental mechanism for giving everyone a chance to have a say in who governs. I denounce all political violence and grieve for Corey Comperatore, who was killed in the assassination attempt, and for his family. I hope for a quick recovery for former President Trump and the bystanders who were injured. I also hope we can put more resources into strengthening the mechanisms of democracy.&nbsp;</p><p>In addition, I wonder what role AI can play in preserving democracy.&nbsp;</p><p>Technology can have positive or negative impacts on specific mechanisms of democracy. For instance, data analysis can help citizens and reporters discover facts. Micro-targeting of political ads and social media can increase polarization, while social media can also provide useful information to voters.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--72--1.jpg" width="1200" /></figure><p>But zooming out to a macro view,</p><ul><li>Concentration of power, which is enhanced by concentration of access to technology, tends to make a subset of society more powerful at the expense of the whole and thus weakens democracy. For example, if only major political parties have the resources to place highly targeted voter ads, it’s hard for new parties to break in.</li><li>However, widespread access to new technologies tends to make everyone more powerful, and thus strengthens democracy. For example, widespread access to smartphones, web search, and now large language model chatbots broadens access to information and lets each individual do more. Thus, I believe spreading new technology as far and wide as possible is an important way to strengthen democracy.&nbsp;</li></ul><p>I’m glad last week’s assassination attempt failed, just as I’m glad the January 6 insurrection at the U.S. Capitol failed. Both events were close calls and resulted in tragic loss of human life. Looking into the future, in addition to specific applications that strengthen elements of democracy, I hope we keep on promoting widespread access to technology. This will enhance fairness and the ability of individuals to vote wisely. That’s why democratizing access to technology will help democracy itself.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/courses/generative-ai-for-software-development?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-17T111109.125.png" width="1680" /></a></figure><p>Enhance your software-development workflow with our new course, “Generative AI for Software Development.” Learn how to use generative AI tools to boost efficiency, improve code quality, and collaborate creatively.&nbsp;<a href="https://www.deeplearning.ai/courses/generative-ai-for-software-development?ref=dl-staging-website.ghost.io" rel="noreferrer">Pre-enroll today and be the first to join when the course goes live</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--73-.jpg" width="1200" /></figure><h1 id="copyright-claim-fails-in-github-case">Copyright Claim Fails in GitHub Case</h1><p>A judge rejected key claims in a lawsuit by developers against GitHub, Microsoft, and OpenAI, the first decision in a series of court actions related to generative AI.&nbsp;</p><p><strong>What’s new</strong>: A U.S. federal judge&nbsp;<a href="https://regmedia.co.uk/2024/07/08/github_copilot_dismiss.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">dismissed</a>&nbsp;claims of copyright infringement and unfair profit in a class-action lawsuit that targeted GitHub Copilot and the OpenAI Codex language-to-code model that underpins it.</p><p><strong>The case:</strong>&nbsp;In November 2022, programmer Matthew Butterick and the Joseph Saveri Law Firm&nbsp;<a href="https://githubcopilotlitigation.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">filed</a>&nbsp;the lawsuit in U.S. federal court. The plaintiffs claimed that GitHub Copilot had generated unauthorized copies of open-source code hosted on GitHub, which OpenAI Codex used as training data. The copies allegedly infringed on developers’ copyrights. The defendants tried repeatedly to get the lawsuit thrown out of court. In May 2023, the judge&nbsp;<a href="https://www.theregister.com/2023/05/12/github_microsoft_openai_copilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">dismissed</a>&nbsp;some claims, including a key argument that GitHub Copilot could generate copies of public code without proper attribution, and allowed the plaintiffs to revise their arguments.</p><p><strong>The decision:</strong>&nbsp;The revised argument focused on GitHub Copilot’s&nbsp;<a href="https://resources.github.com/learn/pathways/copilot/essentials/establishing-trust-in-using-github-copilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">duplication detection filter</a>. When enabled, the filter detects output that matches public code on GitHub and revises it. The plaintiffs argued that the existence of this feature demonstrated GitHub Copilot’s ability to copy code in OpenAI Codex’s training set. The judge was not persuaded.</p><ul><li>The judge stated that the plaintiffs had not presented concrete evidence that Copilot could generate substantial copies of code. He dismissed this copyright claim with prejudice, meaning that the plaintiffs can’t refile it.</li><li>The judge also dismissed a claim that GitHub illicitly profited from coders’ work by charging money for access to GitHub Copilot. To claim unjust enrichment under California law, plaintiffs must show that the defendant enriched itself through “mistake, fraud, coercion, or request.” The judge ruled that the plaintiffs had failed to demonstrate this.</li></ul><p><strong>Yes, but:</strong>&nbsp;The lawsuit is reduced, but it isn’t finished. A breach-of-contract claim remains. The plaintiffs aim to show that OpenAI and GitHub used open-source code without providing proper attribution and thus violated open-source licenses. In addition, the plaintiffs will refile their unjust-enrichment claim.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;The suit against Github et al. is one of several underway that are testing the copyright implications of training AI systems.&nbsp;<a href="https://www.penningtonslaw.com/news-publications/latest-news/2024/generative-ai-in-the-courts-getty-images-v-stability-ai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Getty Images</a>,&nbsp;<a href="https://authorsguild.org/news/ag-and-authors-file-class-action-suit-against-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Authors’ Guild</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-new-york-times-versus-openai-and-microsoft/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">The New York Times</a>, and other media&nbsp;<a href="https://apnews.com/article/ai-media-lawsuits-center-for-investigative-reporting-chatgpt-mother-jones-c48452889750479410b65a119537746c?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">outlets</a>&nbsp;along with a consortium of&nbsp;<a href="https://www.deeplearning.ai/the-batch/sony-umg-and-warner-music-sue-suno-and-udio-over-alleged-copyright-violations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">music-industry giants</a>&nbsp;have sued OpenAI and other AI companies. All these cases rest on a claim that copying works protected by copyright for the purpose of training AI models violates the law — precisely what the plaintiffs failed to show in the GitHub case.</p><p><strong>Why it matters:</strong>&nbsp;This lawsuit specifically concerns code written by open-source developers. A verdict could determine how code can be used and how developers can use generative AI in their work. However, it has broader implications. (Note: We are not lawyers and we do not provide legal advice.) This dismissal is not a final verdict, but it supports the view that AI developers may have a broad right to use data for training models even if that data is protected by copyright.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Broadly speaking, we would like AI to be allowed to do with data, including open source code, anything that humans can legally and ethically do, including study and learn. We hope the judge’s decision gives AI developers further clarity on how they can use training data, and we hope it establishes that it’s ethical to use code-completion tools trained on open-source code.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-17T135649.502.gif" width="1200" /></figure><h1 id="how-open-are-open-models">How Open Are Open Models?</h1><p>The word “open” can mean many things with respect to AI. A new paper outlines the variations and ranks popular models for openness.</p><p><strong>What’s new:</strong>&nbsp;Researchers at Radboud University&nbsp;<a href="https://www.mpi.nl/publications/item3588217/rethinking-open-source-generative-ai-open-washing-and-eu-ai-act?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">evaluated</a>&nbsp;dozens of models billed as open by their developers. They plan to keep their analysis of language models updated&nbsp;<a href="https://opening-up-chatgpt.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">here</a>.<br /><br /><strong>How it works:&nbsp;</strong>The authors assessed 40 large language models and six text-to-image generators, adding OpenAI’s closed models ChatGPT and DALL·E 2 as reference points. They evaluated 14 characteristics, scoring each as open (1 point), partially open (0.5 points), or closed (0 points). For example, an API would be described as partially open if using it requires users to register. They divided the characteristics into three categories:</p><ul><li><strong>Availability</strong>&nbsp;with respect to source code, pretraining data, base weights, fine-tuning data, fine-tuning weights, and licensing under a recognized open-source license</li><li><strong>Documentation</strong>&nbsp;of code, architecture, preprint paper, published peer-reviewed paper, model card, and datasheets that describe how the developer collected and curated the data</li><li><strong>Access</strong>&nbsp;to a downloadable package and open API</li></ul><p><strong>Results:</strong>&nbsp;Of the language models,&nbsp;<a href="https://allenai.org/olmo?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">OLMo 7B Instruct</a>&nbsp;from Allen Institute for AI scored highest with 12 open characteristics and 1 partially open characteristic (it lacked a published, peer-reviewed paper).&nbsp;</p><ul><li>OLMo 7B Instruct and&nbsp;<a href="https://huggingface.co/LLM360/AmberChat?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">AmberChat</a>&nbsp;(based on Llama-7B) were the only language models for which availability was fully open. BigScience’s&nbsp;<a href="https://huggingface.co/bigscience/bloomz?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">BLOOMZ</a>&nbsp;was the only language model whose documentation was fully open.&nbsp;</li><li>Some prominent “open” models scored less well. Alibaba’s Qwen 1.5, Cohere’s Command R+, and Google’s Gemma-7B Instruct were judged closed or partially open for most characteristics.&nbsp;<a href="https://www.deeplearning.ai/the-batch/falcon-the-new-open-source-commercial-llm-explained/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Falcon-40B-Instruct</a>&nbsp;scored 2 open and 5 partially open characteristics. Neither Meta’s Llama 2 Chat nor Llama 3 Instruct achieved any open marks.&nbsp;</li><li>Among text-to-image generators, Stability AI’s Stable Diffusion was far and away the most open. The authors deemed it fully open with respect to availability and documentation, and partially open with respect to access.</li></ul><p><strong>Behind the News:</strong>&nbsp;The Open Source Initiative (OSI), a nonprofit organization that maintains standards for open-source software licenses, is&nbsp;<a href="https://opensource.org/deepdive?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">leading</a>&nbsp;a process to establish a firm definition of “open-source AI.” The current&nbsp;<a href="https://opensource.org/deepdive/drafts/the-open-source-ai-definition-draft-v-0-0-8?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">draft</a>&nbsp;holds that an open-source model must include parameters, source code, and information on training data and methodologies under an OSI-recognized license.</p><p><strong>Why it matters:</strong>&nbsp;Openness is a cornerstone of innovation: It enables developers to build freely on one another’s work. It can also lubricate business insofar as it enables developers to sell products built upon fully open software. And it has growing regulatory implications. For example, the European Union’s AI Act regulates models that are released under an open source license less strictly than closed models. All these factors raise the stakes for clear, consistent definitions. The authors’ framework offers clear, detailed guidelines for developers — and policymakers — in search of clarity.<br /><br /><strong>We’re thinking:</strong>&nbsp;We’re grateful to AI developers who open their work to any degree, and we especially appreciate fully open availability, documentation, and access. We encourage model builders to release their work as openly as they can manage.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-17T135754.238.gif" width="1200" /></figure><h1 id="image-generators-in-the-arena">Image Generators in the Arena</h1><p>An arena-style contest pits the world’s best text-to-image generators against each other.</p><p><strong>What’s new:</strong>&nbsp;Artificial Analysis, a testing service for AI models,&nbsp;<a href="https://artificialanalysis.ai/text-to-image?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">introduced</a>&nbsp;the Text to Image Arena leaderboard, which ranks text-to-image models based on head-to-head matchups that are judged by the general public. At the time of this writing, Midjourney v6 beats more than a dozen other models models in its ability to generate images that reflect input prompts, though it lags behind competitors in speed.</p><p><strong>How it works:</strong>&nbsp;Artificial Analysis selects two models at random and feeds them a unique prompt. Then it&nbsp;<a href="https://artificialanalysis.ai/text-to-image/arena?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">presents</a>&nbsp;the prompt and resulting images. Users can choose which model better reflects the prompt. The leaderboard ranks the models based on&nbsp;<a href="https://www.chess.com/terms/elo-rating-chess?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Elo</a>&nbsp;ratings, which scores competitors relative to one another.</p><ul><li>Artificial Analysis&nbsp;<a href="https://artificialanalysis.ai/text-to-image/methodology?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">selects</a>&nbsp;models to test according to “industry significance” and unspecified performance tests. The goal is to identify and compare the most popular, high-performing models, especially those that are available via APIs. (Midjourney, which has no API, is an exception.) Only 14 models meet this threshold, but Artificial Analysis says it is refining its criteria and may include more models in the future.</li><li>Users who have voted at least 30 times can see a personalized leaderboard based on their own voting histories.&nbsp;</li><li>Separate from the Text to Image Arena, Artificial Analysis&nbsp;<a href="https://artificialanalysis.ai/text-to-image?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">compares</a>&nbsp;each model’s average time to generate and download an image, calculated by prompting each model four times a day and averaging the time to output over 14 days. It also tracks the price to generate 1,000 images.</li></ul><p><strong>Who’s ahead?:</strong>&nbsp;As of this writing, Midjourney v6 (Elo rating 1,176), which won 71 percent of its matches, holds a slim lead over Stable Diffusion 3 (Elo rating 1,156), which won 67 percent. DALL·E 3 HD holds a distant third place, barely ahead of the open-source Playground v2.5. But there are tradeoffs: Midjourney v6 takes 85.3 seconds on average to generate an image, more than four times longer than DALL·E 3 HD and more than 13 times longer than Stable Diffusion 3. Midjourney v6 costs $66 per 1,000 images (an estimate by Artificial Analysis based on Midjourney’s policies, since the model doesn’t offer per-image pricing), nearly equal to Stable Diffusion 3 ($65), less than DALL·E 3 HD ($80), and significantly more than Playground v2.5 ($5.13 per 1,000 images via the&nbsp;<a href="https://replicate.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Replicate</a>&nbsp;API).</p><p><strong>Behind the news:</strong>&nbsp;The Text to Image Arena is a text-to-image counterpart of the&nbsp;<a href="https://www.deeplearning.ai/the-batch/chatbot-arena-compares-chatbots-side-by-side?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">LMSys Chatbot Arena</a>, which lets users write a prompt, feed it to two large language models, and pick the winner.&nbsp;<a href="https://imgsys.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">imgsys</a>&nbsp;and&nbsp;<a href="https://huggingface.co/spaces/TIGER-Lab/GenAI-Arena?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">Gen-AI Arena</a>&nbsp;similarly let users choose between images generated by different models from the same prompt (Gen-AI Arena lets users write their own). However, these venues are limited to open models, which excludes the popular Midjourney and DALL·E.</p><p><strong>Why it matters:</strong>&nbsp;An image generator’s ability to respond appropriately to prompts is a subjective quality. Aggregating user preferences is a sensible way to measure it. However, individual tastes and applications differ, which makes personalized leaderboards useful as well.<br /><br /><strong>We’re thinking:</strong>&nbsp;The user interface for some image generators implicitly asks users to judge images. For example, Midjourney defaults to generating four images and asks users which they want to render at higher resolution. This can give the image generator valuable feedback about which image users like. Perhaps data gathered by an arena could feed an algorithm like reinforcement learning from human feedback to help generators learn to produce output that people prefer.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-17T135854.645.png" width="600" /></figure><h1 id="hallucination-detector">Hallucination Detector</h1><p>Large language models can produce output that’s convincing but false. Researchers proposed a way to identify such hallucinations.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Sebastian Farquhar, Jannik Kossen, Lorenz Kuhn, and Yarin Gal at University of Oxford published a&nbsp;<a href="https://www.nature.com/articles/s41586-024-07421-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">method</a>&nbsp;that indicates whether a large language model (LLM) is likely to have hallucinated its output.</p><p><strong>Key insight:</strong>&nbsp;One way to estimate whether an LLM is hallucinating is to calculate the degree of uncertainty, or entropy, in its output based on the probability of each generated token in the output sequences. The higher the entropy, the more likely the output was hallucinated. However, this approach is flawed: Even if the model mostly generates outputs with a uniform meaning, the entropy of the outputs can still be high, since the same meaning can be phrased in many different ways. A better approach is to calculate entropy based on the distribution of generated meanings instead of generated sequences of words. Given a particular input, the more likely a model is to respond by generating outputs with a variety of meanings, the more likely that a response to that input is a hallucination.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors generated answers to five&nbsp;<a href="http://participants-area.bioasq.org/datasets/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">open-ended</a>&nbsp;<a href="https://rajpurkar.github.io/SQuAD-explorer/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">question</a>-<a href="https://arxiv.org/abs/1705.03551?ref=dl-staging-website.ghost.io&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">and</a>-<a href="https://github.com/arkilpatel/SVAMP?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">answer</a>&nbsp;<a href="https://ai.google.com/research/NaturalQuestions?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">datasets</a>&nbsp;using various sizes of Falcon, LLaMA 2-chat, and Mistral. They checked the answers for hallucinations using the following method:</p><ul><li>Given a question, the model generated 10 answers.</li><li>The authors clustered the answers based on their meanings. They judged two answers to have the same meaning if GPT-3.5 judged that the first followed logically from the second and vice versa.</li><li>They computed the probabilities that the model would generate an answer in each cluster. Then they computed the entropy using those probabilities; that is, they calculated the model’s uncertainty in the meanings of its generated answers.&nbsp;</li><li>All answers to a given question were considered to have been hallucinated if the computed entropy exceeded a threshold.</li></ul><p><strong>Results:</strong>&nbsp;The authors measured the classification performance of their method using AUROC, a score between .5 (the classifier is uninformative) and 1 (the classifier is perfect). On average, across all five datasets and six models, the authors’ method achieved .790 AUROC while the baseline entropy achieved .691 AUROC and the&nbsp;<a href="https://arxiv.org/abs/2207.05221?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">P(True)</a>&nbsp;method achieved .698 AUROC. P(True) asks the model (i) to generate up to 20 answers and (ii) whether, given those answers, the one with the highest probability of having been generated is true or false.</p><p><strong>Yes, but:</strong>&nbsp;The authors’ method fails to detect hallucinations if a model consistently generates wrong answers.</p><p><strong>Behind the news:</strong>&nbsp;Hallucinations can be a major obstacle to deploying generative AI applications, particularly in fields like medicine or law where missteps can result in injury. One study published earlier this year&nbsp;<a href="https://hai.stanford.edu/news/ai-trial-legal-models-hallucinate-1-out-6-or-more-benchmarking-queries?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zO8uuNh9EbBkFJAokTXKxTujRKaiq-z0B9iiyi5sH_gAfph9L318PWgvBzeY82HykJysg" rel="noopener">found</a>&nbsp;that three generative legal tools produced at least partially incorrect or incomplete information in response to at least one out of every six prompts. For example, given the prompt, “Are the deadlines established by the bankruptcy rules for objecting to discharge jurisdictional,” one model cited a nonexistent rule: “[A] paragraph from the Federal Rules of Bankruptcy Procedure, Rule 4007 states that the deadlines set by bankruptcy rules governing the filing of dischargeability complaints are jurisdictional.”<br /><br /><strong>Why it matters:</strong>&nbsp;Effective detection of hallucinations not only fosters trust in users — and consequently rising adoption — but also enables researchers to determine common circumstances in which hallucinations occur, helping them to address the problem in future models.</p><p><strong>We’re thinking:&nbsp;</strong>Researchers are exploring various approaches to mitigate LLM hallucinations in trained models. Retrieval augmented generation (RAG) can help by integrating knowledge beyond a model’s training set, but it isn’t a complete solution. <a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email" rel="noopener">Agentic workflows</a> that include tool use to supply factual information and reflection to prompt the model to check itself are promising.</p><hr /><h2 id="a-message-from-deeplearningai-1">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/pretraining-llms?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/07/The-Batch-ads-and-exclusive-banners---2024-07-16T085539.096.png" width="1680" /></a></figure><p>In “Pretraining LLMs,” a short course built in collaboration with Upstage, you’ll learn about pretraining, the first step of training a large language model. You’ll also learn innovative pretraining techniques like depth upscaling, which can reduce training costs by up to 70 percent.&nbsp;<a href="https://www.deeplearning.ai/short-courses/pretraining-llms?ref=dl-staging-website.ghost.io" rel="noreferrer">Join today</a></p>
]]></content:encoded>
<pubDate>Wed, 17 Jul 2024 19:03:11 GMT</pubDate>
</item>
<item>
<title>AI's Cloudy Path to Zero Emissions, Amazon's Agent Builders, Claude's UI Advance, Training On Consumer GPUs</title>
<link>https://www.deeplearning.ai/the-batch/issue-257</link>
<guid>https://www.deeplearning.ai/the-batch/issue-257</guid>
<content:encoded><![CDATA[
<div> SB 1047, open source, AI innovation, regulatory uncertainty, climate change
<br />
<br />
总结:SB 1047是一项针对AI技术而非应用的法规提案，对开源和AI创新构成威胁。其规定复杂，模糊，给开发者带来风险和无形压力。法案的不确定性和机制会阻碍团队的发展，对开源和AI创新产生负面影响。另外，大型科技公司在追求AI创新的同时也面临减缓温室气体排放的困境。Amazon收购Adept AI和提出GaLore等新方法展示了AI技术发展的趋势和挑战。通过创新的技术和方法，AI技术有望在节能减排和推动绿色能源方面发挥重要作用。 <div>
<p>Dear friends,</p><p>I continue to be alarmed at the progress of proposed California regulation SB 1047 and the attack it represents on open source and more broadly on AI innovation. As I&nbsp;<a href="https://www.deeplearning.ai/the-batch/blenders-versus-bombs-or-why-californias-proposed-ai-law-is-bad-for-everyone/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">wrote</a>&nbsp;previously, this proposed law makes a fundamental mistake of regulating AI technology instead of AI applications, and thus would fail to make AI meaningfully safer. I’d like to explain why the specific mechanisms of SB 1047 are so pernicious to open source.&nbsp;</p><p>To be clear, there are routes that regulators should pursue to improve safety. For example, I would welcome outlawing nonconsensual deepfake pornography, standardizing watermarking and fingerprinting to identify generated content, and investing more in red teaming and other safety research. Unfortunately, the proposed bill pursues a less beneficial and more harmful path.</p><p>SB 1047’s purported goal is to ensure safety of AI models. It puts in place complex reporting requirements for developers who fine-tune models or develop models that cost more than $100 million to train. It is a vague, ambiguous law that imposes significant penalties for violations, creating a huge gray zone in which developers can’t be sure how to avoid breaking the law. This will paralyze many teams.&nbsp;</p><p>You can read the latest draft of the law&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billCompareClient.xhtml?bill_id=202320240SB1047&amp;showamends=false&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">here</a>.&nbsp;I’ve read through it carefully, and I find it ambiguous and very hard to follow.</p><p>Developers who try to navigate the law’s complex requirements face what feels like a huge personal risk. It requires that developers submit&nbsp;a certification of compliance with the requirements of the law. But when the requirements are complex, hard to understand, and can even shift according to the whims of an unelected body (more on this below), how do we ensure we are in compliance?</p><p>For example, the certification must include many different sections. One is an analysis of “the nature and magnitude of critical harms … the model might reasonably cause or enable.” But given that even leading AI researchers aren’t sure what harms models might cause or enable, how is a team of developers supposed to figure this out and declare — under penalty of perjury — that they meet this requirement?&nbsp;</p><p>Further, some developers will be required to implement “protections to prevent … misuse of, or unsafe post-training modifications of, the covered model and all covered model derivatives … that are appropriate in light of the risks associated with the covered model, including from advanced persistent threats or other sophisticated actors.” Even leading AI researchers don’t agree on how best to “protect” AI models against these supposed risks, or what would be “appropriate.” So how are developers supposed to figure out how to comply with this requirement?&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--69-.jpg" width="1200" /></figure><p>This creates a scary situation for developers. Committing perjury could lead to fines and even jail time. Some developers will have to hire expensive lawyers or consultants to advise them on how to comply with these requirements. (I am not a lawyer and am not giving legal advice, but one way to try to avoid perjury is to show that you are relying on expert advice, to demonstrate that you had no intent to lie.) Others will simply refrain from releasing cutting-edge AI products.</p><p>If this law passes, the fear of a trial by a jury — leading to a verdict that can be very unpredictable with significant penalties in the event of a conviction — will be very real. What if someone releases a model today after taking what they genuinely felt were reasonable safeguards, but a few years later, when views on AI technology might have shifted, some aggressive prosecutor manages to convince a jury that whatever they did was not, in hindsight, “reasonable”? Reasonableness is ambiguous and its legal interpretation can depend on case law, jury instructions, and common facts, among other things. This makes it very hard to ensure that what a developer does today will be deemed reasonable by a future jury. (For more on this, see Context Fund’s&nbsp;<a href="https://docs.google.com/document/d/1xi2BolGZ4ljUVi7KNWewetpFJuNOQXRVI1hmBkej4Ew/edit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru#heading=h.8id9zuc4ym7p" rel="noopener">analysis</a>&nbsp;of SB 1047.)</p><p>One highly placed lawyer in the California government who studied this law carefully told me they found it hard to understand. I invite you to read it and judge for yourself — if you find the requirements clear, you might have a brilliant future as a lawyer!&nbsp;</p><p>Adding to the ambiguity, the bill would create a Frontier Model Division (FMD) with a five-person board that has the power to dictate standards to developers. This small board would be a great target for lobbying and regulatory capture. (Bill Gurley has a great&nbsp;<a href="https://www.youtube.com/watch?v=F9cO3-MLHOM&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">video</a>&nbsp;on regulatory capture.) The unelected FMD can levy fees on developers to cover its costs. It can arbitrarily change the computation threshold at which fine-tuning a model becomes subject to its oversight. This can lead to even small teams being required to hire an auditor to check for compliance with an ambiguous safety standard.&nbsp;</p><p>These provisions don’t ensure that AI is safe. They create regulatory uncertainty, and more opportunities for vested interests wishing to stifle open-source to lobby for shifts in the requirements that raise the cost of compliance. This would lock out many teams that don’t have a revenue stream — specifically, many open-source contributors — that would let them pay for lobbyists, auditors, and lawyers to help ensure they comply with these ambiguous and unreasonable requirements.&nbsp;</p><p>Open source is a wonderful force that is bringing knowledge and tools to many people, and is a key pillar of AI innovation. I am dismayed at the concerted attacks on it. Make no mistake, there is a fight in California right now for the future health of open source. I am committed to doing what I can to preserve open source, but I don’t assume that the pro-open source side will prevail. I hope you will join me in speaking out against SB 1047 and other laws that threaten to stifle open source.&nbsp;</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-compression-and-query-optimization?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1040" src="https://dl-staging-website.ghost.io/content/images/2024/07/V2_DeepLearning_MongoDB_Banner_2070x1080--1---2-.png" width="2000" /></a></figure><p>In our new course “Prompt Compression and Query Optimization,” you’ll learn how to use MongoDB’s features to build efficient retrieval augmented generation (RAG) systems and address challenges to scaling, performance, and security.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-compression-and-query-optimization?ref=dl-staging-website.ghost.io">Enroll for free</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-10T143512.450.gif" width="1200" /></figure><h1 id="claude-advances-the-llm-interface">Claude Advances the LLM Interface</h1><p>Claude 3.5 Sonnet lets users work on generated outputs as though they were independent files — a step forward in large language model user interfaces.</p><p><strong>What’s new:</strong>&nbsp;Anthropic&nbsp;<a href="https://www.anthropic.com/news/claude-3-5-sonnet?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">introduced</a>&nbsp;Artifacts, a feature that displays outputs in a separate window of Claude 1.5 Sonnet’s web interface, outside the stream of conversation that creates and modifies them. Artifacts can&nbsp;<a href="https://support.anthropic.com/en/articles/9487310-what-are-artifacts-and-how-do-i-use-them?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">include</a>&nbsp;documents, code snippets, HTML pages, vector graphics, or visualizations built using JavaScript.</p><p><strong>How it works:</strong>&nbsp;Users can enable artifacts from the “feature preview” dropdown in their profile menu at Claude.ai. Then, asked to generate an output that’s likely to act as standalone content and undergo further work, Claude opens an artifact window next to the chat frame, populates it with an initial output, and further updates it according to subsequent prompts.&nbsp;</p><ul><li>Text or code artifacts are typically at least 15 lines long. Visual artifacts created using a programming language or markup can be viewed selectively as code or a rendered display. Users can interact with multiple artifacts (or multiple versions of the same artifact) and switch between them.</li><li>For instance, asking Claude to “create an 8-bit crab” creates an artifact that shows a downloadable vector image of a crab. Ryan Morrison of&nbsp;<em>Tom’s Guide</em>&nbsp;<a href="https://www.tomsguide.com/ai/claude-artifacts-is-the-greatest-innovation-in-ai-this-year-5-prompts-to-try-it-now?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">used</a>&nbsp;artifacts to create pixel art, a simple 2D game, and a tool that builds a family tree one relative at a time.&nbsp;</li><li>Developer and designer Meng To&nbsp;<a href="https://x.com/MengTo/status/1809225832466096343?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">showed</a>&nbsp;a tool built with help from Artifacts that enables users to customize a diagram of a vector field in real time by adjusting sliders and menu options.&nbsp;</li><li>Pliny the Prompter, who regularly shares jailbreaks on X,&nbsp;<a href="https://x.com/elder_plinius/status/1804052791259717665?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">found</a>&nbsp;what appears to be a part of Claude’s internal instructions concerning artifacts. The instructions suggest that Claude avoids rendering an artifact if a chat response will do, avoids creating new artifacts in favor of updating existing ones, renders one artifact per text unless requested otherwise, and deliberates silently about whether to create an artifact by generating text between specific XML tags that hide it from the user. (Artifacts themselves are enclosed in a different set of tags.)</li></ul><p><strong>Why it matters:</strong>&nbsp;Artifacts make working with a large language model more fluidly interactive. Large language models (LLMs) have long been able to generate code but, outside of AI-assisted development environments like GitHub with Copilot, executing generated code typically requires further steps such as copy-pasting the code into a development environment. The additional steps add friction for developers and confusion for non-developers. Keeping and running the code in a separate window makes for a convenient, low-friction experience. Likewise when generating images and other kinds of visual output.</p><p><strong>We’re thinking:&nbsp;</strong>It’s rare when a user interface update makes a tool more useful for casual and hardcore users alike. It’s even more exciting to see it happen to an LLM!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--70-.jpg" width="1200" /></figure><h1 id="ai%E2%80%99s-path-to-zero-emissions-is-cloudy">AI’s Path to Zero Emissions Is Cloudy</h1><p>The boom in AI is jeopardizing big tech’s efforts to reach its targets for emissions of greenhouse gasses.</p><p><strong>What’s new:</strong>&nbsp;Google’s&nbsp;<a href="https://blog.google/outreach-initiatives/sustainability/2024-environmental-report/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">annual environmental report</a>&nbsp;shows that the company’s total carbon dioxide emissions rose nearly 50 percent between 2019 and 2023 to 14.3 million tons. Google attributes the rise to its efforts to satisfy rising demand for AI.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Google’s carbon emissions increased 16.7 percent from 2021 to 2022 and another 13.5 percent from 2022 to 2023 for a total 48 percent rise over those periods. “As we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute, and the emissions associated with the expected increases in our technical infrastructure investment,” the report states.</p><ul><li>Three-quarters of total emissions, or 10.8 million tons, are associated with purchases that include the data-center hardware and construction. These emissions increased 23 percent from 2019 to 2023 and 8 percent year-over-year.</li><li>Powering, heating, and cooling data centers and other facilities accounted for around a quarter of Google’s 2023 emissions. Emissions from these activities have increased more than four-fold since 2019.</li><li>Low-emissions energy has reduced Google’s total data-center emissions substantially, but some regions don’t have enough of it to meet demand. Solar, wind, hydro, geothermal, and nuclear energy account for most of the energy consumed by Google’s data centers in Europe, Canada, and South America. However, these sources account for less than 5 percent in Singapore, Qatar, and Saudi Arabia.</li></ul><p><strong>Countering the trend:&nbsp;</strong>Google is working to reduce its greenhouse gas emissions on several fronts. Its effort to purchase electricity from low-emissions sources cut its net carbon footprint by around 30 percent in 2023. It claims that its owned-and-operated data centers are 1.8 times more energy-efficient than a typical enterprise data center, and its sixth-generation tensor processing units (TPUs) are 67 percent more efficient than the prior generation. Google has asked its largest hardware partners to match 100 percent of their energy consumption with renewable energy 2029. The company is pursuing several AI-based initiatives to mitigate climate change from weather prediction to fuel-efficient vehicle routing. It says that AI has the potential to mitigate 5 to 10 percent of global greenhouse gas emissions by 2030.</p><p><strong>Behind the news:</strong>&nbsp;In 2020, after five years of successfully&nbsp;<a href="https://www.gstatic.com/gumdrop/sustainability/google-2020-environmental-report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">reducing</a>&nbsp;its carbon footprint, Google set an ambitious target to reach net-zero greenhouse gas emissions by 2030. But its total emissions since then have risen each year. Google’s experience mirrors that of Amazon and Microsoft, which aim to reach net-zero carbon emissions by 2030 and 2040 respectively. Amazon’s emissions&nbsp;<a href="https://sustainability.aboutamazon.com/2022-sustainability-report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">increased</a>&nbsp;39 percent from 2019 to 2022, while Microsoft’s emissions&nbsp;<a href="https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RW1lMjE?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">rose</a>&nbsp;29 percent between 2020 and 2023. (Amazon’s and Microsoft’s cloud computing revenues were roughly triple Google’s in 2023 and thus their AI-related greenhouse case emissions&nbsp; presumably were larger.)</p><p><strong>Why it matters:</strong>&nbsp;Growing use of AI means greater consumption of energy. The tech giants’ ambitious emissions goals predate the rapid growth of generative AI, and their latest reports show that it’s time to rethink them. This adds urgency to already critical efforts to develop renewable and other low-emissions energy sources.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;We applaud Google’s efforts to cut its carbon emissions and its transparency in issuing annual environmental reports. We’re somewhat relieved to note that, for now, data centers and cloud computing are responsible for&nbsp;<a href="https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">1 percent</a>&nbsp;of the world’s energy-related greenhouse gas emissions; a drop in the bucket compared to transportation, construction, or agriculture. Moreover, we believe that AI stands to create huge benefits relative to the climate impact of its emissions, and AI is one of the most powerful tools we have to develop low-carbon energy sources and boost energy efficiency throughout society. Continuing to improve the technology will help us develop lower-carbon energy sources and efficient ways to harness them.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--71-.jpg" width="1200" /></figure><h1 id="amazon-onboards-adept">Amazon Onboards Adept</h1><p>Amazon hired most of the staff of agentic-AI specialist Adept AI in a move that echoes Microsoft’s absorption of Inflection in March.</p><p><strong>What’s new:</strong>&nbsp;Amazon onboarded most of the leadership and staff of Adept AI, which has been training models to operate software applications running on local hardware,&nbsp;<em>GeekWire</em>&nbsp;<a href="https://www.geekwire.com/2024/amazon-hires-founders-from-well-funded-enterprise-ai-startup-adept-to-boost-tech-giants-agi-team/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">reported</a>. Amazon licensed Adept’s models, datasets, and other technology non-exclusively. The companies did not disclose the financial terms of the deal. (Disclosure: Andrew Ng serves on Amazon’s board of directors.)</p><p><strong>How it works:</strong>&nbsp;Amazon hired two thirds of Adept’s former employees. Those who remain will “focus entirely on solutions that enable agentic AI” based on proprietary models, custom infrastructure, and other technology.&nbsp;</p><ul><li>Amazon hired Adept CEO David Luan and four of his fellow co-founders, all Google or Open AI alumni. They joined Amazon’s artificial general intelligence (AGI) autonomy team, which reports to Amazon head scientist for AGI Rohit Pradad. The autonomy team will build agents that can automate software workflows.</li><li>Adept built agents that control applications on a user’s desktop in response to natural-language commands based on proprietary language and vision-language models. For example, a recruiter could use Adept’s&nbsp;<a href="https://www.adept.ai/blog/experiments?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">technology</a>&nbsp;to find promising job candidates on LinkedIn and import their profiles into a Salesforce database.&nbsp;</li><li>The startup found that the high cost of building foundation models was unsustainable without further fundraising. Although Adept had&nbsp;<a href="https://www.theinformation.com/articles/to-unlock-ai-spending-microsoft-openai-and-google-prep-agents?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">planned</a>&nbsp;to release a full-fledged agentic tool this year, it also&nbsp;<a href="https://www.theinformation.com/articles/ai-agent-startup-adept-has-talked-to-potential-buyers-including-meta?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">explored</a>&nbsp;an outright sale to several companies including Meta.</li><li>As of March 2023, Adept had&nbsp;<a href="https://techcrunch.com/2023/03/15/adept-a-startup-training-ai-to-use-existing-software-and-apis-raises-350m/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">raised</a>&nbsp;a total of $415 million at a valuation of more than $1 billion.</li></ul><p><strong>Behind the news:</strong>&nbsp;Amazon’s agreement with Adept is one of several moves to compete in AI for both businesses and consumers. In March, the company completed a $4 billion&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">investment</a>&nbsp;in Anthropic in exchange for a minority share in the startup. It’s reportedly developing new models and&nbsp;<a href="https://www.reuters.com/technology/amazon-mulls-5-10-monthly-price-tag-unprofitable-alexa-service-ai-revamp-2024-06-21/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">overhauling</a>&nbsp;its longstanding Alexa voice assistant.</p><p><strong>Why it matters:</strong>&nbsp;Luan and his team say they’re aiming to automate corporate software workflows, a potentially valuable and lucrative market. Although Amazon Web Services’ Bedrock platform already enables users to&nbsp;<a href="https://aws.amazon.com/bedrock/agents/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">build</a>&nbsp;AI agents, Adept’s talent may bring expanded agentic and interactive capabilities.<br /><strong>We’re thinking:</strong>&nbsp;AI agentic capabilities are&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">blossoming</a>, and Adept’s work is a notable example.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-10T143728.158.png" width="600" /></figure><h1 id="like-lora-but-for-pretraining">Like LoRA, But for Pretraining</h1><p>Low-rank adaptation (LoRA) reduces memory requirements when fine-tuning large language models, but it isn’t as conducive to pretraining. Researchers devised a method that achieves similar memory savings but works well for both fine-tuning and pretraining.</p><p><strong>What’s new:&nbsp;</strong>Jiawei Zhao and colleagues at California Institute of Technology, Meta, University of Texas at Austin, and Carnegie Mellon proposed&nbsp;<a href="https://arxiv.org/abs/2403.03507?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">Gradient Low-Rank Projection</a>&nbsp;(GaLore), an optimizer modification that saves memory during training by reducing the sizes of optimizer states. They used this approach to pretrain a 7B parameter transformer using a consumer-grade Nvidia RTX 4090 GPU.</p><p><strong>Key insight:&nbsp;</strong><a href="https://arxiv.org/abs/2106.09685?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">LoRA</a>&nbsp;saves memory during training by learning to approximate a change in the weight matrix of each layer in a neural network using the product of two smaller matrices. This approximation results in good performance when fine-tuning (though not quite as good as fine-tuning all weights) but worse performance when pretraining from a random initialization. The authors proved theoretically that updating weights according to an approximate gradient matrix — which reduces the memory required to store optimizer states — can yield the same performance as using the exact gradient matrix (at least for deep neural networks with ReLU activation functions and classification loss functions). Updating weights only once using an approximate gradient matrix is insufficient. However, updating weights repeatedly using gradient approximations&nbsp;that change with each training step (because the inputs change between training steps)&nbsp;achieves an effect similar to training weights in the usual way.&nbsp;</p><p><strong>How it works:</strong>&nbsp;GaLore approximates a network’s gradient matrix divided into layer-wise matrices. Given a layer’s gradient matrix G (size m x n), GaLore computes a smaller matrix P (size r x m). It uses PG, a smaller approximation of the gradient matrix (size r x n), to update optimizer states.&nbsp;To further save memory, it updates layers one at a time instead of all at once, following&nbsp;<a href="https://www.deeplearning.ai/the-batch/a-method-to-reduce-memory-needs-when-fine-tuning-ai-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">LOMO</a>.&nbsp;</p><ul><li>At each training step, for each layer, GaLore computed the layer-wise gradient matrix normally.</li><li>GaLore computed a smaller matrix P that, when multiplied by the gradient matrix, yielded a smaller matrix that approximated the weight update. GaLore computed P every 200 training steps (that is, it used the same P for 200 training steps at a time before computing a new P).</li><li>GaLore multiplied P by the gradient matrix to compute a smaller, approximate version of the gradient matrix. It used this smaller version to update the Adam optimizer’s internal states, requiring less memory to store the optimizer’s internal states. Then the optimizer used its internal states to update the smaller matrix.</li><li>GaLore multiplied P by the smaller matrix to produce a full-sized approximation of the gradient matrix. It used the full-sized approximation to update the current layer’s weights.&nbsp;</li></ul><p><strong>Results:&nbsp;</strong>The authors tested GaLore in both pretraining and fine-tuning scenarios.</p><ul><li>The authors compared GaLore to Adam while pretraining five transformer architectures from 60 million to 7 billion parameters to generate the next token in&nbsp;<a href="https://arxiv.org/abs/1910.10683v4?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">web text</a>. GaLore (set up to represent its internal states using 8-bit numbers) pretrained LLaMA 7B from scratch using 22GB of memory, while Adam (modified to represent its internal states using 8-bit numbers) needed 46GB of memory. After training on 19.7 billion tokens, LLaMA 7B achieved 14.65 perplexity, while Adam achieved 14.61 perplexity (a measure of how well a model reproduces validation examples, lower is better).</li><li>They also used GaLore to fine-tune RoBERTaBase on the multi-task benchmark&nbsp;<a href="https://aclanthology.org/W18-5446/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">GLUE</a>. GaLore needed 253MB of memory and achieved a score of 85.89 (averaging eight of 11 GLUE tasks), while LoRA needed 257MB of memory and reached 85.61.</li></ul><p><strong>Why it matters:</strong>&nbsp;LoRA’s ability to fine-tune large models using far less memory makes it a very popular fine-tuning method. GaLore is a theoretically motivated approach to memory-efficient training that’s good for both pretraining and fine-tuning.</p><p><strong>We're thinking:&nbsp;</strong>LoRA-style approximation has been unlocking data- and memory-efficient approaches in&nbsp;<a href="https://www.deeplearning.ai/the-batch/apple-unveils-ai-features-in-new-ios-and-macos-update-during-wwdc/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">a</a>&nbsp;<a href="https://arxiv.org/abs/2307.06949?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y9ba0htvZSD2ajaFWcpFgJljbQzfeuVTWVNa9U7pqeXVj2m06K5QuZlOgZMmPFAben4ru" rel="noopener">variety</a>&nbsp;of machine learning situations — an exciting trend as models grow and demand for compute resources intensifies.</p>
]]></content:encoded>
<pubDate>Wed, 10 Jul 2024 19:39:41 GMT</pubDate>
</item>
<item>
<title>OpenAI Blocks China, Tests for Human-Level Models, Music Industry Sues AI Startups, Model Merging Evolves</title>
<link>https://www.deeplearning.ai/the-batch/issue-256</link>
<guid>https://www.deeplearning.ai/the-batch/issue-256</guid>
<content:encoded><![CDATA[
<div> 学习习惯, 质量培训, AI模型, 知识产权, 模型合并
总结:<br /><br />总结:文章介绍了DeepLearning.AI团队坚持以学习者为中心的教育理念，强调提供高质量的人工智能培训；同时探讨了OpenAI限制中国等地区用户的API访问、Hugging Face更新开放大语言模型排行榜、音乐行业起诉AI音乐创作者、Sakana实验室自动化模型合并技术等最新动态。文章涵盖了学习习惯、质量培训、AI模型、知识产权和模型合并等关键话题。 <div>
<p>Dear friends,</p><p>As we reach the milestone of the 256th issue of The Batch, I’m reflecting on how AI has changed over the years and how society continues to change with it. As AI becomes more widely available, it’s clear that many people — developers and non-developers — will benefit from high-quality training to keep up with the changes and gain useful AI skills.&nbsp;</p><p>In my years of working in education, I’ve felt that the world has enough low-quality courses, newsletters, social media posts, and other forms of content. &nbsp;It’s possible to build a business churning out mediocre content in sufficient volume to attract a meaningful amount of attention, but I have no interest in doing that.&nbsp;</p><p>At DeepLearning.AI, our core philosophy is to&nbsp;<em>put learners first</em>. Our team obsesses about how to create quality training or other programs that benefit people who want to learn about AI. We have intense debates about what tools to teach, which examples to include, even which partners to work with, based on what we think is best for learners.</p><p>For example, I recall vividly how, when working on the&nbsp;<em>Machine Learning Specialization</em>, our team spent ages debating whether to use row or column matrices. Both sides showed up with deep analysis of the pros and cons, made Powerpoint presentations to argue their case, and we spent hours debating over what was better for learners in terms of both ease of picking up the concepts as well as subsequently being able to use these skills with third-party machine learning libraries.&nbsp;</p><p>We don’t release a course unless we think it’s a good use of a learner’s time and we’d be proud to recommend it to our own friends and family members. Quality, of course, can mean a lot of things. I expect what we do to be technically accurate, useful, up to date, clear, and time-efficient for learners. And, if possible, fun!&nbsp;</p><p>We don’t always get it right, but we scrutinize learner feedback (one of my most important weekly routines is to study a dashboard that summarizes learner ratings of our courses) and work to make sure our courses serve learners well. And yes, we have a large-language model powered application that reads learner reviews to flag important issues quickly.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--66--1.jpg" width="1200" /></figure><p>Earlier this year, we realized that some of the paid content we had launched was below our quality standard, and that I wouldn’t in good conscience recommend it to my friends or family members. Despite this content being profitable, we did what we felt was the right thing for learners. So we decided to retire that content and forgo the revenues, but we feel much better now for having done the right thing for learners.&nbsp;</p><p>When we teach courses with partners, we tell them our priorities are “learners first, partners second, ourselves last.” I’m grateful to the many wonderful companies and individuals that work with us to teach cutting-edge techniques, and given an opportunity we try to support our partners’ goals as well. But we never prioritize the interest of our educational partners over that of learners. Fortunately, our partners are onboard with this as well. We have a common goal to serve learners. Without their help, it would be difficult to teach many of the topics we do with high-quality content.&nbsp;</p><p>Quite a few companies have tried to offer to pay us to teach a course with them, but we’ve always said no. We work only with the companies that we think help us serve learners best, and are not interested in being paid to teach lower quality courses.</p><p>One reason I obsess about building quality training materials is that I think learning must be a habit. Learning a little every week is important to get through the volume of learning we all need, and additionally to keep up with changing technology. High-quality training that’s also fun supports a healthy learning habit!&nbsp;</p><p>Fun fact: In addition to taking online courses, I also read a lot. Recently I noticed that my digital reading app says I’ve been on a reading streak for 170 weeks. I’ve used the app for many years, but apparently I had broken and restarted my streak 170 weeks ago. What happened then? That was the week that my son was born,&nbsp;<a href="https://www.deeplearning.ai/the-batch/coursera-goes-public/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Coursera became a public company</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-key-to-longevity/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">my grandfather</a>&nbsp;died. While my life has had disruptions since then, I was happy to find that it takes a disruption of this magnitude to make me pause my learning habit for a week.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-ai-fund-and-deeplearningai">A MESSAGE FROM AI FUND AND&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://us06web.zoom.us/webinar/register/3017198521323/WN_cYpQlgFdRDeXBy61YuiO7w?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="540" src="https://dl-staging-website.ghost.io/content/images/2024/07/AIF_Event-Templates--18-.png" width="960" /></a></figure><p>Join us for a Q&amp;A webinar on July 11, 2024, at 11:00 AM Pacific Time. Andrew Ng and Roy Bahat will discuss business trends and strategies to integrate AI into organizations.&nbsp;<a href="https://us06web.zoom.us/webinar/register/3017198521323/WN_cYpQlgFdRDeXBy61YuiO7w?ref=dl-staging-website.ghost.io" rel="noreferrer">Register now</a>&nbsp;</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-03T153037.104.gif" width="1200" /></figure><h1 id="openai-blocks-china-and-elsewhere">OpenAI Blocks China and Elsewhere</h1><p>OpenAI will stop serving users in China and other nations of concern to the U.S. government as soon as next week.</p><p><strong>What’s new:</strong>&nbsp;Open AI notified users in China they would lose API access on July 9,&nbsp;<em>Reuters</em>&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/openai-cut-access-tools-developers-china-other-regions-chinese-state-media-says-2024-06-25/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">reported</a>. The move affects users in countries where the company doesn’t support access to its services officially (which include Cuba, Iran, Russia, North Korea, Syria, Venezuela, and others), but where it appears to have been serving API calls anyway.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Previously OpenAI blocked requests from outside&nbsp;<a href="https://platform.openai.com/docs/supported-countries?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">supported countries</a>&nbsp;if it detected a virtual private network or other method to circumvent geographic restrictions, but it had enforced such limits lightly&nbsp;<a href="https://www.stcn.com/article/detail/1240148.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">according to</a>&nbsp;<em>Securities Times</em>. The email warning started a race among AI companies in China to attract cast-off OpenAI users.</p><ul><li>Baidu said it would give former OpenAI users 50 million free tokens for its&nbsp;<a href="https://www.reuters.com/technology/artificial-intelligence/baidu-launches-upgraded-ai-model-says-user-base-hits-300-mln-2024-06-28/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Ernie</a>&nbsp;model, additional tokens equivalent to a customer’s OpenAI credits, and unlimited access to older models like&nbsp;<a href="http://research.baidu.com/Blog/index-view?id=165&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Wenxin</a>. Alibaba Cloud offered 22 million free tokens for Qwen-plus.&nbsp;<a href="https://open.bigmodel.cn/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Zhipu AI</a>, a lesser-known startup, promised 50 million free tokens for its GPT-4 competitor&nbsp;<a href="https://arxiv.org/abs/2406.12793?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">GLM-4</a>&nbsp;and 100 million tokens for the lower-cost GLM-4 Air.</li><li>Microsoft&nbsp;<a href="https://www.scmp.com/tech/big-tech/article/3268233/microsoft-maintains-ai-services-hong-kong-openai-curbs-api-access-china?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">announced</a>&nbsp;that customers in Hong Kong would be able to address OpenAI models via Azure, which has served the models there despite lack of official support by OpenAI. For the rest of China, Microsoft posted on WeChat a&nbsp;<a href="https://mp.weixin.qq.com/s?__biz=MzA3MTA0ODYyOA%3D%3D&amp;mid=2651435559&amp;idx=1&amp;sn=9a79957563b140a2ef66cc092ded6f41&amp;chksm=84ce9efcb3b917ea3a4ccdd7d562ae4af729dcf51f538a3ae0a02ff4f35799254db4aa075a81&amp;mpshare=1&amp;scene=1&amp;srcid=06263qGLSaYOd75H5Ut3mbDy&amp;sharer_shareinfo=1162dec359fd32b1e0f9ab27bca64d29&amp;sharer_shareinfo_first=1162dec359fd32b1e0f9ab27bca64d29&amp;exportkey=n_ChQIAhIQu31uFQMTmt32Lmlng1rskRKfAgIE97dBBAEAAAAAAEKHDC3c4zIAAAAOpnltbLcz9gKNyK89dVj02BUGLGQW6qhJxWwjTzJSaQtJPMCHTG1%2BZ6KELT9TQemKJjC8gpUGfomNIndMiy96lThhvVsiRrH1r%2FLMdfwTXH1iucLZpU1yxw5ZayJcG27r7fxMruMVgr%2BX4ECa6T%2BvtSYD1nrs9UrJG1g3XzazMhwv4MMKAK5LlxIXCh%2F92nSH11CAmSUPOBb9wIR2FY703EhwgIrMyoKmIT6Jw5vLeszRZhtVUUek9cvbIJzV9ebGNIrEIDPUig39jor6GLojmQfaDH8U0CpTwM%2FXe%2FtxmtwnxDa2eOUi7%2BBmBBoYemMvrGawuLIQvnnaFv6rzukCEmEBvF2nzx%2FZ&amp;acctmode=1&amp;pass_ticket=pMFyhjLD%2BzeFaSyQmWmbCVUa5OdfdTucMEjXf1S6W0wIuUG2iyTKNMer14boYLTT&amp;wx_header=0&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_#rd" rel="noopener">guide</a>&nbsp;to migrating from Open AI’s API to equivalent service by Microsoft’s Chinese partner 21Vianet.</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI’s crackdown on non-supported countries comes amid rising technological rivalry between the governments of the United States and China. The U.S. has taken several steps to try to curb China’s access to U.S.-built AI hardware and software, and some U.S. AI companies such as Anthropic and Google don’t operate in China. The Commerce Department&nbsp;<a href="https://www.reuters.com/technology/us-eyes-curbs-chinas-access-ai-software-behind-apps-like-chatgpt-2024-05-08/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">plans</a>&nbsp;to attempt to restrict China’s access to the most advanced AI models built by U.S. developers such as OpenAI. The Treasury Department&nbsp;<a href="https://home.treasury.gov/news/press-releases/jy2421?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">issued</a>&nbsp;draft restrictions on U.S. investments in AI companies based in China, Hong Kong, and Macau. Moreover, the U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">imposed</a>&nbsp;controls on exports of advanced GPUs to Chinese customers.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Many startups in China and elsewhere relied on OpenAI’s models. However, China’s development of AI models is already quite advanced. For example, Alibaba’s Qwen2, which offers open weights, currently tops Hugging Face’s Open LLM Leaderboard (see below), ahead of Meta's Llama 3.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Efforts to restrict U.S. AI technology can go only so far. At this point, the U.S. seems to have at most a six-month lead over China. OpenAI’s move encourages other nations to make sure they have robust, homegrown models or access to open source alternatives.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-03T153334.258.png" width="600" /></figure><h1 id="challenging-human-level-models">Challenging Human-Level Models</h1><p>An influential ranking of open models revamped its criteria, as large language models approach human-level performance on popular tests.</p><p><strong>What’s new:</strong>&nbsp;Hugging Face&nbsp;<a href="https://huggingface.co/spaces/open-llm-leaderboard/blog?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">overhauled</a>&nbsp;its Open LLM Leaderboard, reshuffling its assessments of the smartest contenders. The&nbsp;<a href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">revised leaderboard</a>&nbsp;is based on new benchmarks designed to be more challenging and harder to game.</p><p><strong>Intelligence reordered:</strong>&nbsp;The new Open LLM Leaderboard paints a very different picture than the earlier version: Some models moved up or down as many as 59 places. In the debut rankings, Qwen2’s recently&nbsp;<a href="https://www.deeplearning.ai/the-batch/new-models-from-nvidia-alibaba-and-stability-ai-expand-open-options/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">released</a>&nbsp;72-billion-parameter, instruction-tuned version topped the list with an average score of 43.02 out of 100. Meta’s Llama 3-70B-Instruct came in second with 36.67.<br /><br /><strong>Addressing saturation and contamination:</strong>&nbsp;Launched last year, the&nbsp;<a href="https://huggingface.co/spaces/open-llm-leaderboard-old/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">earlier version</a>&nbsp;(which is still operating) ranks open large language models according to an aggregate of scores on six popular benchmarks. However, in the intervening months, the best models approached human-level scores, partly due to technical improvements and partly because the test answers leaked into the models’ training sets. The revised leaderboard replaces the old tests and corrects earlier flaws and errors:</p><ul><li><a href="https://arxiv.org/abs/2406.01574?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">MMLU-Pro</a>&nbsp;updates the MMLU set of multiple-choice questions. MMLU-Pro offers 10 choices, while the earlier version offered four. The authors eliminated questions deemed too easy and made many others more difficult by, for instance, adding misleading answers. The results correlate well with human preferences as determined by the&nbsp;<a href="https://www.deeplearning.ai/the-batch/chatbot-arena-compares-chatbots-side-by-side?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">LMSYS Chatbot Arena</a>.</li><li><a href="https://arxiv.org/abs/2311.12022?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">GPQA</a>&nbsp;includes PhD-level questions in biology, physics, and chemistry. It’s intended to be very difficult for non-experts even with access to web search.</li><li><a href="https://arxiv.org/abs/2310.16049?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">MuSR</a>&nbsp;asks models to answer lengthy, complex word problems that test multi-step reasoning. To do well, a model must solve murder mysteries, assign characters to perform tasks, and identify the locations of objects in a narrative.</li><li><a href="https://arxiv.org/abs/2103.03874?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">MATH lvl 5</a>&nbsp;includes multi-step math problems. The dataset covers five levels based on difficulty, but the benchmark includes only the hardest level.</li><li><a href="https://arxiv.org/abs/2311.07911?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">IFEval</a>&nbsp;asks models to respond to prompts that include specific instructions like “no capital letters are allowed” and “your response must have three sections.”</li><li><a href="https://arxiv.org/abs/2210.09261?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">BIG-Bench Hard</a>&nbsp;covers 23 diverse, complex tasks, such as understanding boolean expressions, detecting sarcasm, and determining shapes from graphics vectors. Examples are drawn from the most formidable problems in BIG-Bench. Like MMLU-PRo, BIG-Bench Hard scores correlate well with those of the LMSYS Chatbot Arena.</li></ul><p><strong>Behind the news:</strong>&nbsp;Leakage of training examples into test sets is a rising challenge to evaluating model performance. While Hugging Face relies on open benchmarks, other groups have attempted to address the issue by limiting access to the test questions or changing them regularly. Vals.AI, an independent model testing company,&nbsp;<a href="https://www.deeplearning.ai/the-batch/vals-ai-evaluates-large-language-models-on-industry-specific-tasks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">developed</a>&nbsp;proprietary industry-specific tests for finance and law. Data consultancy Scale AI&nbsp;<a href="https://www.deeplearning.ai/the-batch/private-benchmarks-for-fairer-tests/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">introduced</a>&nbsp;its own leaderboards, measuring models on proprietary tests in natural languages, math, and coding.<br /><br /><strong>Why it matters:</strong>&nbsp;Two million unique visitors browsed the Open LLM Leaderboard in the past year, and over 300,000 Hugging Face community members use and collaborate on it each month. Developers trust its scores, both individually and in aggregate, to decide which models to use and to judge the progress of their own efforts based on open models.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;As its name implies, the Open LLM leaderboard measures performance in natural language skills. Hugging Face also maintains an&nbsp;<a href="https://huggingface.co/spaces/opencompass/open_vlm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Open VLM Leaderboard</a>, which tests vision-language skills.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed--67-.jpg" width="1200" /></figure><h1 id="music-industry-sues-ai-startups">Music Industry Sues AI Startups</h1><p>A smoldering conflict between the music industry and AI companies exploded when major recording companies sued up-and-coming AI music makers.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Sony Music, Universal Music Group (UMG), and Warner Music — the world’s three largest music companies — and a trade organization, Recording Industry Association of America (RIAA),&nbsp;<a href="https://www.riaa.com/record-companies-bring-landmark-cases-for-responsible-ai-againstsuno-and-udio-in-boston-and-new-york-federal-courts-respectively/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">sued</a>&nbsp;Suno and Udio, which offer web-based music generators, for alleged copyright violations.<br /><br /><strong>How it works:</strong>&nbsp;The music powers filed separate lawsuits against&nbsp;<a href="https://www.riaa.com/wp-content/uploads/2024/06/Suno-complaint-file-stamped20.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Suno</a>&nbsp;and&nbsp;<a href="https://www.riaa.com/wp-content/uploads/2024/06/Udio-Complaint-6.24.241.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Udio</a>&nbsp;in U.S. federal courts. The plaintiffs allege that the startups used copyrighted songs owned by RIAA members as training data, in the process making unauthorized copies without receiving permission or compensating the owners. They seek damages of at least $150,000 per song and cessation of further AI training on their catalogs.</p><ul><li>The recording companies argue that training AI models on songs involves making a number of unauthorized copies of the original music, first by scraping the audio files, then cleaning, converting file formats, dividing songs into subunits, and fine-tuning.</li><li>To show that the startups had trained their models on copyrighted music, the recording companies presented&nbsp;<a href="https://www.riaa.com/wp-content/uploads/2024/06/AITrainedonCopyrighted.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">examples</a>&nbsp;(most of which are no longer available) in which they prompted a model to generate a copyrighted work. For instance, given the prompt, “m a r i a h c a r e y, contemporary r&amp;b, holiday, Grammy Award-winning American singer-songwriter, remarkable vocal range,” Udio allegedly generated a facsimile of “All I Want for Christmas is You” by Mariah Carey. Other prompts that caused a model to generate an existing song included the song’s lyrics but not the artist’s name.</li><li>The lawsuits claim that generated music directly competes with original music because Suno and Udio charge for their services and generated music can be used in lieu of copyrighted music. Furthermore, they claim the models’ outputs are not sufficiently transformative of copyrighted works for the copying to be considered fair use.&nbsp;</li><li>Udio did not address the specific allegations. In a blog post, it&nbsp;<a href="https://www.udio.com/blog/ai-and-the-future-of-music?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">compared</a>&nbsp;its models to music students learning and taking inspiration from accomplished musicians. Suno’s CEO&nbsp;<a href="https://www.billboard.com/pro/ai-music-lawsuit-suno-udio-respond-major-labels/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">told</a>&nbsp;<em>Billboard</em>, a music-industry trade magazine, that the company’s technology is transformative rather than copying.</li></ul><p><strong>Behind the news:</strong>&nbsp;Although major music companies have a history of&nbsp;<a href="https://www.deeplearning.ai/the-batch/universal-music-group-targets-ai-generated-music/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">taking</a>&nbsp;<a href="https://www.deeplearning.ai/the-batch/sony-music-accuses-ai-developers-of-copyright-violations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">action</a>&nbsp;against AI companies, music streamers, and musicians who distributed generated likenesses of music they owned, they’re also working with AI startups on their own terms. For instance, UMG is&nbsp;<a href="https://www.rollingstone.com/music/music-news/umg-startsai-voice-clone-partnership-with-soundlabs-1235041808/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">collaborating</a>&nbsp;with voice-cloning startup Soundlabs to create authorized synthetic voices of UMG artists. UMG, Sony, and Warner are also&nbsp;<a href="https://www.ft.com/content/e2d9472d-32e0-43f5-8109-efb753fac330?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">negotiating</a>&nbsp;with YouTube to license music for a song generator to be launched this year.</p><p><strong>Why it matters:</strong>&nbsp;As in similar lawsuits that involve text generators, the outcome of these actions could have an important impact on AI developers and users alike. Copyright law in the United States (and many other countries) does not address whether training AI models on copyrighted materials is a use that requires permission from copyright owners. In lieu of further legislation that answers the question, courts will decide. Assuming these cases go to trial, a verdict in favor of Suno or Udio would set a precedent that copyright doesn’t necessarily protect copyrighted works from AI training. Conversely, a verdict in favor of the music industry could restrict the use of copyrighted works in training, impeding a range of AI technologies that historically have been trained on data from the open internet.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Copyright aims to prohibit unauthorized copying of intellectual property, but routine copying of data is built into the infrastructure of digital communications, never mind training AI systems. A web browser makes a temporary copy of every web page it displays, and web search engines typically copy the page they’ve indexed. It’s high time to&nbsp;<a href="https://www.deeplearning.ai/the-batch/time-to-update-copyright-for-generative-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">revise</a>&nbsp;copyright law for the AI era in ways that create the most value for the most people.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/07/unnamed---2024-07-03T154036.152.gif" width="600" /></figure><h1 id="model-merging-evolves">Model Merging Evolves</h1><p>The technique of model merging combines separate models into a single, more capable model without further training, but it requires expertise and manual effort. Researchers automated the process.</p><p><strong>What's new:</strong>&nbsp;Takuya Akiba and colleagues at Sakana, a research lab based in Tokyo, devised an automated&nbsp;<a href="https://arxiv.org/abs/2403.13187?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">method for merging models</a>. It combines models trained for general tasks to produce models that perform well at the intersection of those tasks.</p><p><strong>Key insight:</strong>&nbsp;Researchers have demonstrated various&nbsp;<a href="https://arxiv.org/abs/2309.15698?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">approaches</a>&nbsp;to model merging. Earlier work showed that vision models of the same architecture can be combined with good results simply by&nbsp;<a href="https://www.deeplearning.ai/the-batch/ensemble-models-simplified/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">averaging their corresponding weights</a>, although subsequent studies revealed limitations in this approach. (When models have different architectures, averaging weights can combine parts they have in common.) An alternative is to&nbsp;<a href="https://arxiv.org/pdf/2312.15166?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">stack layers</a>&nbsp;drawn from different models. These methods can be varied and integrated to offer a wide variety of possible model combinations. An automated process that tries various combinations at random, finds the best performers among the resulting models, and recombines them at random can discover the high-performance combinations of these approaches without relying on intuition and experience.</p><p><strong>How it works:</strong>&nbsp;The authors aimed to build a large language model that would solve problems in Japanese. They used the algorithm known as&nbsp;<a href="https://www.semanticscholar.org/paper/The-CMA-Evolution-Strategy%3A-A-Comparing-Review-Hansen/95a1f9e009d16e141448fbfea33353b02e1e9335?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Covariance Matrix Adaptation Evolution Strategy</a>&nbsp;(CMA-ES) to merge the Japanese-language LLM&nbsp;<a href="https://hf.co/augmxnt/shisa-gamma-7b-v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Shisa-Gamma</a>&nbsp;and two math-specific, English-language LLMs:&nbsp;<a href="https://gair-nlp.github.io/abel/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Abel</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2308.09583?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">WizardMath</a>. All three models were fine-tuned from&nbsp;<a href="https://arxiv.org/abs/2310.06825?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Mistral 7B</a>, which was pretrained on text from the web.</p><ul><li>The authors produced dozens of 10 billion-parameter models by merging the three initial ones. They merged the models by (i) combining weights of two or more layers from each model according to&nbsp;<a href="https://papers.nips.cc/paper_files/paper/2023/hash/1644c9af28ab7916874f6fd6228a9bcf-Abstract-Conference.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">TIES-Merging</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2311.03099?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">DARE</a>&nbsp;and (ii) stacking either the combined layers or the original ones.&nbsp;</li><li>They evaluated the merged models on 1,069 examples translated into Japanese from&nbsp;<a href="https://arxiv.org/abs/2110.14168?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">GSM8k</a>, which contains grade-school word problems.&nbsp;</li><li>They saved the models that performed best and repeated the process more than 100 times, merging the saved models and measuring their performance. The final model was the one with the highest accuracy on the translated GSM8k examples.</li></ul><p><strong>Results:</strong>&nbsp;The authors evaluated their model on the Japanese subset of&nbsp;<a href="https://arxiv.org/abs/2210.03057?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_HmZry9hzNDlU49D59qaA8lrpSNKuFGuqNQrLiCO8EcEC8iLsUQUWZCPLhTrZoxL3ctUX_" rel="noopener">Multilingual Grade School Math</a>&nbsp;(MGSM). The merged model achieved 55.2 percent accuracy. Among the source models, Abel achieved 30.0 percent accuracy, WizardMath 18.4 percent accuracy, and Shisa Gamma 9.6 percent accuracy. The merged model’s performance fell between that of GPT-3.5 (50.4 percent accuracy) and GPT-4 (78.8 percent accuracy), which presumably are an order of magnitude larger.</p><p><strong>Why it matters:</strong>&nbsp;Combining existing models offers a way to take advantage of their strengths without further training. It can be especially valuable in building models at the intersection between tasks, such as understanding Japanese language and solving math problems.</p><p><strong>We're thinking:</strong>&nbsp;In addition to building new models, how can we make best use of the ones we already have? Merging them may be an efficient option.</p>
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 20:43:25 GMT</pubDate>
</item>
<item>
<title>AI Monopolies, Ancestor Avatars, Benchmarks for Agentic Behavior, Chatbot for Minority Languages</title>
<link>https://www.deeplearning.ai/the-batch/issue-255</link>
<guid>https://www.deeplearning.ai/the-batch/issue-255</guid>
<content:encoded><![CDATA[
<div> 音乐制作AI，侵权诉讼，OpenAI支持，AI作为工具，AI公司创造价值，反垄断调查，南亚市场AI竞争，虚拟亡灵avatars，计划和工具使用基准

总结:<br /><br />本文讨论了音乐制作AI在侵权诉讼中的问题，提到了OpenAI的支持立场。同时探讨了AI作为工具的立场，以及人们对于AI的不同看法。文章还提及了反垄断调查，关注于微软、Nvidia和OpenAI公司。另外，介绍了针对南亚市场的多语言AI模型SUTRA和虚拟亡灵avatars技术。最后，分享了关于工具使用和计划的基准测试。 <div>
<p>Dear friends,</p><p>On Monday, a number of large music labels&nbsp;<a href="https://www.nytimes.com/2024/06/25/arts/music/record-labels-ai-lawsuit-sony-universal-warner.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">sued</a>&nbsp;AI music makers Suno and Udio for copyright infringement. Their lawsuit echoes&nbsp;<em>The New York Times</em>’&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-new-york-times-versus-openai-and-microsoft/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">lawsuit</a>&nbsp;against OpenAI in December. The question of what’s fair when it comes to AI software remains a difficult one.&nbsp;</p><p>I&nbsp;<a href="https://x.com/AndrewYNg/status/1744433663969022090?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">spoke</a>&nbsp;out in favor of OpenAI’s side in the earlier lawsuit. Humans can learn from online articles and use what they learn to produce novel works, so I’d like to be allowed to use AI to do so. Some people criticized my view as making an unjustifiable equivalence between humans and AI. This made me realize that people have at least two views of AI: I view AI as a tool we can use and direct to our own purposes, while some people see it as akin to a separate species, distinct from us, with its own goals and desires.</p><p>If I’m allowed to build a house, I want to be allowed to use a hammer, saw, drill, or any other tool that might get the job done efficiently. If I’m allowed to read a webpage, I’d like to be allowed to read it with any web browser, and perhaps even have the browser modify the page’s formatting for accessibility. More generally, if we agree that humans are allowed to do certain things — such as read and synthesize information on the web — then my inclination is to let humans direct AI to automate this task.&nbsp;</p><p>In contrast to this view of AI as a tool, if someone thinks humans and AI are akin to separate species, they’ll frame the question differently. Few people today think all species should have identical rights. If a mosquito annoys a human, the mosquito can be evicted (or worse). In this view, there’s no reason to think that, just because humans are allowed to do something, AI should be allowed to do it as well.&nbsp;</p><p>To be clear, just as humans aren’t allowed to reproduce large parts of copyrighted works verbatim (or nearly verbatim) without permission, AI shouldn’t be allowed to do so either. The lawsuit against Suno and Udio points out that, when prompted in a particular way, these services can nearly reproduce pieces of copyrighted music.</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--64--1.jpg" width="1200" /></figure><p>But here, too, there are complex issues. If someone were to use a public cloud to distribute online content in violation of copyright, typically the person who did that would be at fault, not the cloud company (so long as the company took reasonable precautions and didn’t enable copyright infringement deliberately). The plaintiffs in the lawsuit against Suno and Udio managed to write prompts that caused the systems to reproduce copyrighted work. But is this like someone managing to get a public cloud to scrape and distribute content in a way that violates copyright? Or is this — as OpenAI&nbsp;<a href="https://openai.com/index/openai-and-journalism/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">said</a>&nbsp;— a rare bug that AI companies are working to eliminate?&nbsp;(Disclaimer: I’m not a lawyer and I’m not giving legal advice.)</p><p>Humans and software systems use very different mechanisms for processing information. So in terms of what humans can do — and thus what I’d like to be allowed to use software to help me do — it’s helpful to consider the inputs and outputs. Specifically, if I’m allowed to listen to a lot of music and then compose a novel piece of music, I would like to be allowed to use AI to implement a similar input-to-output mapping. The process for implementing this mapping may be training a neural network on music that’s legally published on the open internet for people to enjoy without encumbrances.</p><p>To acknowledge a weakness of my argument, just because humans are allowed to emit a few pounds of carbon dioxide per day simply by breathing doesn’t mean we should allow machines to emit massively more carbon dioxide without restrictions. Scale can change the nature of an act.&nbsp;</p><p>When I was a high-school student in an internship job, I spent numerous hours photocopying, and I remember wishing I could automate that repetitive work. Humans do lots of valuable work, and AI, used as a tool to automate what we do, will create lots of value. I hope we can empower people to use tools to automate activities they’re allowed to do, and erect barriers to this only in extraordinary circumstances, when we have clear evidence that it creates more harm than benefit to society.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/carbon-aware-computing-for-genai-developers?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-25T085213.553.png" width="1680" /></a></figure><p>Learn to reduce the carbon footprints of your AI projects in “Carbon Aware Computing for GenAI Developers,” a new course built in collaboration with Google Cloud. Perform model training and inference jobs with cleaner, low-carbon energy and make your AI development greener!&nbsp;<a href="https://www.deeplearning.ai/short-courses/carbon-aware-computing-for-genai-developers?ref=dl-staging-website.ghost.io" rel="noreferrer">Join today</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-26T151248.547.png" width="1200" /></figure><h1 id="us-to-probe-ai-monopoly-concerns">U.S. to Probe AI Monopoly Concerns</h1><p>U.S. antitrust regulators are preparing to investigate a trio of AI giants.</p><p><strong>What’s new:</strong>&nbsp;Two government agencies responsible for enforcing United States anti-monopoly laws agreed to investigate Microsoft, Nvidia, and OpenAI,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">reported</a>.&nbsp;</p><p><strong>How it works:&nbsp;</strong>The Department of Justice (DOJ) will investigate Nvidia, which dominates the market for chips that train and run neural networks. The Federal Trade Commission (FTC) will probe Microsoft and its relationship with OpenAI, which together control the distribution of OpenAI’s popular GPT-series models. In February, FTC chair Lina Khan&nbsp;<a href="https://hls.harvard.edu/today/ftc-chair-lina-khan-discusses-ai-antitrust-concerns-at-harvard-law-school/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">said</a>&nbsp;the agency would look for possible anti-competitive forces in the AI market.&nbsp;</p><ul><li>The DOJ is concerned that Nvidia may use unfair practices to maintain its market dominance. They may look into Nvidia’s CUDA software, which strengthens users’ reliance on its chips. They may also explore&nbsp;<a href="https://www.wsj.com/tech/ai/nvidias-french-offices-raided-in-cloud-computing-competition-inquiry-97c094ea?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">claims</a>&nbsp;raised by French authorities that Nvidia favors some cloud computing firms over others.</li><li>The FTC worries that the partnership between OpenAI and Microsoft, which owns 49 percent of OpenAI and&nbsp;<a href="https://www.theverge.com/2023/11/29/23981848/sam-altman-back-open-ai-ceo-microsoft-board?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">holds</a>&nbsp;a non-voting seat on OpenAI’s board of directors, may work to limit consumer choice. Microsoft’s April&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-pays-inflection-ai-650-million-hires-most-of-its-staff/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">agreement</a>&nbsp;with Inflection AI to hire most of its staff in return for a $650 million payment, which resembled an acquisition but left Inflection’s corporate structure intact, raised suspicions that the deal had been structured to avoid automatic antitrust scrutiny.&nbsp;</li><li>The FTC previously investigated investments in Anthropic by&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Amazon</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/anthropic-secures-2-billion-investment-from-google-weeks-after-amazon-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Google</a>&nbsp;as well as whether OpenAI&nbsp;<a href="https://www.washingtonpost.com/technology/2023/07/13/ftc-openai-chatgpt-sam-altman-lina-khan/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">gathered</a>&nbsp;training data in ways that harmed consumers.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;Government attention to top AI companies is rising worldwide. Microsoft’s partnership with OpenAI&nbsp;<a href="https://www.reuters.com/technology/microsofts-openai-investment-risks-eu-merger-probe-eu-regulators-say-2024-01-09/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">faces</a>&nbsp;additional scrutiny by European Union regulators, who are probing whether the relationship violates EU regulations that govern corporate mergers. U.K. regulators are&nbsp;<a href="https://apnews.com/article/microsoft-amazon-anthropic-ai-investment-scrutiny-a52f6409fa6ee9b335ab6801b8e84cde?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">investigating</a>&nbsp;Amazon’s relationship with Anthropic and Microsoft’s relationship with Mistral and Inflection AI. Last year, French regulators&nbsp;<a href="https://www.wsj.com/tech/ai/nvidias-french-offices-raided-in-cloud-computing-competition-inquiry-97c094ea?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">raided</a>&nbsp;an Nvidia office over suspected anti-competitive practices. In 2022, Nvidia&nbsp;<a href="https://edition.cnn.com/2022/02/08/tech/nvidia-arm-deal-softbank-intl-hnk/index.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">withdrew</a>&nbsp;a bid to acquire chip designer Arm Holdings after the proposal attracted international regulatory scrutiny including an FTC lawsuit.</p><p><strong>Why it matters:</strong>&nbsp;Microsoft, Nvidia, and OpenAI have put tens of billions of dollars each into the AI market, and lawsuits, settlements, judgments, or other interventions could shape the fate of those investments. The FTC and DOJ similarly&nbsp;<a href="https://www.reuters.com/article/idUSKCN1T42JF/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">divided</a>&nbsp;their jurisdictions in 2019, resulting in investigations into — and ongoing lawsuits against — Amazon, Apple, Google, and Meta for alleged anti-competitive practices in search, social media, and consumer electronics. Their inquiries into the AI market could have similar impacts.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Governments must limit unfair corporate behavior without stifling legitimate activities. Recently, in the U.S. and Europe, the pendulum has swung toward overly aggressive enforcement. For example, government opposition to Adobe’s purchase of Figma had a chilling effect on acquisitions that seems likely to hurt startups. The UK blocked Meta’s acquisition of Giphy, which didn’t seem especially anticompetitive. We appreciate antitrust regulators’ efforts to create a level playing field, and we hope they’ll take a balanced approach to antitrust.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-26T152037.544.gif" width="1200" /></figure><h1 id="chatbot-for-minority-languages">Chatbot for Minority Languages</h1><p>An AI startup that aims to crack markets in southern Asia launched a multilingual competitor to GPT-4.</p><p><strong>What’s new:</strong>&nbsp;The company known as Two AI&nbsp;<a href="https://www.two.ai/sutra?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">offers</a>&nbsp;SUTRA, a low-cost language model built to be proficient in more than 30 languages, including underserved South Asian languages like Gujarati, Marathi, Tamil, and Telugu. The company also launched&nbsp;<a href="https://chat.two.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">ChatSUTRA</a>, a free-to-use web chatbot based on the model.</p><p><strong>How it works:</strong>&nbsp;SUTRA comprises two mixture-of-experts transformers: a concept model and an encoder-decoder for translation. A&nbsp;<a href="https://arxiv.org/abs/2405.06694?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">paper</a>&nbsp;includes some technical details, but certain details and a description of how the system fits together are either absent or ambiguous.&nbsp;</p><ul><li>The concept model learned to predict the next token. The training dataset included publicly available datasets in a small number of languages for which abundant data is available, including English.</li><li>Concurrently, the translation model learned to translate 100 million human- and machine-translated conversations among many languages. This model learned to map concepts to similar embeddings across all languages in the dataset.&nbsp;</li><li>The authors combined the two models, so the translation model’s encoder fed the concept model, which in turn fed the translation model’s decoder, and further trained them together. More explicitly, during this stage of training and at inference, the translation model’s encoder receives text and produces an initial embedding. The concept model processes the embedding and delivers its output to the translation model’s decoder, which produces the resulting text.&nbsp;</li><li>SUTRA is available via an&nbsp;<a href="https://docs.two.ai/aboutsutra?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">API</a>&nbsp;in versions that are designated Pro (highest-performing), Light (lowest-latency), and Online (internet-connected). SUTRA-Pro and SUTRA-Online cost $1 per 1 million tokens for input and output. SUTRA-Light costs $0.75 per 1 million tokens.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;On&nbsp;<a href="https://huggingface.co/datasets/alexandrainst/m_mmlu?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">multilingual MMLU</a>&nbsp;(a machine-translated version of multiple-choice questions that cover a wide variety of disciplines), SUTRA outperformed GPT-4 in four of the 11 languages for which the developer reported the results: Gujarati, Marathi, Tamil, and Telugu. Moreover, SUTRA’s tokenizer is highly efficient, making the model fast and cost-effective. In key languages, it compares favorably to the tokenizer used with GPT-3.5 and GPT-4, and even narrowly outperforms GPT-4o’s improved tokenizer, according to Two AI’s tokenizer comparison&nbsp;<a href="https://huggingface.co/spaces/TWO/sutra-tokenizer-comparison?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">space</a>&nbsp;on HuggingFace. In languages such as Hindi and Korean that are written in non-Latin scripts and for which GPT-4 performs better on MMLU, SUTRA’s tokenizer generates less than half as many tokens as the one used with GPT-3.5 and GPT-4, and slightly fewer than GPT-4o’s tokenizer.<br /><br /><strong>Yes, but:</strong>&nbsp;Multilingual MMLU tests only 11 of SUTRA’s 33 languages, making it difficult to fully evaluate the model’s multilingual performance.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;Two AI was founded in 2021 by Pranav Mistry, former president and CEO of Samsung Technology &amp; Advanced Research Labs. The startup has offices in California, South Korea, and India. In 2022, it raised $20 million in seed funding from Indian telecommunications firm Jio and South Korean internet firm Naver. Mistry aims to focus on predominantly non-English-speaking markets such as India, South Korea, Japan, and the Middle East, he&nbsp;<a href="https://analyticsindiamag.com/jio-backed-startup-two-ai-unveils-chatsutra-indias-answer-to-chatgpt/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">told</a>&nbsp;<em>Analytics India</em>.</p><p><strong>Why it matters:</strong>&nbsp;Many top models work in a variety of languages, but from a practical standpoint, multilingual models remain a frontier in natural language processing. Although SUTRA doesn’t match GPT-4 in all the languages reported, its low price and comparatively high performance may make it appealing in South Asian markets, especially rural areas where people are less likely to speak English. The languages in which SUTRA excels are spoken by tens of millions of people, and they’re the most widely spoken languages in their respective regions. Users in these places have yet to experience GPT-4-level performance in their native tongues.<br /><br /><strong>We’re thinking:</strong>&nbsp;Can a newcomer like Two AI compete with OpenAI? If SUTRA continues to improve, or if it can maintain its cost-effective service, it may yet carve out a niche.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--65-.jpg" width="1200" /></figure><h1 id="conversing-with-the-departed">Conversing With the Departed</h1><p>Advances in video generation have spawned a market for lifelike avatars of deceased loved ones.</p><p><strong>What’s new:&nbsp;</strong>Several companies in China produce interactive videos that enable customers to chat with animated likenesses of dead friends and relatives,&nbsp;<em>MIT Technology Review</em>&nbsp;<a href="https://www.technologyreview.com/2024/05/07/1092116/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">reported</a>.&nbsp;</p><p><strong>How it works:&nbsp;</strong><a href="https://www.france24.com/en/live-news/20231214-chinese-mourners-use-ai-to-digitally-resurrect-the-dead?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Super Brain</a>&nbsp;and&nbsp;<a href="https://guiji.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Silicon Intelligence</a>&nbsp;have built such models for several thousand customers. They provide a modern equivalent of portrait photos of deceased relatives and a vivid way to commune with ancestors.</p><ul><li>The developers use undisclosed tools to stitch photos, videos, audio recordings, and writings supplied by customers into interactive talking-head avatars of deceased loved ones.</li><li>The cost has dropped dramatically. In December 2023, Super Brain charged between $1,400 and $2,800 for a basic chat avatar wrapped in a phone app. Today it charges between $700 and $1,400 and plans eventually to drop the price to around $140. Silicon Intelligence charges between several hundred dollars for a phone-based avatar to several thousand for one displayed on a tablet.</li></ul><p><strong>Behind the news:</strong>&nbsp;The desire to interact with the dead in the form of an AI-generated avatar is neither new nor limited to China. In the U.S., the startup HereAfter AI&nbsp;<a href="https://www.nytimes.com/2023/12/11/technology/ai-chatbots-dead-relatives.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">builds</a>&nbsp;chatbots that mimic the deceased based on interviews conducted while they were alive. Another startup, StoryFile, markets similar capabilities to elders (<a href="https://www.deeplearning.ai/the-batch/star-trek-the-videobot-generation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">pitched</a>&nbsp;by 93-year-old&nbsp;<em>Star Trek</em>&nbsp;star William Shatner) to keep their memory alive for younger family members. The chatbot app&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-replika-chatbot-stopped-flirting-with-users/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Replika</a>&nbsp;began as a project by founder Eugenia Kuyda to virtually resurrect a friend who perished in a car accident in 2015.&nbsp;</p><p><strong>Yes, but:&nbsp;</strong>In China, language models struggle with the variety of dialects spoken by many elders.</p><p><strong>Why it matters:&nbsp;</strong>Virtual&nbsp;<a href="https://www.deeplearning.ai/the-batch/indian-and-southeast-asian-broadcasters-embrace-ai-news-presenters/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">newscasters</a>&nbsp;and&nbsp;<a href="https://www.theinformation.com/articles/tiktok-plots-using-virtual-influencers-for-advertising?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">influencers</a>&nbsp;are increasingly visible on the web, but the technology has more poignant uses. People long to feel close to loved ones who are no longer present. AI can foster that sense of closeness and rapport, helping to fulfill a deep need to remember, honor, and consult the dead.</p><p><strong>We’re thinking:&nbsp;</strong>No doubt, virtual avatars of the dead can bring comfort to the bereaved. But they also bring the risk that providers might manipulate their customers’ emotional attachments for profit. We urge developers to focus on strengthening relationships among living family and friends.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-26T152214.754.gif" width="1200" /></figure><h1 id="benchmarks-for-agentic-behaviors">Benchmarks for Agentic Behaviors</h1><p>Tool use and planning are key behaviors in agentic workflows that enable large language models (LLMs) to execute complex sequences of steps. New benchmarks measure these capabilities in common workplace tasks.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Recent benchmarks gauge the ability of a large language model (LLM) to use external tools to manipulate corporate databases and to plan events such as travel and meetings.&nbsp;</p><p><strong>Tool use:&nbsp;</strong>Olly Styles, Sam Miller, and colleagues at Mindsdb, University of Warwick, and University of Glasgow proposed&nbsp;<a href="https://arxiv.org/abs/2405.00823?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">WorkBench</a>, which tests an LLM’s ability to use 26 software tools to operate on five simulated workplace databases: email, calendar, web analytics, projects, and customer relationship management. Tools include deleting emails, looking up calendar events, creating graphs, and looking up tasks in a to-do list.</p><ul><li>The benchmark includes 690 problems that require using between zero to 12 tools to succeed. It evaluates individual examples based on whether the databases changed as expected after the final tool had been called (rather than simply whether particular tools were used, as in earlier work). In this way, a model can use tools in any sequence and/or revise its initial choices if they prove unproductive and still receive credit for responding correctly.</li><li>Upon receiving a problem, models are given a list of all tools and an example of how to use each one. Following the&nbsp;<a href="https://arxiv.org/abs/2210.03629?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">ReAct</a>&nbsp;prompting strategy, they’re asked first to reason about the problem and then use a tool. After they’ve received a tool’s output (typically either information or an error message), they’re asked to reason again and choose another tool. The cycle of reasoning, tool selection, and receiving output repeats until the model decides it doesn’t need to use another tool.&nbsp;</li><li>The authors evaluated GPT-4, GPT-3.5, Claude 2, Llama2-70B, and Mixtral-8x7B. GPT-4 performed the best by a large margin: It modified the databases correctly 43 percent of the time. The closest competitor, Claude 2, modified the databases correctly 26 percent of the time.</li></ul><p><strong>Planning:</strong>&nbsp;Huaixiu Steven Zheng, Swaroop Mishra, Hugh Zhang, and colleagues at Google published&nbsp;<a href="https://arxiv.org/abs/2406.04520?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">Natural Plan</a>, a benchmark that evaluates an LLM’s ability to (i) plan trips, (ii) arrange a series of meeting times and locations, and (iii) schedule a group meeting. Each example has only one solution.</p><ul><li>The benchmark includes 1,600 prompts that ask the model to plan a trip based on an itinerary of cities, time to be spent in each city, total duration of the trip, days when other people are available to meet, and available flights between cities.&nbsp;</li><li>1,000 prompts ask the model to plan a schedule to meet as many people as possible. The prompts include places, times when people will be in each place, and how long it takes to drive from one place to another.&nbsp;</li><li>1,000 prompts ask the model, given the existing schedules of a number of people, to find a good time for them to meet.</li><li>The authors tested GPT 3.5, GPT-4, GPT-4o, Gemini 1.5 Flash, and Gemini 1.5 Pro, using five-shot prompts (that is, providing five examples for context). Gemini 1.5 Pro achieved the highest scores on planning trips (34.8 percent) and scheduling group meetings (48.9 percent). GPT-4 ranked second for planning trips (31.1), and GPT-4o ranked second for scheduling meetings (43.7 percent). GPT-4 dominated in arranging meetings (47 percent), followed by GPT-40 (45.2 percent).</li></ul><p><strong>Why it matters:</strong>&nbsp;When building&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_h8fIR12wi1Ly0zU1BnMVBQis8zX_BykeEj6u83DqM0GuFcfDUVh_shE7tXqu3UPPIk6P6" rel="noopener">agentic workflows</a>, developers must decide on LLM choices, prompting strategies, sequencing of steps to be carried out, tool designs, single- versus multi-agent architectures, and so on. Good benchmarks can reveal which approaches work best.</p><p><strong>We're thinking:</strong>&nbsp;These tests have unambiguous right answers, so agent outputs can be evaluated automatically as correct or incorrect. We look forward to further work to evaluate agents that generate free text output.</p>
]]></content:encoded>
<pubDate>Wed, 26 Jun 2024 20:29:04 GMT</pubDate>
</item>
<item>
<title>Open Model Bonanza, Private Benchmarks for Fairer Tests, More Interactive Music Generation, Diffusion + GAN</title>
<link>https://www.deeplearning.ai/the-batch/issue-254</link>
<guid>https://www.deeplearning.ai/the-batch/issue-254</guid>
<content:encoded><![CDATA[
<div> coding agents, benchmarks, stability AI, Scale AI, Udio
<br />
<br />
总结: 这篇文章介绍了关于编码代理、基准测试、稳定AI、规模AI和Udio的最新发展。编码代理被用于帮助解决编码问题，通过大型语言模型分析问题并生成代码。基准测试如HumanEval、MBPP和SWE-bench帮助评估代理性能。稳定AI和Scale AI发布了新的权重开放模型，而Udio的音频生成服务提供了音频编辑和生成功能。通过结合GAN和扩散技术，Stability AI加速了扩散模型的生成过程，实现了更高质量的输出。这些进展推动了编码工具和音频生成技术的发展。 <div>
<p>Dear friends,</p><p>On Father’s Day last weekend, I sat with my daughter to help her practice solving arithmetic problems. To give her practice problems, I used&nbsp;<a href="https://github.com/OpenDevin/OpenDevin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">OpenDevin</a>, an open-source agentic coding framework, to write a Python script that generated questions that she enjoyed answering at her own pace. OpenDevin wrote the code much faster than I could have and genuinely improved my and my daughter’s day.&nbsp;</p><p>Six months ago, coding agents were a novelty. They still frequently fail to deliver, but I find that they’re now working well enough that they might be genuinely useful to more and more people!&nbsp;</p><p>Given a coding problem that’s specified in a prompt, the workflow for a coding agent typically goes something like this: Use a large language model (LLM) to analyze the problem and potentially break it into steps to write code for, generate the code, test it, and iteratively use any errors discovered to ask the coding agent to refine its answer. But within this broad framework, a huge design space and numerous innovations are available to experiment with. I’d like to highlight a few papers that I find notable:</p><ul><li>“<a href="https://arxiv.org/abs/2312.13010?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">AgentCoder: Multiagent-Code Generation with Iterative Testing and Optimisation</a>,” Huang et al. (2024).&nbsp;</li><li>“<a href="https://arxiv.org/abs/2402.16906?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">LDB: A Large Language Model Debugger via Verifying Runtime Execution Step by Step</a>,” Zhong et al., (2024).&nbsp;</li><li>“<a href="https://arxiv.org/abs/2405.15793?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering</a>,” Yang et al. (2024).</li></ul><p>How can we test the code without requiring the user to write test cases? In a multi-agent system, each “agent” is an LLM prompted to play a particular role. An interesting result from&nbsp;<a href="https://arxiv.org/html/2312.13010v2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">AgentCoder</a>&nbsp;shows that having separate agents for writing code and generating tests results in better performance than letting a single agent do both tasks. This is presumably because, if the agent writing the code is also responsible for writing the tests, the tests might be influenced by the code and fail to consider corner cases that the code does not cover.&nbsp;</p><p>When people think of testing code, many initially think of output testing, in which we see if the code generates the correct outputs to a specific set of test inputs. If the code fails a test, an LLM can be prompted to reflect on why the code failed and then to try to fix it. In addition to testing the output, the LDB method is helpful. LDB steps through the code and presents to the LLM values of the variables during intermediate steps of execution, to see if the LLM can spot exactly where the error is. This mimics how a human developer might step through the code to see where one of the computational steps went wrong, and so pinpoint and fix the problem.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154106.403.png" width="600" /></figure><p>A lot of agentic workflows mimic human workflows. Similar to other work in machine learning, if humans can do a task, then trying to mimic humans makes development much easier compared to inventing a new process. However, the authors of&nbsp;<a href="https://arxiv.org/abs/2405.15793?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">SWE-agent</a>&nbsp;noticed that many tools that humans use for coding are very inefficient for agents. For example, giving an agent access to a bash shell and having it find a piece of code by executing numerous cd, ls, and cat commands is inefficient, even though humans can do this rapidly. Similarly, visual coding editors like VSCode, emacs, and vim are easy for humans to use, but hard for LLMs (or LMMs) to navigate. Because agents interact with computers differently than humans do, the authors found that building special-purpose tools (functions) to let an agent search, view, and edit codebases resulted in better performance.&nbsp;</p><p>One reason research into coding agents is making rapid progress is that their performance can be evaluated automatically and reliably. With benchmarks like HumanEval, MBPP, and SWE-bench, researchers can try out an idea and automatically test how often it generates correct code. In contrast, even though there’s considerable activity on AI research agents that search the web and synthesize an article (I’ve enjoyed using the open-source&nbsp;<a href="https://github.com/stanford-oval/storm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">STORM</a>&nbsp;system by Stanford's Yijia Shao et al.), they are&nbsp;<a href="https://www.deeplearning.ai/the-batch/we-need-better-evals-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">hard to evaluate</a>&nbsp;and this makes progress harder.&nbsp;</p><p>Github Copilot was released in 2021, and many developers have been getting coding help by prompting LLMs. The rapid evolution from that to more sophisticated coding agents is expanding how computers can help us with coding tasks, and the pace of progress is rapid. With these tools, I expect programming to become even more fun and more productive.</p><p>Keep coding!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-your-own-database-agent?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-11T083858.583.png" width="1680" /></a></figure><p>Develop an AI agent that interacts with tabular data and SQL databases using natural language prompts to simplify querying and extracting insights!&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-your-own-database-agent?ref=dl-staging-website.ghost.io" rel="noreferrer">Start learning for free</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="Different results from new text-to-image models from Nvidia, Alibaba, and Stability AI" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154252.807.gif" width="600" /></figure><h1 id="more-new-open-models">More New Open Models</h1><p>A trio of powerful open and semi-open models give developers new options for both text and image generation.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Nvidia and Alibaba released high-performance large language models (LLMs), while Stability AI released a slimmed-down version of its flagship text-to-image generator.<br /><br /><strong>How it works:</strong>&nbsp;The weights for Nvidia’s and Alibaba’s new models are fully open, while Stability AI’s are restricted.</p><ul><li>Nvidia offers the&nbsp;<a href="https://research.nvidia.com/publication/2024-06_nemotron-4-340b?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Nemotron-4 340B</a>&nbsp;family of language models, which includes a 340-billion parameter base model as well as versions fine-tuned to follow instructions and to serve as a reward model in reinforcement learning from human feedback. (Nemotron-4 340B-Reward currently&nbsp;<a href="https://huggingface.co/spaces/allenai/reward-bench?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">tops</a>&nbsp;the HuggingFace RewardBench leaderboard, which ranks reward models.) The models, which can work with 4,096 tokens of context, were pretrained on 9 trillion tokens that divide between English-language text, text in over 50 other natural languages, and code in more than 40 programming languages. 98 percent of the alignment training set was generated, and Nvidia also released the generation pipeline. The&nbsp;<a href="https://developer.download.nvidia.com/licenses/nvidia-open-model-license-agreement-june-2024.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>&nbsp;allows people to use and modify the model freely except for illegal uses.&nbsp;</li><li>Alibaba introduced the&nbsp;<a href="https://qwenlm.github.io/blog/qwen2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Qwen2</a>&nbsp;family of language models. Qwen2 includes base and instruction-tuned versions of five models that range in size from 500 million to 72 billion parameters and process context lengths between 32,000 and 128,000 tokens. The largest, Qwen2-72B, outperforms Llama 3-70B on MMLU, MMLU-Pro, HumanEval, and other benchmarks that gauge performance in natural language, mathematics, and coding. Qwen2-72B and Qwen2-72B-Instruct are available under a&nbsp;<a href="https://huggingface.co/Qwen/Qwen2-72B/blob/main/LICENSE?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>&nbsp;that permits users to use and modify them in commercial applications up to 100 million monthly users. The smaller models are available under the Apache&nbsp;<a href="https://apache.org/licenses/LICENSE-2.0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>, which allows people to use and modify them freely. Alibaba said it plans to add multimodal capabilities in future updates.</li><li>Stability AI&nbsp;<a href="https://stability.ai/news/stable-diffusion-3-medium?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">launched</a>&nbsp;the Stable Diffusion 3 Medium text-to-image generator, a 2 billion-parameter based on the&nbsp;<a href="https://arxiv.org/pdf/2403.03206?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">technology</a>&nbsp;that underpins Stable Diffusion 3. The model is intended to run on laptops and home computers that have consumer GPUs and is optimized for Nvidia and AMD hardware. It excels at rendering imaginary scenes and text; early users encountered inaccuracies in depicting human anatomy, a shortcoming that former Stability AI CEO Emad Mostaque, in a social post,&nbsp;<a href="https://x.com/EMostaque/status/1801686921967436056?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">attributed</a>&nbsp;to tuning for safety. The&nbsp;<a href="https://stability.ai/license?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">license</a>&nbsp;allows use of the model’s weights for noncommercial purposes. Businesses that have less than 1 million users and $1 million in revenue can license it, along with other Stability AI models, for $20 per month.</li></ul><p><strong>Why it matters:</strong>&nbsp;AI models that come with published weights are proliferating, and this week’s crop further extends the opportunity to build competitive AI applications. Nemotron-4 340B provides an exceptionally large model among open LLMs. Among smaller models, Qwen2-72B poses stiff competition for Llama 3-70B, which has energized the developer community since its May release. And Stable Diffusion 3 puts Stability AI’s image generation technology into the hands of developers working on edge devices.</p><p><strong>We’re thinking:&nbsp;</strong>Given the difficulty of acquiring high-quality data to train LLMs, and that the terms of service for many leading models prohibit generating data to train other models, Nvidia’s choice to equip Nemotron-4 to generate synthetic data is especially welcome. And it makes sense from a business perspective: Making it easier for developers to train their own LLMs may be good for GPU sales.</p><hr /><figure class="kg-card kg-image-card"><img alt="Safety, Evaluations and Alignment Lab (SEAL) Leaderboards." class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154339.904.gif" width="1200" /></figure><h1 id="private-benchmarks-for-fairer-tests">Private Benchmarks for Fairer Tests</h1><p>Scale AI offers new leaderboards based on its own benchmarks.</p><p><strong>What’s new:</strong>&nbsp;Scale AI, which helps companies prepare and manage training data,&nbsp;<a href="https://scale.com/leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">introduced</a>&nbsp;the Safety, Evaluations and Alignment Lab (SEAL) Leaderboards. Four leaderboards test models’ abilities to (i) generate code, (ii) work on Spanish-language inputs and outputs, (iii) follow detailed instructions, and (iv) solve fifth-grade math problems. The company currently tests 11 models from Anthropic, Google, Meta, Mistral, and OpenAI. Developers who want to have their model ranked can contact Scale AI via email.<br /><br /><strong>How it works:</strong>&nbsp;The leaderboards track performance on proprietary datasets of roughly 1,000 examples. In all but the math tests, models to be evaluated are grouped and pitted against each other. Each pair receives 50 prompts at a time. Human annotators evaluate the models’ responses and grade which was superior and by how much. Then the models receive another 50 prompts. Models are ranked using a variation on Elo, which scores competitors relative to each other. To keep the test sets from leaking, a given model will be tested only once except in “exceptional cases” where Scale AI believes the risk of overfitting is low.&nbsp;</p><ul><li>The&nbsp;<a href="https://scale.com/leaderboard/coding?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">coding</a>&nbsp;evaluation tests models’ abilities to generate code, analyze code, fix errors, and solve problems in SQL, Python, Java, JavaScript, HTML, CSS, C++, C, and C#. Annotators judge the code based on correctness, efficiency, readability, adherence to the prompt, and overall quality.&nbsp;</li><li>The&nbsp;<a href="https://scale.com/leaderboard/spanish?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Spanish</a>&nbsp;dataset tests the ability to respond to prompts written in European and Latin American Spanish, covering both general and cultural subject matter. Annotators evaluate the responses on 16 criteria including style, correctness, harmfulness, and internal contradiction. (The company plans to extend its multilingual evaluation to other languages.)</li><li><a href="https://scale.com/leaderboard/instruction_following?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Instruction Following</a>&nbsp;asks models to fulfill detailed, multi-step instructions in a single response. The dataset includes prompts that ask a model to generate poetry, fiction, social posts, or responses playing a particular role. Annotators evaluate the responses using 12 criteria, including how well they reflect the prompt and how useful they are. They rate how well each model followed the instructions and how well they performed relative to each other.</li><li>The&nbsp;<a href="https://scale.com/leaderboard/math?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Math</a>&nbsp;leaderboard evaluates models on Scale AI’s&nbsp;<a href="https://arxiv.org/abs/2405.00332?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">GSM1k</a>&nbsp;benchmark of fifth-grade arithmetic and algebra problems written in English. Unlike the other three tests, it tests whether responses are correct rather than pitting models against one another.</li></ul><p><strong>Results:</strong>&nbsp;As of this writing, GPT-4 Turbo tops the Coding leaderboard with GPT-4o a very close second. GPT-4o tops the Spanish and Instruction Following leaderboards, just ahead of Gemini 1.5 Pro in Spanish and GPT-4 Turbo in Instruction Following. On the Math leaderboard, Claude 3 Opus holds a narrow lead over GPT-4 Turbo (second) and GPT-4o (third).</p><p><strong>Behind the news:&nbsp;</strong>As more models are trained on data scraped from the web, leakage of test data into training sets has made it more difficult to evaluate their performance on common benchmarks. Earlier this year, researchers at Shanghai Jiao Tong University&nbsp;<a href="https://arxiv.org/html/2404.18824v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">evaluated</a>&nbsp;31 open-source large language models and found that several had a high probability of inaccurate benchmark results due to data leakage. Scale AI built the GSM1k math dataset partly to show that some high-profile language models show evidence of overfitting to the common math benchmark GSM8k.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Traditionally, benchmarks have been open source efforts. But proprietary benchmarks are emerging to help developers evaluate their models and applications with greater confidence. By keeping their datasets under wraps, companies like Scale AI and&nbsp;<a href="https://www.deeplearning.ai/the-batch/vals-ai-evaluates-large-language-models-on-industry-specific-tasks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Vals AI</a>&nbsp;ensure that models haven’t been exposed to test questions and answers previously, making evaluations more reliable. However, private benchmarks lack the transparency of their open counterparts. A mix of public, private, and internal evals may be necessary to get a well rounded picture of a given model’s capabilities.<br /><br /><strong>We’re thinking:</strong>&nbsp;We welcome Scale AI’s contribution to the important field of&nbsp;<a href="https://www.deeplearning.ai/the-batch/we-need-better-evals-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">evals</a>, which also includes open benchmarks,&nbsp;<a href="https://chat.lmsys.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">LMSYS Chatbot Arena</a>, and&nbsp;<a href="https://crfm.stanford.edu/helm/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">HELM</a>.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154435.801.gif" width="600" /></figure><h1 id="from-clip-to-composition">From Clip to Composition</h1><p>Is your song’s verse in need of a chorus? A popular text-to-music generator can extend existing recordings while maintaining their musical character.</p><p><strong>What’s new:</strong>&nbsp;Paying users of Udio, a web service that generates pop-song productions from prompts, can&nbsp;<a href="https://www.udio.com/announcements?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">upload</a>&nbsp;audio clips and extend or alter them according to a text description. The service also increased its context window from 30 seconds to 2 minutes for more coherent output. You can hear the new capability&nbsp;<a href="https://www.youtube.com/watch?v=hFWdHzk70-Q&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">here</a>. Subscriptions start at $10 per month.<br /><br /><strong>How it works:</strong>&nbsp;Given a prompt, Udio generates a 30-second passage and lets you assemble passages into compositions (previously up to four minutes long, now 15 minutes). Now users can create passages by uploading audio clips and extending them or modifying them by, say, adding or removing instruments or vocals complete with lyrics.&nbsp;</p><ul><li>In the demonstration video linked above, Udio adds a singing voice to an instrumental backing track using the prompt “funk, female vocalist.” Other examples enhance an electronic beat with a guitar melody and fill out hard-rock drums with a guitar riff and wailing voice.</li><li>Users are responsible for securing legal rights to use audio files they upload. They retain commercial rights to audio that they produce using the software, as long as they specify that Udio generated the recording.&nbsp;</li><li>Udio has shared few details about how it built its model. “A large amount of publicly available and high-quality music” was in the training set, CEO David Ding&nbsp;<a href="https://musically.com/2024/04/10/ai-music-startup-udio-launches-backed-by-artists-and-instagrams-co-founder/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">told</a>&nbsp;<em>Music Ally</em>. The company has “very strong artist filters and a copyright focus” to avoid generating output that sounded too much like copyrighted music, he added.</li></ul><p><strong>Behind the news:</strong>&nbsp;Udio competes with&nbsp;<a href="https://www.deeplearning.ai/the-batch/text-to-music-services-evolve-with-udio-and-sunos-customized-song-creations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Suno</a>, whose service also generates audio output with vocals, lyrics, and song structures. Also in the mix is Stability AI, whose&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Stable Audio 2.0</a>&nbsp;enables users to upload and extend brief instrumental recordings to a length of around three minutes.</p><p><strong>Why it matters:</strong>&nbsp;Udio is quickly becoming not just a song generator, but a song editor and builder. Just as the ability of text-to-image generators to edit, extend, and infill existing images made those applications more useful in a variety of creative situations, Udio’s audio-to-audio capabilities give composers and producers new horizons for enhancing, orchestrating, and structuring their own productions.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Udio offers impressive capabilities for musicians (and wanna-be musicians), but its developer tools are lacking. A public-facing API would enable producers to automate the service and integrate it with other applications.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-19T154515.714.gif" width="600" /></figure><h1 id="for-faster-diffusion-think-a-gan">For Faster Diffusion, Think a GAN</h1><p>Generative adversarial networks (GANs) produce images quickly, but they’re of relatively low quality. Diffusion image generators typically take more time, but they produce higher-quality output. Researchers aimed to achieve the best of both worlds.</p><p><strong>What's new:</strong>&nbsp;Axel Sauer and colleagues at Stability AI accelerated a diffusion model using a method called&nbsp;<a href="https://arxiv.org/abs/2311.17042?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">adversarial diffusion distillation</a>&nbsp;(ADD). As the name implies, ADD combines diffusion with techniques borrowed from GANs and teacher-student distillation.</p><p><strong>Key insight:</strong>&nbsp;<a href="https://arxiv.org/abs/1406.2661?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">GANs</a>&nbsp;are fast because they produce images in a single step. Diffusion models are slower because they remove noise from a noisy image over many steps. A diffusion model can learn to generate images in a single denoising step if, like a GAN, it learns to fool a discriminator, while the discriminator learns to identify generated output. The resulting one-step output doesn’t match the quality of multi-step diffusion, but distillation can improve it: While learning to fool the discriminator, the diffusion model (the student) can simultaneously learn to emulate the output of a different pretrained diffusion model (the teacher).</p><p><strong>How it works:&nbsp;</strong>The authors paired a pretrained&nbsp;<a href="https://arxiv.org/abs/2307.01952?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">Stable Diffusion XL</a>&nbsp;(SDXL) generator (the student) with a pretrained&nbsp;<a href="https://arxiv.org/abs/2304.07193?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">DINOv2</a>&nbsp;vision transformer discriminator. The teacher was another pretrained Stable Diffusion XL with frozen weights. They didn’t specify the training dataset.&nbsp;&nbsp;</p><ul><li>The researchers added noise to images in the training dataset. Given a noisy image and the corresponding caption, the student model removed noise in a single step.</li><li>Given the student’s output, the discriminator learned to distinguish it from the images in the dataset.</li><li>Given the student’s output with added noise plus the caption, the teacher removed the noise from the image in a single step.</li><li>The student’s loss function encouraged the model to produce images that the discriminator could not distinguish from images in the dataset and to minimize the difference between the student’s and teacher’s output.</li></ul><p><strong>Results:&nbsp;</strong>The authors tested their method using 100 prompts from&nbsp;<a href="https://huggingface.co/datasets/nateraw/parti-prompts?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8IW_mtWbMjRpUm1n1yIADSQ3OWM-lcCDorLB3v-M59gSiEEPtLU7MYnmlKydJVIZ_AhCYQ" rel="noopener">PartiPrompts</a>. They compared the student’s output after either one or four denoising steps to a pretrained SDXL after 50 denoising steps. Human judges were asked which they preferred with respect to (i) image quality and (ii) alignment with the prompt. They preferred the student’s four-step images about 57 percent of the time for image quality and about 55 percent of the time for alignment with the prompt. They preferred SDXL to the student’s one-step images around 58 percent of the time for image quality and 52 percent of the time for alignment with the prompt.</p><p><strong>Why it matters:</strong>&nbsp;In this work, the key steps — having a student model learn from a teacher model, and training a generator against a discriminator&nbsp;— are established techniques in their own right. Combining them conferred upon the student model the advantages of both.</p><p><strong>We're thinking:</strong>&nbsp;With the growing popularity of diffusion models, how to reduce the number of steps they take while maintaining their performance is a hot topic. We look forward to future advances.</p>
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 20:49:35 GMT</pubDate>
</item>
<item>
<title>Apple’s Gen AI Strategy, Stability's Copyright-Clear Audio Generator, International Safety Agreements, LLMs Play Doctor</title>
<link>https://www.deeplearning.ai/the-batch/issue-253</link>
<guid>https://www.deeplearning.ai/the-batch/issue-253</guid>
<content:encoded><![CDATA[
<div> machine learning, agentic systems, Apple Intelligence, Stable Audio Open, AI Seoul Summit

总结:<br /><br />本文介绍了机器学习领域的成功及其对agentic系统的包容性，以及苹果发布的Apple Intelligence，Stable Audio Open生成器，以及AI首尔峰会达成的AI安全协议。机器学习领域在接纳不同工作方面非常包容，对agentic系统的发展也持开放态度。苹果发布了Apple Intelligence，提供了多种生成AI功能，同时保护用户隐私。Stable Audio Open是一个生成音频的工具，专为非商业用途设计。AI首尔峰会达成了AI安全协议，27个国家同意共同开发风险阈值，并与十家AI公司合作实施安全措施。总体来说，这些发展展示了AI技术正在取得积极进展，同时也需要关注其影响和安全性。 <div>
<p>Dear friends,</p><p>One reason for machine learning’s success is that our field welcomes a wide range of work. I can’t think of even one example where someone developed what they called a machine learning algorithm and senior members of our community criticized it saying, “that’s not machine learning!” Indeed, linear regression using a least-squares cost function was used by mathematicians Legendre and Gauss in the early 1800s — long before the invention of computers — yet machine learning has embraced these algorithms, and we routinely call them “machine learning” in introductory courses!</p><p>In contrast, about 20 years ago, I saw statistics departments at a number of universities look at developments in machine learning and say, “that’s not really statistics.” This is one reason why machine learning grew much more in computer science than statistics departments. (Fortunately, since then, most statistics departments have become much more open to machine learning.)</p><p>This contrast came to mind a few months ago, as I thought about how to talk about&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">agentic systems</a>&nbsp;that use design patterns such as&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">reflection</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">tool use</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">planning</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">multi-agent collaboration</a>&nbsp;to produce better results than zero-shot prompting. I had been involved in conversations about whether certain systems should count as “agents.” Rather than having to choose whether or not something is an agent in a binary way, I thought, it would be more useful to think of systems as being agent-like to different degrees. Unlike the noun “agent,” the adjective “agentic” allows us to contemplate such systems and include all of them in this growing movement.</p><p>More and more people are building systems that prompt a large language model multiple times using agent-like design patterns. But there’s a gray zone between what clearly is not an agent (prompting a model once) and what clearly is (say, an autonomous agent that, given high-level instructions, plans, uses tools, and carries out multiple, iterative steps of processing).&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--63-.jpg" width="1200" /></figure><p>Rather than arguing over which work to include or exclude as being a true agent, we can acknowledge that there are different degrees to which systems can be agentic. Then we can more easily include everyone who wants to work on agentic systems. We can also encourage newcomers to start by building simple agentic workflows and iteratively make their systems more sophisticated.&nbsp;</p><p>In the past few weeks, I’ve noticed that, while technical people and non-technical people alike sometimes use the word “agent,” mainly only technical people use the word “agentic” (for now!). So when I see an article that talks about “agentic” workflows, I’m more likely to read it, since it’s less likely to be marketing fluff and more likely to have been written by someone who understands the technology.</p><p>Let’s keep working on agentic systems and keep welcoming anyone who wants to join our field!</p><p>Keep learning,</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/courses/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-12T075130.872.png" width="1680" /></a></figure><p>Grow your generative AI skills with DeepLearning.AI’s&nbsp;<a href="https://www.deeplearning.ai/courses/?ref=dl-staging-website.ghost.io" rel="noreferrer">short courses</a>! Learn how to build highly controllable agents in “AI Agents in LangGraph.”&nbsp;<a href="https://learn.deeplearning.ai/courses/ai-agents-in-langgraph?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free and get started</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/APPLEAI.png" width="1200" /></figure><h1 id="apple%E2%80%99s-gen-ai-strategy-revealed">Apple’s Gen AI Strategy Revealed</h1><p>Apple presented its plan to imbue its phones and computers with artificial intelligence.&nbsp;<br /><br /><strong>What’s new:</strong>&nbsp;Apple&nbsp;<a href="https://www.apple.com/apple-intelligence/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">announced</a>&nbsp;Apple Intelligence, a plethora of generative-AI features that integrate with iOS 18, iPadOS 18, and MacOS Sequoia. The beta version of Apple Intelligence will be available in U.S. English prior to a wider rollout near the end of the year, starting with the iPhone 15 Pro and Mac computers that use&nbsp;<a href="https://support.apple.com/en-gb/116943?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">M-series</a>&nbsp;chips.&nbsp;<br /><br /><strong>On-device and in the cloud:&nbsp;</strong>The new capabilities rely on a suite of language and vision models. Many of the models will run on-device, while workloads that require more processing power will run on a cloud powered by Apple chips.&nbsp;</p><ul><li>Semantic search analyzes the data on a device to better understand context such as the user’s routines and relationships. For example, if a user enters a prompt like, “Show me the files my boss shared with me the other day,” models can identify the user’s boss and the day in question.</li><li>Generative media capabilities are geared to fulfill preset functions. For instance, the text generator offers options to make writing more friendly, professional, or concise. Image generation focuses on tasks like making custom emojis from text prompts and turning rough sketches into polished images.&nbsp;</li><li>Apple’s voice assistant Siri will accept text as well as voice prompts. It will also interact with apps, so Siri can, say, determine whether a meeting scheduled in the Calendar app will prevent a user from attending an event at a location designated in the Maps app.&nbsp;</li><li>Starting later this year, Siri users will be able to converse with OpenAI’s ChatGPT without having an OpenAI account or paying a fee. Paid ChatGPT users will be able to log in for access to paid features. Apple plans to integrate other third-party large language models.</li><li>The underlying infrastructure is designed to maintain user privacy. Apple’s cloud won’t retain user data. Apple won’t have privileged access to user data. Queries to ChatGPT from users who are not logged into an OpenAI account will have their IP masked. In addition, independent researchers can inspect the infrastructure code to verify assurances and find flaws.</li></ul><p><strong>How it works:&nbsp;</strong>Apple&nbsp;<a href="https://machinelearning.apple.com/research/introducing-apple-foundation-models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">outlined</a>&nbsp;the architecture that underpins the new features and compared two models of its against competitors.</p><ul><li>All Apple models were trained on a mix of licensed, synthetic, and web-crawled data (filtered to remove personal and low-quality information). The models were fine-tuned to follow instructions via methods including reinforcement learning from human feedback.&nbsp;</li><li>To adapt its models to specific tasks, Apple uses LoRA weights that plug into a pretrained model and adjust its weights at inference. Such LoRA adapters are included for many tasks including summarization, proofreading, email replies, and answering questions.</li><li>Apple used quantization, a compression technique called low-bit parallelization (also known as&nbsp;<a href="https://www.tensorflow.org/model_optimization/guide/clustering?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">weight clustering</a>), and other methods to improve speed and energy efficiency. On an iPhone 15 Pro, Apple clocked a generation rate of 30 tokens per second.</li><li>Apple hired human graders to test two of its models on an internal benchmark that covers tasks including brainstorming, classification, answering questions, rewriting, summarization, and safety. The graders preferred an on-device model of 3 billion parameters over Phi-3-mini, Mistral-7B, and Gemma-7B. They preferred a large language model designed to run in the cloud to DBRX-Instruct, GPT-3.5-Turbo, and Mixtral-8x22B, but not to GPT-4-Turbo.</li></ul><p><strong>Behind the news:&nbsp;</strong>While rivals like Microsoft and Google dove into generative AI, Apple&nbsp;<a href="https://www.deeplearning.ai/the-batch/apple-is-proceeding-on-the-sly-to-capitalize-on-the-generative-ai-trend/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">moved</a>&nbsp;more cautiously. During the 2010s, it invested heavily in its Siri voice assistant, but the technology was&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-was-the-first-big-company-to-get-chatbots-right/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">outpaced</a>&nbsp;by subsequent developments. Since then, the famously secretive company has been perceived as&nbsp;<a href="https://www.wsj.com/tech/ai/apple-ai-siri-development-behind-9ea65ee8?st=syyxevr53ucieoo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">falling behind</a>&nbsp;big-tech rivals in AI.<br /><br /><strong>Why it matters:</strong>&nbsp;While Apple’s big-tech competitors have largely put their AI cards on the table, Apple has held back. Now its strategy is on display: Proprietary foundation models, LoRA to fine-tune them to specific tasks, emphasis on the user experience over raw productivity, judicious use of edge and cloud computing, and deals with other model makers, all wrapped up in substantial privacy protections.<br />&nbsp;<br /><strong>We’re thinking:&nbsp;</strong>Apple’s control over its product ecosystem gives the company an extraordinary distribution channel. That’s why Google reportedly&nbsp;<a href="https://www.msn.com/en-us/money/other/court-documents-reveal-google-s-payments-to-apple-increased-to-an-eye-watering-20-billion-in-2022/ar-AA1o2J6w?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">paid</a>&nbsp;Apple $20 billion in 2022 to provide the default search engine in Apple’s Safari web browser. This advantage means that, whatever its pace of development and strategy in AI, Apple’s competitive edge remains sharp.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/STABLEAUDIOOPEN.png" width="1200" /></figure><h1 id="audio-generation-clear-of-copyrights">Audio Generation Clear of Copyrights</h1><p>Sonically minded developers gained a high-profile text-to-audio generator.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Stability AI&nbsp;<a href="https://stability.ai/news/introducing-stable-audio-open?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">released</a>&nbsp;Stable Audio Open, which takes text prompts and generates&nbsp;16kHz-resolution&nbsp;music or sound effects. The model’s code and weights are available for noncommercial use. You can listen to a few sample outputs&nbsp;<a href="https://stability.ai/news/introducing-stable-audio-open?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">here</a>.<br /><br /><strong>How it works:</strong>&nbsp;Stability AI promotes Stable Audio Open for generating not full productions but elements that will be assembled into productions. Although it’s similar to the earlier&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Stable Audio 2.0</a>, it has important differences.</p><ul><li>Stable Audio Open is available for download. In contrast, Stable Audio 2.0 is available via API or web user interface.</li><li>The new model accepts only text input, while Stable Audio 2.0 accepts text or audio. It generates stereo, clips up to 47 seconds long rather than Stability Audio 2.0’s three minutes.</li><li>Its training dataset was drawn from open source&nbsp;<a href="https://freesound.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">audio</a>&nbsp;<a href="https://freemusicarchive.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">databases</a>&nbsp;that anyone can use without paying royalties. In contrast, Stable Audio 2.0 was trained on a commercial&nbsp;<a href="https://www.audiosparx.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">dataset</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;Stable Audio Open competes not only with Stable Audio 2.0 but also with a handful of recent models. ElevenLabs,&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-cloned-voices-take-over-youtube-twitch-and-spotify/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">known</a>&nbsp;for voice cloning and generation,&nbsp;<a href="https://elevenlabs.io/sound-effects?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">introduced</a>&nbsp;Sound Effects, which generates brief sound effects from a text prompt. Users can input up to 10,000 prompt characters with a free account. For music generation,&nbsp;<a href="https://www.deeplearning.ai/the-batch/text-to-music-services-evolve-with-udio-and-sunos-customized-song-creations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Udio and Suno</a>&nbsp;offer web-based systems that take text prompts and generate structured compositions including songs with lyrics, voices, and full instrumentation. Users can generate a handful of compositions daily for free.</p><p><strong>Why it matters:</strong>&nbsp;Stable Audio Open is pretrained on both music and sound effects, and it can be fine-tuned and otherwise modified. The fact that its training data was copyright-free guarantees that users won’t make use of proprietary sounds — a suitable option for those who prefer to steer clear of the music industry’s brewing intellectual property&nbsp;<a href="https://www.deeplearning.ai/the-batch/sony-music-accuses-ai-developers-of-copyright-violations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">disputes</a>.<br /><br /><strong>We’re thinking:</strong>&nbsp;We welcome Stability AI’s latest contribution, but we don’t consider it open source. Its license doesn’t permit commercial use and thus, as far as we know, doesn’t meet the definition established by the&nbsp;<a href="http://opensource.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Open Source Initiative</a>. We urge the AI community toward greater clarity and consistency with respect to the term “open source.”&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-12T145349.047.png" width="600" /></figure><h1 id="seoul-ai-summit-spurs-safety-agreements">Seoul AI Summit Spurs Safety Agreements</h1><p>At meetings in Seoul, government and corporate officials from dozens of countries agreed to take action on AI safety.<br /><br /><strong>What’s new:&nbsp;</strong>Attendees at the AI Seoul Summit and AI Global Forum, both held concurrently in Seoul, formalized the broad-strokes agreements to govern AI,&nbsp;<em>The Guardian</em>&nbsp;<a href="https://www.theguardian.com/technology/article/2024/may/28/techscape-ai-global-summit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">reported</a>. Presented as a sequel to November’s AI summit in Bletchley Park outside of London, the meetings yielded several multinational declarations and commitments from major tech firms.</p><p><strong>International commitments:</strong>&nbsp;Government officials hammered out frameworks for promoting innovation while managing risk.</p><ul><li>27 countries and the European Union&nbsp;<a href="https://www.gov.uk/government/publications/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">agreed</a>&nbsp;to jointly develop risk thresholds in coming months. Thresholds may include a model’s ability to evade human oversight or help somebody create weapons of mass destruction. (Representatives from China didn’t join this agreement.)</li><li>10 of those 27 countries (Australia, Canada, France, Germany, Italy, Japan, the Republic of Korea, the Republic of Singapore, the United Kingdom, and the United States) and the European Union&nbsp;<a href="https://www.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-inclusive-ai-ai-seoul-summit-2024/seoul-declaration-for-safe-innovative-and-inclusive-ai-by-participants-attending-the-leaders-session-ai-seoul-summit-21-may-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">declared</a>&nbsp;a common aim to create shared policies while encouraging AI development.&nbsp;</li><li>In a separate statement, those 10 nations and the EU&nbsp;<a href="https://www.gov.uk/government/publications/seoul-declaration-for-safe-innovative-and-inclusive-ai-ai-seoul-summit-2024/seoul-statement-of-intent-toward-international-cooperation-on-ai-safety-science-ai-seoul-summit-2024-annex?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">laid out</a>&nbsp;more specific goals including exchanging information on safety tests, building an international AI safety research network, and expanding AI safety institutes beyond those currently established in the U.S., UK, Japan, and Singapore.</li></ul><p><strong>Corporate commitments:</strong>&nbsp;AI companies agreed to monitor their own work and collaborate on further measures.</p><ul><li>Established leaders (Amazon, Google, IBM, Meta, Microsoft, OpenAI, Samsung) and startups (Anthropic, Cohere, G42, Inflection, xAI) were among 16 companies that&nbsp;<a href="https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">agreed</a>&nbsp;to evaluate advanced AI models continually for safety risks. They agreed to abide by clear risk thresholds developed in concert with their home governments, international agreements, and external evaluators. If they deem that a model has surpassed a threshold, and that risk can’t be mitigated, they agreed to stop developing that model immediately.</li><li>14 companies, including six that didn’t sign the agreement on risk thresholds,&nbsp;<a href="https://aiseoulsummit.kr/kor/press/?uid=43&amp;mod=document&amp;pageid=1&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">committed</a>&nbsp;to collaborate with governments and each other on AI safety, including developing international standards.</li></ul><p><strong>Behind the news:</strong>&nbsp;Co-hosted by the UK and South Korean governments at the Korea Advanced Institute of Science and Technology, the meeting followed an initial summit held at Bletchley Park outside London in November. The earlier summit&nbsp;<a href="https://www.deeplearning.ai/the-batch/countries-and-tech-giants-collaborate-on-global-ai-safety-regulation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">facilitated</a>&nbsp;agreements to create AI&nbsp;<a href="https://www.nist.gov/aisi?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">safety</a>&nbsp;<a href="https://www.gov.uk/government/organisations/ai-safety-institute?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">institutes</a>, test AI products before public release, and create an international panel akin to the&nbsp;<a href="https://www.ipcc.ch/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Intergovernmental Panel on Climate Change</a>&nbsp;to draft reports on the state of AI. The panel&nbsp;<a href="https://assets.publishing.service.gov.uk/media/66474eab4f29e1d07fadca3d/international_scientific_report_on_the_safety_of_advanced_ai_interim_report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">published</a>&nbsp;an interim report in May. It will release its final report at the&nbsp;<a href="https://www.gov.uk/government/news/uk-and-france-to-deepen-research-and-ai-links-following-horizon-association?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">next summit</a>&nbsp;in Paris in November 2024.</p><p><strong>Why it matters:</strong>&nbsp;There was a chance that the Bletchley Park summit would be a one-off. The fact that a second meeting occurred is a sign that public and private interests alike want at least a seat at the table in discussions of AI safety. Much work remains to define terms and establish protocols, but plans for future summits indicate a clear appetite for further cooperation.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Andrew Ng spoke at the AI Global Forum on the importance of&nbsp;<a href="https://www.deeplearning.ai/the-batch/issue-252/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">regulating applications rather than technology</a>&nbsp;and chatted with many government leaders there. Discussions focused at least as much on promoting innovation as mitigating hypothetical risks. While some large companies continued to lobby for safety measures that would unnecessarily impede dissemination of cutting-edge foundation models and hamper open-source and smaller competitors, most government leaders seemed to give little credence to science-fiction risks, such as AI takeover, and express concern about concrete, harmful applications like the use of AI to interfere with democratic elections. These are encouraging shifts!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-12T145439.840.gif" width="600" /></figure><h1 id="the-llm-will-see-you-now">The LLM Will See You Now</h1><p>A critical step in diagnosing illnesses is a conversation between doctor and patient to assemble a medical history, discuss approaches to managing symptoms, and so on. Can a large language model play the doctor’s role? Researchers trained one to do surprisingly well.</p><p><strong>What's new:</strong>&nbsp;<a href="https://arxiv.org/abs/2401.05654?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">Articulate Medical Intelligence Explorer</a>&nbsp;(AMIE), a chatbot built by Google researchers Tao Tu, Anil Palepu, Mike Schaekermann and colleagues, showed better diagnostic ability and bedside manner than doctors in conversations with patients. The conversations covered a range of complaints including cardiovascular, respiratory, gastroenterology, neurology, urology, obstetric, and gynecology conditions.</p><p><strong>Key insight:&nbsp;</strong>A pretrained LLM that’s fine-tuned on conversations between doctors and patients can learn to mimic the doctor’s role. However, such models are limited because available datasets of real-world medical conversations don’t cover the full range of medical scenarios and include ambiguities, interruptions, implicit references and the like, posing difficulties for learning. Conversations generated by a pretrained LLM can cover more conditions in more articulate language. After fine-tuning on real-world conversations, further tuning on generated conversations can improve performance. In addition, after a conversation, critiquing the “doctor’s” performance can improve its ability to render diagnoses, suggest plans for managing symptoms, empathize with patients, and otherwise perform its role.</p><p><strong>How it works:&nbsp;</strong>The authors fine-tuned a pretrained&nbsp;<a href="https://arxiv.org/abs/2305.10403?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">PaLM-2</a>&nbsp;on medical&nbsp;<a href="https://github.com/jind11/MedQA?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_gIrmbxcITc28FhuvGDCyEatfevaCrKevCJqk0DMR46aWOdQblPdiiop0C21jprkMtzx6e" rel="noopener">multiple-choice questions</a>&nbsp;that describe symptoms, possible causes, and evidence for the correct diagnosis, as well as datasets for tasks like summarizing and continuing medical dialogs. They further fine-tuned the model on its own output.</p><ul><li>Given a medical condition, the authors searched the web to retrieve background information about symptoms, management, and patient demographics. Using that information, they prompted PaLM-2 to generate a patient scenario like scenarios used to assess real-world medical interviewing skills.&nbsp;</li><li>The authors prompted separate instances of PaLM-2 to play doctor and patient. They fed the generated scenario to the patient and prompted the models to produce a conversation. After each turn, a third instance of PaLM-2 decided whether the conversation was over based on whether the doctor had given a diagnosis and the patient had further questions (or either had said “goodbye”).&nbsp;</li><li>Given the generated conversation, a fourth instance of PaLM-2 generated a critique of the doctor model’s empathy, professionalism, repetition, conversation flow, factual accuracy, and whether the doctor had asked questions that led to a diagnosis.&nbsp;&nbsp;</li><li>Given the critique, the doctor initiated a second iteration of its conversation with the patient.&nbsp;</li><li>The authors fine-tuned PaLM-2 to predict the next token in the second conversation. Then they repeated the process from the beginning a number of times, generating fresh conversations and fine-tuning the model.&nbsp;</li><li>At inference, users conversed with the doctor model. Once the conversation was complete, the authors prompted the model to list 10 potential diagnoses.</li></ul><p><strong>Results:</strong>&nbsp;Specialist physicians evaluated the doctor model’s performance in 149 conversations with human actors who played the roles of patients based on scenarios supplied by clinical providers. They compared the model’s output with those of 20 primary care physicians based on their own conversations with the actors.&nbsp;</p><ul><li>The model included the correct diagnosis among its top three in about 90 percent of cases. The physicians included the correct diagnoses among their top three in 77 percent of the scenarios.&nbsp;</li><li>Specialist physicians also rated the conversations on 32 subjective qualities including relationship fostering, responding to emotions, understanding patient concerns, and explaining relevant information accurately. Of the 32 qualities, AMIE rated higher on 28 of them. For instance, the physicians said AMIE responded to emotions favorably or very favorably about 83 percent of the time, while physicians responded to emotions favorably or very favorably 31 percent of the time.&nbsp;</li><li>The actors also rated the conversations they had with AMIE and the physicians on 26 qualities including whether they had explained the condition and treatment, appeared honest and trustworthy, expressed caring and commitment, and valued the patient as a person. Among those 26 qualities, AMIE outperformed the physicians on 24 of them. For instance, the actors said that AMIE valued them as people 79 percent of the time, while the physicians valued them as people 59 percent of the time.</li></ul><p><strong>Why it matters:</strong>&nbsp;LLMs can generate fine-tuning data that improves their own performance. By training on relevant, factually correct medical information from the web, LLMs can generate realistic conversations at scale — even in a highly technical, high-stakes discipline like medicine and despite their potential to generate potentially dangerous hallucinations. Used as fine-tuning data, this output enables LLMs to converse with humans more effectively.</p><p><strong>We're thinking:</strong>&nbsp;AI promises to spread intelligence far and wide. As the authors acknowledge, further work remains to demonstrate this work’s efficacy, ethics, security, and regulatory compliance in a clinical setting. Yet it’s an exciting glimpse of a world in which medical intelligence is fast, cheap, and widely available.</p>
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 19:57:05 GMT</pubDate>
</item>
<item>
<title>The AI PC Arrives, OpenAI Used For Disinformation, U.S. and China Seek AI Agreement, Training Models to Reason</title>
<link>https://www.deeplearning.ai/the-batch/issue-252</link>
<guid>https://www.deeplearning.ai/the-batch/issue-252</guid>
<content:encoded><![CDATA[
<div> California, AI models, OpenAI, disinformation, U.S. and China

总结:<br /><br />本文主要关注加州提出的涉及AI模型的法律，指出该法案可能对AI模型构建者造成不合理的责任。同时介绍了OpenAI模型在网络虚假信息活动中的应用情况。另外，文章探讨了美国和中国就AI相关问题进行的对话。最后提出了一个新的学生LMM学习技术，可以通过模仿更大的教师模型来提升学生模型的表现。 <div>
<p>Dear friends,</p><p>The effort to protect innovation and open source continues. I believe we’re all better off if anyone can carry out basic AI research and share their innovations. Right now, I’m deeply concerned about California's proposed law&nbsp;<a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">SB-1047</a>.&nbsp;It’s a long, complex bill with many parts that require safety assessments, shutdown capability for models, and so on.</p><p>There are many things wrong with this bill, but I’d like to focus here on just one: It defines an unreasonable “hazardous capability” designation that may make builders of large AI models potentially liable if someone uses their models to do something that exceeds the bill’s definition of harm (such as causing $500 million in damage). That is practically impossible for any AI builder to ensure. If the bill is passed in its present form, it will stifle AI model builders, especially open source developers.&nbsp;</p><p>Some AI applications, for example in healthcare, are risky. But as I wrote&nbsp;<a href="https://www.deeplearning.ai/the-batch/keep-open-source-free/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">previously</a>, regulators should regulate&nbsp;<em>applications</em>&nbsp;rather than&nbsp;<em>technology</em>.&nbsp;</p><ul><li>Technology refers to tools that can be applied in many ways to solve various problems.</li><li>Applications are specific implementations of technologies designed to meet particular customer needs.</li></ul><p>For example, an electric motor is a technology. When we put it in a blender, an electric vehicle, dialysis machine, or guided bomb, it becomes an application. Imagine if we passed laws saying, if anyone uses a motor in a harmful way, the motor manufacturer is liable. Motor makers would either shut down or make motors so tiny as to be useless for most applications. If we pass such a law, sure, we might stop people from building guided bombs, but we’d also lose blenders, electric vehicles, and dialysis machines.&nbsp;In contrast, if we look at specific applications, like blenders, we can more rationally assess risks and figure out how to make sure they’re safe, and even ban classes of applications, like certain types of munitions.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed--62--1.jpg" width="1200" /></figure><p>Safety is a property of applications, not a property of technologies (or models), as Arvind Narayanan and Sayash Kapoor have&nbsp;<a href="https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">pointed out</a>. Whether a blender is a safe one can’t be determined by examining the electric motor. A similar argument holds for AI. &nbsp;</p><p>SB-1047 doesn’t account for this distinction. It ignores the reality that the number of beneficial uses of AI models is, like electric motors, vastly greater than the number of harmful ones. But, just as no one knows how to build a motor that can’t be used to cause harm, no one has figured out how to make sure an AI model can’t be adapted to harmful uses. In the case of open source models, there’s no known defense to fine-tuning to remove RLHF alignment. And jailbreaking work has shown that even closed-source, proprietary models that have been properly aligned can be attacked in ways that make them give harmful responses. Indeed, the sharp-witted&nbsp;<a href="https://x.com/elder_plinius?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Pliny the Prompter</a>&nbsp;regularly tweets about jailbreaks for closed models. Kudos also to Anthropic’s Cem Anil and collaborators for publishing their work on&nbsp;<a href="https://www.anthropic.com/research/many-shot-jailbreaking?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">many-shot jailbreaking</a>, an attack that can get leading large language models to give inappropriate responses and is hard to defend against.&nbsp;</p><p>California has been home to a lot of innovation in AI. I’m worried that this anti-competitive, anti-innovation proposal has gotten so much traction in the legislature. Worse, other jurisdictions often follow California, and it would be awful if they were to do so in this instance.</p><p>SB-1047 passed in a key vote in the State Senate in May, but it still has additional steps before it becomes law. I hope you will speak out against it if you get a chance to do so.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/06/The-Batch-ads-and-exclusive-banners---2024-06-04T083916.036.png" width="1680" /></a></figure><p>In this course, you’ll learn how to build and implement highly controllable AI agents with LangGraph and use agentic search to enhance your agents’ built-in knowledge.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll today</a>&nbsp;</p><hr /><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-05T180415.022.png" width="600" /></figure><h1 id="rise-of-the-ai-pc">Rise of the AI PC</h1><p>Generative AI plays a starring role in the latest Windows PCs.</p><p><strong>What’s new:</strong>&nbsp;Microsoft&nbsp;<a href="https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">introduced</a>&nbsp;its Copilot+ PCs, an AI-first laptop specification that offers features unavailable to other Windows users. Copilot+ PCs will be available from Microsoft as well as Acer, Asus, Dell, HP, Lenovo, and Samsung starting in mid-June.<br /><br /><strong>How it works:</strong>&nbsp;Copilot+ PCs provide AI-powered generative and search functions thanks to unnamed AI models that run on-device.&nbsp;</p><ul><li>A feature called&nbsp;<a href="https://learn.microsoft.com/en-us/windows/ai/apis/recall?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Recall</a>&nbsp;enables users to search their activities in apps, documents, and websites to find, say, topics discussed in a text conversation or items viewed on a website. Every five seconds, the PC takes a screenshot of its current status. Users can browse the timeline of screenshots or call an unidentified AI model to find images and/or text via a&nbsp;<a href="https://learn.microsoft.com/en-us/microsoftsearch/semantic-index-for-copilot?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">semantic index</a>.</li><li>Other features include Cocreator, which generates images from text prompts using models that run on-device, and Live Captions, which generates subtitles for English-language audio in any of 40 languages.</li><li>Developers have access to these features via a software stack called Windows Copilot Runtime. This includes&nbsp;<a href="https://learn.microsoft.com/en-us/windows/ai/apis/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Copilot Library</a>, a set of APIs that call more than 40 models that run on-device, and&nbsp;<a href="https://github.com/microsoft/DiskANN?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">DiskANN</a>, a set of search algorithms that quickly sort through a vector database.</li><li>The first machines will be based on the&nbsp;<a href="https://www.tomsguide.com/computing/snapdragon-x-plus?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Qualcomm Snapdragon X</a>&nbsp;processor. The chip comes with 10 and 12 CPU cores, a&nbsp;<a href="https://www.qualcomm.com/products/features/adreno?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">GPU</a>&nbsp;and a&nbsp;<a href="https://www.qualcomm.com/developer/software/hexagon-npu-sdk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">neural processing unit</a>&nbsp;(NPU) that accelerates neural networks while using less energy and memory than a typical CPU or GPU.</li></ul><p><strong>Nvidia’s rejoinder:</strong>&nbsp;Nvidia&nbsp;<a href="https://www.theverge.com/2024/6/2/24169568/microsoft-copilot-plus-gaming-pc-nvidia-amd?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">plans</a>&nbsp;to launch Copilot+-compatible RTX AI PCs that run Nvidia’s own&nbsp;<a href="https://developer.nvidia.com/rtx/ai-toolkit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">toolkit</a>&nbsp;for calling and customizing models with on-device GPUs. These computers, initially built by Asus and MSI based on AMD CPUs, eventually will deliver all Copilot+ features. Nvidia&nbsp;<a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidia-criticizes-ai-pcs-says-microsofts-45-tops-requirement-is-only-good-enough-for-basic-ai-tasks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">criticized</a>&nbsp;Microsoft’s NPU specification, which calls for 45 trillion operations per second (TOPS), claiming that that speed is enough to process only basic AI workloads. Meanwhile, Nvidia’s game-focused GPUs&nbsp;<a href="https://www.theverge.com/2024/6/2/24169568/microsoft-copilot-plus-gaming-pc-nvidia-amd?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">deliver</a>&nbsp;more than 1,000 TOPS.</p><p><strong>Why it matters:</strong>&nbsp;Microsoft is betting that on-device AI will change the PC experience. The Copilot+ PC specification gives developers a versatile toolkit for adding AI to existing apps while opening the door to fundamentally new functionality like Recall.</p><p><strong>We’re thinking:</strong>&nbsp;As we&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-ai-will-move-to-edge-devices/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">wrote</a>&nbsp;earlier, makers of chips and operating systems alike have a strong incentive to promote on-device (or edge) AI. The growing presence of AI accelerators in consumer devices brings significant privacy benefits for consumers and opens exciting new opportunities for developers.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-05T180448.900.png" width="600" /></figure><h1 id="disinformation-documented">Disinformation Documented</h1><p>OpenAI models were used in five disinformation campaigns, the company said.</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/index/disrupting-deceptive-uses-of-AI-by-covert-influence-operations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">discovered</a>&nbsp;that operations based in Russia, China, Iran, and Israel had used the company’s models to create and/or revise text in attempts to influence international political opinion. The generated media failed to reach a mass audience, the company said. It banned the accounts.</p><p><strong>How it works:</strong>&nbsp;Most of the groups primarily used OpenAI’s language models to generate inauthentic social media comments for posting on dummy accounts intended to create the illusion of popular support for certain causes. Some groups used the company’s models to debug code, generate text for websites, and produce images such as political cartoons. Four of the five groups already were known to disinformation researchers.</p><ul><li>A Russian organization previously unknown to researchers generated large volumes of pro-Russia and anti-Ukraine comments in Russian and English and distributed them via messaging service Telegram. The comments often included poor grammar or telltale phrases such as, “As an AI model, . . .”&nbsp;</li><li>Another Russian group that researchers call&nbsp;<a href="https://www.disinfo.eu/doppelganger-operation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Doppelganger</a>&nbsp;generated pro-Russia social media comments in English, French, and German. It also used OpenAI models to translate articles from Russian into other languages for publication on websites. Doppelganger used a third-party API to circumvent OpenAI’s restrictions on Russian users. OpenAI has suspended the API.</li><li>A Chinese operation known to researchers as&nbsp;<a href="https://graphika.com/reports/spamouflage?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Spamouflage</a>&nbsp;generated Chinese-language social media comments that supported the Chinese government. It also used OpenAI technology to debug code for a website dedicated to criticizing opponents of the government.</li><li>An Iranian organization called the International Union of Virtual Media (IUVM) generated English and French articles, headlines, and other text for its website. IUVM is&nbsp;<a href="https://www.reuters.com/article/idUSKCN1LD2R7/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">considered</a>&nbsp;a mouthpiece for the Iranian government.</li><li>STOIC, an Israeli company that runs political social media campaigns, generated articles and social media comments. It also created fictitious bios for inauthentic social media accounts that included images apparently created by other AI models. STOIC created both pro-Israel and anti-Palestine comments as well as comments critical of India’s ruling Bharatiya Janata Party.</li></ul><p><strong>Behind the news:</strong>&nbsp;AI-produced misinformation on the internet — mostly images, videos, and audio clips — rose sharply starting in the first half of 2023, research&nbsp;<a href="https://arxiv.org/abs/2405.11697?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">found</a>&nbsp;at Google and several fact-checking organizations. By the end of that year, generative AI was responsible for more than 30 percent of media that was manipulated by computers.<br /><br /><strong>Why it matters:</strong>&nbsp;Many observers are concerned about potential proliferation of political disinformation as AI models that generate realistic text, images, video, and audio become widely available. This year will see elections in at least 64 countries including most of the world’s most populous nations — a rich opportunity for AI-savvy propagandists. While propagandists have taken advantage of OpenAI’s models, the company was able to detect them and shut them down. More such efforts are bound to follow.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Generative AI’s potential to fuel propaganda is worth tracking and studying. But it’s also worth noting that the accounts identified by OpenAI failed to reach significant numbers of viewers or otherwise have an impact. So far, at least, distribution, not generation, continues to be the limiting factor on disinformation.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/06/unnamed---2024-06-05T180527.254.png" width="1200" /></figure><h1 id="us-and-china-seek-ai-agreement">U.S. and China Seek AI Agreement</h1><p>The United States and China opened a dialogue to avert hypothetical AI catastrophes.<br /><br /><strong>What’s new:</strong>&nbsp;Officials of the two nations met in Geneva for an initial conversation intended to prevent AI-driven accidents or worse,&nbsp;<em>The Washington Post</em>&nbsp;<a href="https://www.washingtonpost.com/technology/2024/05/13/us-china-ai-talks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;The meeting followed up on a November meeting between U.S. president Joe Biden and Chinese president Xi Jinping. The discussion was conceived as an opportunity for the nuclear-armed superpowers, both of which have pegged their strategic ambitions to AI technology, to air their concerns. It resulted in no public statements about concrete actions or commitments.</p><ul><li>The meeting aimed to prevent a “miscalculation” that might lead to unintended conflict,&nbsp;<a href="https://www.ft.com/content/e10b034d-ac25-476c-b3a5-c09aae8eb7f9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">U.S. officials</a>&nbsp;said. They ruled out the possibility that it might promote technical collaboration.</li><li>U.S. diplomats wished to discuss China’s “misuse” of AI, a U.S. government spokesperson&nbsp;<a href="https://www.whitehouse.gov/briefing-room/statements-releases/2024/05/15/statement-from-nsc-spokesperson-adrienne-watson-on-the-u-s-prc-talks-on-ai-risk-and-safety-2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">said</a>&nbsp;without further clarification. Chinese envoys expressed dissatisfaction with “U.S. restrictions and pressure in the field of artificial intelligence,” such as U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">restrictions</a>&nbsp;on the sale of AI chips to Chinese customers.</li><li>Neither side indicated whether or when further meetings would occur.</li></ul><p><strong>Behind the news:&nbsp;</strong>AI-related tensions between the two countries have intensified in recent years. The U.S. government, in an effort to maintain its technological advantage and hamper China’s AI development, has&nbsp;<a href="https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">imposed</a>&nbsp;controls on the export of specialized AI chips like the Nvidia A100 and H100 to Chinese customers. Restrictions on the development of models that bear on U.S. national security may&nbsp;<a href="https://www.reuters.com/technology/us-lawmakers-unveil-bill-make-it-easier-restrict-exports-ai-models-2024-05-10/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">follow</a>&nbsp;if further proposed export controls are enacted. Such controls have&nbsp;<a href="https://www.scmp.com/comment/opinion/article/3228220/china-fed-us-sanctions-hitting-back-export-controls-and-more-could-come?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">rankled</a>&nbsp;the Chinese government. Meanwhile,&nbsp;<a href="https://www.airandspaceforces.com/kendall-ai-piloted-flight-embrace-autonomy/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">both</a>&nbsp;<a href="https://www.deeplearning.ai/the-batch/meet-zhuhaiyun-the-chinese-navys-new-autonomous-ship/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">countries</a>&nbsp;have developed and deployed autonomous military vehicles, and autonomous weapons are&nbsp;<a href="https://www.nature.com/articles/d41586-024-01029-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">proliferating</a>. In November 2023, both countries signed the Bletchley Park&nbsp;<a href="https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">declaration</a>&nbsp;to mitigate AI-related risks including cybersecurity, biotechnology, and misinformation.<br /><br /><strong>What they’re saying:</strong>&nbsp;“The real verdict on whether these talks were successful will be whether they continue into the future.” — Helen Toner, analyst at Georgetown University’s Center for Security and Emerging Technology and former OpenAI board member,&nbsp;<a href="https://apnews.com/article/artificial-intelligence-china-united-states-biden-xi-geneva-506da7b5fa72d5fe1bcd54fb8ec4f898?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">quoted</a>&nbsp;by Associated Press.</p><p><strong>Why it matters:</strong>&nbsp;Officials and observers alike worry that rivalry between the U.S. and China may lead to severe consequences. However, just as the&nbsp;<a href="https://en.wikipedia.org/wiki/Moscow%E2%80%93Washington_hotline?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">red telephone</a>&nbsp;enabled U.S. and Soviet leaders to communicate during emergencies in the Cold War, face-to-face dialogue can help bring the two countries into alignment around AI-related risks and ways to reduce them.</p><p><strong>We’re thinking:&nbsp;</strong>We support harmonious relations between the U.S. and China, but we’re deeply concerned that export controls could stifle open source software. This might slow down China’s progress in AI, but would also hurt the U.S. and its allies.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="400" src="https://dl-staging-website.ghost.io/content/images/2024/06/REASONv2-2.gif" width="600" /></figure><h1 id="better-teachers-make-better-students">Better Teachers Make Better Students</h1><p>A relatively small student LLM that learns to mimic a larger teacher model can perform nearly as well as the teacher while using much less computation. It can come even closer if the teacher also teaches reasoning techniques.</p><p><strong>What’s new:</strong>&nbsp;Arindam Mitra and colleagues at Microsoft proposed&nbsp;<a href="https://arxiv.org/abs/2311.11045?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Orca 2</a>, a technique that improves the output of student LLMs an order of magnitude smaller than their teachers.</p><p><strong>Key insight:</strong>&nbsp;Large language models can provide better output when they’re prompted to use a particular reasoning strategy such as think step by step, recall then generate, or explain then generate. Different reasoning strategies may yield better output depending on the task at hand. Moreover, given the same task, different models may perform better using different reasoning strategies. Consequently, in a teacher-student situation, the teacher and student models may need to use different strategies to achieve their highest performances on a given task. The student will achieve its best performance if it mimics the teacher's reasoning and response when the teacher uses not its own best-performing strategy, but the student’s best-performing strategy.</p><p><strong>How it works:</strong>&nbsp;The teacher, GPT-4, helped generate a fine-tuning dataset to improve the output of the student,&nbsp;<a href="https://arxiv.org/abs/2307.09288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Llama 2</a>&nbsp;(13 billion parameters), both of which had been pretrained. They created the fine-tuning dataset and fine-tuned Llama 2 as follows:</p><ul><li>The authors assembled an initial dataset that included examples (prompts and responses) of roughly 1,500 tasks. They drew from datasets including&nbsp;<a href="https://arxiv.org/abs/2109.01652?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">FLAN</a>&nbsp;(which includes text classification, math questions, logic questions, and multiple choice questions), math problems from 10 datasets not in FLAN, few-shot prompts in the&nbsp;<a href="https://arxiv.org/abs/2306.02707?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">Orca</a>&nbsp;dataset, and summarizations generated using GPT-4.</li><li>The authors fed each prompt to Llama 2 using each of several reasoning strategies including direct answer, think step by step, explain then answer, and more. (The authors don’t specify all the strategies they used.) They measured its performance on each task per reasoning strategy.</li><li>For each task, they prompted GPT-4 with all examples of that task, specifying the reasoning strategy that had enabled Llama 2 to achieve its highest performance on that task. In this way, GPT-4 augmented the dataset to include, for each prompt, both the response and the reasoning it used to arrive at it.&nbsp;</li><li>They fine-tuned Llama 2, given a prompt — without specifying the reasoning strategy — to produce the detailed reasoning and response generated by GPT-4.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared their model to models of similar size including WizardLM-13B (also based on Llama 2) and larger models including GPT-3.5 Turbo (an order of magnitude larger) and GPT-4 (parameter count undisclosed). They evaluated the percentage of correct responses on average over six reasoning benchmarks such as&nbsp;<a href="https://arxiv.org/pdf/2304.06364.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">AGIEval</a>, which includes multiple-choice and fill-in-the-blank questions from the Scholastic Aptitude Test, American Mathematics Competitions, and other tests designed for humans. Their model exactly matched the correct answer 66.92 percent of the time compared to WizardLM-13B (50.32 percent). It performed nearly as well as the 10x larger GPT-3.5 Turbo (which achieved 67.65 percent) but much less well than GPT-4 (which achieved 79.03 percent).</p><p><strong>Why it matters:</strong>&nbsp;Learning how to reason is an important complement to learning facts and perspectives. A model that has been trained to reason using its most effective strategy generally will provide better output. Users don’t need to tell it which strategy to apply. They can simply enter a prompt, and the model will figure out how to reason its response.</p><p><strong>We’re thinking:</strong>&nbsp;Perhaps a similar approach could be used to prompt a model to improve its own output. In effect, this would be similar to an agentic workflow designed to enable a model to produce its own training data, as recently&nbsp;<a href="https://www.deeplearning.ai/the-batch/issue-247/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9fI9QstXaP4Ymya088giiFna5q8Io3XAtE183kvRgxaoDPVHs0eH9nRwmx06I7I6QFVfQu" rel="noopener">described</a>&nbsp;in&nbsp;<em>The Batch</em>.</p>
]]></content:encoded>
<pubDate>Wed, 05 Jun 2024 23:09:39 GMT</pubDate>
</item>
<item>
<title>Heart-Risk Model Saves Lives, Self-Driving on Unruly Roads, Knowledge Workers Embrace AI, Richer Context for RAG</title>
<link>https://www.deeplearning.ai/the-batch/issue-251</link>
<guid>https://www.deeplearning.ai/the-batch/issue-251</guid>
<content:encoded><![CDATA[
<div> evaluations, AI applications, limitations, improvements, RAG

总结:<br /><br />
本文讨论了评估生成式AI的困难，特别是定制AI应用程序生成自由文本的评估。作者提出了加入事实检查代理是否能提高结果的问题，并指出当前评估方法的局限性。文章介绍了针对大型语言模型的评估工具和针对基于LLMs构建的应用程序的评估方法的挑战。此外，还介绍了新颖的AI应用领域，包括心脏风险模型在医院中拯救生命、印度自动驾驶汽车技术的发展、知识工作者对AI的接受程度和RAG技术的创新。整体来说，文章呼吁创新改进评估方法，以推动AI应用程序的发展。 <div>
<p>Dear friends,</p><p>A barrier to faster progress in generative AI is evaluations (evals), particularly of custom AI applications that generate free-form text. Let’s say you have a multi-agent research system that includes a researcher agent and a writer agent. Would adding a fact-checking agent improve the results? If we can’t efficiently evaluate the impact of such changes, it’s hard to know which changes to keep.</p><p>For evaluating general-purpose foundation models such as large language models (LLMs) — which are trained to respond to a large variety of prompts — we have standardized tests like MMLU (multiple-choice questions that cover 57 disciplines like math, philosophy, and medicine) and HumanEval (testing code generation). We also have the&nbsp;<a href="https://chat.lmsys.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">LMSYS Chatbot Arena</a>, which pits two LLMs’ responses against each other and asks humans to judge which response is superior, and large-scale benchmarking like&nbsp;<a href="https://crfm.stanford.edu/helm/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">HELM</a>. These evaluation tools took considerable effort to build, and they are invaluable for giving LLM users a sense of different models’ relative performance. Nonetheless, they have limitations. For example, leakage of benchmarks datasets’ questions and answers into training data is a constant worry, and human preferences for certain answers does not mean those answers are more accurate.</p><p>In contrast, our current options for evaluating applications built using LLMs are far more limited. Here, I see two major types of applications.&nbsp;</p><ul><li>For applications designed to deliver unambiguous, right-or-wrong responses, we have reasonable options. Let’s say we want an LLM to read a resume and extract the candidate’s most recent job title, or read a customer email and route it to the right department. We can create a test set that comprises ground-truth labeled examples with the right responses and measure the percentage of times the LLM generates the right output. The main bottleneck is creating the labeled test set, which is expensive but surmountable.</li><li>But many LLM-based applications generate free-text output with no single right response. For example, if we ask an LLM to summarize customer emails, there’s a multitude of possible good (and bad) responses. The same holds for an agentic system to do web research and write an article about a topic, or a RAG system for answering questions. It’s impractical to hire an army of human experts to read the LLM’s outputs every time we tweak the algorithm and evaluate if the answers have improved; we need an automated way to test the outputs. Thus, many teams use an advanced language model to evaluate outputs. In the customer email summarization example, we might design an evaluation rubric (scoring criteria) for what makes a good summary. Given an email summary generated by our system, we might prompt an advanced LLM to read it and score it according to our rubric. I’ve found that the results of such a procedure, while better than nothing, can also be noisy — sometimes too noisy to reliably tell me if the way I’ve tweaked an algorithm is good or bad.</li></ul><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--61-.jpg" width="1200" /></figure><p>The cost of running evals poses an additional challenge. Let’s say you’re using an LLM that costs $10 per million input tokens, and a typical query has 1000 tokens. Each user query therefore costs only $0.01. However, if you iteratively work to improve your algorithm based on 1000 test examples, and if in a single day you evaluate 20 ideas, then your cost will be 20*1000*0.01 = $200. For many projects I’ve worked on, the development costs were fairly negligible until we started doing evals, whereupon the costs suddenly increased. (If the product turned out to be successful, then costs increased even more at deployment, but that was something we were happy to see!)&nbsp;</p><p>Beyond the dollar cost, evals have a significant time cost. Running evals on 1000 examples might take tens of minutes or even hours. Time spent waiting for eval jobs to finish also slows down the speed with which we can experiment and iterate over new ideas. In an earlier letter, I&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-we-need-more-compute-for-inference/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">wrote</a>&nbsp;that fast, inexpensive token generation is critical for agentic workflows. It will also be useful for evals, which involve nested for-loops that iterate over a test set and different model/hyperparameter/prompt choices and therefore consume large numbers of tokens.&nbsp;</p><p>Despite the limitations of today’s eval methodologies, I’m optimistic that our community will invent better techniques (maybe involving agentic workflows like&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">reflection</a>&nbsp;for getting LLMs to evaluate such output.&nbsp;</p><p>If you’re a developer or researcher and have ideas along these lines, I hope you’ll keep working on them and consider open sourcing or publishing your findings.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p></p><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-05-22T112453.236.png" width="1680" /></a></figure><p>Learn how to build and customize multi-agent systems in “AI Agentic Design Patterns with AutoGen,” made in collaboration with Microsoft and Penn State University. Use the AutoGen framework and implement four agentic design patterns: Reflection, Tool Use, Planning, and Multi-Agent Collaboration.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up for free</a>&nbsp;</p><hr /><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-29T152617.317.png" width="1200" /></figure><h1 id="heart-risk-model-saves-lives">Heart-Risk Model Saves Lives</h1><p>A deep learning model significantly reduced deaths among critically ill hospital patients.</p><p><strong>What’s new:</strong>&nbsp;A system built by Chin-Sheng Lin and colleagues at Taiwan’s National Defense Medical Center analyzed patients’ heart signals and alerted physicians if it detected a high risk of death. It&nbsp;<a href="https://www.nature.com/articles/s41591-024-02961-4.epdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">reduced</a>&nbsp;deaths of high-risk patients by 31 percent in a randomized clinical trial.</p><p><strong>How it works:</strong>&nbsp;Researchers&nbsp;<a href="https://journals.sagepub.com/doi/10.1177/20552076231187247?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">trained</a>&nbsp;a convolutional neural network, given an electrocardiogram (a measurement of the heart’s electrical activity), to&nbsp;<a href="https://en.wikipedia.org/wiki/Proportional_hazards_model?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">estimate</a>&nbsp;a risk score. The system compares a patient’s risk score against those of other patients. Scores that rank in the 95th percentile or higher are considered high risk of death within 90 days.</p><ul><li>The authors tested the system on 16,000 patients at two hospitals for 90 days.</li><li>Patients in the experimental group were measured by electrocardiograms, which were fed to the system. If the system identified a high-risk patient, it alerted their attending physician.</li><li>The control group received typical care. The model monitored their electrocardiograms, but physicians saw its output only after the trial was over.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;8.6 percent of patients in the control group and 8.9 percent of patients in the experimental group raised a high-risk alert during the trial. In the experimental group, 16 percent of high-risk patients died; in the control group, 23 percent of high-risk patients died. Overall, in the experimental group, 3.6 percent of patients died; in the control group, 4.3 percent of patients died. The model was trained to predict mortality from all causes, but it showed unusually strong predictive capability for heart-related deaths. Examining causes of death, the authors found that 0.2 percent of patients in the experimental group died from heart-related conditions such as cardiac arrest versus 2.4 percent in the control group.<br /><br /><strong>Behind the news:</strong>&nbsp;Hospitals use AI-powered alert systems to&nbsp;<a href="https://www.deeplearning.ai/the-batch/managing-medical-uncertainty/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">identify</a>&nbsp;patients in need of urgent medical attention. Such systems monitor emergency room patients for sepsis, predict whether those patients need intensive care, and predict the risk that discharged patients will require further care. They help hospitals to allocate resources by directing attention where it’s needed most urgently.<br /><br /><strong>Why it matters:</strong>&nbsp;It’s rare for any kind of medical intervention to reduce mortality in a subgroup by 31 percent. The authors speculate that the system not only helped direct attention to patients urgently in need of attention but also may have identified electrocardiogram features that doctors typically either don’t understand well or can’t detect.</p><p><strong>We’re thinking:</strong>&nbsp;This relatively low-cost AI system unambiguously saved lives over three months at different hospitals! We look forward to seeing it scale up.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-29T152721.294.gif" width="600" /></figure><h1 id="self-driving-on-indian-roads">Self-Driving on Indian Roads</h1><p>Few makers of self-driving cars have braved the streets of India. Native startups are filling the gap.</p><p><strong>What’s new:</strong>&nbsp;Indian developers are testing autonomous vehicles on their nation’s disorderly local roads. To cope with turbulent traffic, their systems use different technology from their Western and East Asian counterparts,&nbsp;<em>IEEE Spectrum</em>&nbsp;<a href="https://spectrum.ieee.org/india-self-driving-car?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;In Indian cities, two-, three-, and four-wheelers share the road with trucks, pedestrians, and animals. Drivers often contend with debris and potholes, and many don’t follow rules. These conditions demand vehicles outfitted with technology that’s more flexible (and less expensive) than the interwoven sensors, models, and 3D maps employed by self-driving cars designed for driving conditions like those found in the United States.</p><ul><li>Where typical self-driving cars combine visible-light cameras, radar, lidar, and GPS, vehicles built by&nbsp;<a href="https://www.swaayattrobots.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Swaayatt Robots</a>&nbsp;view the world solely through off-the-shelf cameras. The company’s software creates a probabilistic representation of their environment. Although this is normally computationally intensive, Swaayatt claims to have found a low-cost way to do it. Trained via multi-agent reinforcement learning, its systems use game theory to model road interactions and computer vision to fill in missing lane markings. A&nbsp;<a href="https://www.youtube.com/watch?v=cdJ1ETCC6fY&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">video</a>&nbsp;shows one of the company’s SUVs navigating narrow roads in its home city of Bhopal.</li><li><a href="https://www.minuszero.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Minus Zero</a>&nbsp;focuses on highway driving. Its&nbsp;<a href="https://www.designboom.com/technology/autonomous-vehicle-zpod-self-driving-minus-zero-ai-artificial-intelligence-12-13-2023/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">zPod</a>&nbsp;vehicle navigates using cameras and a GPS sensor. Rather than a series of models dedicated to a single task such as object detection or motion planning, zPod employs a world model that recognizes important details in its surroundings and plans accordingly. The company&nbsp;<a href="https://www.reuters.com/business/autos-transportation/indias-ashok-leyland-partners-with-minus-zero-develop-self-driving-trucks-2024-03-19/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">partnered</a>&nbsp;with Indian truck manufacturer Ashok Leyland to deploy the technology in the next several years.</li><li><a href="https://rosh.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">RoshAI</a>&nbsp;specializes in retrofitting existing vehicles with autonomous capabilities. It offers separate systems that map a vehicle’s surroundings, control speed and steering, and generate simulations for testing. It aims to retrofit conventional vehicles at lower cost than the price of an integrated self-driving car.</li></ul><p><strong>Behind the news:</strong>&nbsp;Bringing self-driving cars to India has political as well as technical dimensions. Many Indians hire full-time drivers, and the country’s minister of roads and highways has&nbsp;<a href="https://www.hindustantimes.com/car-bike/around-80-lakh-drivers-will-become-jobless-gadkari-again-says-will-not-allow-autonomous-cars-in-india-101702884761198.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">resisted</a>&nbsp;approving the technology because of its potential impact on those jobs. Drivers cost as little as $150 per month, which puts self-driving car makers under pressure to keep their prices very low. Moreover, India’s government insists that vehicles sold there must be manufactured locally, posing a barrier to foreign makers of self-driving cars.</p><p><strong>Why it matters:</strong>&nbsp;Rather than starting with an assumption that traffic follows orderly patterns with many edge cases, Indian developers assume that traffic is essentially unpredictable. For them, events that most developers would consider outliers — vehicles approaching in the wrong lanes, drivers who routinely play chicken, domestic animals in the way — are common. This attitude is leading them to develop robust self-driving systems that not only may be better suited to driving in complex environments but also may respond well to a broader range of conditions.</p><p><strong>We’re thinking:</strong>&nbsp;Former Uber CEO Travis Kalanick&nbsp;<a href="https://www.firstpost.com/tech/news-analysis/uber-ceo-travis-kalanick-says-india-will-be-the-last-place-to-get-autonomous-cars-3694283.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">said</a>&nbsp;that India would be “the last one” to get autonomous cars. These developers may well prove him wrong!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-29T152833.184.gif" width="1200" /></figure><h1 id="knowledge-workers-embrace-ai">Knowledge Workers Embrace AI</h1><p>AI could offer paths to promotion and relief from busywork for many knowledge workers.</p><p><strong>What’s new:</strong>&nbsp;75 percent of knowledge workers worldwide use AI even if they need to supply their own tools, according to&nbsp;<a href="https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">survey</a>&nbsp;conducted by Microsoft and Linkedin.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors questioned 3,800 workers in 31 countries throughout the Americas, Europe, Asia, and Australia, asking whether and how they used consumer-grade generative systems like Microsoft Copilot and OpenAI ChatGPT. Majorities of all age groups used AI at work, including 85 percent of respondents 28 or younger and 73 percent of those 58 or older.&nbsp;</p><ul><li>Of those who said they used AI at work, 46 percent had started within the past six months, and 78 percent had started without mandates from employers or managers. More than 80 percent said AI tools helped them save time, focus on the most important work, be more creative, and enjoy work more.</li><li>One motivation for using AI was to keep up with basic tasks such as replying to emails and summarizing meetings. In a separate survey, Microsoft found that, over six months, Copilot users spent more time working in creative applications than managing work communications and created or edited 10 percent more documents in Word, Excel, or PowerPoint.</li><li>The survey identified a group that had used AI several times a week and saved at least 30 minutes daily. These users were 68 percent more likely than average to experiment with different ways to use AI and 66 percent more likely to redesign their workflows. Such users were 53 percent more likely to have received encouragement and training in AI from their employer.&nbsp;</li><li>Some employees saw AI as a double-edged sword. 53 percent worried that it made them replaceable. 52 percent of AI users were reluctant to admit using AI for important tasks. Yet 69 percent said that AI could help them get promoted more quickly, and 76 percent said they needed AI skills to stay competitive in the job market.</li><li>66 percent of executives at the vice president level or above said they wouldn’t hire an applicant who didn’t know how to use basic generative AI tools. Junior and less-experienced candidates were more likely to get hired and receive increased responsibility if they had AI skills. Hiring managers reported updating job descriptions and requirements appropriately.</li></ul><p><strong>Behind the news:</strong>&nbsp;The survey results agree with those of other studies of AI’s impact on the workplace. In January, the International Monetary Fund&nbsp;<a href="https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">projected</a>&nbsp;that AI would affect 40 percent of all jobs worldwide (either complementing or replacing them), including 60 percent of jobs in countries like the UK and U.S. that have greater percentages of knowledge workers. A 2023 research paper&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-occupations-likely-to-be-most-affected-by-language-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">argued</a>&nbsp;that white-collar occupations were most likely to be affected by generative AI, in contrast to previous waves of automation that primarily affected blue-collar jobs. Automation driven by AI increased overall employment, evidence gathered by the European Central Bank&nbsp;<a href="https://www.deeplearning.ai/the-batch/european-central-bank-study-finds-surprising-growth-in-jobs-affected-by-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">shows</a>.</p><p><strong>Why it matters:</strong>&nbsp;AI is transforming work from the bottom up. Executives and managers want employees who know how to use the technology, but only 39 percent of the people who already do so received training from their employers. Company-wide encouragement to experiment with and take advantage of AI leads to the best outcomes.</p><p><strong>We’re thinking:</strong>&nbsp;Knowing how to use AI tools is a plus in the current job market. Knowing how to build applications using AI opens another world of doors.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="400" src="https://dl-staging-website.ghost.io/content/images/2024/06/RAPTORv2-1.gif" width="600" /></figure><h1 id="richer-context-for-rag">Richer Context for RAG</h1><p>Text excerpts used in retrieval augmented generation (RAG) tend to be short. Researchers used summarization to pack more relevant context into the same amount of text.</p><p><strong>What’s new:&nbsp;</strong>Parth Sarthi and colleagues at Stanford built&nbsp;<a href="https://arxiv.org/abs/2401.18059?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Recursive Abstractive Processing for Tree-Organized Retrieval</a>&nbsp;(RAPTOR), a retrieval system for LLMs. RAPTOR can choose to deliver original text or summaries at graduated levels of detail, depending on the LLM’s maximum input length.</p><p><strong>Key insight:</strong>&nbsp;RAG improves the output of large language models by gathering from documents and/or web pages excerpts that are relevant to a user’s prompt. These excerpts tend to be brief to avoid exceeding an LLM’s maximum input length. For instance, Amazon Bedrock’s default excerpt length is 200 tokens (words or parts of a word). But important details may be scattered throughout longer passages, so short excerpts can miss them. A summarizer can condense longer passages into shorter ones, and summarizing summaries can condense large amounts of text into short passages.</p><p><strong>How it works:</strong>&nbsp;RAPTOR retrieved material from&nbsp;<a href="https://arxiv.org/abs/2105.03011?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">QASPER</a>, a question answering corpus that contains around 1,600 research papers on natural language processing. The authors processed QASPER through an iterative cycle of summarizing, embedding, and clustering. The result was a graduated series of summaries at ever higher levels of abstraction.</p><ul><li>The authors divided the corpus into excerpts of 100 tokens each. The&nbsp;<a href="https://aclanthology.org/D19-1410.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">SBERT</a>&nbsp;encoder embedded the excerpts.&nbsp;</li><li>A&nbsp;<a href="https://link.springer.com/referenceworkentry/10.1007/978-0-387-73003-5_196?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Gaussian mixture model</a>&nbsp;(GMM) clustered the embeddings into groups of similar excerpts.&nbsp;<a href="https://platform.openai.com/docs/models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">GPT-3.5-turbo</a>&nbsp;summarized each group of excerpts.&nbsp;</li><li>This cycle repeated — SBERT embedded the summaries, GMM clustered the embeddings into groups, and&nbsp;<a href="https://platform.openai.com/docs/models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">GPT-3.5-turbo</a>&nbsp;&nbsp;summarized each group of summaries — until no further groups could be formed.&nbsp;</li><li>At inference, to retrieve passages relevant to a user’s prompt, the system computed the cosine similarity between SBERT’s embedding of the prompt and the embedding of each excerpt and summary. It ranked the excerpts and summaries according to their similarity to the prompt, retrieved the highest-scoring ones, and prepended them to the input. It stopped when adding another excerpt or summary would exceed the LLM’s maximum input length.&nbsp;</li><li>The LLM received the concatenated prompt plus excerpts and/or summaries and generated its response.</li></ul><p><strong>Results:</strong>&nbsp;Paired with a variety of LLMs, RAPTOR exceeded other retrievers in RAG performance on QASPER’s test set. Paired with the&nbsp;<a href="https://aclanthology.org/2020.findings-emnlp.171/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">UnifiedQA</a>&nbsp;LLM, RAPTOR achieved 36.7 percent&nbsp;<a href="https://aclanthology.org/D16-1264.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">F1 score</a>&nbsp;(here, the percentage of tokens in common between the output and ground truth), while SBERT (with access to only the 100-token excerpts) achieved 36.23 percent F1 score. Paired with GPT-4, RAPTOR achieved 55.7 percent F1 score (setting a new state of the art for QASPER),&nbsp;<a href="https://aclanthology.org/2020.emnlp-main.550/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">DPR</a>&nbsp;achieved 53.0 percent F1 score, and providing paper titles and abstracts achieved 22.2 percent F1 score.</p><p><strong>Why it matters:</strong>&nbsp;Recent LLMs can process very long inputs, notably&nbsp;<a href="https://deepmind.google/technologies/gemini/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Gemini 1.5</a>&nbsp;(up to 2 million tokens) and&nbsp;<a href="https://www.anthropic.com/news/claude-3-family?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--7E9rghpH8hgDEBV2C5pyiXXeAIJY6LnrVppijwY-3E1T3PURd5sLMLgkuo5131igbto6Y" rel="noopener">Claude 3</a>&nbsp;(200,000 tokens). But it takes time to process so many tokens. Further, prompting with long inputs can be expensive, approaching a few dollars for a single prompt in extreme cases. RAPTOR enables models with tighter input limits to get more context from fewer tokens.</p><p><strong>We’re thinking:</strong>&nbsp;This may be the technique that developers who struggle with input context length have been long-ing for!</p>
]]></content:encoded>
<pubDate>Wed, 29 May 2024 20:31:32 GMT</pubDate>
</item>
<item>
<title>Music Industry Titan Targets AI, End-to-End Multimodality, Millions of Tokens of Context, More Responsive Text-to-Image</title>
<link>https://www.deeplearning.ai/the-batch/issue-250</link>
<guid>https://www.deeplearning.ai/the-batch/issue-250</guid>
<content:encoded><![CDATA[
<div> Lego, AI项目, GPT-4o, Gemini 1.5 Pro, Sony Music Group
<br />
AI项目的启动，建议从课程开始，然后进行项目工作。小型周末项目可以帮助学习。建议尝试建立独特项目，如孩子们的乐高创作。GPT-4o和Gemini 1.5 Pro等新模型的发布提供更多选择。索尼音乐集团警告AI开发者尊重版权。总结: 欢迎开始AI学习，建议玩乐高等小项目，关注新AI模型，警惕版权法律问题。 <div>
<p>Dear friends,</p><p>A good way to get started in AI is to start with coursework, which gives a systematic way to gain knowledge, and then to work on projects. For many who hear this advice, “projects” may evoke a significant undertaking that delivers value to users. But I encourage you to set a lower bar and relish small, weekend tinkering projects that let you learn, even if they don’t result in a meaningful deliverable.&nbsp;</p><p>Recently, my son and daughter (ages 3 and 5) were building Lego vehicles. They built a beautiful ice-cream truck as well as a . . . umm . . . colorful and asymmetric dinosaur car, shown in the picture below. While most observers would judge the ice-cream truck as the superior creation, my kids built it by following Lego’s&nbsp;<a href="https://www.lego.com/en-us/product/creative-vehicles-11036?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">instructions</a>, and it is likely identical to thousands of ice-cream trucks built by others. In contrast, building the dinosaur car required creativity and novel thinking. The exercise helped them hone their ability to pick and assemble Lego building blocks.</p><p>There is, of course, room for both mimicking others’ designs (with permission) and coming up with your own. As a parent, I try to celebrate both. (To be honest, I celebrated the dinosaur car more.) When learning to build Lego, it’s helpful to start by following a template. But eventually, building your own unique projects enriches your skills.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T145628.272-1.png" width="1200" /></figure><p>As a developer, too, I try to celebrate unique creations. Yes, it is nice to have beautiful software, and the impact of the output does matter. But good software is often written by people who spend many hours tinkering and building things. By building unique projects, you master key software building blocks. Then, using those blocks, you can go on to build bigger projects.</p><p>I routinely tinker with building AI applications, and a lot of my tinkering doesn’t result in anything useful. My latest example: I built a Streamlit app that would authenticate to Google docs, read the text in a doc, use a large language model to edit my text, and write the result back into the doc. I didn’t find it useful in the end because of friction in the user interface, and I’m sure a commercial provider will soon, if they haven’t already, build a better product than I was able to throw together in a couple of hours on a weekend. But such tinkering helps me hone my intuition and master software components (I now know how to programmatically interface with Google docs) that might be useful in future projects. &nbsp;</p><p>If you have an idea for a project, I encourage you to build it! Often, working on a project will also help you decide what additional skills to learn, perhaps through coursework. To sustain momentum, it helps to find friends with whom to talk about ideas and celebrate projects — large or small.&nbsp;</p><p>Keep tinkering!&nbsp;<br /><br />Andrew&nbsp;&nbsp;</p><p>P.S. On the heels of Microsoft’s announcement of the Copilot+ PC, which uses on-device AI optimized for a Qualcomm chip, we have a short course on deploying on-device AI created with Qualcomm! In “Introduction to On-Device AI,” taught by Qualcomm’s Senior Director of Engineering Krishna Sridhar, you’ll deploy a real-time image segmentation model on-device and learn key steps for on-device deployment: neural network graph capture, on-device compilation, hardware acceleration, and validating on-device numerical correctness.&nbsp;<a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Please sign up here!</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T145727.291.gif" width="1200" /></figure><h1 id="faster-cheaper-multimodality">Faster, Cheaper Multimodality</h1><p>OpenAI’s latest model raises the bar for models that can work with common media types in any combination.<br /><br /><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/index/hello-gpt-4o/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">introduced</a>&nbsp;GPT-4o, a model that accepts and generates text, images, audio, and video — the “o” is for omni — more quickly, inexpensively, and in some cases more accurately than its predecessors. Text and image input and text-only output are available currently via ChatGPT and API, with image output coming soon. Speech input and output will roll out to paying users in coming weeks. General audio and video will be available first to partners before rolling out more broadly.&nbsp;&nbsp;</p><p><strong>How it works:</strong>&nbsp;GPT-4o is a single model trained on multiple media types, which enables it to process different media types and relationships between them faster and more accurately than earlier GPT-4 versions that use separate models to process different media types. The context length is 128,000 tokens, equal to GPT-4 Turbo but well below the 2-million limit newly set by Google Gemini 1.5 Pro.&nbsp;</p><ul><li>The demos are impressive. In a&nbsp;<a href="https://www.youtube.com/watch?v=DQacCB9tDaw&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">video</a>, one of the model’s four optional voices — female, playful, and extraordinarily realistic — narrates a story while adopting different tones from robotic to overdramatic, translates fluidly between English and Italian, and interprets facial expressions captured by a smartphone camera.</li><li>API access to GPT-4o costs half as much as GPT-4 Turbo: $5 per million input tokens and $15 per million output tokens.</li><li>GPT-4o is 2x faster than GPT-4 Turbo on a per-token basis and expected to accelerate to 5x (10 million tokens per minute) in high volumes.&nbsp;</li><li>Audio processing is much faster. GPT-4o responds to audio prompts in 0.3 seconds on average, while ChatGPT’s previous voice mode took 2.8 or 5.4 seconds on average relying on a separate speech-to-text step and then GPT-3.5 or GPT-4, respectively.</li><li>An improved tokenizer makes text processing more token-efficient depending on the language. Gujarati, for instance, requires 4.4x fewer tokens, Telegu 3.5x fewer, and Tamil 3.3x fewer. English, French, German, Italian, Portuguese, and Spanish require between 1.1x and 1.3x fewer tokens.</li></ul><p>GPT-4o significantly outperforms Gemini Pro 1.5 at several benchmarks for understanding text, code, and images including&nbsp;<a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">MMLU</a>,&nbsp;<a href="https://github.com/openai/human-eval?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">HumanEval</a>,&nbsp;<a href="https://mmmu-benchmark.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">MMMU</a>, and&nbsp;<a href="https://www.docvqa.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">DocVQA</a>. It outperformed OpenAI’s own&nbsp;<a href="https://huggingface.co/openai/whisper-large-v3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Whisper-large-v3</a>&nbsp;speech recognition model at speech-to-text conversion and&nbsp;<a href="https://arxiv.org/pdf/2007.10310?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">CoVoST 2</a>&nbsp;language translation.&nbsp;</p><p><strong>Aftershocks:&nbsp;</strong>As OpenAI launched the new model,&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">troubles</a>&nbsp;resurfaced that had led to November’s rapid-fire ouster and reinstatement of CEO Sam Altman. Co-founder and chief scientist Ilya Sutskever, who co-led a team that focused on mitigating long-term risks, resigned. He did not give a reason for his departure; previously he had&nbsp;<a href="https://www.theinformation.com/articles/before-openai-ousted-altman-employees-disagreed-over-ai-safety?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">argued</a>&nbsp;that Altman didn’t prioritize safety sufficiently. The team’s other co-leader Jan Leike followed,&nbsp;<a href="https://x.com/janleike/status/1791498185627865147?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">alleging</a>&nbsp;that the company had a weak commitment to safety. The company promptly&nbsp;<a href="https://www.wired.com/story/openai-superalignment-team-disbanded/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">dissolved</a>&nbsp;the team altogether and redistributed its responsibilities. Potential legal issues also flared when actress Scarlett Johansson, who had declined an invitation to supply her voice for a new OpenAI model, issued a&nbsp;<a href="https://x.com/yashar/status/1792682664845254683?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">statement</a>&nbsp;saying that one of GPT-4o’s voices sounded “eerily” like her own and demanding to know how the artificial voice was built. OpenAI denied that it had used or tried to imitate Johansson’s voice and withdrew that voice option.</p><p><strong>Why it matters:</strong>&nbsp;Competition between the major AI companies is putting more powerful models in the hands of developers and users at a dizzying pace. GPT-4o shows the value of end-to-end modeling for multimodal inputs and outputs, leading to significant steps forward in performance, speed, and cost. Faster, cheaper processing of tokens makes the model more responsive and lowers the barrier for powerful agentic workflows, while tighter integration between processing of text, images, and audio makes multimodal applications more practical.&nbsp;&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Between GPT-4o, Google’s Gemini 1.5, and Meta’s newly announced&nbsp;<a href="https://arxiv.org/html/2405.09818v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Chameleon</a>, the latest models are media omnivores. We’re excited to see what creative applications developers build as the set of tasks such models can perform continues to expand!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="337" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T145823.262.gif" width="600" /></figure><h1 id="2-million-tokens-of-context-more">2 Million Tokens of Context &amp; More</h1><p>Google’s annual I/O developers’ conference brought a plethora of updates and new models.&nbsp;<br /><br /><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://blog.google/technology/developers/gemini-gemma-developer-updates-may-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">announced</a>&nbsp;improvements to its Gemini 1.5 Pro large multimodal model — notably increasing its already huge input context window — as well as new open models, a video generator, and a further step in digital assistants. In addition, Gemini models will power new features in&nbsp;<a href="https://www.euronews.com/next/2024/05/15/google-to-roll-out-ai-generated-summaries-at-top-of-search-engine?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Google Search</a>, Gmail, and Android.</p><p><strong>How it works:</strong>&nbsp;Google launched a variety of new capabilities.</p><ul><li>Gemini 1.5 Pro’s maximum input context window doubled to 2 million tokens of text, audio, and/or video — roughly 1.4 million words, 60,000 lines of code, 2 hours of video, or 22 hours of audio. The 2 million-token context window is available in a “private preview” via Google’s&nbsp;<a href="https://aistudio.google.com/app/waitlist/97595554?utm_source=blog&amp;utm_medium=referral&amp;utm_campaign=keyword&amp;utm_content=&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">AI Studio</a>&nbsp;and&nbsp;<a href="https://cloud.google.com/earlyaccess/cloud-ai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Vertex AI</a>. The 1 million-token context window ($7 per 1 million tokens) is generally available on those services in addition to the previous 128,000 window ($3.50 per 1 million tokens).</li><li><a href="https://deepmind.google/technologies/gemini/flash/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Gemini 1.5 Flash</a>&nbsp;is a faster distillation of Gemini 1.5 Pro that features a 1 million token context window. It’s available in preview via&nbsp;<a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-1.5-flash-preview-0514?pli=1&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Vertex AI</a>. Due to be generally available in June, it will cost $0.35 per million tokens of input for prompts up to 128,000 tokens or $0.70 per million tokens of input for longer prompts.</li><li>The&nbsp;<a href="https://deepmind.google/technologies/veo/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Veo</a>&nbsp;video generator can create videos roughly a minute long at 1080p resolution. It can also alter videos, for instance keeping part of the imagery constant and regenerating the rest. A web interface called VideoFX is available via a&nbsp;<a href="https://aitestkitchen.withgoogle.com/tools/video-fx?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">waitlist</a>. Google plans to roll out Veo to YouTube users.</li><li>Google&nbsp;<a href="https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">expanded</a>&nbsp;the Gemma family of open models. PaliGemma, which is available now, accepts text and images and generates text. Gemma 2, which will be available in June, is a 27 billion-parameter large language model that aims to match the performance of Llama 3 70B at less than half the size.</li><li>Gemini Live is a smartphone app for real-time voice chat. The app can converse about photos or video captured by the phone’s camera — in the video demo shown above, it remembers where the user left her glasses! It’s part of&nbsp;<a href="https://deepmind.google/technologies/gemini/project-astra/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Project Astra</a>, a DeepMind initiative that aims to create real-time, multimodal digital assistants.</li></ul><p><strong>Precautionary measures:</strong>&nbsp;Amid the flurry of new developments, Google&nbsp;<a href="https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">published</a>&nbsp;protocols for evaluating safety risks. The “Frontier Safety Framework” establishes risk thresholds such as a model’s ability to extend its own capabilities, enable a non-expert to develop a potent biothreat, or automate a cyberattack. While models are in development, researchers will evaluate them continually to determine whether they are approaching any of these thresholds. If so, developers will make a plan to mitigate the risk. Google aims to implement the framework by early 2025.</p><p><strong>Why it matters:</strong>&nbsp;Gemini 1.5 Pro’s expanded context window enables developers to apply generative AI to multimedia files and archives that are beyond the capacity of other models currently available — corporate archives, legal testimony, feature films, shelves of books — and supports prompting strategies such as&nbsp;<a href="https://www.deeplearning.ai/the-batch/issue-249/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">many-shot learning</a>. Beyond that, the new releases address a variety of developer needs and preferences: Gemini 1.5 Flash offers a lightweight alternative where speed or cost is at a premium, Veo appears to be a worthy competitor for OpenAI’s Sora, and the new open models give developers powerful options.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Google’s quick iteration on its Gemini models is impressive. Gemini 1.0 was&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-you-need-to-know-about-gemini-googles-new-multimodal-model/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">announced</a>&nbsp;less than six months ago. White-hot competition among AI companies is giving developers more choices, faster speeds, and lower prices.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1043" src="https://dl-staging-website.ghost.io/content/images/2024/05/V3_DeepLearning_Qualcomm_C1_Banner_2070x1080--1-.png" width="2000" /></a></figure><p>In our new short course “Introduction to On-Device AI,” made in collaboration with Qualcomm, you’ll learn to deploy AI models on edge devices using local compute for faster inference and privacy. Join the next wave of AI as models go beyond the cloud!&nbsp;<a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T150014.575.gif" width="1200" /></figure><h1 id="music-titan-targets-ai">Music Titan Targets AI</h1><p>The world’s second-largest music publisher accused AI developers of potential copyright violations.<br /><br /><strong>What’s new:</strong>&nbsp;Sony Music Group&nbsp;<a href="https://www.sonymusic.com/sonymusic/declaration-of-ai-training-opt-out/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">declared</a>&nbsp;that AI developers had trained models on Sony’s intellectual property without permission and that any method of collecting media or other data owned by the company violated its copyrights. Whether AI developers actually have violated copyrights has not been established.</p><p><strong>How it works:</strong>&nbsp;In a&nbsp;<a href="https://www.sonymusic.com/sonymusic/declaration-of-ai-training-opt-out/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">statement</a>&nbsp;posted on the company’s website and&nbsp;<a href="https://www.ft.com/content/c5b93b23-9f26-4e6b-9780-a5d3e5e7a409?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">letters</a>&nbsp;to developers, Sony forbade the use of its music or other media such as lyrics, music videos, album art for “training, developing, or commercializing any AI systems.”</p><ul><li>Sony Music Group sent letters to more than 700 AI developers and streaming services. Letters to AI developers demanded that they reveal which works they had used for training by the following week. Recipients included Google, Microsoft, and text-to-music startups Suno and Udio. Letters sent to streaming services, including Apple and Spotify, asked them to modify their terms of service to prohibit anyone from using streaming services to collect data owned by Sony, among other measures.</li><li>It reserved the right to grant specific developers permission to use its material as training data, asking interested parties to contact Sony by email if they wanted to make a deal.</li></ul><p><strong>Behind the news:</strong>&nbsp;In April, more than 200 music artists&nbsp;<a href="https://artistrightsnow.medium.com/200-artists-urge-tech-platforms-stop-devaluing-music-559fb109bbac?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">called</a>&nbsp;for streaming services and AI developers to stop using their work for training and stop generating music in the styles of specific musicians without compensation. Universal Music Group (UMG), which is Sony Music’s top competitor, has also opposed unrestricted AI-generated music.</p><p>Last year, UMG&nbsp;<a href="https://www.deeplearning.ai/the-batch/universal-music-group-targets-ai-generated-music/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">ordered</a>&nbsp;Apple Music and Spotify to block AI developers from downloading its recordings and issued takedown notices to YouTube and Spotify uploaders who generated music that sounds like artists who are under contract to Universal.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Sony Music Group’s warning comes as generated audio is&nbsp;<a href="https://www.deeplearning.ai/the-batch/text-to-music-services-evolve-with-udio-and-sunos-customized-song-creations/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">approaching</a>&nbsp;a level of quality that might attract a mainstream audience, and it could chill further progress. Although it is not yet clear whether training AI systems on music recordings without permission violates copyrights, Sony Music Group has&nbsp;<a href="https://www.nme.com/news/sony-awarded-more-than-800k-over-tiktok-copyright-infringement-3749902?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">demonstrated</a>&nbsp;its willingness to pursue both individuals and companies for alleged copyright violations. The company accounted for 22 percent of the global music market in 2023. (UMG accounted for 32 percent.) Its catalog includes many of the world’s most popular artists including AC/DC, Adele, Celine Dion, and Harry Styles.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>We believe that AI developers should be allowed to let their software learn from data that’s freely available on the internet, but uncertainty over the limits of copyright protection isn’t good for anyone.&nbsp;It’s high time to&nbsp;<a href="https://www.deeplearning.ai/the-batch/time-to-update-copyright-for-generative-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">update</a>&nbsp;to intellectual property laws for the era of generative AI.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-22T150103.924.gif" width="600" /></figure><h1 id="interpreting-image-edit-instructions">Interpreting Image Edit Instructions</h1><p>The latest text-to-image generators can alter images in response to a text prompt, but their outputs often don’t accurately reflect the text. They do better if, in addition to a prompt, they’re told the general type of alteration they’re expected to make.<br /><br /><strong>What’s new:&nbsp;</strong>Developed by Shelly Sheynin, Adam Polyak, Uriel Singer, Yuval Kirstain, Amit Zohar and colleagues at Meta,&nbsp;<a href="https://arxiv.org/abs/2311.10089?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Emu Edit</a>&nbsp;enriches prompts with task classifications that help the model interpret instructions for altering images. You can see examples&nbsp;<a href="https://emu-edit.metademolab.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">here</a>.<br /><br /><strong>Key insight:</strong>&nbsp;Typical training datasets for image-editing models tend to present, for each example, an initial image, an instruction for altering it, and a target image. To train a model to interpret instructions in light of the type of task it describes, the authors further labeled examples with a task. These labels included categories for regional alterations such as adding or removing an object or changing the background, global alterations such as changing an image’s style, and computer-vision tasks such as detecting or segmenting objects. &nbsp;<br /><br /><strong>How it works:</strong>&nbsp;Emu Edit comprises a pretrained&nbsp;<a href="https://arxiv.org/abs/2309.15807?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Emu</a>&nbsp;latent diffusion image generator and pretrained/fine-tuned Flan-T5 large language model. The system generates a novel image given an image, text instruction, and one of 16 task designations. The authors generated the training set through a series of steps and fine-tuned the models on it.</p><ul><li>The authors prompted a&nbsp;<a href="https://arxiv.org/abs/2307.09288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Llama 2</a>&nbsp;large language model, given an image caption from an unspecified dataset, to generate (i) an instruction to alter the image, (ii) a list of which objects to be changed or added, and (iii) a caption for the altered image. For example, given a caption such as, “Beautiful cat with mojito sitting in a cafe on the street,” Llama 2 might generate&nbsp;<em>{"edit": "include a hat", "edited object": "hat", "output": "Beautiful cat wearing a hat with mojito sitting in a cafe on the street"}</em>.</li><li>Given Llama 2’s output, the&nbsp;<a href="https://arxiv.org/abs/2208.01626?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Prompt-to-Prompt</a>&nbsp;image generator produced initial and target images.&nbsp;</li><li>The authors modified Prompt-to-Prompt with unique enhancements for each task. For instance, to alter only parts of an image, Prompt-to-Prompt usually computes and applies a mask to the initial image while generating the target image. The authors noted that the masks tend to be imprecise if original and target captions differ by more than simple word substitutions. To address this, they modified the method for computing masks. In the change-an-object task, a multi-step procedure involving&nbsp;<a href="https://arxiv.org/abs/2304.02643?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">SAM</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2303.05499?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">Grounding DINO</a>&nbsp;(a DINO variant fine-tuned for object recognition) generated a mask of the list of objects to be changed.</li><li>Following the typical diffusion process for generating images, Emu learned to remove noise from noisy versions of the target images, given the initial image, the instruction, and the task label.&nbsp;</li><li>The authors fine-tuned Flan-T5. Given a generated instruction, Flan-T5 learned to classify the task. At inference, given the instruction, Flan-T5 provided the task to Emu Edit.</li></ul><p><strong>Results:</strong>&nbsp;Judges compared altered images produced by the authors’ method,&nbsp;<a href="https://www.deeplearning.ai/the-batch/instructpix2pix-for-text-to-image-editing-explained/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">InstructPix2Pix</a>, and&nbsp;<a href="https://arxiv.org/abs/2306.10012?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--m4fcSeHyJiOf4e1eGvAF8GwjRy14x6ZFA7G4MfWSSp4-IyUmw-vCQVPjnJ0ispU4C92r2" rel="noopener">MagicBrush</a>&nbsp;using the MagicBrush test set. Evaluating how well the generated images aligned with the instruction, 71.8 percent of the time, the judges preferred Emu Edit over InstructPix2Pix, and 59.5 percent of the time, they preferred Emu Edit over MagicBrush. Evaluating how well the generated images preserve elements from the input images, 71.6 percent preferred Emu Edit over InstructPix2Pix, and 60.4 percent preferred Emu Edit over MagicBrush.<br /><br /><strong>Why it matters:</strong>&nbsp;Richer data improves machine learning results. Specifying tasks and generating images that reflect them improved Emu Edit’s data compared to other works, enabling it to achieve better results.&nbsp;<br /><br /><strong>We’re thinking:&nbsp;</strong>Text-to-image generators are amazing and fun to use, but their output can be frustratingly unpredictable. It’s great to see innovations that make them more controllable.</p><hr /><h2 id="a-message-from-fourthbrain">A MESSAGE FROM FOURTHBRAIN</h2><figure class="kg-card kg-image-card"><a href="https://fourthbrain.ai/programs/?utm_campaign=Spring%20Workshops&amp;utm_source=email"><img alt="" class="kg-image" height="972" src="https://dl-staging-website.ghost.io/content/images/2024/05/FourthBrain-Batch-Ad-05222024.png" width="1728" /></a></figure><p>Join FourthBrain's two live workshops next week! In these interactive sessions, you’ll build useful applications with large language models and walk away with practical skills. Enroll as an individual or register as a team for a group discount.&nbsp;<a href="https://fourthbrain.ai/programs/?utm_campaign=Spring%20Workshops&amp;utm_source=email" rel="noreferrer">Learn more</a></p>
]]></content:encoded>
<pubDate>Wed, 22 May 2024 20:05:31 GMT</pubDate>
</item>
<item>
<title>OpenAI’s Rules for Model Behavior, Better Brain-Controlled Robots, AlphaFold 3 Covers All Biochemistry, AI Oasis in the Desert</title>
<link>https://www.deeplearning.ai/the-batch/issue-249</link>
<guid>https://www.deeplearning.ai/the-batch/issue-249</guid>
<content:encoded><![CDATA[
<div> Google, Gemini Pro 1.5, OpenAI, GPT-4o, AlphaFold 3
总结:<br /><br />文章介绍了Google宣布Gemini Pro 1.5的输入上下文窗口从100万提升至200万tokens，以及OpenAI发布的GPT-4o，这些发展标志着近18个月以来的趋势。对于开发者来说，随着GPT-4和其他先进模型推理能力的提高，编写详细的指示成为了最佳实践。此外，随着输入上下文窗口长度的增加，LLM不再仅限于少量例子，可以给出更多的例子以优化程序。另外，DeepMind的AlphaFold 3扩展了其模型的实用性，增加了对生物分子之间相互作用的预测能力。最后，文章还提到了沙特阿拉伯计划通过投资AI等技术成为全球AI中心的举措，展示了AI在国家发展和竞争中的重要性。 <div>
<p>Dear friends,</p><p>In the last couple of days, Google announced a doubling of Gemini Pro 1.5's input context window from 1 million to 2 million tokens, and OpenAI released GPT-4o, which generates tokens 2x faster and 50% cheaper than GPT-4 Turbo and natively accepts and generates multimodal tokens. I view these developments as the latest in an 18-month trend. Given the improvements we've seen, best practices for developers have changed as well.</p><p>Since the launch of ChatGPT in November 2022, with key milestones that include the releases of GPT-4, Gemini 1.5 Pro, Claude 3 Opus, and Llama 3-70B, many model providers have improved their capabilities in two important ways: (i) reasoning, which allows LLMs to think through complex concepts and and follow complex instructions; and (ii) longer input context windows.&nbsp;</p><p>The reasoning capability of GPT-4 and other advanced models makes them quite good at interpreting complex prompts with detailed instructions. Many people are used to dashing off a quick, 1- to 2-sentence query to an LLM. In contrast, when building applications, I see sophisticated teams frequently writing prompts that might be 1 to 2 pages long (my teams call them “mega-prompts”) that provide complex instructions to specify in detail how we’d like an LLM to perform a task. I still see teams not going far enough in terms of writing detailed instructions. For an example of a moderately lengthy prompt, check out&nbsp;<a href="https://twitter.com/AmandaAskell/status/1765207842993434880?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Claude 3’s system prompt</a>. It’s detailed and gives clear guidance on how Claude should behave.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--59--1.jpg" width="1200" /></figure><p>This is a very different style of prompting than we typically use with LLMs’ web user interfaces, where we might dash off a quick query and, if the response is unsatisfactory, clarify what we want through repeated conversational turns with the chatbot.</p><p>Further, the increasing length of input context windows has added another technique to the developer’s toolkit. GPT-3 kicked off a lot of research on few-shot in-context learning. For example, if you’re using an LLM for text classification, you might give a handful — say 1 to 5 examples — of text snippets and their class labels, so that it can use those examples to generalize to additional texts. However, with longer input context windows — GPT-4o accepts 128,000 input tokens, Claude 3 Opus 200,000 tokens, and Gemini 1.5 Pro 1 million tokens (2 million just announced in a limited preview) — LLMs aren’t limited to a handful of examples. With&nbsp;<a href="https://arxiv.org/abs/2404.11018?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">many-shot learning</a>, developers can give dozens, even hundreds of examples in the prompt, and this works better than few-shot learning.&nbsp;</p><p>When building complex workflows, I see developers getting good results with this process:&nbsp;</p><ul><li>Write quick, simple prompts and see how it does.</li><li>Based on where the output falls short, flesh out the prompt iteratively.&nbsp;This often leads to a longer, more detailed, prompt, perhaps even a mega-prompt.</li><li>If that’s still insufficient, consider few-shot or many-shot learning (if applicable) or, less frequently, fine-tuning.</li><li>If that still doesn’t yield the results you need, break down the task into subtasks and apply an agentic workflow.</li></ul><p>I hope a process like this will help you build applications more easily. If you’re interested in taking a deeper dive into prompting strategies, I recommend the Medprompt&nbsp;<a href="https://arxiv.org/abs/2311.16452?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">paper</a>, which lays out a complex set of prompting strategies that can lead to very good results.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p>P.S. Two new short courses:</p><ul><li>“Multi AI Agent Systems with crewAI” taught by crewAI Founder and CEO João Moura: Learn to take a complex task and break it into subtasks for a team of specialized agents. You’ll learn how to design agent roles, goals, and tool sets, and decide how the agents collaborate (such as which agents can delegate to other agents). You'll see how a multi-agent system can carry out research, write an article, perform financial analysis, or plan an event. Architecting multi-agent systems requires a new mode of thinking that's more like managing a team than chatting with LLMs.&nbsp;<a href="https://www.deeplearning.ai/short-courses/ai-agent-workflows-with-crewai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Sign up here!</a></li><li>“Building Multimodal Search and RAG” taught by Weaviate's Sebastian Witalec: In this course, you'll create RAG systems that reason over contextual information across text, images and video. You will learn how to train multimodal embedding models to map similar data to nearby vectors, so as to carry out semantic search across multiple modalities, and learn about visual instruction tuning to add image capabilities to large language models.&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Sign up here!</a></li></ul><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164130.114.gif" width="1200" /></figure><h1 id="why-chatgpt-acts-that-way">Why ChatGPT Acts That Way</h1><p>OpenAI pulled back the curtain on revised rules that will guide its models.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;OpenAI published its&nbsp;<a href="https://cdn.openai.com/spec/model-spec-2024-05-08.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Model Spec</a>, high-level guidelines for use by human labelers to steer model behavior. The company is inviting public&nbsp;<a href="https://openai.com/form/model-spec-feedback?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">comments</a>&nbsp;on the spec until May 22. It has not stated whether or how it will incorporate comments.</p><p><strong>How it works:</strong>&nbsp;During training, human labelers rate a model’s responses so it can be fine-tuned to conform with human preferences in the process known as&nbsp;<a href="https://arxiv.org/pdf/2203.02155?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">reinforcement from human feedback</a>&nbsp;(RLHF). The Model Spec outlines the principles — some new, some previously in use — that will drive those ratings. The principles are arranged hierarchically, and each category will override those below it.</p><ul><li>Three top-level objectives describe basic principles for model behavior: (i) “Assist the developer and end user” defines the relationship between humans and the model. (ii) “Benefit humanity” guides the model to consider both benefits and harms that may result from its behavior. (iii) “Reflect well on OpenAI” reinforces the company’s brand identity as well as social norms and laws.</li><li>Six rules govern behavior. In order, models are to prioritize platform rules above requests from developers, users, and tools; follow laws; withhold hazardous information; respect intellectual property; protect privacy; and keep their output “safe for work.” (These rules can lead to contradictions. For instance, the model will comply if a user asks ChatGPT to translate a request for drug-related information because the directive to follow requests from users precedes the one to withhold hazardous information.)</li><li>What OpenAI calls&nbsp;<em>defaults</em>&nbsp;govern the model’s interaction style. These include “ask clarifying questions when necessary,” “express uncertainty,” “assume an objective point of view,” and “don't try to change anyone's mind.” For example, if a user insists the Earth is flat, the model may respond, “Everyone's entitled to their own beliefs, and I'm not here to persuade you!”</li><li>The spec will evolve in response to the AI community’s needs. In the future, developers may be able to customize it. For instance, the company is considering allowing developers to lift prohibitions on “not safe for work” output such as erotica, gore, and some profanity.</li></ul><p><strong>Behind the news:&nbsp;</strong>OpenAI’s use of the Model Spec and RLHF contrasts with<strong>&nbsp;</strong>Anthropic’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/toward-safer-more-helpful-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Constitutional AI</a>. To steer the behavior of Anthropic models,&nbsp;that company’s engineers define a constitution, or list of principles, such as “Please choose the response that is the most helpful, honest, and harmless” and “Do NOT choose responses that are toxic, racist, or sexist, or that encourage or support illegal, violent, or unethical behavior.” Rather than human feedback, Anthropic relies on&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">AI feedback</a>&nbsp;to interpret behavioral principles and guide reinforcement learning.</p><p><strong>Why it matters:</strong>&nbsp;AI developers require a degree of confidence that the models they use will behave as they expect and in their users’ best interests. OpenAI’s decision to subject its guidelines to public scrutiny could help to instill such confidence, and its solicitation of public comments might make its models more responsive to social and market forces.</p><p><strong>We’re thinking:</strong>&nbsp;OpenAI’s openness with respect to its Model Spec is a welcome step toward improving its models’ safety and performance.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164233.811.gif" width="600" /></figure><h1 id="alphafold-3-embraces-all-biochemistry">AlphaFold 3 Embraces All Biochemistry&nbsp;</h1><p>The latest update of DeepMind’s AlphaFold model is designed to find the structures of not just proteins but all biologically active molecules as well as interactions between them.</p><p><strong>What’s new:&nbsp;</strong>Google&nbsp;<a href="https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">announced</a>&nbsp;AlphaFold 3, which models the 3D shapes of biomolecules including proteins, DNA, RNA, and ligands (molecules that bind to proteins or DNA, which includes antibodies and many drugs) in any combination. AlphaFold Server&nbsp;<a href="https://golgi.sandbox.google.com/about?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">provides</a>&nbsp;access for noncommercial uses (with some limitations). Unlike earlier versions, AlphaFold 3 is not open source.<br /><br /><strong>Key insight:</strong>&nbsp;Given a sequence of amino acids (the building blocks of proteins), the previous version of AlphaFold drew on an existing knowledge of amino acid structures, computed their locations and angles, and assembled them like Lego blocks. To adapt the system for molecules that aren’t made of amino acids, AlphaFold 3 represents them as collections of individual atoms and uses a generative model to find their positions in space.<br /><br /><strong>How it works:</strong>&nbsp;Given a list of molecules, AlphaFold 3 generates their joint 3D structure, revealing how they fit together. Several transformers hone embeddings of proteins and amino acids, while a diffusion model (also a transformer) processes embeddings of atoms. The team trained the system on five datasets including ground truth protein, DNA, and RNA structures interactions in the&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/10592235/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Protein Data Bank</a>. They also trained it on protein shapes computed by AlphaFold 2; that model’s explicit knowledge of amino acid structures helped overcome AlphaFold 3’s tendency to hallucinate in some instances. Among the key processes:</p><ul><li>Given a protein’s amino acid sequence, a molecule’s set of atoms, or any combination thereof, AlphaFold 3 first represents each common amino acid, nucleotide, and individual atom (that isn’t a part of a common amino acid or nucleotide) with a single token.&nbsp;</li><li>For each token, the system draws on existing databases to compute a variety of features, which fall into five categories: (i) per-token features like position, (ii) features of proteins in the Protein Data Bank, (iii) features of a given molecule, (iv) features derived from a genetic search (for example, whether two amino acid sequences appear to be related evolutionarily) and (v) features that describe chemical bonds between two tokens.&nbsp;</li><li>Given these features, a transformer produces a single embedding that represents all tokens and pairwise embeddings that represent relationships between each pair of tokens. A second transformer refines the pairwise embeddings based on known molecules that share subsequences of amino acids or nucleotides with the input. A third transformer further refines the embeddings.</li><li>Given the features, embeddings, and a noisy point cloud of atoms, the diffusion model removes the noise. (That is, it learned to modify the atoms’ positions to match those in their dataset.)</li><li>AlphaFold 3 learned to optimize seven additional loss terms, including one that minimized the difference between the predicted and actual length of bonds between molecules and another that minimized the difference between predicted and actual distances between pairs of atoms.</li></ul><p><strong>Results</strong>: On&nbsp;<a href="https://github.com/maabuu/posebusters?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">PoseBusters</a>, a database of protein and protein-molecule shapes, AlphaFold 3 successfully found the shapes of about 77 percent of examples, while AutoDock Vina (a non-learning program that models molecular interactions) achieved about 53 percent. On a Protein Data Bank evaluation set, AlphaFold 3 successfully found about 84 percent of protein shapes, while AlphaFold Multimer 2.3 (an update of AlphaFold 2) found 83 percent. Modeling protein-protein interactions, AlphaFold 3 achieved 77 percent, while AlphaFold Multimer 2.3 achieved 67 percent, according to&nbsp;<a href="https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0161879&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">DockQ</a>&nbsp;(a metric for the quality of such interactions).<br /><br /><strong>Behind the news:</strong>&nbsp;The original AlphaFold solved one of the most challenging problems in molecular biology by figuring out how long chains of amino acids would fold, giving scientists clear targets for designing new bioactive molecules. Google&nbsp;<a href="https://www.deeplearning.ai/the-batch/deepmind-isomorphic-alphafold/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">spun off</a>&nbsp;Isomorphic Labs to apply AlphaFold 2 to drug discovery. That company will use AlphaFold 3 and control commercial access to it.<br /><br /><strong>Why it matters:&nbsp;</strong>AlphaFold 3 is a triumph of machine learning. It extends the utility of the previous version beyond proteins, and it computes with unprecedented accuracy how biological molecules will combine, allowing for a more comprehensive understanding of how drugs interact with the body. Its ability to predict how antibodies will bind to proteins could help stave off future pandemics and other illnesses.<br /><br /><strong>We’re thinking:</strong>&nbsp;Although Isomorphic Labs retains control of AlphaFold 3, biologists&nbsp;<a href="https://www.nature.com/articles/d41586-024-01383-z?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">said</a>&nbsp;the information in the paper is enough for other researchers to develop similar systems. We look forward to open versions!</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-05-14T170959.188.png" width="1680" /></a></figure><p>Learn to develop smarter search, retrieval augmented generation (RAG), and recommender systems for multimodal retrieval and generation in this short course, built in collaboration with Weaviate.&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVG04x6mmDF0W4ZDjnP4LvKh1W4xGMq_5f6rl-N6ybcYq3qgyTW8wLKSR6lZ3mYW4SSkjQ5g9lFJW60DtnC325gKfW1Zq1QN5s92lCW73RYh38tB0mfW4lcNQP7VmHYqW2HRyWZ8nQg2xN5VKrkldDqHYW40GMWb1ws47FW6J9CtY7YQDrHN8cqrdmW0CwRN76_QHhgZrtTW2-k2R-20FYfyMjp31LByGNdW7cK6KR1XqlgkW3BWmDj2vxv6rW4Cm69g6L1fQ1W1h1RV596pQyrW6ztG1-98xX4cW7Kpz9k3QNmVSW5YLMRX2-b_ZqN6lJNhNK8TLBW6cnZCc60jk97W48dxGz3tRHcnW1Kb3cf15wCmsW1rKFgC19Qb_GW8HL9ZM8Y23_dW90sVxk298rm6W3NYsXN4SkX_5f5D3jz-04?ref=dl-staging-website.ghost.io" rel="noopener">Enroll today!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164459.448.png" width="1200" /></figure><h1 id="building-an-ai-oasis">Building an AI Oasis</h1><p>Saudi Arabia plans to spend billions of dollars to become a global AI hub.&nbsp;</p><p><strong>What's new:</strong>&nbsp;The desert kingdom has allocated $100 billion to invest in AI and other technologies,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2024/04/25/technology/to-the-future-saudi-arabia-spends-big-to-become-an-ai-superpower.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">reported</a>. The massive potential outlay is attracting AI giants and startups alike.</p><p><strong>How it works:</strong>&nbsp;Saudi Arabia, whose economy is based on large reserves of oil, aims to channel its considerable wealth into more sustainable industries. AI is a major target.&nbsp;</p><ul><li>The state-owned Public Investment Fund (PIF) established a subsidiary, Alat, that plans to invest $100 billion in technology broadly by 2030. Alat has joined with partners to commit as much as $200 million to security and surveillance and $150 million to fully automated manufacturing.&nbsp;</li><li>PIF is&nbsp;<a href="https://www.nytimes.com/2024/03/19/business/saudi-arabia-investment-artificial-intelligence.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">negotiating</a>&nbsp;to establish a $40 billion AI fund with Silicon Valley venture capital firm Andreessen Horowitz. The Saudi government also&nbsp;<a href="https://gaia.newnative.ai/news-blog/gaia-launch?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">established</a>&nbsp;GAIA, a $1 billion partnership with U.S. venture capital firm NewNative, to offer startups with seed funding and compute resources provided by Amazon and Google. GAIA-supported companies must register in Saudi Arabia and spend 50 percent of their investment in the country.</li><li>In March, attendees at the third annual LEAP technology conference, held near the Saudi capital of Riyadh, inked more than $10 billion worth of technology deals. For instance, Amazon&nbsp;<a href="https://press.aboutamazon.com/2024/3/aws-to-launch-an-infrastructure-region-in-the-kingdom-of-saudi-arabia?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">committed</a>&nbsp;$5.3 billion to Saudi cloud computing infrastructure and AI training.&nbsp;</li><li>The Saudi government spent considerable resources building an AI research hub at King Abdullah University of Science and Technology. The university has hired foreign AI researchers and arranged to&nbsp;<a href="https://www.datacenterdynamics.com/en/news/report-saudi-arabia-acquires-3000-nvidia-gpus-uae-buys-thousands/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">buy</a>&nbsp;more than 3,000 Nvidia H100 chips.</li></ul><p><strong>Behind the news:</strong>&nbsp;Where AI is concerned, Saudi Arabia is competing with the neighboring United Arab Emirates (UAE). In March, UAE member state Abu Dhabi&nbsp;<a href="https://www.reuters.com/breakingviews/middle-east-ai-dream-depends-luring-brainpower-2024-03-22/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">established</a>&nbsp;its own multibillion-dollar investment fund, MGX, which aims to secure deals in AI models, data centers, and semiconductors. One of MGX’s founding partners (and a cornerstone in the UAE’s AI efforts) is G42, a conglomerate with ties to the Emirati government that owns numerous AI research labs and other assets. G42 recently&nbsp;<a href="https://news.microsoft.com/2024/04/15/microsoft-invests-1-5-billion-in-abu-dhabis-g42-to-accelerate-ai-development-and-global-expansion/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">received</a>&nbsp;$1.5 billion from Microsoft. Last year, it&nbsp;<a href="https://www.deeplearning.ai/the-batch/nvidias-competitor-cerebras-secured-a-contract-with-a-major-tech-conglomerate/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">paid</a>&nbsp;U.S. chip designer Cerebras an initial $100 million to build up to nine supercomputers.<br /><br /><strong>Yes, but:</strong>&nbsp;Saudi investments have not always arrived on the expected schedule. Founders of startups that were promised GAIA funding have&nbsp;<a href="https://www.forbes.com/sites/iainmartin/2024/04/16/saudi-arabia-promised-ai-founders-billions-in-investment-some-are-still-waiting-to-get-paid/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">complained</a>&nbsp;of delays and nonpayments. Moreover, U.S. partners such as Microsoft have drawn&nbsp;<a href="https://www.hrw.org/news/2023/05/23/saudi-arabia-microsoft-should-suspend-data-center-plans?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">criticism</a>&nbsp;for working with Saudi Arabia, which has been&nbsp;<a href="https://en.wikipedia.org/wiki/Human_rights_in_Saudi_Arabia?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">accused</a>&nbsp;of violating human rights. The U.S. government&nbsp;<a href="https://www.dw.com/en/us-china-tech-war-ai-sparks-first-battle-in-middle-east/a-66968886?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">blocked</a>&nbsp;fulfillment of the King Abdullah University’s purchase of Nvidia chips because it may help researchers associated with the Chinese military to circumvent U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/loopholes-help-chinese-companies-get-us-chips/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">restrictions</a>&nbsp;on the export of advanced semiconductors. Earlier this year, U.S.-based generative AI startup Anthropic&nbsp;<a href="https://www.cnbc.com/2024/03/22/anthropic-lining-up-a-new-slate-of-investors-ruled-out-saudi-arabia.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">rejected</a>&nbsp;potential investment from PIF citing national security concerns.</p><p><strong>Why it matters:</strong>&nbsp;AI is fast becoming a source of national power, and many countries are eager to build their capabilities. Saudi Arabia’s investment could go a long way toward building facilities and talent in a part of the world that has not been known for high tech. For the country itself, it could bring economic growth and geopolitical advantage. For foreign companies and talent, it’s an immense new source of funding to pursue valuable projects and gain practical experience.</p><p><strong>We're thinking:</strong>&nbsp;We are happy to see AI hubs emerge around the world, especially in places that can provide more opportunities for people who live outside of established AI centers.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-15T164549.473.gif" width="600" /></figure><h1 id="brain-controlled-robots-get-more-versatile">Brain-Controlled Robots Get More Versatile</h1><p>Brain-to-computer interfaces that enable users to control robots with their thoughts typically execute a single type of task such as reaching and grasping. Researchers designed a system that responds to a variety of intentions.</p><p><strong>What's new:</strong>&nbsp;Ruohan Zhang and colleagues at Stanford introduced&nbsp;<a href="https://arxiv.org/abs/2311.01454?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Neural Signal Operated Intelligent Robots (NOIR)</a>. Their method commands a robot to perform practical tasks, such as ironing a cloth or making a sandwich, via signals from an electroencephalogram (EEG), a non-invasive way to measure brain waves via electrodes attached to the scalp.</p><p><strong>Key insight:</strong>&nbsp;Currently neuroscientists can derive from EEG signals only simple thoughts, such as the intention to move a limb. However, a sequence of simple thoughts can drive an arbitrarily complex action. Specifically, simple thoughts (such as the intention to move a hand) can drive a robot to perform complex actions by repeatedly (i) selecting an object, (ii) selecting an action to apply to the object, and (iii) selecting the part of the object to act upon. For instance, to iron a cloth, the initial sequence would be: (i) select the iron and (ii) grasp it (iii) by the handle. This sequence might be followed by (i) select the cloth and (ii) slide the iron across it (iii) starting at the nearest portion. And so on.</p><p><strong>How it works:</strong>&nbsp;Users who wore EEG electrodes concentrated on specific sequences of thoughts to execute tasks as they watched a screen that displayed the output of a camera attached to either a&nbsp;<a href="https://franka.de/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">robotic arm</a>&nbsp;or&nbsp;<a href="https://pal-robotics.com/robots/tiago/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">wheeled robot with two arms</a>.&nbsp;</p><ul><li>Prior to attempts to control a robot, the authors recorded EEG signals to train the system for each individual user. Users spent 10 minutes imagining grasping a ball in their right or left hand, pushing a pedal with both feet, or focusing on a cross displayed on the screen (a resting state). The authors used the resulting data to train two&nbsp;<a href="https://en.wikipedia.org/wiki/Quadratic_classifier?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Quadratic Discriminant Analysis</a>&nbsp;(QDA) classifiers for each user.</li><li>To enable users to select objects, a pretrained&nbsp;<a href="https://arxiv.org/abs/2205.06230?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">OWL-ViT</a>&nbsp;segmented the camera image to mark individual objects on the screen. Objects available to be manipulated flickered at different frequencies between 6 and 10 times per second. When a user concentrated on an object, the resulting brainwaves synchronized with the frequency of its flickering. The system selected the object that corresponded to the most prominent frequency.&nbsp;</li><li>Once the user had selected an object, the system presented up to four possible actions, such as “pick from top,” “pick from side,” and “push.” Each action was accompanied by an image of a right or left hand, feet, or a cross. To select an action, the user imagined using the designated body part or focusing on the cross. Given the EEG signal, one classifier selected the action.</li><li>To select a location on the object, the other classifier helped the user to point at it using a cursor. To move the cursor in one direction, the user imagined using one hand. To move it in the opposite direction, the user focused on a cross. The user repeated this process for each of three axes of motion (horizontal, vertical, and depth).</li><li>In case the system didn’t read a selection correctly, the user could reset the process by clenching their jaw.</li><li>To make the system easier to use, the authors adapted an&nbsp;<a href="https://arxiv.org/abs/2203.12601?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">R3M</a>&nbsp;embedding model to suggest commonly selected objects and actions. R3M was pretrained to generate similar embeddings of paired robot instructions and camera views and dissimilar embeddings of mismatched robot instructions and camera views. The authors added several fully connected layers and trained them on the individual-user data to produce similar embeddings of images from the camera with the same object-action combination and dissimilar embeddings of images with other object-action combinations. Given an image from the camera, the model returned the object-action that corresponded to the most similar image.</li></ul><p><strong>Results:&nbsp;</strong>Three users controlled the two robots to execute 20 everyday tasks. On average, the system selected objects with 81.2 percent accuracy, actions with 42.2 percent accuracy, and locations with 73.9 percent accuracy. Users took an average of about 20 minutes to complete each task.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Brain signals are enormously complex, yet relatively simple statistical techniques — in this case, QDA — can decode them in useful ways.</p><p><strong>We're thinking:</strong>&nbsp;Sometimes the simplest solution to a difficult problem is not to train a larger model but to break down the problem into manageable steps.</p><hr /><h2 id="new-from-deeplearningai-1">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-05-14T171114.198.png" width="1680" /></a></figure><p>In “Multi AI Agent Systems with crewAI,” you’ll learn key principles for designing AI agents and organizing teams of agents to perform complex, multi-step tasks. You’ll apply these concepts to automate six common business processes.&nbsp;<a href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_PU4gmbfJN9_gBrzLMkZheDB1ROQnQWYv9cSxeMK53CO9ix0aYRLcabOd6v3xmmbHcM7HE" rel="noopener">Sign up for free!</a></p>
]]></content:encoded>
<pubDate>Wed, 15 May 2024 21:51:45 GMT</pubDate>
</item>
<item>
<title>OpenAI Licenses News Archives, Generative Coding From Plan to Pull Request, Recognizing Landmines, Streamlined Inference</title>
<link>https://www.deeplearning.ai/the-batch/issue-248</link>
<guid>https://www.deeplearning.ai/the-batch/issue-248</guid>
<content:encoded><![CDATA[
<div> 关键词: AI, 开源, 监管, 美国政府, 新闻档案<br />
<br />
总结:<br />本文讨论了AI和监管在美国政府层面所取得的进展，强调保护开源技术的重要性。文章指出，一些公司试图限制开源，但随着论据的转变，监管的焦点也在不断变化。从华盛顿的讨论中可以看出，政府正逐渐理解AI的风险，认识到需要制定防范措施。同时，开源对国家安全的影响也成为了争议焦点之一。而OpenAI则通过与新闻媒体合作，获取高质量的训练数据，加速自身技术发展。通过介绍新的短期课程和最新技术进展，文章强调了AI在促进创新和解决实际问题上的重要作用。 <div>
<p>Dear friends,</p><p>Last week, I spoke about AI and regulation at the U.S. Capitol at&nbsp;an event that was attended by legislative and business leaders. I’m encouraged by the progress the open source community has made fending off regulations that would have stifled innovation. But opponents of open source are continuing to shift their arguments, with the latest worries centering on open source's impact on national security. I hope we’ll all keep protecting open source!&nbsp;</p><p>Based on my conversations with legislators, I’m encouraged by the progress the U.S. federal government has made getting a realistic grasp of AI’s risks. To be clear, guardrails are needed. But they should be applied to AI applications, not to general-purpose AI technology.&nbsp;</p><p>Nonetheless, as I&nbsp;<a href="https://www.deeplearning.ai/the-batch/keep-open-source-free/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">wrote</a>&nbsp;previously, some companies are eager to limit open source, possibly to protect the value of massive investments they’ve made in proprietary models and to deter competitors. It has been fascinating to watch their arguments change over time.</p><p>For instance, about 12 months ago, the Center For AI Safety’s “<a href="https://www.safe.ai/work/statement-on-ai-risk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Statement on AI Risk</a>” warned that AI could cause human extinction and stoked fears of AI taking over. This alarmed leaders in Washington. But many people in AI pointed out that this dystopian science-fiction scenario has little basis in reality. About six months later, when I&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-doomsday-scenarios-and-how-to-guard-against-them/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">testified</a>&nbsp;at the U.S. Senate’s AI Insight forum, legislators no longer worried much about an AI takeover.</p><p>Then the opponents of open source shifted gears. Their leading argument shifted to the risk of AI helping to create bioweapons. Soon afterward,&nbsp;<a href="https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">OpenAI</a>&nbsp;and&nbsp;<a href="https://www.rand.org/news/press/2024/01/25.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">RAND</a>&nbsp;showed that current AI does not significantly increase the ability of malefactors to build bioweapons. This fear of AI-enabled bioweapons has diminished. To be sure, the possibility that bad actors could use bioweapons — with or without AI — remains a topic of great international concern.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T152327.782-1.png" width="1200" /></figure><p>The latest argument for blocking open source AI has shifted to national security. AI is useful for both economic competition and warfare, and open source opponents say the U.S. should make sure its adversaries don’t have access to the latest foundation models. While I don’t want authoritarian governments to use AI, particularly to wage unjust wars, the LLM cat is out of the bag, and authoritarian countries will fill the vacuum if democratic nations limit access. When, some day, a child somewhere asks an AI system questions about democracy, the role of a free press, or the function of an independent judiciary in preserving the rule of law, I would like the AI to reflect democratic values rather than favor authoritarian leaders’ goals over, say, human rights.&nbsp;</p><p>I came away from Washington optimistic about the progress we’ve made. A &nbsp;year ago, legislators seemed to me to spend 80% of their time talking about guardrails for AI and 20% about investing in innovation. I was delighted that the ratio has flipped, and there was far more talk of investing in innovation.</p><p>Looking beyond the U.S. federal government, there are many jurisdictions globally. Unfortunately, arguments in favor of &nbsp;regulations that would stifle AI development continue to proliferate. But I’ve learned from my trips to Washington and other nations’ capitals that talking to regulators does have an impact. If you get a chance to talk to a regulator at any level, I hope you’ll do what you can to help governments better understand AI.&nbsp;</p><p>Keep learning,<br />Andrew</p><p>P.S. Two new short courses!</p><ul><li>I’m thrilled to announce our first short course focused on agentic workflows: “<a href="https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9rsco1t53WrNq8oTk-wX4HAtWVypFA6VFpC58cihdUR6gTq4FHeMdGGzcO3FCdxtzMHScF" rel="noopener">Building Agentic RAG with LlamaIndex</a>,” taught by LlamaIndex CEO Jerry Liu. This covers an important shift in RAG. Rather than having a developer write explicit routines to retrieve information to feed into an LLM’s context, we can build a RAG agent that has access to tools to retrieve information. This lets it decide what information to fetch, and lets it answer more complex questions using multi-step reasoning.</li><li>Additionally, I’m delighted to launch “<a href="https://www.deeplearning.ai/short-courses/quantization-in-depth/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9rsco1t53WrNq8oTk-wX4HAtWVypFA6VFpC58cihdUR6gTq4FHeMdGGzcO3FCdxtzMHScF" rel="noopener">Quantization in Depth</a>,” taught by Hugging Face’s&nbsp;Marc Sun and Younes Belkada. Quantization is a key technique for making large models accessible. You’ll learn about implementing linear quantization variants, quantizing at different granularities, and compressing deep learning models to 8-bit and 2-bit precision.</li></ul><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T152519.838-1.gif" width="1200" /></figure><h1 id="coding-assistance-start-to-finish">Coding Assistance Start to Finish</h1><p>GitHub Copilot’s latest features are designed to help manage software development from plan to pull request.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;GitHub&nbsp;<a href="https://github.blog/2024-04-29-github-copilot-workspace/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">unveiled</a>&nbsp;a preview of Copilot Workspace, a generative development environment that’s designed to encompass entire projects. Users can sign up for a&nbsp;<a href="https://githubnext.com/projects/copilot-workspace?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">waitlist</a>&nbsp;to gain access to Workspace until the preview ends. Afterward, Copilot Workspace will be available to subscribers to GitHub Copilot (which starts at $10 per month for individuals and $19 per month for businesses).</p><p><strong>How it works:&nbsp;</strong>Copilot Workspace is based on GPT-4 Turbo and integrated with GitHub code repositories and libraries. Where GitHub Copilot previously generated code snippets and provided suggestions for editing code segments, Copilot Workspace integrates these tasks within a larger plan.&nbsp;</p><ul><li>Users begin by providing a known bug, feature request, or codebase and then prompting the system. For instance, a user can provide code for a simple Pong-style video game and request a feature, such as an automated opponent to play against.</li><li>Given the request, the system determines the current state of the codebase, then proposes goals the code will meet once the new feature has been implemented. For example, the system might propose, “the computer controls the left paddle automatically, allowing for a single-player game against the computer” and “the game mechanics and logic for the computer’s movement have been added to index.jsx.”</li><li>The goals function as a new prompt, spurring the system to plan intermediate steps to reach them. For instance, the revised plan might include, “add computer player logic for paddle 1 that blocks the ball 95% of the time” and “remove logic for player control of paddle 1.”&nbsp;</li><li>Users can edit all of this before telling the system to carry out the plan. Afterward, the resulting code can be edited, previewed, shared, and subjected to new tests.&nbsp;</li><li>Once the code has passed the tests, users can upload it directly to GitHub as a pull request or fork in the code repository or library.</li></ul><p><strong>Yes, but:&nbsp;</strong>Initial users&nbsp;<a href="https://every.to/chain-of-thought/i-spent-24-hours-with-github-copilot-workspaces?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">noted</a>&nbsp;that Copilot Workspace is best at solving straightforward, well defined problems and struggles with more complex ones. Choices can be difficult to unwind later on, and the system is slower than simpler AI coding assistants.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;Generative coding assistants quickly have become central tools for software development. Copilot has&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-04-17/microsoft-s-ai-copilot-is-starting-to-automate-the-coding-industry?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">attracted</a>&nbsp;1.3 million paid subscribers as of April 2024, including 50,000 businesses. Amazon’s&nbsp;<a href="https://aws.amazon.com/q/developer/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Q Developer</a>&nbsp;(formerly CodeWhisperer), Google’s&nbsp;<a href="https://cloud.google.com/products/gemini/code-assist?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Gemini Code Assist</a>&nbsp;(formerly Duet AI), and&nbsp;<a href="https://cursor.sh/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Cursor</a>&nbsp;offer coding companions that integrate with or fork popular integrated development environments like Microsoft’s VSCode. On the frontier are&nbsp;<a href="https://www.deeplearning.ai/the-batch/next-generation-coding-tools-empower-developers-with-agent-style-interactions/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">agentic tools</a>&nbsp;that plan and carry out complex, multi-step coding tasks.<br /><br /><strong>Why it matters:</strong>&nbsp;Copilot Workspace attempts to extend Copilot’s code-completion and chat capabilities to a wider swath of the software development cycle. Simpler coding assistants have been shown to&nbsp;<a href="https://dl.acm.org/doi/pdf/10.1145/3633453?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">boost</a>&nbsp;productivity markedly. Bringing natural-language prompting to tasks like planning, testing, and reading documentation is a natural step.</p><p><strong>We’re thinking:</strong>&nbsp;There are many ways to use AI in coding. To learn about a few more, check out our short course, “<a href="https://www.deeplearning.ai/short-courses/pair-programming-llm/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">Pair Programming With a Large Language Model</a>,” taught by Google AI advocate Laurence Moroney.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--58-.jpg" width="1200" /></figure><h1 id="openai-licenses-news-archives">OpenAI Licenses News Archives</h1><p>OpenAI has been making deals with publishers to gain access to high-quality training data. It added&nbsp;<em>Financial Times</em>&nbsp;to the list.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://www.ft.com/content/33328743-ba3b-470f-a2e3-f41c3a366613?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">licensed</a>&nbsp;the archive of business news owned by&nbsp;<em>Financial Times&nbsp;</em>(<em>FT</em>) for an undisclosed sum. The agreement lets OpenAI train its models on the publisher’s articles and deliver information gleaned from them. This is OpenAI’s fifth such agreement with major news publishers in the past year.</p><p><strong>How it works:&nbsp;</strong>Although the parties didn’t disclose the length of their agreement, OpenAI’s other news licensing deals will end within a few years. The limited commitment suggests that these arrangements are experimental rather than strategic. The deal includes articles behind the publisher’s paywall; that is, not freely available on the open internet. This enables OpenAI to train its models on material that competitors may not have. Other deals have given OpenAI exclusive access, shutting competitors out.</p><ul><li>The deal with&nbsp;<em>FT</em>&nbsp;gives OpenAI nonexclusive rights to search, index, and train its models on the publisher’s articles, including articles behind its paywall. It also lets OpenAI enable ChatGPT to cite, summarize, and link to the publishers’ works. The parties&nbsp;<a href="https://aboutus.ft.com/press_release/openai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">called</a>&nbsp;the deal a “strategic partnership” as well as a licensing agreement, although it’s unclear whether OpenAI will share technology or data with&nbsp;<em>FT</em>.</li><li>In March, OpenAI&nbsp;<a href="https://openai.com/index/global-news-partnerships-le-monde-and-prisa-media?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">announced</a>&nbsp;multi-year agreements with French newspaper&nbsp;<em>Le Monde</em>&nbsp;and Prisa Media (Spanish owner of the newspapers&nbsp;<em>El País</em>,&nbsp;<em>Diario AS</em>, and&nbsp;<em>Cinco Días</em>). The agreements give OpenAI rights to summarize and train AI models on their articles and make the publishers, respectively, OpenAI’s exclusive providers of French- and Spanish-language news.</li><li>In December 2023, OpenAI&nbsp;<a href="https://www.axelspringer.com/en/ax-press-release/axel-springer-and-openai-partner-to-deepen-beneficial-use-of-ai-in-journalism?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">signed</a>&nbsp;a three-year, nonexclusive deal with German publisher Axel Springer, owner of German-language newspapers&nbsp;<em>Bild</em>&nbsp;and&nbsp;<em>Die Welt</em>&nbsp;as well as English-language websites&nbsp;<em>Politico</em>&nbsp;and&nbsp;<em>Business Insider</em>. The deal allows OpenAI to train on, summarize, and link to Axel Springer’s articles, including paywalled content, and makes the publisher OpenAI’s exclusive supplier of German-language news. It was worth “tens of millions of euros,”&nbsp;<a href="https://finance.yahoo.com/news/openai-axel-springer-ink-deal-145333092.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">according to</a>&nbsp;<em>Bloomberg</em>.</li><li>In July 2023, OpenAI&nbsp;<a href="https://www.ap.org/media-center/press-releases/2023/ap-open-ai-agree-to-share-select-news-content-and-technology-in-new-collaboration/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">gained</a>&nbsp;nonexclusive rights for two years to train its models on some of the text of the&nbsp;<em>Associated Press</em>&nbsp;(<em>AP</em>) archive of news articles, which freely is available on the open web. In return,&nbsp;<em>AP</em>&nbsp;received undisclosed access to OpenAI’s “technology and product expertise.” Unlike the other agreements, the deal with&nbsp;<em>AP</em>&nbsp;(which does not have a paywall) does not grant OpenAI specific rights to summarize or link to&nbsp;<em>AP</em>’s stories.</li></ul><p><strong>Behind the news:</strong>&nbsp;Archives of news articles may be handy if OpenAI proceeds with a rumored search service&nbsp;<a href="https://www.theinformation.com/articles/openai-develops-web-search-product-in-challenge-to-google?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">reported</a>&nbsp;by in February by&nbsp;<em>The Information</em>. Licensing is a way to get such material that is unambiguously legal. Although AI researchers commonly scrape data from the web and use it for training models without obtaining licenses for copyrighted works, whether a license is required to train AI models on works under copyright in the U.S. has yet to be determined. Copyright owners lately have challenged this practice in court. In December 2023,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-new-york-times-versus-openai-and-microsoft/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">sued</a>&nbsp;OpenAI and Microsoft, claiming that OpenAI infringed its copyrights by training models on its articles. In April 2024, eight U.S. newspapers owned by Alden Global Capital, a hedge fund,&nbsp;<a href="https://www.theguardian.com/technology/2024/apr/30/us-newspaper-openai-lawsuit?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">filed</a>&nbsp;a lawsuit against the same defendants on similar grounds. Licensing material from publishers gives OpenAI access to their works while offering them incentives to negotiate rather than sue.<br /><br /><strong>Why it matters:</strong>&nbsp;AI developers need huge amounts of media to train larger and larger models. News publishers have huge archives with high-quality text, relatively well written and fact-checked, that’s relevant to current events of interest to a broad audience. Licensing those archives gives developers access to what they need without incurring legal risk. Furthermore, making news archives available for retrieval augmented generation makes chatbots more capable and reliable.</p><p><strong>We’re thinking:&nbsp;</strong>We support efforts to clarify the legal status of training AI models on data scraped from the web. It makes sense to treat the open web pages and paywalled content differently, but we advocate that AI models be free to learn from the open internet just as humans can.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/4--3-.png" width="1680" /></a></figure><p>Explore the newest additions to our short courses with “<a href="https://www.deeplearning.ai/short-courses/quantization-in-depth/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m">Quantization in Depth</a>,” where you’ll build a quantizer in PyTorch, and “<a href="https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m">Building Agentic RAG with LlamaIndex</a>,” which teaches how to build agents capable of tool use, reasoning, and making decisions based on your data.&nbsp;<a href="https://www.deeplearning.ai/short-courses/?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up now!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T164752.068.png" width="1200" /></figure><h1 id="landmine-recognition">Landmine Recognition</h1><p>An AI system is scouring battlefields for landmines and other unexploded ordnance, enabling specialists to defuse them.</p><p><strong>What’s new:</strong>&nbsp;The military hardware firm Safe Pro Group developed Spotlight AI, a computer vision system that identifies mines based on aerial imagery,&nbsp;<em>IEEE Spectrum</em>&nbsp;<a href="https://spectrum.ieee.org/ukraine-drones?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">reported</a>. Nongovernmental organizations that remove landmines, including the Norwegian People's Aid and the HALO Trust, are using the system in Ukraine.&nbsp;</p><p><strong>How it works:</strong>&nbsp;SpotlightAI processes visual-light imagery taken by flying drones. The system provides centimeter-resolution maps that guide mine-removal teams through the territory.</p><ul><li>The system includes an unidentified vision model trained to recognize 150 types of explosive munitions, primarily of U.S. and Russian origin. In a test, the model detected 87 percent of munitions scattered across a munitions test range in Hungary.</li><li>With sufficient computational resources, the system can analyze an image in around 0.5 seconds. A human reviewer typically takes three minutes.</li><li>The system struggles to identify explosives concealed by earth or dense vegetation. To address this limitation, Safe Pro Group has begun to test it with infrared, lidar, magnetometry, and other types of imagery. In addition, the company has developed a system that converts drone imagery into a heat map that shows a machine learning model’s estimated probability that it can detect explosives in a given location. A patch of grass, for example, may have a higher estimated probability than a dense thicket of trees and bushes.</li><li>The company aims to fine-tune its model to detect unexploded ordnance in other current or former conflict zones such as Angola, Iraq, and Laos.</li></ul><p><strong>Behind the news:</strong>&nbsp;In addition to drones, satellites can help machine learning models to find deadly remnants of warfare. In 2020, Ohio State University researchers&nbsp;<a href="https://www.deeplearning.ai/the-batch/where-are-the-live-bombs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">estimated</a>&nbsp;the number of undetonated explosives in Cambodia by collating bomb craters in satellite images identified by a computer vision model with records of U.S. military bombing campaigns in that country in the 1960s and 1970s.</p><p><strong>Why it matters:</strong>&nbsp;Unexploded mines, bombs, and other types of munitions&nbsp;<a href="https://www.the-monitor.org/media/3389440/landmine-monitor-2023_web.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8LNS8DF2FAurlzNv-TFTZKbJ0jKgiLC0wmKt8MgCKBZQFvWmuJJuwXqSWNb-qAt3KNkO8m" rel="noopener">killed or injured</a>&nbsp;more than 4,700 people — 85 percent of them civilians and half of them children where military status and age were known — in 2022 alone. Efforts to remove every last mine from a former battlefield likely will continue to rely on traditional methods — manual analysis of overhead imagery along with sweeps by human specialists and explosive-sniffing dogs — but machine learning can significantly reduce the hazard and accelerate the work.</p><p><strong>We’re thinking:</strong>&nbsp;Although this system locates unexploded mines and shells, removing them often still falls to a brave human. We hope for speedy progress in robots that can take on this work as well.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-08T164933.555.gif" width="600" /></figure><h1 id="streamlined-inference">Streamlined Inference</h1><p>It’s not necessary to activate all parts of a large language model to process a given input. Using only the necessary parts saves processing.</p><p><strong>What’s new:</strong>&nbsp;Zichang Liu and collaborators at Rice University, Zhe Jiang University, Stanford, University of California San Diego, ETH Zürich, Adobe, Meta, and Carnegie Mellon proposed&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFv3qgyTW7lCdLW6lZ3q4W7jY3WF8hg_kcW26q5z22x1L8sW2M0rg84-DZ9SW2GR61_2BkmYLW2nQvXX66qh5dW8Q_Str879wCbW3qQ6QW6bdyhCW8YnJmq1ZtLZVW5JtVGY4K1hb5W3nnL886btGhKW2J_Yr15YB_qCW11nQQY5RMWB-W1tfHhv7xH4fyW5SrZq_2HzkDkW8phBJW2_NsMVN7mrmCgskvN3W1rWVJ47hYf2qVq7VV743fqjwN1-BYcgjlYQ8VHf78S4_WwW2VXJSpw1TcMl6W12GC-H3Rhn0MVrJfj55wjc6VW63lj1j1hx8dbf4kFFlR04?ref=dl-staging-website.ghost.io" rel="noopener">Deja Vu</a>, an algorithm that accelerates inferencing of large language models (LLMs) by using small vanilla neural networks to predict which parts of it to use.</p><p><strong>Key insight:</strong>&nbsp;Transformer-based neural networks can save a lot of time at inference by activating only a fraction of (i) attention heads and (ii) neurons in fully connected layers. But it’s necessary to activate the right neurons, because different parts of the network learn about different patterns of inputs. By using the input to decide which parts of the network to activate, the network can maintain accuracy using only the parts relevant for the current input.</p><p><strong>How it works:</strong>&nbsp;The authors used pretrained&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3nTW4LydH91RLl6QW3BJN4R84l_7GW2-h6c54swtF0W6tLHpN8Y4KjGW7nk2Sp18W-LWN3MBhL7d5q1sN5y8GBsfTgV5W5kWbf27p7NwlW8dQcf84cQWbPW3b1CDc7qlj64N6P7Nqm6bgm3W91PtwH5CvWh-W5GfbS_3w6XQcW6sYRS-6rzLy9N6ypWg4CC9-vW4nt-ss9gwkSWW8wbSzR3H2zMxW2Q8XDp8mYRs1VkT-LZ9m1-KSVLDv4f2wMGkcW756bRY8mhsGWN4CSFxvBRG-Pf7F36SF04?ref=dl-staging-website.ghost.io" rel="noopener">OPT</a>&nbsp;models of various sizes (175, 66, and 30 billion parameters). They built a dataset by feeding examples from&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3pjW6KTZKm1LxSrMN8BSzzM_lBD-VG39nC44SkC7W6NNBQw4869bZMC7Wc1b5bhTN8n85VLCy1RZW1NzTVN52JMDDW3ZfhHJ3wrr7gW4npQwR3PvF_hW6cdM3H332WwyW6n96fp7l1BbPW4dqL8-2z96tcW1vBXC-5ZQ84LVc9PbD5CYmKmW7N_CKx8tLjVnW2ChCqF4s-G3pW6JQWZZ4CFD8QW546gW65qhm9vW6HZxss3WMCPqW77FWkB47V5jKW5f5sj01N-QkNW8lxCqd8-TLycf8Kkvr604?ref=dl-staging-website.ghost.io" rel="noopener">OpenBookQA</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3lZW7-CP1c80tXv7W5M89jq3TtQrrW8_DBX285mpmPW4dWr1c8nnpYVVJ5_j_2hnMXhW2sJGXF2BYWrmW8B6TTb2SznlfW4p1QJF78-52mW5RW1Q72W3tzvN808-tLVXQckW5VGP_K2txgbsW3qd0cX5009TNW4pSTBZ8vKG-gW6h85Xs2VqmQlN7qQ8sZ9L7xCW2bxGLf7tQ1mSW3vZ01V1ydWBqW6h-3mW3Z6-8gW2nPv9y6-VGflVg37m17NrJmHW7zzxLx74m-1FW6JZF0s7_RBz7f7_V4DF04?ref=dl-staging-website.ghost.io" rel="noopener">Wiki-Text</a>&nbsp;to the OPTs and recording the outputs of all attention heads and fully-connected-layer neurons. By activating various portions of these networks, they learned that, for a given input, they could discard most of an OPT’s lowest-output attention heads and fully-connected-layer neurons without degrading its performance.</p><ul><li>The authors used their dataset to train a sparsity predictor for each of an OPT’s fully connected layers. This small vanilla neural network classified which neurons in a fully connected layer to activate (because they produced large outputs), given the output of the previous fully connected layer.</li><li>Using the same dataset, they trained, for each attention layer, a small vanilla neural network to classify which attention heads to activate (because they produced large outputs), given the output of the previous attention layer.</li><li>At inference, an OPT and its predictor networks ran in parallel. While the OPT computed an attention layer, a predictor network predicted the neurons to activate in the following fully connected layer. Similarly, while the OPT computed each fully connected layer, a predictor network predicted the heads to activate in the following attention layer.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;Deja Vu (175 billion parameters) produced a sequence of 128 tokens in 20 milliseconds, while an Nvidia implementation of OPT of the same size needed 40 milliseconds and a Hugging Face implementation of OPT of the same size needed 105 milliseconds. Moreover, Deja Vu achieved these speedups without reducing accuracy. On&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3n4MS_20LqRzYMW2N2tvW6wD-6qW53fkQ13WcsckN4TPKQGvkSLwW5trlwt7C1k6hW1HvJfy7Kzc9lW9kSBDr25gbtRN2xzGHGHf9LSW28fFCh4jkcQSW5jJ1T81qjS0ZW39J8lw1m2FkfW5_4Xxg2KKkXjW50x3dt8XK_p_W1mjl-V8kctbJW8XGmfG1-D0QVW8s2qlr4Gs2WyW2c5ldV4t-1ByN1mKr9PmyGlDW2lV9Z_6Y_HMnW1CYy0-6C53ZsW1MjY894kFp62W1Sb4rz18fCFlf3T1FBq04?ref=dl-staging-website.ghost.io" rel="noopener">WikiText</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFv3qgyTW7lCdLW6lZ3mWW2RGtFv15PkrPW5kKSPx8r1tQbW32DK6Y6WyJ1BW5kHknw2dXhfDW1tNBgZ4YX730W88WwrD8L2wCqN91s699wWHrwW8N0MR46JyyQ1W2DVrwk6vXTGWW9fyl0H7D3q_3W6Hvs95447nHJW675RTN7677pvW4nHqkQ5R0clcVLNLHC19sQXkN1f3hmsM2vkxW24PV7x1gWY4zVQC0823KZtxlW41f2G26y0VMyN8Ck-slpnJPNVhq71_2jBhrfW16JVdd3WHw8ZVvD_pX8FQPdnW6rN34C2JV-Y0W8CL3xM4PkdH9f2jffrv04?ref=dl-staging-website.ghost.io" rel="noopener">C4</a>, Deja Vu’s ability to predict the next word held steady while activating 25 percent of attention heads and fully-connected-layer neurons. On datasets such as&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3p3W9g72g641Kg1jW5PbLvF15zT9WW7NmR0t49L4PrW7DxP3G4nYPLxW2VV9KW8wMbTfW77D_sK8-ZhgyW52dSmC44TCbcW6bC6Cr19FhBgW1qWyP965C_2tW1t0_Nc9lPxyBW7G2Z2Z3pvQzcW95v4Vx7z_P8-W381LGB7Vm2BJW8XBRjR50HjvNW7jYG522nQmhHW5lNRxC2r7h61W3c3QWF4360qLW29jRYv48g3VqW1_HlyV1qSZQ_W7P_fGb4V_012W35J7j366CHRxW40-86d7Dx0b_f44FQ1g04?ref=dl-staging-website.ghost.io" rel="noopener">WinoGrande</a>&nbsp;and&nbsp;<a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVv7fs6w8krqVqW-g86H4M79W7MhRLh5dSpFkN8SvFFb3qgyTW6N1vHY6lZ3mjW8mb41M5Q2xtvW6vn9Rc8Gd8MvVFtcsP1yy5NvW3hhrMn3sW51mW39m6Ty7l1hqLW5CMnts8stl8zMnMBJbWZ9-YW98nR7s7lqrRDN1T39gpGp6ymW8-T5t94qK5v1VnHHRJ4V05vZW2dgmk17HZ0G3W7Z6sZ-863_PdW6Y1RFF9bzZQ3W7sGt7l3SF-LJW44d7bX1RGdXvW9hjRl_1HdHS_W8YZskJ6bq5ftW8wnSWB1dzt2rW2F6hkK7H--cqW1qhQVP8c10G1W2VbR4N59dPJNf83b0fF04?ref=dl-staging-website.ghost.io" rel="noopener">OpenBookQA</a>, it maintained its accuracy while activating 35 percent of attention heads and fully-connected-layer neurons.</p><p><strong>Why it matters:</strong>&nbsp;Efficient use of processing power becomes increasingly important as models become larger. Moreover, faster token generation benefits agentic workflows, which can consume large numbers of tokens.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Deja Vu’s design is in the spirit of the mixture of experts (MoE) architecture: For each transformer layer, MoE uses a neural-network layer to choose which fully connected layer to use. In contrast, for each attention head and fully-connected-layer neuron, Deja Vu uses small neural networks to decide which to activate.</p><hr /><h2 id="new-from-deeplearningai-1">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1043" src="https://dl-staging-website.ghost.io/content/images/2024/05/V4_Waitlist_DeepLearning_Qualcomm_C1_Banner_2070x1080.png" width="2000" /></a></figure><p>New course with Qualcomm coming soon! In “Introduction to On-Device AI,” you’ll learn how to deploy AI models on edge devices using local computation for faster inference and privacy. Join the next wave of AI as models go beyond the cloud.&nbsp;<a href="https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up for the waitlist</a>!</p>
]]></content:encoded>
<pubDate>Wed, 08 May 2024 22:07:00 GMT</pubDate>
</item>
<item>
<title>Apple's Tiny LLMs, Amazon Rethinks Cashier-Free Stores, Predicting Scientific Discoveries</title>
<link>https://www.deeplearning.ai/the-batch/issue-247</link>
<guid>https://www.deeplearning.ai/the-batch/issue-247</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、预训练、大规模数据、生成数据、苹果公司
总结:
- 语言模型通过预训练和Fine-tuning进行训练，但需要大规模的数据作为预训练数据。
- 生成的数据通常不能用于直接训练模型，但结合自主工作流程可能产生更高质量的数据。
- 苹果公司推出了新的开源大规模语言模型OpenELM，适用于手机等边缘设备，并在多个任务上获得了良好表现。
- AI在科学研究中的应用，如预测材料性质，可以通过构建科学家及其研究对象的关系图来实现。

总结: 语言模型可以通过自主工作流程产生高质量的数据，开源大规模语言模型OpenELM适用于手机等边缘设备，在科学研究中AI能够预测材料性质等。 <div>
<p>Dear friends,</p><p>Inexpensive token generation and agentic workflows for large language models (LLMs) open up intriguing new possibilities for training LLMs on synthetic data. Pretraining an LLM on its own directly generated responses to prompts doesn't help. But if an agentic workflow implemented with the LLM results in higher quality output than the LLM can generate directly, then training on that output becomes potentially useful.</p><p>Just as humans can learn from their own thinking, perhaps LLMs can, too. For example, imagine a math student who is learning to write mathematical proofs. By solving a few problems — even without external input — they can reflect on what does and doesn’t work and, through practice, learn how to more quickly generate good proofs.&nbsp;</p><p>Broadly, LLM training involves (i) pretraining (learning from unlabeled text data to predict the next word) followed by (ii) instruction fine-tuning (learning to follow instructions) and (iii) RLHF/DPO tuning to align the LLM’s output to human values. Step (i) requires many orders of magnitude more data than the other steps. For example,&nbsp;<a href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Llama 3</a>&nbsp;was pretrained on over 15 trillion tokens, and LLM developers are still hungry for more data. Where can we get more text to train on?&nbsp;</p><p>Many developers train smaller models directly on the output of larger models, so a smaller model learns to mimic a larger model’s behavior on a particular task. However, an LLM can’t learn much by training on data it generated directly, just like a supervised learning algorithm can’t learn from trying to predict labels it generated by itself. Indeed, training a model repeatedly on the output of an earlier version of itself can result in&nbsp;<a href="https://www.deeplearning.ai/the-batch/study-reveals-serious-defects-in-models-trained-on-their-own-content/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">model collapse</a>.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--57-.jpg" width="1200" /></figure><p>However, an LLM wrapped in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">agentic workflow</a>&nbsp;may produce higher-quality output than it can generate directly. In this case, the LLM’s higher-quality output might be useful as pretraining data for the LLM itself.&nbsp;</p><p>Efforts like these have precedents:</p><ul><li>When using&nbsp; reinforcement learning to play a game like chess, a model might learn a function that evaluates board positions. If we apply game tree search along with a low-accuracy evaluation function, the model can come up with more accurate evaluations. Then we can train that evaluation function to mimic these more accurate values.</li><li>In the alignment step, Anthropic’s&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">constitutional AI</a>&nbsp;method uses RLAIF (RL from AI Feedback) to judge the quality of LLM outputs, substituting feedback generated by an AI model for human feedback.&nbsp;</li></ul><p>A significant barrier to using LLMs prompted via agentic workflows to produce their own training data is the cost of generating tokens. Say we want to generate 1 trillion tokens to extend a pre-existing training dataset. Currently, at publicly announced prices, generating 1 trillion tokens using GPT-4-turbo ($30 per million output tokens), Claude 3 Opus ($75), Gemini 1.5 Pro ($21), and Llama-3-70B on Groq ($0.79) would cost, respectively, $30M, $75M, $21M and $790K. Of course, an agentic workflow that uses a design pattern like&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Reflection</a>&nbsp;would require generating more than one token per token that we would use as training data. But budgets for training cutting-edge LLMs easily surpass $100M, so spending a few million dollars more for data to boost performance is quite feasible.</p><p>That’s why I believe agentic workflows will open up intriguing new opportunities for high-quality synthetic data generation.&nbsp;</p><p>Keep learning!</p><p>Andrew</p><p>P.S. In “Prompt Engineering for Vision Models,” taught by Abby Morgan, Jacques Verré, and Caleb Kaiser of Comet, you’ll learn how to prompt and fine-tune a variety of vision models for image generation, image editing, object detection, and&nbsp; segmentation. For example, you’ll use OWL-ViT to detect an object you describe in a text prompt, pass the bounding box to SAM to create a segmentation mask, and feed the mask into Stable Diffusion with a text prompt to replace the original object with a new one. Controlling vision models can be tricky, and this course will teach you the techniques to control their output. Get started&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-01T152036.759.gif" width="1200" /></figure><h1 id="think-different-small">Think<strong>&nbsp;<s>Different</s>&nbsp;</strong>Small</h1><p>Apple is thinking small — very small — with a new family of open large language models.</p><p><strong>What's new:&nbsp;</strong>Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, and colleagues at Apple released&nbsp;<a href="https://arxiv.org/abs/2404.14619?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Open Source Efficient LLM</a>&nbsp;(OpenELM), a family of smaller large language models. OpenELM ranges from 270 million parameters — plenty small enough to fit on a phone — to 3 billion parameters.&nbsp;</p><p><strong>How it works:</strong>&nbsp;OpenELM comes in pretrained and instruction-tuned versions with parameter counts of 270 million, 450 million, 1.1 billion, and 3 billion. They can process 2,048 tokens of context. The&nbsp;<a href="https://github.com/apple/corenet?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">release</a>&nbsp;includes weights, code for training and inference, and code for running the models on Apple chips.&nbsp;</p><ul><li>The authors pretrained OpenELM on 1.8 trillion tokens drawn from subsets of&nbsp;<a href="https://arxiv.org/abs/2306.01116?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">publicly</a>&nbsp;<a href="https://www.together.ai/blog/redpajama?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">available</a>&nbsp;<a href="https://arxiv.org/abs/2101.00027?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">text</a>&nbsp;<a href="https://arxiv.org/abs/2402.00159?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">datasets</a>.</li><li>They fine-tuned the instruction-tuned models on the&nbsp;<a href="https://arxiv.org/abs/2310.01377?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">UltraFeedback</a>&nbsp;dataset of 60 thousand prompts.</li><li>OpenELM follows most of the architecture choices of current state-of-the-art transformer models with a major exception: The number of attention heads and size of fully connected layers increase the deeper in the network they are, following the idea that layers later in the network learn more complex representations of the input than early ones. This architecture contrasts to the current common practice, in which a transformer’s number of attention heads and size of fully connected layers remains consistent throughout the network.</li></ul><p><strong>Results:&nbsp;</strong>OpenELM beat a number of other open-source models trained solely on publicly available data.</p><ul><li>For example, on average across five tasks on the&nbsp;<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Open LLM Leaderboard</a>, a 1.08 billion parameter OpenELM beat a 1.18 billion parameter&nbsp;<a href="https://arxiv.org/abs/2402.00838?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">OLMo</a>&nbsp;45.93 percent to 43.57 percent, although OLMo trained on twice as much data. The 270 million-parameter OpenELM achieved 38.72 percent.</li><li>Comparing speed between OpenELM models that ran on consumer-grade computers, the 270 million-parameter model was over twice as fast as the 3 billion-parameter version. Apple did not present results obtained on phones.</li><li>OpenELM fell short on&nbsp;<a href="https://arxiv.org/abs/2009.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MMLU</a><strong>&nbsp;</strong>(multiple choice questions from mathematics to microeconomics), achieving within 2.05 percent of random chance (25 percent) for all model sizes. To be fair, the other models chosen for comparison didn’t do much better. It’s possible that publicly available data isn’t sufficient for learning to solve MMLU. By comparison, Microsoft’s Phi-3-mini (3.8 billion parameters trained on web data filtered according to “educational level” plus generated data) achieved 68.8 percent accuracy.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;After years of becoming only larger, neural networks lately have also been getting smaller. The smallest OpenELMs are tiny compared to, say, Microsoft’s Phi-3-mini. Apple has an extra incentive to make models capable of running on edge devices like phones. The company makes a major selling point of user privacy, and models run entirely on a smartphone (as opposed to in the cloud) keep the user’s activity under wraps.</p><p><strong>We're thinking:</strong>&nbsp;<a href="https://arxiv.org/pdf/2008.00623?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">DeLighT</a>&nbsp;introduced this layer-scaling approach in 2020. Sometimes it takes a while for good ideas to catch on!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/AIINDEX_1200px_14secHolds--1-.gif" width="1200" /></figure><h1 id="ai-trends-in-depth">AI Trends in Depth</h1><p>More expensive models, superhuman performance, growing impacts on society — an extensive report takes stock of developments in machine learning over the past year.&nbsp;</p><p><strong>What's new:</strong>&nbsp;Stanford’s Institute for Human-Centric AI&nbsp;<a href="https://aiindex.stanford.edu/report/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">published</a>&nbsp;the seventh “AI Index Report,” its annual overview of the state of AI. The report documents rising costs and capabilities, a shift from academic to corporate dominance, and the public’s anxiety as the technology becomes ever more embedded in daily life.</p><p><strong>Themes and findings:</strong>&nbsp;The 500-page report collates a wide variety of papers, benchmarks, market research, and surveys published in 2023. It delves deeply into AI technology, economics, governance, and impact. Among its key conclusions:&nbsp;</p><ul><li>Foundation models, defined as versatile models trained on very large datasets, ballooned in number and cost. The Index counted 149 foundation models released in 2023 (including Google’s Gemini Ultra, which cost $191.4 million to train). That’s up from 32 foundation models in 2022, 9 in 2021, and 2 in 2020 (when OpenAI’s GPT-3 175B cost an estimated $4.3 million to train).</li><li>Open foundation models, too, are on the rise: 66 percent of last year’s foundation models were open, up from 33 percent in 2021.</li><li>State-of-the-art models approached or surpassed human performance on several popular benchmarks. These include&nbsp;<a href="https://arxiv.org/pdf/2009.03300v3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MMLU</a>&nbsp;(multitask language understanding),&nbsp;<a href="https://arxiv.org/pdf/2308.06595?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">VisIT-Bench</a>&nbsp;(vision-language instructions), and&nbsp;<a href="https://arxiv.org/pdf/2103.03874?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MATH</a>&nbsp;(difficult math problems).&nbsp;</li><li>Industry was the primary driver of innovation, contributing 57 percent of “notable” machine learning models. Partnerships between industry and academia accounted for 23 percent and academia alone for 17 percent. Corporate dominance in model building was a significant shift from previous years; in 2016, academia and industry contributed AI models equally.</li><li>New models have achieved dramatic results in the sciences. For instance,&nbsp;<a href="https://www.nature.com/articles/s41586-023-06004-9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">AlphaDev</a>&nbsp;found superior sorting algorithms.&nbsp;<a href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">GraphCast</a>&nbsp;generated mid-range weather forecasts more accurately than conventional methods.&nbsp;<a href="https://www.nature.com/articles/s41586-023-06735-9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">GNoME</a>&nbsp;discovered new materials, and&nbsp;<a href="https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">AlphaMissense</a>&nbsp;pinpointed genetic mutations that cause human diseases.</li></ul><p><strong>Behind the news:</strong>&nbsp;The differences between the new one and the initial, 2018 edition highlight the field’s rapid pace of change. For instance, the 2018 report opened by trumpeting the nearly 9x growth of AI research papers published between 2000 and 2017. The new one opened not with the annual rate of research publications (though it has roughly doubled since 2017) but with a graph of industry’s growing dominance in innovation.&nbsp;<em>The Batch</em>&nbsp;has&nbsp;<a href="https://www.deeplearning.ai/the-batch/tag/ai-index/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">covered</a>&nbsp;several editions.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The “AI Index Report” offers a detailed snapshot of AI as it advances at an unprecedented rate and shows potential to revolutionize virtually every field of human endeavor. It dives deeply into areas of special concern to researchers (such as Gemini’s nearly $200 million training cost), practitioners (for instance, the slightly narrowing gender gap among computer science PhDs), businesses (the sharply rising number of regulations), and users (half of those who are aware of ChatGPT use it weekly). This year’s report includes new emphases on public opinion and geopolitics.</p><p><strong>We're thinking:</strong>&nbsp;It’s heartening to see AI thriving. The field faces daunting challenges, yet the report highlights achievements in foundation models, science, medicine, and elsewhere that portend greater benefits directly ahead. What an exciting time for AI!</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-04-29T162119.517.png" width="1680" /></a></figure><p>Expand your prompting skills with our new short course, “Prompt Engineering for Vision Models.” Learn how to prompt and fine-tune vision models to accomplish tasks from image generation to object detection.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models?ref=dl-staging-website.ghost.io" rel="noreferrer">Start learning today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-01T152511.553.png" width="1200" /></figure><h1 id="amazon-rethinks-cashier-free-stores">Amazon Rethinks Cashier-Free Stores</h1><p>Amazon is removing grab-and-go shopping from its cart.</p><p><strong>What’s new:</strong>&nbsp;Amazon withdrew Just Walk Out, an AI-driven checkout service, from most of its Amazon Fresh grocery stores,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/amazons-grocery-stores-to-drop-just-walk-out-checkout-tech?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">reported</a>. Instead, the stores will provide smart shopping carts. (Disclosure: Andrew Ng is a member of Amazon’s Board of Directors.)<br /><br /><strong>Checking out:</strong>&nbsp;<a href="https://www.deeplearning.ai/the-batch/no-cashier-no-problem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Just Walk Out</a>&nbsp;enables shoppers to scan a payment method upon entering a store, take items from shelves tracked by computer vision and weight-detection sensors, and simply exit with their purchases, bypassing the checkout counter. Amazon had installed the system in 47 Amazon Fresh stores in the U.S. and UK. In most of those locations. Amazon will replace Just Walk Out with&nbsp;<a href="https://www.aboutamazon.com/news/retail/amazon-dash-cart-new-features-whole-foods?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Dash Cart</a>, a shopping cart that enables customers to scan purchases as they shop. Amazon will retain Just Walk Out in its Amazon Go convenience stores and an unspecified number of smaller, UK-based Amazon Fresh stores. It has licensed the system to other retailers including Hudson Markets and plans to install in more third-party stores this year.</p><ul><li>Just Walk Out isn’t well suited to grocery shopping, in which customers may buy large numbers of items, since customers may not be aware of their total spending until they receive a receipt via email after leaving the store, Amazon executive Tony Hoggett said. Dash Cart enables users to see the bill in real time.</li><li>Just Walk Out&nbsp;<a href="https://www.theinformation.com/articles/how-amazons-big-bet-on-just-walk-out-stumbled?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">relied on</a>&nbsp;more than 1,000 remote employees to label video for training and review cases where it failed, and Amazon wasn’t able to improve the system as quickly as it expected, according to an earlier report by&nbsp;<em>The Information</em>. As of mid-2022, the system required about 700 human reviews per 1,000 sales, compared to a target between 20 and 50 per 1,000 sales. Amazon said the percentage of sales that require human review has declined since then.</li><li>Training the models required 2,000 technologists and cost hundreds of millions of dollars in cloud computing resources to train and run.</li><li>Just Walk Out’s cameras and sensors can be difficult to install in existing stores and sometimes requires extensive remodeling. The system also&nbsp;<a href="https://www.theverge.com/2019/9/10/20857921/amazon-go-rollout-delay-cashierless-convenience-stores-whole-foods?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">requires</a>&nbsp;high ceilings, which existing stores may not have.</li></ul><p><strong>Behind the news:</strong>&nbsp;Amazon&nbsp;<a href="https://www.deeplearning.ai/the-batch/retailers-spend-on-smarter-stores/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">introduced</a>&nbsp;Just Walk Out in 2016 at its first Amazon Go convenience store in Seattle. It&nbsp;<a href="https://www.deeplearning.ai/the-batch/no-cashier-no-problem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">extended</a>&nbsp;the system to Amazon Fresh in 2020. Between September 2020 and September 2022, Amazon opened 44 Fresh stores in the U.S. and 19 in the UK, most of which included Just Walk Out. But Amazon’s brick-and-mortar locations&nbsp;<a href="https://www.cnbc.com/2022/02/19/amazons-sprawling-grocery-business-has-become-an-expensive-hobby.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">suffered</a>&nbsp;during the COVID-19 pandemic. From September 2022 to mid-2024, amid broader cost-cutting efforts, the company&nbsp;<a href="https://www.theinformation.com/articles/zombie-amazon-grocery-stores-pile-up-as-openings-grind-to-a-halt?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">paused</a>&nbsp;opening new grocery stores.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Grab-and-go shopping seems like a solid bet, given the increasing focus of retailing on immediate gratification. Yet Amazon’s retreat from Just Walk Out in larger stores suggests that the technology is less well suited to such environments. In addition, shoppers may not have adjusted easily to grab-and-go behavior, which removes social interactions with cashiers and encourages customers to spend without reviewing the bill.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;AI has the potential to revolutionize every field, including retailing, and it’s important to find productive uses for it. Not all experiments will succeed, but patient investment and experimentation can illuminate productive paths forward.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/SCIENCE-FIX.gif" width="600" /></figure><h1 id="predicting-scientific-discoveries">Predicting Scientific Discoveries</h1><p>A new AI method directs scientists toward promising avenues of inquiry.</p><p><strong>What's new:</strong>&nbsp;Jamshid Sourati and James A. Evans at University of Chicago proposed a&nbsp;<a href="https://www.nature.com/articles/s41562-023-01648-z?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">method to predict new scientific discoveries</a>&nbsp;by building a graph that connects researchers, their objects of study, and the scientific properties thereof. They evaluated their approach using data from materials science.</p><p><strong>Key insight:</strong>&nbsp;Overlapping interests among researchers may indicate areas where further research would be fruitful. For example, if one group of researchers studies a material A and its property P, a second group studies materials A and B, and another group studies materials B and C, it may turn out that material C exhibits property P.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors tried to predict whether certain inorganic materials have certain electrical properties based on&nbsp;<a href="https://europepmc.org/article/med/31270483?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">scientific literature</a>&nbsp;through the year 2000. From 1.5 million articles that described 100,000 inorganic compounds, they extracted the author names, materials mentioned (for example, sodium nitrite), and their properties (for example, thermoelectricity, the ability to convert heat into electricity and vice versa). They used this data to construct a graph whose nodes were authors, materials, and properties. Edges connected the nodes that appeared in the same paper, for example a particular author whose paper covered specific material or property.</p><ul><li>The authors conducted random walks through the graph, stepping from node to node, to produce sequences of authors, materials, and properties. Then they removed the authors from the sequences, because they were interested mainly in establishing possible connections between materials and properties.&nbsp;</li><li>They trained&nbsp;<a href="https://arxiv.org/abs/1301.3781?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Word2Vec</a>, which computes word embeddings, on their sequences, treating materials and properties as words and sequences as documents. This yielded an embedding for each material and property.</li><li>To predict possible discoveries — that is, which material might exhibit a given property — the authors scored each material based on (i) the similarity between the material’s embedding and the given property’s embedding and (ii) the smallest number of edges in the path that connected each material and the property. Then they summed scores (i) and (ii). The 50 highest-scoring materials were predicted to have the property (that weren’t directly connected in the graph; that is, excluding materials that already were known to have the property).&nbsp;&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;The authors predicted which materials possessed each of three properties. They compared their results with predictions obtained in a similar way using a Word2Vec model trained exclusively on text from scientific papers. They used papers from 2001 through 2018 to evaluate the predictions. For thermoelectricity, the cumulative precision (percentage of predicted discoveries proven correct) was 76 percent, while the cumulative precision of the alternative method was 48 percent. The cumulative precision of random guesses was about 3 percent. The authors obtained similar results for the other two properties.</p><p><strong>Why it matters:</strong>&nbsp;Science is a social endeavor, where the connections between people and their work can be represented as a graph that reflects the collective attention of the scientific community. The collective attention acts as a signal that predicts promising avenues for further research — a signal that machine learning can help to tease out.&nbsp;</p><p><strong>We're thinking:</strong>&nbsp;The authors also predicted drug discoveries with similarly good results. Their method may be useful for identifying fruitful directions in other scientific areas, and perhaps in other domains entirely.</p><hr /><h1 id="data-points">Data Points</h1><p>This week's <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> features these highlights: Adobe's latest Firefly Image 3 model, enhanced smart glasses with Meta’s AI assistant, an AI-powered gene editor, and more.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-247/?ref=dl-staging-website.ghost.io" rel="noreferrer">Catch up on the latest in AI now.</a></p>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 20:39:36 GMT</pubDate>
</item>
<item>
<title>Pop Song Generators, 3D Mesh Generators, Real-World Benchmarks, AI for Manufacturing</title>
<link>https://www.deeplearning.ai/the-batch/issue-246</link>
<guid>https://www.deeplearning.ai/the-batch/issue-246</guid>
<content:encoded><![CDATA[
<div> 大规模语言模型，生成token的速度，计算力成本下降，AI在制造业的应用，基于单张图像生成3D模型 <br /><br />总结:<br />本文介绍了大规模语言模型在训练和推理过程中所需的计算力以及生成token的速度对于人工智能的重要性。作者指出，除了训练外，推理过程也需要更多的计算资源。而在今天的应用场景中，大量的token生成是十分有价值的，生成速度慢会成为利用基础模型的瓶颈。此外，作者也表示，计算力成本正在快速下降，这对于应用构建者和AI工作流有着积极的影响。文章还介绍了一些相关的技术进展，如基于文本的音乐生成和基于单张图像的3D模型生成。最后，文章提到了制造业中的AI应用，并指出了技能和数据的瓶颈可能是制造业中推广AI的挑战。总的来说，本文探讨了AI技术在各个领域的不断发展和应用前景。 <div>
<p>Dear friends,</p><p>Much has been said about many companies’ desire for more compute (as well as data) to train larger foundation models. I think it’s under-appreciated that we have nowhere near enough compute available for inference on foundation models as well.</p><p>Years ago, when I was leading teams at Google, Baidu, and Stanford that focused on scaling up deep learning algorithms, many semiconductor manufacturers, data center operators, and academic researchers asked me whether I felt that AI technology would continue to make good use of more compute if they kept on delivering it. For many normal desktop processing workloads, like running a web browser or a text editor, having a faster CPU doesn’t help that much beyond a certain point. So do we really need faster and faster AI processors to train larger and larger models? Each time, I confidently replied “yes!” and encouraged them to keep scaling up compute. (Sometimes, I added half-jokingly that I had never met a machine learning engineer who felt like they had enough compute. 😀)</p><p>Fortunately, this prediction has been right so far.&nbsp;However, beyond training, I believe we are also far from exhausting the benefits of faster and higher volumes of inference.</p><p>Today, a lot of LLM output is primarily for human consumption. A human might read around 250 words per minute, which is around 6 tokens per second (250 words/min / (0.75 words/token) / (60 secs/min)). So it might initially seem like there’s little value to generating tokens much faster than this. &nbsp;</p><p>But in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">agentic workflow</a>, an LLM might be prompted repeatedly to reflect on and improve its output, use tools, plan and execute sequences of steps, or implement multiple agents that collaborate with each other. In such settings, we might easily generate hundreds of thousands of tokens or more before showing any output to a user. This makes fast token generation very desirable and makes slower generation a bottleneck to taking better advantage of existing foundation models.</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/TOKEN-GENERATION.png" width="1200" /></figure><p>That’s why I’m excited about the work of companies like&nbsp;<a href="https://groq.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Groq</a>, which can generate hundreds of tokens per second. Recently,&nbsp;<a href="https://fast.snova.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">SambaNova</a>&nbsp;published an impressive demo that hit hundreds of tokens per second.</p><p>Incidentally, faster, cheaper token generation will also help make running evaluations (evals), a step that can be slow and expensive today since it typically involves iterating over many examples, more palatable. Having better evals will help many developers with the process of tuning models to improve their performance.</p><p>Fortunately, it appears that both training and inference are rapidly becoming cheaper. I recently spoke with Cathie Wood and Charles Roberts of the investment firm ARK, which is famous for its bullish predictions on tech. They&nbsp;<a href="https://www.ark-invest.com/big-ideas-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">estimate</a>&nbsp;that AI training costs are falling at 75% a year. If they are right, a foundation model that costs $100M to train this year might cost only $25M to train next year. Further, they report that for “enterprise scale use cases, inference costs seem to be falling at an annual rate of ~86%, even faster than training costs.”</p><p>I don’t know how accurate these specific predictions will turn out to be, but with improvements in both semiconductors and algorithms, I do see training and inference costs falling rapidly. This will be good for application builders and help AI agentic workflows lift off.</p><p>Keep learning!</p><p>Andrew</p><p>P.S. New short course with Mistral AI! Mistral’s open-source Mixtral 8x7B model uses a mixture of experts (MoE) architecture. Unlike a standard transformer, MoE uses multiple expert feed-forward networks with a gating network that selects a number of experts at inference time. This enables MoE to match the performance of larger models but with faster inference. Mixtral 8x7B has 46.7B parameters but activates only 12.9B at inference time to predict the next token. In “Getting Started with Mistral,” taught by Sophia Yang, you’ll explore Mistral’s open-source (Mistral 7B, Mixtral 8x7B) and commercial models, learn about function calling for tool use with Mistral, and build a Mistral-powered chat interface that can reference external documents. Please sign up&nbsp;<a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-24T134335.199.gif" width="1200" /></figure><h1 id="songs-made-to-order">Songs Made to Order</h1><p>A new breed of audio generator produces synthetic performances of songs in a variety of popular styles.</p><p><strong>What’s new:</strong>&nbsp;Udio&nbsp;<a href="https://www.udio.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">launched</a>&nbsp;a web-based, text-to-song generator that creates songs in styles from barbershop to heavy metal.&nbsp;<a href="https://suno.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Suno</a>, which debuted its service late last year with similar capabilities, upgraded to its offering.</p><p><strong>How it works:</strong>&nbsp;Both services take text prompts and generate full-band productions complete with lyrics, vocals, and instrumental solos, two separate generations per prompt. Users can generate lyrics to order or upload their own words, and they can download, share, and/or post the results for others to hear. Leaderboards rank outputs according to plays and likes.&nbsp;</p><ul><li>Founded by alumni of Google’s DeepMind division, Udio lets registered users generate up to 1,200 songs monthly for free and expects to offer paid services at an unspecified future date. Users enter a text prompt and/or choose style tags. The system automatically replaces artist names with stylistic descriptions but sometimes produces results that sound uncannily&nbsp;<a href="https://youtu.be/7U57R_icuOg?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">like</a>&nbsp;the artists requested. Users can choose to generate an instrumental track or add lyrics, allocating them to verse, chorus, or background vocals. Udio generates audio segments 33 seconds long, which users can extend, remix, and modify. The company has not released information about the underlying technology.&nbsp;</li><li>Suno lets users generate 10 songs daily for free or pay to generate more. Enter a prompt, and the system generates complete songs up to 2 minutes long; alternatively, users can specify lyrics, style, and title in separate prompts. The system refuses to generate music from prompts that include the name of a real-world artist. Suno hasn’t disclosed technical information, but last year it&nbsp;<a href="https://github.com/suno-ai/bark?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">released</a>&nbsp;an open-source model called Bark that turns a text prompt into synthetic music, speech, and/or sound effects.</li></ul><p><strong>Behind the news:</strong>&nbsp;Most earlier text-to-music generators were designed to produce relatively free-form instrumental compositions rather than songs with structured verses, choruses, and vocals. Released earlier this month,&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Stable Audio 2</a>&nbsp;generates instrumental tracks up to three minutes long that have distinct beginnings, middles, and endings. Users can also upload audio tracks and use Stable Audio 2.0 to modify them.</p><p><strong>Yes, but:&nbsp;</strong>Like text-to-image generators circa last year, current text-to-music models offer little ability to steer their output. They don’t respond consistently to basic musical terminology such as “tempo” and “harmony,” and requesting a generic style like “pop” can summon a variety of subgenres from the last 50 years of popular music.</p><p><strong>Why it matters:</strong>&nbsp;With the advent of text-to-music models that produce credible songs, audio generation seems primed for a Midjourney moment, when the public realizes that it can produce customized music at the drop of a prompt. Already Udio’s and Suno’s websites are full of whimsical paeans to users’ pets and hobbies. The technology has clear implications for professional performers and producers, who, regrettably, have little choice but to&nbsp;<a href="https://www.deeplearning.ai/the-batch/grimes-released-a-voice-cloning-tool/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">adapt</a>&nbsp;to increasing automation. But for now fans have fun, new toys to play with.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;You can dance to these algo-rhythms!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/VALS-4Leaderboards_1200px--1-.gif" width="1200" /></figure><h1 id="benchmarks-for-industry">Benchmarks for Industry</h1><p>How well do large language models respond to professional-level queries in various industry domains? A new company aims to find out.</p><p><strong>What’s new:</strong>&nbsp;<a href="https://www.vals.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Vals.AI</a>, an independent model testing service, developed benchmarks that rank large language models’ performance of tasks associated with income taxes, corporate finance, and contract law; it also maintains a pre-existing legal benchmark. Open AI’s GPT-4 and Anthropic’s Claude 3 Opus did especially well in recent tests.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Vals AI hosts leaderboards that compare the performance of several popular large language models (LLMs) with respect to accuracy, cost, and speed, along with with analysis of the results. The company worked with independent experts to develop multiple-choice and open-ended questions in industrial domains. The datasets are not publicly available.&nbsp;</p><ul><li><a href="https://www.vals.ai/contractlaw?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">ContractLaw</a>&nbsp;includes questions related to contracts. They ask models to retrieve parts of contracts that are relevant to particular terms, edit excerpts, and determine whether excerpts meet legal standards.</li><li><a href="https://www.vals.ai/corpfin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">CorpFin</a>&nbsp;tests accuracy in answering corporate finance questions. It feeds to models a public commercial credit agreement — terms of a business loan or a line of credit — and poses questions that require extracting information and reasoning over it.</li><li><a href="https://www.vals.ai/taxeval?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">TaxEval</a>&nbsp;tests accuracy on tax-related prompts. Half of the questions test skills like calculating taxable income, marginal rate, and the like. The other half cover knowledge such as how different accounting methods impact taxes or how taxes apply to various types of assets.</li><li>Vals AI also tracks&nbsp;<a href="https://www.vals.ai/legalbench?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">performance</a>&nbsp;on&nbsp;<a href="https://arxiv.org/abs/2308.11462?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">LegalBench</a>, an open benchmark that evaluates legal reasoning.</li></ul><p><strong>Results:</strong>&nbsp;Among 15 models, GPT-4 and Claude 3 Opus dominated Vals.AI’s leaderboards as of April 11, 2024. GPT-4 topped CorpFin and TaxEval, correctly answering 64.8 and 54.5 percent of questions, respectively. Claud 3 Opus narrowly beat GPT-4 on ContractLaw and LegalBench, achieving 74.0 and 77.7 percent, respectively. The smaller Claude 3 Sonnet took third place in ContractLaw, CorpFin, and TaxEval with 67.6, 61.4, and 37.1 percent. Google’s Gemini Pro 1.0 took third place in LegalBench with 73.6 percent.</p><p><strong>Behind the news:</strong>&nbsp;Many practitioners in&nbsp;<a href="https://www.deeplearning.ai/the-batch/new-report-on-the-ai-capabilities-of-major-banks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">finance</a>&nbsp;and&nbsp;<a href="https://www.clio.com/blog/lawyer-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">law</a>&nbsp;use LLMs in applications that range from processing documents to&nbsp;<a href="https://www.deeplearning.ai/the-batch/jpmorgan-trained-ai-to-interpret-the-federal-reserves-intent/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">predicting interest rates</a>. However, LLM output in such applications requires oversight. In 2023, a New York state judge&nbsp;<a href="https://www.deeplearning.ai/the-batch/attorney-faces-disciplinary-action-for-using-chatgpts-fictional-brief/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">reprimanded</a>&nbsp;a lawyer for submitting an AI-generated brief that referred to fictitious cases.</p><p><strong>Why it matters:</strong>&nbsp;Typical AI benchmarks are designed to evaluate general knowledge and cognitive abilities. Many developers would like to measure more directly performance in real-world business contexts, where specialized knowledge may come into play.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Open benchmarks can benefit from public scrutiny, and they’re available to all developers. However, they can be abused when developers cherry-pick benchmarks on which their models perform especially well. Moreover, they may find their way into training sets, making for unfair comparisons. Independent testing on proprietary benchmarks is one way to address these issues.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-23T091059.531.png" width="1680" /></a></figure><p>Join “Getting Started with Mistral” and access Mistral AI’s open source and commercial models via API calls. Learn to select the right model for your use case and get hands-on with features like JSON mode, function calling, and effective prompting techniques.&nbsp;<a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Enroll for free</a>!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/MANUFACTURING_14-SecHolds_1200px--1---1-.gif" width="1200" /></figure><h1 id="ai-progress-report-manufacturing">AI Progress Report: Manufacturing</h1><p>Manufacturers are embracing AI even as they struggle to find the talent and data required.</p><p><strong>What’s new:</strong>&nbsp;The market-research arm of&nbsp;<em>MIT Technology Review</em>&nbsp;<a href="https://www.technologyreview.com/2024/04/09/1090880/taking-ai-to-the-next-level-in-manufacturing/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">surveyed</a>&nbsp;manufacturers’ use of AI in engineering, design, procurement, and production. All respondents were at least experimenting with AI, and many expect to launch their first deployments in the next year or two. Microsoft sponsored the research.</p><p><strong>How it works:</strong>&nbsp;The authors interviewed executives at 300 manufacturers in aerospace, automotive, chemicals, electronics, and heavy equipment. All were either applying or considering AI in product design or factory operations.&nbsp;</p><ul><li>The most common uses of AI in production involved designing products, creating content such as technical documentation, and building chatbots. The most common uses in earlier stages were knowledge management and quality control.</li><li>35 percent of respondents had deployed AI in production. Another 37 percent were experimenting with AI, while 27 percent were conducting preliminary research.</li><li>45 percent of respondents in electronics and 39 percent in automotive had deployed AI in production. Larger companies were more likely to have deployed AI (77 percent of companies with revenues over $10 billion compared to 4 percent of those with revenues under $500 million). Larger companies were also more likely to forecast increases in AI spending in the next two years.</li><li>Asked to name the biggest challenges to scaling up uses of AI, respondents most often pointed to shortages of skills and talent. Asked to name challenges their company faced with respect to data, they pointed to maintaining data quality, integrating data from different parts of an organization, and governing data.</li></ul><p><strong>Behind the news:</strong>&nbsp;Manufacturers are using AI to help&nbsp;<a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/generative-ai-fuels-creative-physical-product-design-but-is-no-magic-wand?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">design products</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/super-human-quality-control/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">visually inspect goods</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/if-it-aint-broke-fix-it/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">maintain equipment</a>. The field has attracted major players: Last year, Microsoft and Siemens&nbsp;<a href="https://www.deeplearning.ai/the-batch/siemens-and-microsoft-launch-gpt-powered-copilot-for-manufacturing-machinery/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">launched</a>&nbsp;a pilot of Industrial Copilot, which enables users to interact in natural language with software that drives assembly lines.</p><p><strong>Why it matters:</strong>&nbsp;Manufacturers want to use AI, but many face obstacles of talent and data. That spells opportunities for budding practitioners as well as for manufacturers that lack infrastructure for collecting and managing data.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;One key to successful implementation of AI in manufacturing is tailoring systems to the unique circumstances of each individual facility. The highly heterogeneous tasks, equipment, and surroundings in different factories mean that one model doesn’t fit all. Developers who can solve this long-tail problem stand to reap rewards.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-24T134817.631.gif" width="600" /></figure><h1 id="a-3d-model-from-one-2d-image">A 3D Model From One 2D Image</h1><p>Video diffusion provides a new basis for generating 3D models.<br /><strong>What's new:&nbsp;</strong>Vikram Voleti, Chun-Han Yao, Mark Boss, Varun Jampani, and colleagues at Stability AI produced a&nbsp;<a href="https://arxiv.org/abs/2403.12008?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">method</a>&nbsp;that generates a 3D model from a single image based on Stability’s video diffusion model. You can see its output&nbsp;<a href="https://stability.ai/news/introducing-stable-video-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">here</a>.<br /><br /><strong>Key insight:</strong>&nbsp;The approach known as a&nbsp;<a href="https://arxiv.org/abs/2003.08934?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Neural Radiance Field</a>&nbsp;(NeRF) learns to create a 3D model from images of the same object shot at various angles. Given a single image of an object, a video diffusion model can learn to generate videos that orbit around it. The frames from such orbital videos give NeRF the information it needs to produce a 3D model.&nbsp;<br /><br /><strong>How it works:</strong>&nbsp;To generate an image, the authors took one step before and two steps during inference. Before inference: Learn to generate an orbital video. During inference: (i) Train a NeRF model on an orbital video. (ii) Improve the 3D model using diffusion following&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-dreamfusion-generates-3d-images-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">DreamFusion</a>.&nbsp;</p><ul><li>The authors fine-tuned a pretrained&nbsp;<a href="https://arxiv.org/abs/2311.15127?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Stable Video Diffusion</a>, given an image of an object, to generate an orbital video. They fine-tuned the model on orbital views of synthetic objects in the&nbsp;<a href="https://arxiv.org/abs/2212.08051?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Objaverse</a>&nbsp;dataset, first without and then with information about the camera’s orbit. They called the fine-tuned model Stable Video 3D (SV3D).</li><li>At inference, SV3D generated an orbital video from an image, where the orbit periodically went up and down to ensure the top and bottom of the object were visible. From these images, the authors trained an&nbsp;<a href="https://arxiv.org/abs/2201.05989?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Instant-NGP</a>&nbsp;NeRF model, which learned to represent the object as a 3D model and generate pictures from new camera angles based on different views of the same object.&nbsp;</li><li>To improve the 3D model, the authors first represented it using DMTet&nbsp;instead of Instant-NGP. DMTet is a system of networks built to refine 3D shapes from rough point clouds or low-resolution 3D models. The authors rendered images of DMTet’s 3D model along random camera orbits. For each image, the authors added noise to the image’s representation and removed it using SV3D. DMTet learned to update its 3D model to minimize the difference between the rendered image and the updated version from SV3D.</li></ul><p><strong>Results:</strong>&nbsp;The authors produced 3D models from images of 50 objects in&nbsp;<a href="https://arxiv.org/abs/2204.11918?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">GSO</a>, a 3D object dataset of scanned household items. They compared their 3D models to those produced by other methods including&nbsp;<a href="https://arxiv.org/abs/2402.03908?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">EscherNet</a>, a method that uses an image diffusion model to generate images of an object from different angles that are used to train a&nbsp;<a href="https://arxiv.org/abs/2106.10689?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">pair of vanilla neural networks</a>&nbsp;to produce a 3D model. Evaluated according to Chamfer distance, a measure of the distance between the points on the ground truth and generated 3D models (lower is better), their method achieved .024, while EscherNet achieved .042.</p><p><strong>Why it matters:</strong>&nbsp;Video diffusion models must generate different views of the same object, so they require a greater understanding of 3D objects than image diffusion models, which need to generate only one view at a time. Upgrading from an image diffusion model to a video diffusion model makes for better 3D object generation.<br /><br /><strong>We’re thinking:</strong>&nbsp;Building 3D models used to be difficult, but with models like this, it's becoming less of a mesh.</p>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 18:50:15 GMT</pubDate>
</item>
<item>
<title>AI Agents With Low/No Code, Hallucinations Create Security Holes, Tuning for RAG Performance, GPT Store's Lax Moderation</title>
<link>https://www.deeplearning.ai/the-batch/issue-245</link>
<guid>https://www.deeplearning.ai/the-batch/issue-245</guid>
<content:encoded><![CDATA[
<div> 多智能体协作, LLM, 复杂任务, 分解子任务, 多种角色, 结果表明, LLM的能力, <div>
<p>Dear friends,</p><p>Multi-agent collaboration is the last of the four&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">key AI agentic design patterns</a>&nbsp;that I’ve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles — such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on — and have different agents accomplish different subtasks.</p><p>Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: “You are an expert in writing clear, efficient code. Write code to perform the task . . ..”&nbsp;</p><p>It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I’d like to offer a few reasons:</p><ul><li>It works! Many teams are getting good results with this method, and there’s nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.&nbsp;</li><li>Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role’s subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.</li><li>Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.</li></ul><figure class="kg-card kg-image-card"><img alt="Proposed ChatDev architecture, illustrated." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T155856.845-1.png" width="1200" /></figure><p>In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.&nbsp;</p><p>While managing people is hard, it's a sufficiently familiar idea that it gives us a mental framework for how to "hire" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!&nbsp;</p><p>Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you're interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their&nbsp;<a href="https://github.com/OpenBMB/ChatDev?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">GitHub repo</a>&nbsp;and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does.&nbsp;</p><p>Like the design pattern of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Planning</a>, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Reflection</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Tool Use</a>&nbsp;are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!&nbsp;</p><p>If you're interested in learning more, I recommend:&nbsp;</p><ul><li>“<a href="https://arxiv.org/abs/2307.07924?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Communicative Agents for Software Development</a>,” Qian et al. (2023) (the ChatDev paper)</li><li>“<a href="https://arxiv.org/abs/2308.08155?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a>,” Wu et al. (2023)&nbsp;</li><li>“<a href="https://arxiv.org/abs/2308.00352?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">MetaGPT: Meta Programming for a Multi-Agent Collaborative Framework</a>,” Hong et al. (2023)</li></ul><p>Keep learning!</p><p>Andrew</p><p>P.S. Large language models (LLMs) can take gigabytes of memory to store, which limits your ability to run them on consumer hardware. Quantization can reduce model size by 4x or more while maintaining reasonable performance. In our new short course “Quantization Fundamentals,” taught by Hugging Face's Younes Belkada and Marc Sun, you’ll learn how to quantize LLMs and how to use int8 and bfloat16 (Brain Float 16) data types to load and run LLMs using PyTorch and the Hugging Face Transformers library. You’ll also dive into the technical details of linear quantization to map 32-bit floats to 8-bit integers. I hope you’ll&nbsp;<a href="https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">check it out</a>!&nbsp;</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T160143.589.gif" width="1200" /></figure><h1 id="custom-agents-little-coding">Custom Agents, Little Coding</h1><p>Google is empowering developers to build autonomous agents using little or no custom code.</p><p><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://cloud.google.com/blog/products/ai-machine-learning/build-generative-ai-experiences-with-vertex-ai-agent-builder?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">introduced</a>&nbsp;Vertex AI Agent Builder, a low/no-code toolkit that enables Google’s AI models to run external code and ground their responses in Google search results or custom data.<br /><br /><strong>How it works:</strong>&nbsp;Developers on Google’s Vertex AI platform can build agents and integrate them into multiple applications. The service&nbsp;<a href="https://cloud.google.com/products/agent-builder?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">costs</a>&nbsp;$12 per 1,000 queries and can use Google Search for $2 per 1,000 queries.</p><ul><li>You can set an agent’s goal in natural language (such as “You are a helpful assistant. Return your responses in markdown format.”) and provide instructions (such as “Greet the user, then ask how you can help them today”).&nbsp;</li><li>Agents can ground their outputs in external resources including information retrieved from Google’s&nbsp;<a href="https://cloud.google.com/enterprise-search?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Enterprise Search</a>&nbsp;or&nbsp;<a href="https://cloud.google.com/bigquery?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">BigQuery</a>&nbsp;data warehouse. Agents can generate a confidence score for each grounded response. These scores can drive behaviors such as enabling an agent to decide whether its confidence is high enough to deliver a given response.</li><li>Agents can use tools, including a code interpreter that enables agents to run Python scripts. For instance, if a user asks about popular tourist locations, an agent can call a tool that retrieves a list of trending attractions near the user’s location. Developers can define their own tools by providing instructions to call a function, built-in&nbsp;<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">extension</a>, or external API.</li><li>The system integrates custom code via the open source library<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua"><u>&nbsp;</u>LangChain</a>&nbsp;including the&nbsp;<a href="https://blog.langchain.dev/langgraph-multi-agent-workflows/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">LangGraph</a>&nbsp;extension for building multi-agent workflows. For example, if a user is chatting with a conversational agent and asks to book a flight, the agent can route the request to a subagent designed to book flights.</li></ul><p><strong>Behind the news:&nbsp;</strong>Vertex AI Agent Builder consolidates agentic features that some of Google’s competitors have rolled out in recent months. For instance, OpenAI’s&nbsp;<a href="https://platform.openai.com/docs/assistants/overview?context=with-streaming&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Assistants API</a>&nbsp;lets developers build agents that respond to custom instructions, retrieve documents (limited by file size), call functions, and access a code interpreter. Anthropic recently&nbsp;<a href="https://docs.anthropic.com/claude/docs/tool-use?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">launched</a>&nbsp;Claude Tools, which lets developers instruct Claude language models to call customized tools. Microsoft’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-extends-copilot-365-windows/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Windows Copilot</a>&nbsp;and&nbsp;<a href="https://support.microsoft.com/en-us/topic/microsoft-copilot-gpt-builder-overview-65499971-a502-4a96-a5c3-265cb59c012d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Copilot Builder</a>&nbsp;can call functions and retrieve information using Bing search and user documents stored via Microsoft Graph.</p><p><strong>Why it matters:&nbsp;</strong>Making agents practical for commercial use can require grounding, tool use, multi-agent collaboration, and other capabilities. Google’s new tools are a step in this direction, taking advantage of investments in its hardware infrastructure as well as services such as search. As tech analyst Ben Thompson&nbsp;<a href="https://stratechery.com/2024/gemini-1-5-and-googles-nature/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">writes</a>, Google’s combination of scale, interlocking businesses, and investment in AI infrastructure makes for a compelling synergy.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>Big-tech offerings like Vertex Agent Builder compete with an expanding universe of open source tools such as AutoGen, CrewAI, and LangGraph. The race is on to provide great agentic development frameworks!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T170803.947.png" width="1200" /></figure><h1 id="hallucination-creates-security-holes">Hallucination Creates Security Holes</h1><p>Language models can generate code that erroneously points to software packages, creating vulnerabilities that attackers can exploit.</p><p><strong>What’s new:</strong>&nbsp;A cybersecurity researcher noticed that large language models, when used to generate code, repeatedly produced a command to install a package that was not available on the specified path,&nbsp;<em>The Register</em>&nbsp;<a href="https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">reported</a>. He created a dummy package of the same name and uploaded it to that path, and developers duly installed it.<br /><br /><strong>How it works:</strong>&nbsp;Bar Lanyado, a researcher at Lasso Security, found that the erroneous command&nbsp;<em>pip install huggingface-cli</em>&nbsp;appeared repeatedly in generated code. The package&nbsp;<em>huggingface-cli</em>&nbsp;does exist, but it is installed using the command&nbsp;<em>pip install -U “huggingface_hub[cli]"</em>. The erroneous command attempts to download a package from a different repository. Lanyado published some of his findings in a&nbsp;<a href="https://www.lasso.security/blog/ai-package-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">blog post</a>.&nbsp;</p><ul><li>Lanyado uploaded a harmless package with that name. Between December 2023 and March 2024, the dummy package was downloaded more than 15,000 times. It is not clear whether the downloads resulted from generated code, mistaken advice on bulletin boards, or user error.&nbsp;</li><li>Several repositories on Github used or recommended the dummy package, including&nbsp;<a href="https://github.com/alibaba/graphtranslator?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">GraphTranslator</a>, which has been updated to remove the reference. Hugging Face itself called the package in one of its own projects; the company&nbsp;<a href="https://github.com/huggingface/diffusers/commit/56b68459f50f7d3af383a53b02e298a6532f3084?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">removed</a>&nbsp;the call after Lanyado notified it.</li><li>In research published last year, Lanyado&nbsp;<a href="https://vulcan.io/blog/ai-hallucinations-package-risk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">described</a>&nbsp;ChatGPT’s tendency to recommend a nonexistent Node.js package called arangodb. (<a href="https://arangodb.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">ArangoDB</a>&nbsp;is a real database query system, but its official Node.js package is arangojs.) Lanyado demonstrated that it was possible to create a new package with the erroneous name and install it using ChatGPT’s instructions.</li></ul><p><strong>Testing:</strong>&nbsp;Lanyado&nbsp;<a href="https://www.lasso.security/blog/ai-package-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">tested</a>&nbsp;Cohere AI’s Coral, Google’s Gemini Pro, and OpenAI’s GPT-4 and GPT-3.5. His aim was to determine how often they hallucinated packages and how often they referred repeatedly to the same hallucinated package. First he collected roughly 47,000 “how to” questions related to over 100 subjects in Go, .NET, Node.js, Python, and Ruby. Then he identified questions that produced hallucinated packages from a zero-shot prompt. He selected 20 of these questions at random and prompted each model 100 times to see whether it would refer to the same package every time.</p><ul><li>Of the models tested, Gemini Pro hallucinated packages most often, while Coral hallucinated packages most repeatedly. Here's (a) how often each model hallucinated packages and (b) how often it hallucinated the same package repeatedly. Coral: (a) 29.1 percent, (b) 24.2 percent. Gemini Pro: (a) 64.5 percent, (b) 14 percent. GPT-4: (a) 24.2 percent, (b) 19.6 percent. GPT-3.5 (a) 22.2 percent, (b) 13.6 percent.</li><li>The percentage of references to hallucinated packages also varied depending on the programming language. Using GPT-4, for example, 30.9 percent of Go queries referred to a hallucinated package compared to 28.7 percent of .NET queries, 19.3 percent of Node.js queries, 25 percent of Python queries, and 23.5 percent of Ruby queries.</li><li>Generally, Python and Node.js are more vulnerable to this type of attack than Go and .NET, which block access to certain paths and filenames. Of the Go and .NET prompts that returned a hallucinated package name, 2.9 percent and 21.2 percent were exploitable, respectively.</li></ul><p><strong>Why it matters:</strong>&nbsp;Lanyado’s method is not known to have been used in an attack, but it may be only a matter of time given its similarity to&nbsp;<a href="https://blog.gitguardian.com/protecting-your-software-supply-chain-understanding-typosquatting-and-dependency-confusion-attacks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">hacks</a>&nbsp;like typosquatting, dependency confusion, and masquerading.</p><p><strong>We’re thinking:</strong>&nbsp;Improved AI-driven coding tools should help to address this issue. Meanwhile, the difference between a command like pip install huggingface-cli and pip install -U "huggingface_hub[cli]" is subtle. In cases like this, package providers can look out for potential doppelgangers and warn users from being misled.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-16T091800.593.png" width="1680" /></figure><p>In the short course “Quantization Fundamentals with Hugging Face,” you’ll learn how to cut the computational and memory costs of AI models through quantization. Learn to quantize nearly any open source model!&nbsp;<a href="https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Join today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T171422.978.gif" width="600" /></figure><h1 id="gpt-store-shows-lax-moderation">GPT Store Shows&nbsp;Lax Moderation</h1><p>OpenAI has been moderating its GPT Store with a very light touch.</p><p><strong>What’s new:</strong>&nbsp;In a survey of the GPT Store’s offerings,&nbsp;<em>TechCrunch</em>&nbsp;<a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">found</a>&nbsp;numerous examples of custom ChatGPT instances that appear to violate the store’s own&nbsp;<a href="https://openai.com/policies/usage-policies?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">policies</a>.</p><p><strong>How it works:</strong>&nbsp;The GPT Store has a low bar for entry by design — any paid ChatGPT user can create a custom-prompted variation of the chatbot, known as a GPT, and include it in the store. The store lists GPTs in several categories, such as Writing, Productivity, Programming, and Lifestyle. While many are useful, some are questionable.</p><ul><li>Some GPTs purported to jailbreak ChatGPT. In&nbsp;<em>TechCrunch</em>’s survey, some of them were able to circumvent OpenAI’s own guardrails. Since then, they have been tamed. The GPT Store’s terms of use prohibit efforts to thwart OpenAI’s safeguards and safety measures.</li><li>GPTs like Humanizer Pro, the second-ranked instance in the Writing category at the time of writing, purport to rewrite text and make it undetectable to programs designed to detect generated text. These GPTs may violate OpenAI’s ban on GPTs that enable academic dishonesty.</li><li>Many GPTs purport to allow users to chat with trademarked characters without clear authorization from the trademark owners. The store prohibits use of content owned by third parties without their permission.</li><li>Other GPTs purport to represent real-life figures such as Elon Musk, Donald Trump, and Joe Rogan, or companies such as Microsoft and Apple (many of them obviously satirical). OpenAI allows GPTs to respond in the style of a real person if they do not impersonate that person. However, many such GPTs don’t indicate that they are not associated with the genuine person.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI&nbsp;<a href="https://www.deeplearning.ai/the-batch/openai-releases-the-gpt-store-a-curated-chatbot-marketplace/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">launched</a>&nbsp;the GPT Store in January. Since then, users have uploaded more than 3 million GPTs that include enhanced search engines, creative writing aids, and tools that produce short videos. The most popular GPTs have millions of downloads. Despite its “store” name, the GPT Store’s contents are free to download. OpenAI is&nbsp;<a href="https://help.openai.com/en/articles/9119255-monetizing-your-gpt-faq?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">piloting</a>&nbsp;a program in which U.S.-based uploaders of popular GPTs can earn money.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The GPT Store is the chatbot era’s answer to Apple’s App Store or Android’s Google Play Store. If it succeeds, it could democratize chatbot development just as the App Store helped to popularize building smartphone applications. How OpenAI moderates the store may have real financial and reputational impacts on developers in the years ahead.<br /><br /><strong>We’re thinking:</strong>&nbsp;The GPT Store’s low barrier to entry is a boon to well-meaning developers, but it may encourage less responsible actors to take advantage of lax moderation. We applaud OpenAI’s willingness to execute an ambitious vision and hope it finds a workable balance.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T171539.453.gif" width="600" /></figure><h1 id="tuning-llms-for-better-rag">Tuning LLMs for Better RAG</h1><p>Retrieval-augmented generation (RAG) enables large language models to generate better output by retrieving documents that are relevant to a user’s prompt. Fine-tuning further improves RAG performance.</p><p><strong>What’s new:</strong>&nbsp;Xi Victoria Lin, Xilun Chen, Mingda Chen, and colleagues at Meta proposed&nbsp;<a href="https://arxiv.org/abs/2310.01352?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">RA-DIT</a>, a fine-tuning procedure that trains an LLM and retrieval model together to improve the LLM’s ability to capitalize on retrieved content.</p><p><strong>Retrieval augmented generation (RAG) basics:</strong>&nbsp;When a user prompts an LLM, RAG supplies documents that are relevant to the prompt. A separate retrieval model computes the probability that each chunk of text in a separate dataset is relevant to the prompt. Then it grabs the chunks with the highest probability and provides them to the LLM to append to the prompt. The LLM generates each token based on the chunks plus the prompt and tokens generated so far.</p><p><strong>Key insight:</strong>&nbsp;Typically LLMs are not exposed to retrieval-augmented inputs during pretraining, which limits how well they can use retrieved text to improve their output.&nbsp;<a href="https://proceedings.mlr.press/v119/guu20a.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Such</a>&nbsp;<a href="https://proceedings.mlr.press/v162/borgeaud22a.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">methods</a>&nbsp;have been proposed, but they’re costly because they require processing a lot of data. A more data-efficient, and therefore compute-efficient, approach is to (i) fine-tune the LLM to better use retrieved knowledge and then (ii) fine-tune the retrieval model to select more relevant text.</p><p><strong>How it works:</strong>&nbsp;The authors fine-tuned&nbsp;<a href="https://arxiv.org/abs/2307.09288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Llama 2</a>&nbsp;(65 billion parameters) and&nbsp;<a href="https://arxiv.org/abs/2302.07452?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">DRAGON+</a>, a retriever. They call the system RA-DIT 65B.</p><ul><li>The authors fine-tuned Llama 2 on prompts that consist of retrieved text and a question or instruction. They used 20 datasets including&nbsp;<a href="https://arxiv.org/abs/2304.0732?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">dialogue</a>,&nbsp;<a href="https://huggingface.co/datasets/yahoo_answers_qa?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">question-answering</a>,&nbsp;<a href="https://arxiv.org/abs/1806.03822?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">answering questions about a given text passage</a>,&nbsp;<a href="https://proceedings.neurips.cc/paper/2015/hash/afdec7005cc9f14302cd0474fd0f3c96-Abstract.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">summarization</a>, and datasets in which the model must answer questions and&nbsp;<a href="https://aclanthology.org/P17-1015/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">explain its reasoning</a>.&nbsp;</li><li>They fine-tuned DRAGON+’s encoder to increase the probability that it retrieved a given chunk if the chunk improved the LLM’s chance of generating the correct answer. Fine-tuning was supervised for the tasks listed above. Fine-tuning was self-supervised for completion of&nbsp;<a href="https://arxiv.org/abs/2208.03299?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">37 million text chunks</a>&nbsp;from Wikipedia and 362 million text chunks from&nbsp;<a href="https://commoncrawl.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">CommonCrawl</a>.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;On average, across four collections of questions from datasets such as&nbsp;<a href="https://arxiv.org/abs/2009.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">MMLU</a>&nbsp;that cover topics like elementary mathematics, United States history, computer science, and law, RA-DIT 65B achieved 49.1 percent accuracy, while the combination of LLaMA 2 65B and DRAGON+ without fine-tuning achieved 45.1 percent accuracy, and LLaMA 2 65B without retrieval achieved 32.9 percent accuracy. When the input included five examples that showed the model how to perform the task, RA-DIT 65B achieved 51.8 percent accuracy, LLaMA 2 65B combined with DRAGON+ achieved 51.1 percent accuracy, and LLaMA 2 65B alone achieved 47.2 percent accuracy. On average, over eight common-sense reasoning tasks such as&nbsp;<a href="https://arxiv.org/abs/1803.05457?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">ARC-C</a>, which involves common-sense physics such as the buoyancy of wood, RA-DIT 65B achieved 74.9 percent accuracy, LLaMA 2 65B with DRAGON+ achieved 74.5 percent accuracy, and LLaMA 2 achieved 72.1 percent accuracy.</p><p><strong>Why it matters:</strong>&nbsp;This method offers an inexpensive way to improve LLM performance with RAG.</p><p><strong>We’re thinking:</strong>&nbsp;Many developers have found that putting more effort into the retriever, to make sure it provides the most relevant text, improves RAG performance. Putting more effort into the LLM helps, too.</p><hr /><h1 id="data-points">Data Points</h1><p>In this week’s <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, find new model and feature releases from Google, Microsoft, Mistral, OpenAI, and Spotify, plus AI art projects and government investments.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-245/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read your short-form digest of this week’s AI news now</a></p>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:19:54 GMT</pubDate>
</item>
<item>
<title>Autonomous Coding Agents, Instability at Stability AI, Mamba Mania, What Users Do With GenAI</title>
<link>https://www.deeplearning.ai/the-batch/issue-244</link>
<guid>https://www.deeplearning.ai/the-batch/issue-244</guid>
<content:encoded><![CDATA[
<div> 关键词: Planning, AI Agentic moment, large language models (LLMs), tasks, coding agents.

总结:
Planning is an important aspect of using large language models (LLMs) to accomplish tasks. It allows an agent to break down a larger task into smaller subtasks and decide on the steps to execute. The article highlights the author's surprise when an agent autonomously switched to a different search tool during a live demo, showcasing the AI Agentic moment. Planning enables agents to dynamically decide on the steps to take, making it a powerful capability. However, it can also lead to less predictable results. The article also mentions the emergence of coding agents, which automate programming tasks, and the common uses of generative AI, such as brainstorming and text editing. Furthermore, it discusses the challenges faced by Stability AI and introduces an alternative architecture called Mamba, which improves upon transformers. <div>
<p>Dear friends,</p><p>Planning is a key&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">agentic AI design pattern</a>&nbsp;in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute to accomplish a larger task. For example, if we ask an agent to do online research on a given topic, we might use an LLM to break down the objective into smaller subtasks, such as researching specific subtopics, synthesizing findings, and compiling a report.&nbsp;</p><p>Many people had a “ChatGPT moment” shortly after ChatGPT was released, when they played with it and were surprised that it significantly exceeded their expectation of what AI can do. If you have not yet had a similar “AI Agentic moment,” I hope you will soon. I had one several months ago, when I presented a live demo of a research agent I had implemented that had access to various online search tools.&nbsp;</p><p>I had tested this agent multiple times privately, during which it consistently used a web search tool to gather information and wrote up a summary. During the live demo, though, the web search API unexpectedly returned with a rate limiting error. I thought my demo was about to fail publicly, and I dreaded what was to come next. To my surprise, the agent pivoted deftly to a Wikipedia search tool — which I had forgotten I’d given it — and completed the task using Wikipedia instead of web search.&nbsp;</p><p>This was an AI Agentic moment of surprise for me. I think many people who haven’t experienced such a moment yet will do so in the coming months. It’s a beautiful thing when you see an agent autonomously decide to do things in ways that you had not anticipated, and succeed as a result!</p><p>Many tasks can’t be done in a single step or with a single tool invocation, but an agent can decide what steps to take. For example, to simplify an example from the HuggingGPT paper (cited below), if you want an agent to consider a picture of a boy and draw a picture of a girl in the same pose, the task might be decomposed into two distinct steps: (i) detect the pose in the picture of the boy and (ii) render a picture of a girl in the detected pose. An LLM might be fine-tuned or prompted (with few-shot prompting) to specify a plan by outputting a string like&nbsp;<em>"{tool: pose-detection, input: image.jpg, output: temp1 } {tool: pose-to-image, input: temp1, output: final.jpg}"</em>.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T140722.194.png" width="1200" /></figure><p>This structured output, which specifies two steps to take, then triggers software to invoke a pose detection tool followed by a pose-to-image tool to complete the task. (This example is for illustrative purposes only; HuggingGPT uses a different format.)&nbsp;</p><p>Admittedly, many agentic workflows do not need planning. For example, you might have an agent reflect on, and improve, its output a fixed number of times. In this case, the sequence of steps the agent takes is fixed and deterministic. But for complex tasks in which you aren’t able to specify a decomposition of the task into a set of steps ahead of time, Planning allows the agent to decide dynamically what steps to take.&nbsp;</p><p>On one hand, Planning is a very powerful capability; on the other, it leads to less predictable results. In my experience, while I can get the agentic design patterns of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Reflection</a>&nbsp;and&nbsp;<a href="http://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Tool use</a>&nbsp;to work reliably and improve my applications’ performance, Planning is a less mature technology, and I find it hard to predict in advance what it will do. But the field continues to evolve rapidly, and I'm confident that Planning abilities will improve quickly.&nbsp;</p><p>If you’re interested in learning more about Planning with LLMs, I recommend:</p><ul><li>“<a href="https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>,” Wei et al. (2022)</li><li>“<a href="https://arxiv.org/abs/2303.17580?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a>,” Shen et al. (2023)</li><li>“<a href="https://arxiv.org/pdf/2402.02716.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Understanding the planning of LLM agents: A survey</a>,” by Huang et al. (2024)</li></ul><p>Keep learning!<br /><br />Andrew<br /><br />P.S. Making sure your RAG system has access to the data it needs to answer questions is an important, but often laborious, step for good performance. Our new short course “Preprocessing Unstructured Data for LLM Applications,” taught by Matt Robinson of Unstructured, teaches you how to build systems that can easily ingest data from a wide range of formats (like text, images, and tables) and from many different sources (like PDF, PowerPoint, and HTML). You’ll learn practical ways to extract and normalize content from diverse formats, enrich your content with metadata to enable more powerful retrieval and reasoning, and use document layout analysis and vision transformers to process embedded images and tables. Putting these components together, you’ll build a RAG bot that draws from multiple document types, demonstrating how high-quality data ingestion and preprocessing affect the quality of RAG output. <a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Sign up here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/DEVIN-PLUS-v6_1200px.gif" width="1200" /></figure><h1 id="coding-agents-proliferate">Coding Agents Proliferate</h1><p>New coding tools act like agents to automate software programming tasks.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;A wave of open source software-development tools based on large language models take advantage of the ability of large language models to plan, critique their own work, and extend themselves by calling functions.&nbsp;</p><p><strong>How it works:</strong>&nbsp;These projects follow hot on the heels of Cognition’s&nbsp;<a href="https://www.cognition-labs.com/introducing-devin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Devin</a>, a commercial system billed as a semi-autonomous software developer that’s available to selected customers upon request. Some, like Devin, provide sandboxed chat for natural-language commands, command line shell, code editor, and/or a web browser through which the agent can test code or find documentation. Given a prompt, they generate a step-by-step plan and execute it. They may ask for further information or instructions, and users can interrupt to modify their requests.&nbsp;</p><ul><li><a href="https://github.com/stitionai/devika?tab=readme-ov-file&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY#readme" rel="noopener">Devika</a>&nbsp;uses Anthropic’s Claude 3, OpenAI’s GPT-4 and GPT-3.5, and models supported by&nbsp;<a href="https://ollama.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Ollama</a>, a tool that runs large language models locally. Like Devin, Devika runs in a web browser and includes an agent that performs planning and reasoning. A persistent knowledge base and database recalls active projects.</li><li><a href="https://github.com/opendevin/opendevin?tab=readme-ov-file&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY#readme" rel="noopener">OpenDevin</a>&nbsp;is based on GPT-4 but has access to more than 100 models via&nbsp;<a href="https://github.com/BerriAI/litellm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">litellm</a>, a package that simplifies API calls. OpenDevin’s developers aim to match Devin’s user interface and enable the system to evaluate its own accuracy.&nbsp;</li><li><a href="https://swe-agent.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">SWE-agent</a>&nbsp;addresses bugs and issues in Github repositories. It can use any language model. Using GPT-4, it resolved 12.3 percent of tasks in the&nbsp;<a href="https://www.swebench.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">SWE-bench</a>&nbsp;dataset of real-world GitHub issues. (Devin&nbsp;<a href="https://www.cognition-labs.com/post/swe-bench-technical-report?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">resolved</a>&nbsp;13.9 percent of SWE-bench tasks. Claude 3, the highest-scoring model not specifically trained for coding, resolved 4.8 percent of SWE-bench tasks.)</li></ul><p><strong>Behind the News:&nbsp;</strong>Code-completion tools like Github Copilot and Code Llama quickly have become&nbsp;<a href="https://www.deeplearning.ai/the-batch/code-generation-services-took-off-in-2022?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">ubiquitous</a>.&nbsp;<a href="https://docs.agpt.co/autogpt/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">AutoGPT</a>, released in 2023, is an open-source generalist AI agent based on GPT-4 that has been used to write and debug code. Recently Replit, known for its Ghostwriter code-completion and chatbot applications, began building&nbsp;<a href="https://blog.replit.com/code-repair?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">its own LLMs</a>&nbsp;for automated code repair.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Agentic coding tools are distinguished by&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">techniques</a>&nbsp;that enable large language models to plan, reflect on their work, call tools, and collaborate with one another. Users&nbsp;<a href="https://leaddev.com/process/what-devin-and-can-it-really-replace-developers?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">report</a>&nbsp;that, unlike previous coding assistants, the new tools are better at sustaining extended tasks and correcting their own work.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Many software developers worry that large language models will make human coders obsolete. We doubt that AI will replace coders, but we believe that coders who use AI will replace those who don’t. Agent-based tools still have a long way to go, but they seem likely to augment programmers’ abilities in a larger development pipeline.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141020.606.png" width="1200" /></figure><h1 id="what-users-do-with-generative-ai">What Users Do With Generative AI</h1><p>Generative AI is being used mostly to generate ideas.</p><p><strong>What’s new:</strong>&nbsp;The tech consultancy Filtered&nbsp;<a href="https://hbr.org/2024/03/how-people-are-really-using-genai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">studied</a>&nbsp;the most common uses for generative AI. While most gen AI users produced text, the study surprisingly found that users were slightly more likely to generate videos than images.<br /><br /><strong>How it works:&nbsp;</strong>The analysts sifted through tens of thousands of posts on popular online forums for anecdotes that described uses of generative AI. The analysts grouped the posts into a list of 100 most popular uses of generative AI and ranked each one by reach and value added.&nbsp;</p><ul><li>Most often, individuals used generative AI as an aid to brainstorming, both at work and otherwise. They also turned to generative AI for specific suggestions, like recommending movies, suggesting holiday destinations, and generating characters for role-playing games.</li><li>Other uses in the top five: text editing, emotional support, deep dives into niche subjects, and searching for information. (One poster used a chatbot to track down the brand of cookie his grandmother liked.)</li><li>Many users employed generative AI to revise their own work, for example troubleshooting or optimizing code, editing emails before sending them, improving marketing copy, or tweaking images.</li><li>Workplace-related uses included drafting cover letters, creating notes in preparation for meetings, summarizing meetings after they happened, and analyzing sales data. Many students found generative AI useful as a learning aid to review course materials or create personalized ways to learn.</li><li>Many users found that generative AI helped them better understand technical information, such as legal advice or medical expertise. Users relied on chatbots for tasks that might have required them to consult a human expert, like drafting legal complaints, summarizing jargon-filled documents, and seeking information on medical test results.</li></ul><p><strong>Behind the news:</strong>&nbsp;The range of use cases reflects the huge number of people, from all walks of life and all parts of the world, who are using generative AI tools. In a given week in November 2023, more than 100 million people&nbsp;<a href="https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">used</a>&nbsp;ChatGPT, the most popular of these tools. Independently, in February 2024, Pew Research&nbsp;<a href="https://www.pewresearch.org/short-reads/2024/03/26/americans-use-of-chatgpt-is-ticking-up-but-few-trust-its-election-information/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">found</a>&nbsp;that 23 percent of U.S. adults had used ChatGPT at least once, including 43 percent of respondents under 30 years old and 37 percent of those with postgraduate degrees. According to the Pew report, 20 percent of all Americans had used ChatGPT for work, and 17 percent had used it for entertainment, with younger and more educated users leading the way.<br /><br /><strong>Why it matters:</strong>&nbsp;It’s clear that millions of people use generative AI but less clear how they use it. Understanding how and where they actually apply it is helpful for anyone who aims to develop new generative AI products and services or plans to integrate the tech into their organization.</p><p><strong>We’re thinking:</strong>&nbsp;While it’s encouraging that more than a fifth of U.S. adults have tried ChatGPT,&nbsp; it also suggests huge room for growth in generative AI at large.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-09T091357.311.png" width="1680" /></a></figure><p>Integrate diverse data types into your LLM applications in our new short course built in collaboration with Unstructured. Learn techniques to extract and normalize data from PDFs, tables, and images into a structured format.&nbsp;<a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Sign up today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141216.341.gif" width="1200" /></figure><h1 id="instability-at-stability-ai">Instability at Stability AI</h1><p>The CEO of Stability AI resigned as the company faces an increasingly competitive market.</p><p><strong>What’s new:</strong>&nbsp;Emad Mostaque stepped down from Stability AI, developer of the Stable Diffusion image generator among other models, amid financial woes, uncertain direction, and sinking confidence from investors and employees alike,&nbsp;<em>Forbes</em>&nbsp;<a href="https://www.forbes.com/sites/kenrickcai/2024/03/29/how-stability-ais-founder-tanked-his-billion-dollar-startup/?sh=2e53d2e3e630&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">reported</a>. Mostaque’s departure followed the exits of numerous executives and key employees.</p><p><strong>How it works:&nbsp;</strong>Stability&nbsp;<a href="https://stability.ai/news/stabilityai-announcement?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">confirmed</a>&nbsp;Mostaque’s departure in a blog post. The company’s chief operating officer Shan Shan Wong and chief technology officer Christian Laforte will act as co-CEOs until its directors find a permanent replacement. They inherit a company with troubles beyond leadership.&nbsp;</p><ul><li>Stability faces serious cash-flow issues. In 2023, it projected $11 million in revenue against $153 million in costs. Currently it&nbsp;<a href="https://www.ft.com/content/d7bbb769-20f1-4242-bd15-201741c90720?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">spends</a>&nbsp;$8 million monthly compared to revenue of $3 million in November and $5.4 million in February.</li><li>The company’s bill for processing power provided by Amazon Web Services, Google, and CoreWeave amounts to $99 million annually. It often failed to pay on time. Stability contemplated reselling access to its leased GPUs to make up for its revenue shortfall.</li><li>Stability struggled to commercialize its models. It tried to strike deals with companies such as Samsung, Snap, and Canva and governments such as Singapore, but the parties couldn’t agree on terms.</li><li>Throughout 2023, it tried to raise funds by courting investors like Nvidia and Google. Negotiations failed partly over questions about the company’s finances. Ultimately it sought a buyer, but no deal emerged.</li><li>Stability faces unpredictable liabilities due to&nbsp;<a href="https://www.deeplearning.ai/the-batch/artists-file-a-lawsuit-against-stability-ai-and-midjourney/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">lawsuits</a>&nbsp;over its alleged use of copyrighted images as training data and its models’ ability to produce images in the styles of human artists.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;Despite its troubles, Stability continued to release new models. In February, it&nbsp;<a href="https://stability.ai/news/stable-diffusion-3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">opened</a>&nbsp;the waitlist for the third-generation version of Stable Diffusion. Last month, it&nbsp;<a href="https://stability.ai/news/introducing-stable-video-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">released</a>&nbsp;Stable Video 3D, a project in which the team produced three-dimensional objects from images. This month, it&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">released</a>&nbsp;Stable Audio 2.0, which can produce music files up to three minutes long from a text prompt.<br /><br /><strong>Why it matters:</strong>&nbsp;Stability has been a standard bearer for open-source AI in a field where tech giants aim to dominate with closed models. Effective leadership could have a major impact on the models available to developers in the years ahead.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Stability helped capture the public imagination during the generative AI boom of 2022, and its open models, particularly its diffusion models, have been a huge benefit to the AI community. We hope new leadership puts the company on firm footing.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141759.545.gif" width="1200" /></figure><h1 id="a-transformer-alternative-emerges">A Transformer Alternative Emerges</h1><p>An architectural innovation improves upon transformers — up to 2 billion parameters, at least.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Albert Gu at Carnegie Mellon University and Tri Dao at Princeton University developed the&nbsp;<a href="https://arxiv.org/abs/2312.00752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Mamba</a>&nbsp;architecture, a refinement of the earlier state space sequence architecture. A relatively small Mamba produced tokens five times faster and achieved better accuracy than a vanilla transformer of similar size while processing input up to a million tokens long.</p><p><strong>Structured State Space Sequence (S4) basics:</strong>&nbsp;<a href="https://arxiv.org/abs/2111.00396?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">S4s</a>, also known as structured SSMs, can be functionally similar to recurrent neural networks (RNNs): They can accept one token at time and produce a linear combination of the current token and an embedding that represents all previous tokens. Unlike RNNs and their extensions including LSTMs — but like transformers — they can also perform an equivalent computation in parallel during training. In addition, they are more computationally efficient than transformers. An S4’s computation and memory requirements rise linearly with input size, while a vanilla transformer’s rise quadratically — a heavy burden with long input sequences.</p><p><strong>Key insight:</strong>&nbsp;S4s are more efficient than transformers but, while a transformer’s input length is limited only by processing and memory, an S4’s input length is limited by how well its hidden state can represent previously input tokens as new tokens arrive. A&nbsp;<a href="https://arxiv.org/abs/1612.08083?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">gating mechanism</a>&nbsp;that lets the model process the most important parts of an input and ignore the rest can enable it to process longer inputs. One viable gate: Typically S4s apply the same mathematical function to all input tokens, whose parameters consist of four learned matrices. Changing the matrices for each input enables the model to learn which tokens or parts of tokens are least important and can be ignored (set to zero). This condenses the input, enabling the modified S4 to process very long input sequences.</p><p><strong>How it works:</strong>&nbsp;Mamba is made up of blocks, each of which includes a modified S4 (which the authors call a selective SSM). The authors pretrained different instances on a variety of tasks including generating tokens from&nbsp;<a href="https://arxiv.org/abs/2101.00027?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">The Pile</a>&nbsp;(a collection of text from the web) and predicting DNA base pairs in&nbsp;<a href="https://www.nature.com/articles/s41592-021-01252-x?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HG38</a>&nbsp;(a single human genome) in sequences up to 1 million tokens long.&nbsp;</p><ul><li>In each block, the authors replaced three of the S4’s four fixed matrices with learned linear functions of the input. That is, they replaced each of three learned matrices with a learned matrix multiplied by the input. (The authors hypothesized that modifying the fourth matrix would not help, so they didn’t change it.)</li><li>The following layer multiplied the model’s output with a linear projection of the block’s input. This acted as a gate to filter out irrelevant parts of the embedding.</li></ul><p><strong>Results:</strong>&nbsp;Mamba achieved better speed and accuracy than transformers of similar size, including tasks that involved inputs of 1 million tokens.&nbsp;</p><ul><li>Running on an Nvidia A100 GPU with 80GB, a Mamba of 1.4 billion parameters produced 1,446 tokens per second, while a transformer of 1.3 billion parameters produced 344 tokens per second.</li><li>In sizes from 130 million parameters to 2.8 billion parameters, Mamba outperformed the transformer&nbsp;<a href="https://arxiv.org/abs/2304.01373?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Pythia</a>&nbsp;and the S4&nbsp;<a href="https://arxiv.org/abs/2212.14052?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">H3</a>&nbsp;on many tasks. It was better at predicting the next word of The Pile, and it was better at question-answering tasks such as&nbsp;<a href="https://arxiv.org/abs/1907.10641?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">WinoGrande</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/1905.07830?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HellaSwag</a>. For instance, on WinoGrande, using models of roughly 2.8 billion parameters, Mamba achieved 63.5 percent accuracy, Pythia 59.7 percent accuracy, and H3 61.4 percent accuracy.&nbsp;</li><li>After fine-tuning on Great Apes DNA Classification (classifying DNA segments up to 1 million tokens long as belonging to one of five species of great ape), using models of 1.4 million parameters, Mamba achieved 70 percent accuracy, while&nbsp;<a href="https://arxiv.org/abs/2306.15794?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Hyena DNA</a>&nbsp;achieved 55 percent accuracy.</li></ul><p><strong>Yes, but:</strong>&nbsp;The authors tested model sizes much smaller than current state-of-the-art large language models.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Google’s transformer-based Gemini 1.5 Pro offers context lengths up to 1 million tokens, but methods for building such models aren’t yet widely known. Mamba provides an alternative architecture that can accommodate very long input sequences while processing them more efficiently. Whether it delivers compelling benefits over large transformers and variations that provide higher efficiency and larger context is a question for further research</p><p><strong>We're thinking:</strong>&nbsp;Research on Mamba is gaining momentum. Other teams are probing the architecture in projects like&nbsp;<a href="https://arxiv.org/abs/2403.07487?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Motion Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.09417?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Vision Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.04081?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">MoE-Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.13660?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">MambaByte</a>, and&nbsp;<a href="https://arxiv.org/abs/2403.19887?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Jamba</a>.</p><hr /><h1 id="data-points">Data Points</h1><p>Read <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> to find the latest AI updates of the week, including:&nbsp;</p><p>👉 Advanced new editing tools by DALL·E<br />👉 Command R+, a new LLM by Cohere<br />👉 An update on big tech's hunt for AI training</p><p>And more!&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-244/?ref=dl-staging-website.ghost.io" rel="noreferrer">Check out Data Points now.</a></p>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 19:58:19 GMT</pubDate>
</item>
<item>
<title>Microsoft Absorbs Inflection, Nvidia's New GPUs, Managing AI Bio Risk, More Factual LLMs</title>
<link>https://www.deeplearning.ai/the-batch/issue-243</link>
<guid>https://www.deeplearning.ai/the-batch/issue-243</guid>
<content:encoded><![CDATA[
<div> GPT-4, LLM, tool use, Inflection AI, Microsoft<br />
工具使用是LLM的关键设计模式，允许LLM调用函数以获取信息、执行操作或操作数据。Inflection AI被微软收购并加入Microsoft AI，注重大型企业客户。Nvidia发布了新一代AI芯片，提高了AI的速度和能源效率。科学家承诺控制使用能够设计蛋白质的AI生成模型的风险。研究人员提出了一种方法来提高LLM的事实性输出。总结：LLM工具使用 <div>
<p>Dear friends,</p><p>Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design pattern of&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">AI agentic workflows</a>. You may be familiar with LLM-based systems that can perform a web search or execute code. Indeed, some of the large, consumer-facing LLMs already incorporate these features. But tool use goes well beyond these examples.&nbsp;<br /><br />If you prompt an online LLM-based chat system, “What is the best coffee maker according to reviewers?”, it might decide to carry out a web search and download one or more web pages to gain context. Early on, LLM developers realized that relying only on a pre-trained transformer to generate output tokens is limiting, and that giving an LLM a tool for web search lets it do much more. With such a tool, an LLM is either fine-tuned or prompted (perhaps with few-shot prompting) to generate a special string like {tool: web-search, query: "coffee maker reviews"} to request calling a search engine. (The exact format of the string depends on the implementation.) A post-processing step then looks for strings like these, calls the web search function with the relevant parameters when it finds one, and passes the result back to the LLM as additional input context for further processing.&nbsp;</p><p>Similarly, if you ask, “If I invest $100 at compound 7% interest for 12 years, what do I have at the end?”, rather than trying to generate the answer directly using a transformer network — which is unlikely to result in the right answer — the LLM might use a code execution tool to run a Python command to compute 100 * (1+0.07)**12 to get the right answer. The LLM might generate a string like this: {tool: python-interpreter, code: "100 * (1+0.07)**12"}.&nbsp;</p><p>But tool use in agentic workflows now goes much further. Developers are using functions to search different sources (web, Wikipedia, arXiv, etc.), to interface with productivity tools (send email, read/write calendar entries, etc.), generate or interpret images, and much more. We can prompt an LLM using context that gives detailed descriptions of many functions. These descriptions might include a text description of what the function does plus details of what arguments the function expects. And we’d expect the LLM to automatically choose the right function to call to do a job.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/TOOL-USE-3.png" width="1200" /></figure><p>Further, systems are being built in which the LLM has access to hundreds of tools. In such settings, there might be too many functions at your disposal to put all of them into the LLM context, so you might use heuristics to pick the most relevant subset to include in the LLM context at the current step of processing. This technique, which is described in the Gorilla paper cited below, is reminiscent of how, if there is too much text to include as context, retrieval augmented generation (RAG) systems offer heuristics for picking a subset of the text to include.&nbsp;</p><p>Early in the history of LLMs, before widespread availability of large multimodal models (LMMs) &nbsp;like LLaVa, GPT-4V, and Gemini, LLMs could not process images directly, so a lot of work on tool use was carried out by the computer vision community. At that time, the only way for an LLM-based system to manipulate an image was by calling a function to, say, carry out object recognition or some other function on it. Since then, practices for tool use have exploded. GPT-4’s function calling capability, released in the middle of last year, was a significant step toward general-purpose tool use. Since then, more and more LLMs are being developed to similarly be facile with tool use.&nbsp;</p><p>If you’re interested in learning more about tool use, I recommend:&nbsp;</p><ul><li>“<a href="https://arxiv.org/abs/2305.15334?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Gorilla: Large Language Model Connected with Massive APIs</a>,” Patil et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2303.11381?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action</a>,” Yang et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2401.17464?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Efficient Tool Use with Chain-of-Abstraction Reasoning</a>,” Gao et al. (2024)&nbsp; &nbsp;</li></ul><p>Both Tool Use and Reflection, which I described in last week’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">letter</a>, are design patterns that I can get to work fairly reliably on my applications — both are capabilities well worth learning about. In future letters, I’ll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies.&nbsp;<br /><br />Keep learning!</p><p>Andrew</p><p>P.S. Learn to carry out red-teaming attacks against your own LLM-based applications to spot and patch vulnerabilities! In our new short course, “Red Teaming LLM Applications,” Matteo Dora and Luca Martial of LLM testing company Giskard teach how to simulate malicious actions to discover vulnerabilities and improve security. We start with prompt injection, which can trick an LLM into bypassing safeguards to reveal private information or say something inappropriate. There is no one-size-fits-all approach to security, but this course will help you identify some scenarios to protect against.</p><p>We believe that widespread knowledge of red-teaming capabilities will result in greater transparency and safer LLM-based systems. However, we ask you to use the skills you gain from this course ethically.</p><p><a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Sign up here</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed--56-.jpg" width="1200" /></figure><h1 id="microsoft-absorbs-inflection">Microsoft Absorbs Inflection</h1><p>Microsoft took over most of the once high-flying chatbot startup Inflection AI in an unusual deal.</p><p><strong>What’s new:&nbsp;</strong>Microsoft hired Inflection CEO Mustafa Suleyman and much of the startup’s staff and paid roughly $650 million for access to its models and legal protections,&nbsp;<em>Bloomberg</em>&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-03-21/microsoft-to-pay-inflection-ai-650-million-after-scooping-up-most-of-staff?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">reported</a>. Inflection will&nbsp;<a href="https://inflection.ai/the-new-inflection?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">shift</a>&nbsp;from serving consumers to focusing on large companies.<br /><br /><strong>How it works:&nbsp;</strong>Microsoft did not formally purchase any assets of Inflection, which remains a separate, independent company. $650 million is significantly less than the $1.3 billion in investment that Inflection&nbsp;<a href="https://techcrunch.com/2023/06/29/inflection-ai-lands-1-3b-investment-to-build-more-personal-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">received</a>&nbsp;last year at a $4 billion valuation.</p><ul><li>Microsoft paid $620 million for a non-exclusive license to serve Inflection’s models, including the&nbsp;<a href="https://inflection.ai/inflection-2-5?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Inflection-2.5</a>&nbsp;large language model, which will be available on the Microsoft Azure cloud service. Inflection said APIs will be available soon on Azure and other services.</li><li>Microsoft hired most of Inflection’s 70-person staff, including Suleyman and co-founder Karén Simonyan. The ex-Inflection hires joined a new Microsoft division&nbsp;<a href="https://blogs.microsoft.com/blog/2024/03/19/mustafa-suleyman-deepmind-and-inflection-co-founder-joins-microsoft-to-lead-copilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">called</a>&nbsp;Microsoft AI. Inflection waived legal rights related to Microsoft’s hiring activity in return for a roughly $30 million payment.</li><li>Inflection will use its gains plus cash on hand to compensate its investors at $1.10 or $1.50 per dollar invested. Investors will retain their equity in Inflection.</li><li>The new organization, which includes some of Microsoft’s prior AI teams, will oversee the company’s AI efforts. Microsoft AI will develop and deploy consumer AI products like the Bing search engine and the company’s various Copilot assistants. Former Bing chief Mikhail Parakhin, who would have reported to Suleyman,&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-03-26/microsoft-bing-chief-exiting-role-after-suleyman-named-ai-leader?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">departed</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;Inflection was co-founded in 2022 by Suleyman (a founder of DeepMind, now a division of Google), Simonyan, and LinkedIn chairman Reed Hoffman with funding partly from Microsoft. The startup initially positioned itself as a competitor to OpenAI and Anthropic, seeking to develop AI assistants for consumers. Its flagship product was&nbsp;<a href="https://www.nytimes.com/2023/05/03/technology/personaltech/ai-chatbot-pi-emotional-support.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Pi</a>, a chatbot trained to provide emotional support. Microsoft CEO Satya Nadella began courting Suleyman several months ago, and Suleyman wanted to bring Inflection’s staff along with him. Microsoft made a similar offer to OpenAI in November, during that company’s leadership&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">shakeup</a>, when the tech giant proposed hiring briefly-ousted CEO Sam Altman and many of his co-workers to staff a new organization at Microsoft.</p><p><strong>Yes, but:</strong>&nbsp;The unusual nature of the deal — with Microsoft absorbing most of Inflection’s staff while leaving the startup intact as a company — may have been&nbsp;<a href="https://www.ft.com/content/4fd00a0e-3d5c-4e73-90a4-46abe5b5d40f?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">designed</a>&nbsp;to avoid the antitrust scrutiny that comes with acquisitions. The deal doesn’t automatically trigger a&nbsp;<a href="https://www.ftc.gov/advice-guidance/competition-guidance/guide-antitrust-laws/mergers/premerger-notification-merger-review-process?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">review</a>&nbsp;by U.S. regulators because Microsoft did not acquire Inflection assets. Microsoft’s close relationship with OpenAI has attracted attention from regulators in the&nbsp;<a href="https://www.politico.com/news/2024/01/19/doj-ftc-microsoft-openai-antitrust-00136624?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">U.S.</a>,&nbsp;<a href="https://www.gov.uk/government/news/cma-seeks-views-on-microsofts-partnership-with-openai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">UK</a>, and&nbsp;<a href="https://ec.europa.eu/commission/presscorner/detail/en/mex_24_101?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">EU</a>.<br /><br /><strong>Why it matters:</strong>&nbsp;Tech giants are searching for an edge in AI development after being briefly leapfrogged in the market by large language model startups. Microsoft invested $13 billion in&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-boosts-its-investment-in-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">OpenAI</a>, and Nadella says that partnership remains a strategic priority. This year, Microsoft has sought to diversify its AI interests, sealing deals with&nbsp;<a href="https://www.deeplearning.ai/the-batch/mistral-enhances-ai-landscape-in-europe-with-microsoft-partnership-and-new-language-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Mistral</a>&nbsp;and now Inflection, while also beefing up its internal efforts. The distribution channel for AI models increasingly runs through large companies and their cloud services.<br /><br /><strong>We’re thinking:</strong>&nbsp;Even with strong talent, powerful backing, and a multibillion-dollar valuation, Inflection struggled to gain traction. Its journey from hot consumer startup to streamlined enterprise software provider shows how competitive the chatbot sector has become.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="669" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-03T133929.961.png" width="1200" /></figure><h1 id="nvidia-revs-ai-engine">Nvidia Revs AI Engine</h1><p>Nvidia’s latest chip promises to boost AI’s speed and energy efficiency.</p><p><strong>What’s new:</strong>&nbsp;The market leader in AI chips&nbsp;<a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">announced</a>&nbsp;the B100 and B200 graphics processing units (GPUs) designed to eclipse its in-demand H100 and H200 chips. The company will also offer systems that integrate two, eight, and 72 chips.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The new chips are based on Blackwell, an updated chip architecture specialized for training and inferencing transformer models. Compared to Nvidia’s earlier Hopper architecture, used by H-series chips, Blackwell features hardware and firmware upgrades intended to cut the energy required for model training and inference.</p><ul><li>Training a 1.8-trillion-parameter model (the estimated size of OpenAI’s GPT-4 and Beijing Academy of Artificial Intelligence’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/large-language-models-for-chinese/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">WuDao</a>) would require 2,000 Blackwell GPUs using 4 megawatts of electricity, compared to 8,000 Hopper GPUs using 15 megawatts, the company said.</li><li>Blackwell includes a second-generation&nbsp;<a href="https://www.deeplearning.ai/the-batch/transformer-accelerator/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Transformer Engine</a>. While the first generation used 8 bits to process each neuron in a neural network, the new version can use as few as 4 bits, potentially doubling compute bandwidth.</li><li>A dedicated engine devoted to reliability, availability, and serviceability monitors the chip to identify potential faults. Nvidia hopes the engine can reduce compute times by minimizing chip downtime.</li><li>An upgraded version of the NVLink switch, which allows GPUs to communicate with each other, accommodates up to 1.8 terabytes of traffic in each direction, compared to Hopper’s maximum of 900 gigabytes. The architecture can handle up to 576 GPUs in combination, compared to Hopper’s&nbsp;<a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">cap</a>&nbsp;of 256.</li><li>Nvidia doesn’t make it easy to compare the B200 with rival AMD’s top offering, the&nbsp;<a href="https://www.amd.com/en/products/accelerators/instinct/mi300/mi300x.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">MI300X</a>. Here are a few comparisons based on specs&nbsp;<a href="https://www.nvidia.com/en-us/data-center/hgx/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">reported</a>&nbsp;for Nvidia’s eight-GPU system: The B200 processes 4.5 dense/9 sparse PFLOPS at 8-bit precision, while the MI300X processes 2.61 dense/5.22 sparse PFLOPS at 8-bit precision. The B200 has 8TB/s peak memory bandwidth and 192GB of memory, while the MI300X has 5.3TB/s peak memory bandwidth and 192GB of memory. &nbsp;</li></ul><p><strong>Price and availability:</strong>&nbsp;The B200 will cost between $30,000 and $40,000, similar to the&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">going rate</a>&nbsp;for H100s today, Nvidia CEO Jensen Huang&nbsp;<a href="https://www.cnbc.com/2024/03/19/nvidias-blackwell-ai-chip-will-cost-more-than-30000-ceo-says.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">told</a>&nbsp;<em>CNBC</em>. Nvidia did not specify when the chip would be available. Google, Amazon, and Microsoft&nbsp;<a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">stated</a>&nbsp;intentions to offer Blackwell GPUs to their cloud customers.</p><p><strong>Behind the news:</strong>&nbsp;Demand for the H100 chip has been so intense that the chip has been&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">difficult</a>&nbsp;to find, driving some users to adopt alternatives such as AMD’s MI300X. Moreover, in 2022, the U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">restricted</a>&nbsp;the export of H100s and other advanced chips to China. The B200 also falls under the ban.<br /><br /><strong>Why it matters:</strong>&nbsp;Nvidia&nbsp;<a href="https://www.reuters.com/technology/nvidia-chases-30-billion-custom-chip-market-with-new-unit-sources-2024-02-09/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">holds</a>&nbsp;about 80 percent of the market for specialized AI chips. The new chips are primed to enable developers to continue pushing AI’s boundaries, training multi-trillion-parameter models and running more instances at once.&nbsp;<br /><br /><strong>We’re thinking:</strong>&nbsp;Cathie Wood, author of ARK Invest’s “<a href="https://www.ark-invest.com/big-ideas-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Big Ideas 2024”</a>&nbsp;report, estimated that training costs are falling at a very rapid 75 percent annually, around half due to algorithmic improvements and half due to compute hardware improvements. Nvidia’s progress paints an optimistic picture of further gains. It also signals the difficulty of trying to use model training to build a moat around a business. It’s not easy to maintain a lead if you spend $100 million on training and next year a competitor can replicate the effort for $25 million.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-02T085923.011.png" width="1680" /></a></figure><p>In our new short course “Red Teaming LLM Applications,” you will learn industry-proven manual and automated techniques to proactively test, attack, and improve the robustness of your large language model (LLM) applications.&nbsp;<a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Join now!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-03T133956.061.gif" width="1200" /></figure><h1 id="toward-managing-ai-bio-risk">Toward Managing AI Bio Risk</h1><p>Scientists pledged to control their use of AI to produce potentially hazardous biological materials.</p><p><strong>What’s new:</strong>&nbsp;More than 150 biologists in Asia, Europe, and North America&nbsp;<a href="https://responsiblebiodesign.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">signed</a>&nbsp;a voluntary commitment to internal and external oversight of machine learning models that can be used to design proteins.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The scientists made 10 voluntary commitments regarding synthetic biology research. They promised broadly to avoid research likely to enable harm and to promote research that responds to infectious disease outbreaks or similar emergencies.</p><ul><li>The signatories committed to evaluating the risks of AI models that generate protein structures based on user-defined characteristics such as shape or length. They also promised to improve methods for evaluating and mitigating risks.</li><li>They vowed to acquire synthetic DNA — fabricated gene sequences that can instruct cells to produce proteins designed by AI — only from providers that rigorously screen the DNA for potential to create hazardous molecules. They agreed to support development of new screening methods.</li><li>They promised to disclose potential benefits, risks, and efforts to mitigate the risks of their research. They pledged to review the capabilities of synthetic biology at regular, secure meetings and report unethical or concerning research practices.</li><li>They also agreed to revise their commitments “as needed.”</li></ul><p><strong>Behind the news:</strong>&nbsp;The potential role of AI in producing bioweapons is a major focus of research in AI safety. The current pledge arose from a University of Washington meeting on responsible AI and protein design held late last year. The&nbsp;<a href="https://www.deeplearning.ai/the-batch/countries-and-tech-giants-collaborate-on-global-ai-safety-regulation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">AI Safety Summit</a>, which took place at around the same time, also addressed the topic, and Helena, a think tank devoted to solving global problems, convened a similar meeting&nbsp;in mid-2023.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;DeepMind’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/biomedical-treasure-chest/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">AlphaFold</a>, which finds the structures of proteins, has&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S2405471223002983?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">spawned</a>&nbsp;models that enable users to design proteins with specific properties. Their output could help scientists cure diseases, boost agricultural production, and craft enzymes that aid industrial processes. However, their potential for misuse has led to scrutiny by&nbsp;<a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">national</a>&nbsp;and&nbsp;<a href="https://www.who.int/news/item/18-01-2024-who-releases-ai-ethics-and-governance-guidance-for-large-multi-modal-models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">international</a>&nbsp;organizations. The biology community’s commitment to use such models safely may reassure the public and forestall onerous regulations.</p><p><strong>We’re thinking:</strong>&nbsp;The commitments are long on general principles and relatively short on concrete actions. We’re glad they call for ongoing revision and action, and we hope they lead to the development of effective safeguards.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-03T133938.278.png" width="1200" /></figure><h1 id="more-factual-llms">More Factual LLMs</h1><p>Large language models sometimes generate false statements. New work makes them more likely to produce factual output.</p><p><strong>What’s new:</strong>&nbsp;Katherine Tian, Eric Mitchell, and colleagues at Stanford and University of North Carolina proposed&nbsp;<a href="https://arxiv.org/abs/2311.08401?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">FactTune</a>, a procedure that fine-tunes large language models (LLMs) to increase their truthfulness without collecting human feedback.</p><p><strong>Key insight:</strong>&nbsp;Just as fine-tuning based on feedback has made LLMs less harmful, it can make them more factual. The typical method for such fine-tuning is reinforcement learning from human feedback (RLHF). But a combination of&nbsp;<a href="https://www.deeplearning.ai/the-batch/human-feedback-without-reinforcement-learning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">direct preference optimization</a>&nbsp;(DPO) and&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">reinforcement learning from AI feedback</a>&nbsp;(RLAIF) is far more efficient. DPO replaces cumbersome reinforcement learning with a simpler procedure akin to supervised learning. RLAIF eliminates the cost of collecting human feedback by substituting model-generated preferences for human preferences.</p><p><strong>How it works:</strong>&nbsp;The authors built models designed to deliver factual output within a specific domain.&nbsp;</p><ul><li>The authors asked GPT-3.5 to prompt&nbsp;<a href="https://arxiv.org/abs/2302.13971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">LLaMA-7B</a>&nbsp;to generate 10 biographies of roughly 300 people profiled by Wikipedia.&nbsp;</li><li>Instead of human fact checking, which would be prohibitively expensive, they relied on&nbsp;<a href="https://aclanthology.org/2023.emnlp-main.741/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">FActScore</a>, an automated fact checker that uses a separate LLaMA fine-tuned for fact-checking to determine whether a separate model’s output is supported by Wikipedia. FActScore asked GPT-3.5 to extract claims in the biographies and determined whether each claim was supported by Wikipedia. Then it scored the biographies according to the percentage of supported claims.</li><li>The authors built a dataset by choosing two biographies of the same person at random. They annotated the one with the higher factuality score as preferred and the one with the lower score as not preferred.&nbsp;&nbsp;</li><li>They used the dataset to fine-tune the LLaMA-7B via Direct Preference Optimization (DPO).</li></ul><p><strong>Results:</strong>&nbsp;Fine-tuning by the authors’ method improved the factuality of models in two domains.&nbsp;</p><ul><li>The authors generated biographies of people in the test set using LLaMA-7B before and after fine-tuning via their method. Human judges who used Wikipedia as a reference deemed factual 58 percent of the claims generated by the model without fine-tuning and 85 percent of claims generated by the fine-tuned model.</li><li>The authors generated answers to a wide variety of medical questions drawn from Wikipedia using LLaMA-7B before and after fine-tuning via their method. Judges gave factual ratings to 66 percent of answers generated by the model without fine-tuning and 84 percent of answers generated by the fine-tuned model.</li></ul><p><strong>Why it matters:</strong>&nbsp;LLMs are known to hallucinate, and the human labor involved in fact checking their output is expensive and time-consuming. The authors applied well tested methods to improve the factuality of texts while keeping human involvement to a minimum.</p><p><strong>We’re thinking:</strong>&nbsp;This work, among others, shows how LLMs can bootstrap their way to better results. We’ve only just begun to explore combinations of LLMs working together as well as individual LLMs working iteratively in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">agentic workflow</a>.</p><hr /><h1 id="data-points">Data Points</h1><p>The latest AI news in brief is yours with <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, a spinoff of The Batch:</p><p>OpenAI is cautiously probing the synthetic voice market with Voice Engine.</p><p>Also, a city in California is testing an AI tool to identify homeless encampments.&nbsp;</p><p>Plus, a tech coalition plans on challenging Nvidia's lock-in of its chip users by developing new open-source cloud software..</p><p>Find these stories and more. <a href="https://www.deeplearning.ai/the-batch/data-points-issue-243/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points now</a>.</p>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 19:37:07 GMT</pubDate>
</item>
<item>
<title>One Agent For Many Worlds, Cross-Species Cell Embeddings, U.S. Deploys AI Targeting, Robo Football Gets Real</title>
<link>https://www.deeplearning.ai/the-batch/issue-242</link>
<guid>https://www.deeplearning.ai/the-batch/issue-242</guid>
<content:encoded><![CDATA[
<div> Reflection, Tool use, Planning, Multi-agent collaboration, agentic workflow<br /><br />总结: 本文介绍了AI agentic workflows的四种设计模式：反思、工具使用、规划和多智能体协作。其中介绍了反思的设计模式，即模型对自己的输出进行批判性反馈并改进。通过给LLM提供产生代码、写文本或回答问题的任务，并提示其对输出进行反思和改进，可以提高模型的输出质量。使用自我反思和工具评估的方法可以帮助模型在多个任务上实现更好的表现。此外，作者还介绍了通过多智能体框架实现反思的方法。反思是一种相对基础的agentic workflow，但在一些案例中，它已经取得了显著的效果提升。 <div>
<p>Dear friends,</p><p>Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. In this letter, I'd like to discuss Reflection. For a design pattern that’s relatively quick to implement, I've seen it lead to surprising performance gains.&nbsp;<br /><br />You may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.&nbsp;<br /><br />Take the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. After that, we can prompt it to reflect on its own output, perhaps as follows:</p><p><em>Here’s code intended for task X:&nbsp;[previously generated code]&nbsp; &nbsp;&nbsp;<br />Check the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.</em><br /><br />Sometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and the constructive feedback and (ii) ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/AGENTS-REFLECTION-1.jpg" width="1200" /></figure><p>And we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.</p><p>Further, we can implement Reflection using a multi-agent framework. I've found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent's output. The resulting discussion between the two agents leads to improved responses.</p><p>Reflection is a relatively basic type of agentic workflow, but I've been delighted by how much it improved my applications’ results in a few cases. I hope you will try it in your own work. If you’re interested in learning more about reflection, I recommend these papers:</p><ul><li>“<a href="https://arxiv.org/abs/2303.17651?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Self-Refine: Iterative Refinement with Self-Feedback</a>,” Madaan et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2303.11366?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Reflexion: Language Agents with Verbal Reinforcement Learning</a>,” Shinn et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2305.11738?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing</a>,” Gou et al. (2024)</li></ul><p>I’ll discuss the other agentic design patterns in future letters.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p>P.S. New JavaScript short course! Learn to build full-stack web applications that use RAG in “JavaScript RAG Web Apps with LlamaIndex,” taught by Laurie Voss, VP of Developer Relations at LlamaIndex and co-founder of npm.&nbsp;</p><ul><li>Build a RAG application for querying your own data.</li><li>Develop tools that interact with multiple data sources and use an agent to autonomously select the right tool for a given query.</li><li>Create a full-stack web app step by step that lets you chat with your data.&nbsp;</li><li>Dig further into production-ready techniques like how to persist your data, so you don’t need to reindex constantly.</li></ul><p><a href="https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Sign up here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/SIMA.jpg" width="1200" /></figure><h1 id="one-agent-many-environments">One Agent, Many Environments</h1><p>AI agents are typically designed to operate a particular software environment. Recent work enabled a single agent to take actions in a variety of three-dimensional virtual worlds.</p><p><strong>What's new:</strong>&nbsp;A team of 90 people at Google and University of British Columbia announced&nbsp;<a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Scalable Instructable Multiworld Agent</a>&nbsp;(SIMA), a system that learned to follow text instructions (such as “make a pile of rocks to mark this spot” or “see if you can jump over this chasm”) in seven commercial video games and four research environments.&nbsp;</p><p><strong>How it works:</strong>&nbsp;SIMA’s architecture consists of several transformers and a vanilla neural network. The authors trained it to mimic human players using a dataset of gameplay broken into 10 second tasks, including onscreen images, text instructions, keyboard presses, and mouse motions. The video games included Goat Simulator 3 (a third-person game in which the player takes the form of a goat), No Man’s Sky (a first- or third-person game of exploration and survival in outer space), Hydroneer (a first-person game of mining and building), and others.&nbsp;&nbsp;</p><ul><li>Given a text instruction and a frame of onscreen imagery,&nbsp;<a href="https://arxiv.org/abs/2401.09865?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">SPARC</a>&nbsp;(a pair of transformers pretrained on text-image pairs to produce similar embeddings of similar text and images) produced text and image embeddings. Given recent frames,&nbsp;<a href="https://www.deeplearning.ai/the-batch/googles-phenaki-generates-long-form-video-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Phenaki</a>&nbsp;(a transformer pretrained to predict future frames in a video) generated a video embedding.</li><li>Given the image, text, and video embeddings, a collection of transformers learned to produce a representation of the game. (The authors don’t fully describe this part of the architecture.)&nbsp;</li><li>Given the game representation, a vanilla neural network learned to produce the corresponding keyboard and mouse actions.</li></ul><p><strong>Results:</strong>&nbsp;Judges evaluated SIMA’s success or failure at completing nearly 1,500 instructions that spanned tasks in nine categories like action (“jump”), navigation (“go to your ship”), and gathering resources (“get raspberries”). In Goat Simulator 3, SIMA completed 40 percent of the tasks. In No Man’s Sky, the judges compared SIMA’s performance to that of the human players whose gameplay produced the training data. SIMA was successful 34 percent of the time, while the players were successful 60 percent of the time. Judges also compared SIMA to versions that were trained to be experts in a single game. SIMA was successful more than 1.5 times more often than the specialized agents.</p><p><strong>Behind the news:</strong>&nbsp;SIMA extends Google’s earlier successes building agents that rival or beat human players at individual games including&nbsp;<a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Go</a>,&nbsp;<a href="https://deepmind.google/discover/blog/agent57-outperforming-the-human-atari-benchmark/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">classic Atari games</a>, and&nbsp;<a href="https://deepmind.google/discover/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">StarCraft II</a>.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Training agents to follow directions in various environments, seeing the same things humans would, is a step toward building instructable agents that can work in any situation. The authors point to potential applications in robotics, simulations, and gaming; wherever an agent might need to be guided through diverse challenges.&nbsp;</p><p><strong>We're thinking:</strong>&nbsp;This work shows that an agent trained on multiple games can perform better than an agent trained on just one, and that the richer the language inputs in a gameworld, the better the agent can perform. With only a handful of training environments under its belt, SIMA doesn’t demonstrate superhuman performance, but it gets the job done a surprising amount of the time!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="630" src="https://dl-staging-website.ghost.io/content/images/2024/03/CELLS.jpg" width="1120" /></figure><h1 id="cross-species-cell-embeddings">Cross-Species Cell Embeddings</h1><p>Researchers used an AI system to identify animal cell types from gene sequences, including a cell type that conventional approaches had discovered only in the past year.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Biologists at Stanford trained a&nbsp;<a href="https://www.biorxiv.org/content/10.1101/2023.11.28.568918v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">system</a>&nbsp;to produce embeddings that represent individual cells in an organism. This enabled them to find cell types that have common function in different animals; for instance, the Norn cell, a type of kidney cell that biologists had previously theorized but&nbsp;<a href="https://www.nature.com/articles/s41591-023-02314-7?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">discovered</a>&nbsp;only in 2023.</p><p><strong>How it works:</strong>&nbsp;Universal Cell Embedding (UCE) comprises two transformers that produce embeddings of genes and cells respectively, plus a classifier based on a vanilla neural network. The authors trained the classifier, given embeddings of a gene and cell, to classify whether or not the cell produces the protein coded by that gene. The training dataset included RNA sequences of 36.2 million cells from eight animal species (humans and mice accounted for 33.9 million) along with related protein structures.&nbsp;</p><ul><li>The authors represented each cell as a sequence of gene embeddings, laid out in the order in which they appear in the cell’s genome. Instead of including all of a cell’s genes, the authors sampled 1,024 genes known to encode proteins. A pretrained&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/36927031/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">ESM-2</a>&nbsp;transformer computed each gene’s embedding based on the protein(s) — that is, amino acid sequence(s) — it produces.&nbsp;</li><li>The authors randomly masked 20 percent of the gene embeddings. Given the masked sequence, a vanilla transformer learned to compute an embedding of the cell.&nbsp;</li><li>For each gene in the cell, the authors concatenated its embedding with the cell embedding. Given the combined embeddings, the vanilla neural network learned to classify whether the genes encoded a protein.</li></ul><p><strong>Results:</strong>&nbsp;Cell embeddings produced by UCE enabled the authors to identify cell types in animal species that weren’t in the training set. For instance, the authors embedded a dataset of mouse cells and applied&nbsp;<a href="https://arxiv.org/abs/1802.03426?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">UMAP</a>&nbsp;clustering to differentiate the types. They labeled the clusters as specific cell types (including Norn cells, which biologists took more than a century to find) based on the presence of certain genes that distinguish one cell type from another. Using the labels, they trained a logistic classifier. They applied the classifier to their training dataset and found Norn cells, among other cell types, in species other than mice. They verified the findings by looking for genes that tend to show up only in Norn cells.</p><p><strong>Why it matters:</strong>&nbsp;UCE’s embeddings encode biologically meaningful information about individual cells, enabling a clustering algorithm to group them into recognized cell types. The fact that the recently discovered Norn cell was among those clusters suggests that UCE may yield further discoveries that accelerate development of new medicines, lab processes, and research methods. In fact, the model found Norn cells — which are known to occur in the kidney — in organs where they have not been seen before. If this result turns out to be valid, UCE will have made a discovery that has eluded biologists to date.</p><p><strong>We’re thinking:</strong>&nbsp;It’s a truism that a machine learning model is only as good as its data. That makes this work all the more impressive: Its training data included a handful of species, yet it generalized to others.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1125" src="https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-25T154251.995.png" width="2000" /></a></figure><p>Join our short course on “JavaScript RAG Web Apps with LlamaIndex” to learn how to build full-stack JavaScript web applications that let you chat with your data. Harness the capabilities of large language models and retrieval augmented generation (RAG)!&nbsp;<a href="https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex/?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/MAVEN.jpg" width="1200" /></figure><h1 id="us-deploys-ai-assisted-targeting">U.S. Deploys AI-Assisted Targeting</h1><p>The United States military is using computer vision to target enemy positions in the Red Sea and elsewhere.<br /><br /><strong>What’s new:</strong>&nbsp;Maven, a system that analyzes satellite and geolocation data, has been used to identify targets in real-world conflicts,&nbsp;<em>Bloomberg</em>&nbsp;<a href="https://www.bloomberg.com/features/2024-ai-warfare-project-maven/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">reported</a>. The system was developed primarily by&nbsp;<a href="https://www.deeplearning.ai/the-batch/a-military-chatbot-can-create-battle-plans/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Palantir</a>&nbsp;and integrates technology from Amazon, Microsoft, information technology firms ECS Federal and L3Harris, aerospace firms Maxar and Sierra Nevada, and other unnamed companies.<br /><br /><strong>How it works:</strong>&nbsp;The 18th Airborne Corps, a U.S. Army unit organized for rapid deployment around the world, used Maven in live-fire training exercises. The system helped locate surface vessels in the Red Sea, rocket launchers in Yemen, and potential airstrike targets in Iraq and Syria. The U.S. used it to help Ukraine’s armed forces to locate Russian equipment, anonymous sources said.&nbsp;</p><ul><li>Maven melds various data streams into a top-down image of a geographic area. Satellites provide still images and video, and radar and infrared observations enable the system to see through clouds and other obstructions. It can also integrate non-visual information such as location data from mobile devices and social media posts.</li><li>Computer vision models identify military equipment such as aircraft and tanks, highlighting significant changes to object locations. They can register a buildup of equipment that may indicate a new, or newly active, military base.&nbsp;</li><li>The system displays a map that outlines potential targets in yellow and friendly forces, schools, hospitals, and other no-strike zones outlined in blue. Human decision-makers review output and authorize responses.</li></ul><p><strong>Behind the news:</strong>&nbsp;Google initially developed Maven for the U.S. Defense Department around 2017. Palantir&nbsp;<a href="https://www.businessinsider.com/palantir-took-over-from-google-on-project-maven-2019-12?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">inherited</a>&nbsp;the project after Google, facing protests by employees who did not want to contribute to government intelligence systems,&nbsp;<a href="https://www.nytimes.com/2018/06/01/technology/google-pentagon-project-maven.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">declined</a>&nbsp;to renew its contract in 2018. The U.S. military now has more than 800 active AI projects with a wide range of technology partners and contractors. Other countries are deploying similar technology:&nbsp;<a href="https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Israel</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/ukraines-drone-industry-takes-flight-amidst-conflict/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Ukraine</a>&nbsp;have used AI-assisted targeting in their ongoing conflicts.</p><p><strong>Yes, but:</strong>&nbsp;Some U.S. military experts worry about Maven’s accuracy. In tests, Maven successfully identified objects about 60 percent of the time, while human analysts working with the 18th Airborne Corps did so 84 percent of time. Moreover, the system’s training data emphasizes deserts, and its success rate drops in other types of environments.<br /><br /><strong>Why it matters:</strong>&nbsp;Maven and similar systems offer some advantages over human analysts. They can observe and integrate multiple data streams simultaneously, and they can identify potential targets much more quickly. It’s likely that more data will make these systems more accurate. On the other hand, they represent a further step toward automated warfare in which automated assistance could come to displace human decision-making.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Automated targeting is increasingly used in military applications, and less-sophisticated systems have been in&nbsp;<a href="https://www.jstor.org/stable/pdf/resrep32146.4.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">use</a>&nbsp;for decades. However, humans should always be in control of decisions to fire. We support a global&nbsp;<a href="https://news.un.org/en/story/2023/10/1141922?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">ban</a>&nbsp;on fully autonomous weapons.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="335" src="https://dl-staging-website.ghost.io/content/images/2024/03/SOCCER-ezgif.com-optimize.gif" width="600" /></figure><h1 id="robo-football-from-simulation-to-reality">Robo-Football From Simulation to Reality</h1><p>Humanoid robots can play football (known as soccer in the United States) in the real world, thanks to reinforcement learning.</p><p><strong>What’s new:&nbsp;</strong>Tuomas Haarnoja and colleagues at Google and University of Oxford trained an&nbsp;<a href="https://arxiv.org/abs/2304.13653?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">agent</a>&nbsp;to play one-on-one football in a simulated environment. They applied the agent to 20-inch hardware robots on a scaled-down field. You can see it in action&nbsp;<a href="https://sites.google.com/view/op3-soccer?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;In reinforcement learning, an agent improves as it explores various motions. However, such exploration risks damaging expensive hardware. By training in a simulation, the agent can attempt a diversity of motions without risking a physical robot. Once the agent is trained, it can make the leap from simulation to reality.</p><p><strong>How it works:</strong>&nbsp;The agent learned in a&nbsp;<a href="https://ieeexplore.ieee.org/document/6386109?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">virtual world</a>&nbsp;to control the robot’s motion given (i) a simulated robot’s state (including the position, velocity, and acceleration of each of 20 joints), (ii) the current game state (including the location and velocity of the ball and opponent), (iii) the game state at each of the last five time steps, and (iv) the agent’s five previous actions. Training proceeded via reinforcement learning in two stages.&nbsp;</p><ul><li>During the first stage of training, the authors trained two teachers, both of which were vanilla neural networks. (i) The first teacher learned to predict movements that help a simulated robot score goals against an untrained opponent that immediately fell over. The teacher earned rewards for scoring and was penalized for falling over or letting the opponent score, among other rewards and penalties. (ii) The second teacher learned to make a fallen simulated robot stand up. It received larger rewards for smaller differences, and smaller rewards for larger differences, between the robot’s joint positions and the joint positions for key robot poses&nbsp;<a href="https://github.com/ROBOTIS-GIT/ROBOTIS-OP3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">recorded</a>&nbsp;during a manually designed process of standing up.</li><li>The second stage of training involved another agent, also a vanilla neural network. This agent played a match against a previous version of itself in which each agent controlled a simulated robot. It received rewards for moving the robot’s joints in ways that helped it win the match or resembled the two teachers’ movements; this encouraged the agent to score goals and stand up after falling. To better approximate real-world conditions, the authors randomly perturbed the simulation, adding noise to the sensors that measured the robot’s actions and delaying parts of the simulation. They also restricted the joints’ range of motion to prevent the simulated robot from acting in ways that would damage a hardware robot.</li><li>At inference, the trained agent controlled an off-the-shelf&nbsp;<a href="https://emanual.robotis.com/docs/en/platform/op3/introduction/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Robotis OP3</a>&nbsp;humanoid robot, which costs around $14,000.</li></ul><p><strong>Results:</strong>&nbsp;The agent learned not only to turn and kick but also to anticipate the ball’s motion and block an opponent’s shots. It scored penalties against a stationary goalie with 90 percent success in simulation and 70 percent success in the physical world. It stood up in 0.9 seconds on average, while a manually designed agent stood up in 2.5 seconds. Its maximum walking speed of 0.69 meters per second beat the manually designed agent’s 0.27 meters per second. However, its kicks propelled the ball at 2.0 meters per second on average, slower than the manually designed agent’s 2.1 meters per second.</p><p><strong>Why it matters:</strong>&nbsp;Controlling humanoid robots is challenging, as they’re less stable than&nbsp;<a href="https://arxiv.org/abs/2304.01159?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">quadrupeds</a>. Just getting them to do one type of motion, such as&nbsp;<a href="https://arxiv.org/abs/2302.09450?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">jumping</a>, can require dedicated research. This work drives humanoid robots in complex motions by combining established training methods: training in a noisy simulation, self-play, and using teacher agents to reward particular actions.</p><p><strong>We’re thinking:</strong>&nbsp;This work demonstrates that robots get a kick out of machine learning.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>The latest AI updates of the week include: </p><p>👉 Stability AI’s Stable Video 3D<br />👉 Sakana’s evolution-inspired model merging technique<br />👉 The new Blackwell B200 GPU by Nvidia </p><p>And much more. </p><p>Read <a href="https://www.deeplearning.ai/the-batch/data-points-issue-242/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, your weekly AI news digest.</p>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 17:36:33 GMT</pubDate>
</item>
<item>
<title>Robots Talk Back, AI Security Risks, Political Deepfakes, Pretrained Models on the Cheap</title>
<link>https://www.deeplearning.ai/the-batch/issue-241</link>
<guid>https://www.deeplearning.ai/the-batch/issue-241</guid>
<content:encoded><![CDATA[
<div> AI agent workflows, LLMs, massive progress, foundation models, iterative process, agent loop, design patterns, security risk, Hugging Face, deepfakes, Indian elections, cost-saving method
总结:<br /><br />今年，AI代理工作流程将推动AI的巨大进展，可能甚至超过下一代基础模型。这是一个重要的趋势，我敦促所有从事AI的人关注此事。LLM在当前主要以零-shot模式使用，一次性生成最终输出的代码。但是，通过使用代理工作流程，可以使LLM多次迭代文档。这种迭代过程对于大多数人类作家来说都是至关重要的，通过AI完成这个过程，可以比一次性写作取得更好的结果。Covariant推出了RFM-1，可以使机器人对指令作出反应，回答关于所见的问题，并请求进一步指令。然而，Hugging Face的平台存在安全漏洞，部分模型可以攻击用户设备。 Deepfakes在印度选举中也变得非常常见。斯坦福大学的研究人员提出了一种节省成本的方法，通过顺序调用LLM，可以减少开销但保持质量。这些都是本文的要点。 <div>
<p><em>Dear friends,</em></p><p><em>I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it. </em></p><p><em>Today, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!&nbsp;</em></p><p><em>With an agent workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:</em></p><ul><li><em>Plan an outline.</em></li><li><em>Decide what, if any, web searches are needed to gather more information.</em></li><li><em>Write a first draft.</em></li><li><em>Read over the first draft to spot unjustified arguments or extraneous information.</em></li><li><em>Revise the draft taking into account any weaknesses spotted.</em></li><li><em>And so on.</em></li></ul><p><em>This iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.&nbsp;</em></p><p><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVhS90hnNhW8PzczX33Rs2tW61z83B5bWrzYN2K0T3n3qgyTW7lCdLW6lZ3m0W58_lW-6R-sR5W8Wfq2H7p9nZkN5QkgcFkL5nsW83Wxt393rnQ8W9jQM7t7nptmvW59WLNt7hFQVcW1vyStQ1HbrL8W6q6Mb-44YQnPW3fYZZW8qF7FSW4JDLSC4G4pGXVtf5md3gLz4CW1ky80g2Smw8FW5TCSvB7P0x_mW17TSGH2k2JhsW7H4QSb3BHvgqN4Q0XzXfmjznW8bsvSf8L6SrNW6Fn_sS3nHzgrW76DN-T3wtmF5N13tFYHDckM-W3y1yY298N14kW5mVnt612LQmkW7fK7S42W2Xd6N87C8gl-Z4KPdvVnKH04?ref=dl-staging-website.ghost.io" rel="noopener">Devin</a><em>’s splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm’s ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--55-.jpg" width="1200" /></figure><p><em>GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.&nbsp;</em></p><p><em>Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.</em></p><ul><li><em>Reflection: The LLM examines its own work to come up with ways to improve it.&nbsp;</em></li><li><em>Tool use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.</em></li><li><em>Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).</em></li><li><em>Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.</em></li></ul><p><em>Next week, I’ll elaborate on these design patterns and offer suggested readings for each.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. Build an optimized large language model (LLM) inference system from the ground up in our new short course “Efficiently Serving LLMs,” taught by Predibase CTO Travis Addair.</em></p><ul><li><em>Learn techniques like KV caching, continuous batching, and quantization to speed things up and optimize memory usage.</em></li><li><em>Benchmark LLM optimizations to explore the trade-offs between latency and serving many users at once.</em></li><li><em>Use low-rank adaptation (LoRA) to serve hundreds of custom fine-tuned models on a single device efficiently.</em></li></ul><p><a href="https://www.deeplearning.ai/short-courses/efficiently-serving-llms?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Sign up now!</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-20T163430.388.gif" width="600" /></figure><h1 id="conversational-robots">Conversational Robots</h1><p>Robots equipped with large language models are asking their human overseers for help.</p><p><strong>What's new:</strong>&nbsp;Andrew Sohn and colleagues at Covariant&nbsp;<a href="https://covariant.ai/insights/introducing-rfm-1-giving-robots-human-like-reasoning-capabilities/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">launched</a>&nbsp;RFM-1, a model that enables robots to respond to instructions, answer questions about what they see, and request further instructions. The model is available to Covariant customers.</p><p><strong>How it works:</strong>&nbsp;RFM-1 is a transformer that comprises 8 billion parameters. The team started with a pretrained large language model and further trained it, given text, images, videos, robot actions, and/or robot sensor readings, to predict the next token of any of those types. Images and videos are limited to 512x512 pixels and 5 frames per second.</p><ul><li>Proprietary models embed non-language inputs.&nbsp;&nbsp;</li><li>RFM-1 responds conversationally to text and/or image inputs. Given an image of a bin filled with fruit and the question “Are there any fruits in the bin?” the model can respond yes or no. If yes, it can answer follow-up questions about the fruit’s type, color, and so on.</li><li>Given a robotic instruction, the model generates tokens that represent a combination of high-level actions and low-level commands. For example, asked to “pick all the red apples,” it generates the tokens required to pluck the apples from a bin.</li><li>If the robot is unable to fulfill an instruction, the model can ask for further direction. For instance, in one demonstration, it asks, “I cannot get a good grasp. Do you have any suggestions?” When the operator responds, “move 2 cm from the top of the object and knock it over gently,” the robot knocks over the item and automatically finds a new way to pick it up.</li><li>RFM-1 can predict future video frames. For example, if the model is instructed to remove a particular item from a bin, prior to removing the item, it can generate an image of the bin with the item missing.</li></ul><p><strong>Behind the news:</strong>&nbsp;Covariant’s announcement follows a wave of&nbsp;<a href="https://arxiv.org/abs/2210.03094?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">robotics</a>&nbsp;<a href="https://arxiv.org/abs/2204.06252?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">research</a>&nbsp;<a href="https://arxiv.org/abs/2307.15818?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">in</a>&nbsp;<a href="https://arxiv.org/abs/2202.02005?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">recent</a>&nbsp;<a href="https://proceedings.mlr.press/v205/shridhar23a/shridhar23a.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">years</a>&nbsp;that enables robots to take action in response to&nbsp;<a href="https://openreview.net/pdf?id=U0jfsqmoV-4&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">text</a>&nbsp;<a href="https://arxiv.org/abs/2109.01115?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">instructions</a>.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Giving robots the ability to respond to natural language input not only makes them easier to control, it also enables them to interact with humans in new ways that are surprising and useful. In addition, operators can change how the robots work by issuing text instructions rather than programming new actions from scratch.</p><p><strong>We're thinking:</strong>&nbsp;Many people fear that robots will make humans obsolete. Without downplaying such worries, Covariant’s conversational robot illustrates one way in which robots can work alongside humans without replacing them.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="339" src="https://dl-staging-website.ghost.io/content/images/2024/03/BACKDOOR2.gif" width="600" /></figure><h1 id="some-models-pose-security-risk">Some Models Pose Security Risk</h1><p>Security researchers sounded the alarm about holes in Hugging Face’s platform.<br /><br /><strong>What’s new:</strong>&nbsp;Models in the Hugging Face open source AI repository can attack users’ devices,&nbsp;<a href="https://jfrog.com/blog/data-scientists-targeted-by-malicious-hugging-face-ml-models-with-silent-backdoor/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">according to</a>&nbsp;cybersecurity experts at JFrog, a software firm. Meanwhile, a different team discovered a&nbsp;<a href="https://hiddenlayer.com/research/silent-sabotage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">vulnerability</a>&nbsp;in one of Hugging Face’s own security features.<br /><br /><strong>Compromised uploads:</strong>&nbsp;JFrog developed scanned models on Hugging Face for known exploits. They flagged around 100 worrisome models. Flagged models may have been uploaded by other security researchers but pose hazards nonetheless, JFrog said.</p><ul><li>Around 50 percent of the flagged models were capable of hijacking objects on users’ devices. Around 20 percent opened a reverse shell on users’ devices, which theoretically allows an attacker to access them remotely. 95 percent of the flagged models were built using PyTorch, and the remainder were based on TensorFlow Keras.&nbsp;</li><li>For instance, a model called goober2 (since deleted) took advantage of a vulnerability in&nbsp;<a href="https://docs.python.org/3/library/pickle.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Pickle</a>, a Python module that serializes objects by a list or array into a byte stream and back again. The model, which had been uploaded to Hugging Face by a user named baller23, used Pickle to insert code into PyTorch that attempted to start a reverse shell connection to a remote IP address.&nbsp;</li><li>The apparent origin of goober2 and many other flagged models — the South Korean research network&nbsp;<a href="https://wiki.kreonet.net/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK#all-updates" rel="noopener">KREONET</a>&nbsp;—&nbsp;suggests that it may be a product of security researchers.&nbsp;</li></ul><p><strong>Malicious mimicry:</strong>&nbsp;Separately, HiddenLayer, a security startup,&nbsp;<a href="https://hiddenlayer.com/research/silent-sabotage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">demonstrated</a>&nbsp;a way to compromise&nbsp;<a href="https://huggingface.co/docs/safetensors/en/index?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Safetensors</a>, an alternative to Pickle that stores data arrays more securely. The researchers built a malicious PyTorch model that enabled them to mimic the Safetensors conversion bot. In this way, an attacker could send pull requests to any model that gives security clearance to the Safetensors bot, making it possible to execute arbitrary code; view all repositories, model weights, and other data; and replace users’ models.&nbsp;</p><p><strong>Behind the News:</strong>&nbsp;Hugging Face implements a variety of security measures. In most cases, it flags potential issues but does not remove the model from the site; users download at their own risk. Typically, security issues on the site arise when users inadvertently make their own information available. For instance, in December 2023, Lasso Security&nbsp;<a href="https://www.lasso.security/blog/1500-huggingface-api-tokens-were-exposed-leaving-millions-of-meta-llama-bloom-and-pythia-users-for-supply-chain-attacks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">discovered</a>&nbsp;available API tokens that afforded access to over 600 accounts belonging to organizations like Google, Meta, and Microsoft.&nbsp;&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;As the AI community grows, AI developers and users become more attractive targets for malicious attacks. Security teams have discovered vulnerabilities in popular platforms, obscure models, and essential modules like Safetensors.</p><p><strong>We’re thinking:&nbsp;</strong>Security is a top priority whenever private data is concerned, but the time is fast approaching when AI platforms, developers, and users must harden their models, as well as their data, against attacks.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/efficiently-serving-llms/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-18T100446.882.png" width="1680" /></a></figure><p>In our new short course “Efficiently Serving Large Language Models,” you’ll pop the hood on large language model inference servers. Learn how to increase the performance and efficiency of your LLM-powered applications!&nbsp;<a href="https://www.deeplearning.ai/short-courses/efficiently-serving-llms?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Enroll today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-20T163811.726.png" width="1200" /></figure><h1 id="deepfakes-become-politics-as-usual">Deepfakes Become Politics as Usual</h1><p>Synthetic depictions of politicians are taking center stage as the world’s biggest democratic election kicks off.</p><p><strong>What’s new:</strong>&nbsp;India’s political parties have&nbsp;<a href="https://www.aljazeera.com/news/2024/2/20/deepfake-democracy-behind-the-ai-trickery-shaping-indias-2024-elections?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">embraced</a>&nbsp;AI-generated campaign messages ahead of the country’s parliamentary elections, which will take place in April and May,&nbsp;<em>Al Jazeera</em>&nbsp;<a href="https://www.aljazeera.com/news/2024/2/20/deepfake-democracy-behind-the-ai-trickery-shaping-indias-2024-elections?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;Prime Minister Narendra Modi, head of the ruling Bharatiya Janata Party (BJP), helped&nbsp;<a href="https://www.deeplearning.ai/the-batch/untitled-4/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">pioneer</a>&nbsp;the use of AI in campaign videos in 2020. They’ve become common in recent state elections.&nbsp;</p><ul><li>The party that governs the state of Tamil Nadu&nbsp;<a href="https://www.aljazeera.com/economy/2024/2/12/how-ai-is-used-to-resurrect-dead-indian-politicians-as-elections-loom?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">released</a>&nbsp;videos that feature an AI-generated likeness of a leader who died in 2018. The Indian media firm Muonium built the model by training a voice model on the politician’s speeches from the 1990s.</li><li>In a December state election, the Congress party circulated a video in which its chief opponent, the leader of a rival BRS party, tells voters to choose Congress. BRS said the video was deepfaked.</li><li>A startup called&nbsp;<a href="https://theindiandeepfaker.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">The Indian Deepfaker</a>&nbsp;has cloned candidates’ voices and produced younger-looking images of them for several parties. In November, the firm cloned the voice of a state leader of the Congress party to send personalized audio messages to potential voters. It rejected more than 50 requests to alter video and audio to target political opponents, including calls to create pornographic material.</li></ul><p><strong>Meanwhile, in Pakistan:</strong>&nbsp;Neighboring Pakistan was deluged with deepfakes in the run-up to its early-February election. Former prime minister Imran Khan, who has been imprisoned on&nbsp;<a href="https://www.bbc.com/news/world-asia-65541518?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">controversial</a>&nbsp;charges since last year,&nbsp;<a href="https://www.nytimes.com/2024/02/11/world/asia/imran-khan-artificial-intelligence-pakistan.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">communicated</a>&nbsp;with followers via a clearly marked AI-generated likeness. However, he found himself victimized by deepfakery when an AI-generated likeness of him, source unknown,&nbsp;<a href="https://www.voanews.com/a/deepfakes-internet-access-cuts-make-election-coverage-hard-journalists-say-/7498917.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">urged</a>&nbsp;his followers to boycott the polls.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;Deepfakes have proliferated in India in the absence of comprehensive laws or regulations that govern them. Instead of regulating them directly, government officials have pressured social media operators like Google and Meta to moderate them.</p><p><strong>What they’re saying:</strong>&nbsp;“Manipulating voters by AI is not being considered a sin by any party,” an anonymous Indian political consultant told&nbsp;<em>Al Jazeera</em>. “It is just a part of the campaign strategy.”</p><p><strong>Why it matters:</strong>&nbsp;Political deepfakes are quickly becoming a global phenomenon. Parties from&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-generated-imagery-flooded-argentinas-presidential-race/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Argentina</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-republicans-released-the-first-ai-generated-attack-ad/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">the United States</a>, and&nbsp;<a href="https://www.theguardian.com/world/2023/may/24/new-zealand-national-party-admits-using-ai-generated-people-in-ads?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">New Zealand</a>&nbsp;have distributed AI-generated imagery or video. But the sheer scale of India’s national election — in which more than&nbsp;<a href="https://www.thehindu.com/news/national/india-has-nearly-97-crore-voters-now-says-ec/article67828780.ece?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">900 million people</a>&nbsp;are eligible to vote — has made it an active laboratory for synthetic political messages.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Synthetic media has legitimate political uses, especially in a highly multilingual country like India, where it can enable politicians to communicate with the public in a variety of languages and dialects. But unscrupulous parties can also use it to sow misinformation and&nbsp;<a href="https://gvu.gatech.edu/research/projects/liars-dividend-impact-deepfakes-and-fake-news-politician-support-and-trust-media?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">undermine</a>&nbsp;trust in politicians and media. Regulations are needed to place guardrails around deepfakes in politics. Requiring identification of generated campaign messages would be a good start.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-20T163859.691.gif" width="600" /></figure><h1 id="cutting-the-cost-of-pretrained-models">Cutting the Cost of Pretrained Models</h1><p>Research aims to help users select large language models that minimize expenses while maintaining quality.</p><p><strong>What's new:</strong>&nbsp;Lingjiao Chen, Matei Zaharia, and James Zou at Stanford proposed&nbsp;<a href="https://arxiv.org/abs/2305.05176?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">FrugalGPT</a>, a cost-saving method that calls pretrained large language models (LLMs) sequentially, from least to most expensive, and stops when one provides a satisfactory answer.&nbsp;</p><p><strong>Key insight:</strong>&nbsp;In many applications, a less-expensive LLM can produce satisfactory output most of the time. However, a more-expensive LLM may produce satisfactory output more consistently. Thus, using multiple models selectively can save substantially on processing costs. If we arrange LLMs from least to most expensive, we can start with the least expensive one. A separate model can evaluate its output, and if it’s unsatisfactory, another algorithm can automatically call a more expensive LLM, and so on.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors used a suite of 12 commercial LLMs, a model that evaluated their output, and an algorithm that selected and ordered them. At the time, the LLMs’ costs (which are subject to change) spanned two orders of magnitude: GPT-4 cost $30/$60 per 1 million tokens of input/output, while GPT-J hosted by Textsynth cost $0.20/$5 per 10 million tokens of input/output.&nbsp;</p><ul><li>To classify an LLM’s output as satisfactory or unsatisfactory, the authors fine-tuned separate&nbsp;<a href="https://arxiv.org/abs/1910.01108?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">DistilBERTs</a>&nbsp;on a diverse selection of datasets:&nbsp;<a href="https://arxiv.org/abs/2009.04202?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">one</a>&nbsp;that paired news headlines and subsequent changes in the price of gold,&nbsp;<a href="https://arxiv.org/abs/2104.08671?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">another</a>&nbsp;that labeled excerpts from court documents according to whether they rejected a legal precedent, and a&nbsp;<a href="https://arxiv.org/abs/1808.07042?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">third</a>&nbsp;dataset of questions and answers. Given an input/output pair (such as a question and answer), they fine-tuned DistilBERT to produce a high score if the output was correct and low score if it wasn’t. The output was deemed satisfactory if its score exceeded a threshold.</li><li>A custom algorithm (which the authors don’t describe in detail) learned to choose three LLMs and put them in order. For each dataset, it maximized the percentage of times a sequence of three LLMs generated the correct output within a set budget.&nbsp;</li><li>The first LLM received an input. If its output was unsatisfactory, the second LLM received the input. If the second LLM’s output was unsatisfactory, the third LLM received the input.</li></ul><p><strong>Results:</strong>&nbsp;For each of the three datasets, the authors found the accuracy of each LLM. Then they found the cost for FrugalGPT to match that accuracy. Relative to the most accurate LLM, FrugalGPT saved 98.3 percent, 73.3 percent, and 59.2 percent, respectively.</p><p><strong>Why it matters:</strong>&nbsp;Many teams choose a single model to balance cost and quality (and perhaps speed). This approach offers a way to save money without sacrificing performance.</p><p><strong>We're thinking:</strong>&nbsp;Not all queries require a GPT-4-class model. Now we can pick the right model for the right prompt.</p><hr /><h1 id="data-points">Data Points</h1><p>Find more AI news of the week in <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, including:&nbsp;</p><p>◆ AI takes over hockey and racing<br />◆ An advanced brain surgery assistant<br />◆ Google’s measures for the Indian General Election<br />◆ OpenAI’s licensing agreement with Le Monde and Prisa&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-241/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points now</a>.</p>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 21:41:36 GMT</pubDate>
</item>
<item>
<title>Anthropic Ups the Ante, India Warns Developers, Google Tests Generative News, Learning Language Without Language Training</title>
<link>https://www.deeplearning.ai/the-batch/issue-240</link>
<guid>https://www.deeplearning.ai/the-batch/issue-240</guid>
<content:encoded><![CDATA[
<div> 关键词：数据吸引力、生成AI应用、数据传输成本、云计算

总结:
数据吸引力是指数据或围绕数据的活动会吸引和产生更多数据的概念。然而，对于许多生成AI应用来说，处理数据的成本远远高于传输数据的成本。这导致数据与存储它的云服务提供商或数据中心的联系变得弱化，因此在不同的服务器之间传输数据包变得更加实际。这意味着即使我们主要在特定的云平台上构建软件，也可以将LLM提示传输到其他服务提供商以获取响应。对于开发人员和企业来说，数据吸 <div>
<p><em>Dear friends,</em></p><p><em>I’ve noticed a trend in how generative AI applications are built that might affect both big companies and developers: The gravity of data is decreasing. </em></p><p><em>Data gravity is the idea, proposed by IT engineer Dave McCrory in 2010, that data, or activity around data, attracts and creates more data. With traditional software workloads, data gravity is strong. If you have terabytes of data stored in a particular cloud, the cost to transmit it elsewhere for processing is high. So many teams pick a cloud such as AWS, Azure, or Google Cloud and build on it.</em></p><p><em>However, for many generative AI applications, the cost of processing is much greater than the cost of transmission. This weakens data gravity because data is more weakly bound to the cloud provider or data center where it’s stored, so it’s more practical to build systems that send packets to different servers all over the internet.&nbsp;</em></p><p><em>Let’s say transmitting 1GB of data costs $0.10. 1GB of text might correspond to about 250 million inputs tokens (if we average four characters per token), which costs about $125 to process using the relatively inexpensive gpt-3.5-turbo-0125 model. (With gpt-4-0125-preview, the cost would be 20x higher.) The cost of processing the data is significantly higher than the cost of transmission. Also, given the computationally intensive nature of using an LLM to read and generate tokens, the latency is high enough that sending your text or image tokens across the internet usually doesn’t add that much further latency.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--51--1.jpg" width="1200" /></figure><p><em>This means that, even if we’re building software primarily on a particular cloud provider, it’s still quite feasible to transmit LLM prompts to OpenAI, Anthropic, Anyscale, or Together.ai — or, for that matter, AWS, Azure, or Google Cloud — to get a response. The incentive to build only on a single, monolithic cloud platform is lower than before. &nbsp;</em></p><p><em>This situation has implications for stakeholders:</em></p><ul><li><em>For developers, it means we’re increasingly assembling AI applications from lots of SaaS providers all across the internet, and stitching their services together.</em></li><li><em>For CIOs, it’s creating headaches in terms of managing where their data goes and how to maintain lists of trusted vendors.</em></li><li><em>For the big cloud companies, it’s changing the basis of competition, since the generative AI portions of their customer workloads look quite different from traditional software workloads.</em></li><li><em>For new tool developers, it’s creating new opportunities for users to use their services, even if they aren’t bundled into one of cloud environments.</em></li></ul><p><em>To be clear, many applications have large traditional software components (that serve up a websites, maintain databases, and so on) as well as new generative AI components (say, a chatbot built on top of the traditional infrastructure). My remarks here apply only to the generative AI portion, and the competitive dynamics of the traditional software components haven’t changed much.</em></p><p><em>Further, as new types of AI components emerge, I expect their gravity to evolve as well. For example, right now it appears reasonably easy to change LLM providers; if you’ve built a system on one LLM, it’s annoying but not impossible to switch to a different LLM provider. In comparison, shifting databases is much harder, and once you’ve stored a lot of data in one vector database, the complexity of migrating to a different one can be high.&nbsp;</em></p><p><em>The gravity of data has been a fundamental tenet of cloud computing, and a major factor of competition for many companies. Decreasing data gravity is decreasing is a complex, exciting trend that will affect many developers and businesses.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S.&nbsp;Our new short course “Knowledge Graphs for RAG” is now available, taught by Andreas Kollegger of Neo4j! Knowledge graphs are a data structure that’s great at capturing complex relationships among data of multiple types. They can improve the context you pass to the LLM and the performance of your RAG applications by enabling more sophisticated retrieval of text than similarity search alone. In this course, you’ll build a knowledge graph&nbsp;from scratch and see how it improves chat applications by providing both text and graph data to an LLM.&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener"><em>Sign up here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-13T144706.378.gif" width="1200" /></figure><h1 id="anthropic-ups-the-ante">Anthropic Ups the Ante</h1><p>Anthropic announced a suite of large multimodal models that set new states of the art in key benchmarks.</p><p><strong>What’s new:</strong>&nbsp;Claude 3 comprises three language-and-vision&nbsp;<a href="https://www.anthropic.com/news/claude-3-family?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">models</a>: Opus (the largest and most capable), Sonnet (billed as the most cost-effective for large-scale deployments), and Haiku (the smallest, fastest, and least expensive to use). Opus and Sonnet are available via the Claude API, on&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Amazon Bedrock</a>, and in a private preview on&nbsp;<a href="https://www.deeplearning.ai/the-batch/anthropic-secures-2-billion-investment-from-google-weeks-after-amazon-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Google Cloud</a>. Opus also is&nbsp; available with the Claude Pro chatbot, which costs $20 monthly. Sonnet powers Claude’s free chatbot.</p><p><strong>How it works:</strong>&nbsp;The models, whose parameter counts are undisclosed, were trained on public, proprietary, and synthetic data ending in August 2023. They can process 200,000 tokens of context. Opus can accommodate up to 1 million tokens of context, comparable to&nbsp;<a href="https://www.deeplearning.ai/the-batch/gemini-1-5-pro-a-leap-in-multimodal-ai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Google’s Gemini 1.5 Pro</a>, upon request.</p><ul><li>Opus costs $15 per 1 million tokens of input and $75 per 1 million tokens of output; Sonnet costs $3/$15 per 1 million tokens of input/output. Haiku, which is not yet available, will cost $0.25/$1.25 per 1 million tokens of&nbsp; input/output.</li><li>Opus achieved state-of-the-art performance on several benchmarks that cover language, mathematics, reasoning, common knowledge, and code generation, outperforming OpenAI's GPT-4 and Google’s Gemini 1.0 Ultra. It ranks above Gemini 1.0 Pro on the&nbsp;<a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">LMSYS Chatbot Arena Leaderboard</a>, which reflects crowdsourced human preferences.</li><li>Sonnet set a new state of the art in AI2D (interpreting science diagrams). It outperforms GPT-4 and Gemini 1.0 Pro on several benchmarks.</li><li>Haiku achieved top marks in Chart Q&amp;A (answering questions about charts) via zero-shot, chain-of-thought prompting. Generally, it outperforms Gemini 1.0 Pro and GPT-3.5.</li></ul><p><strong>Test recognition:</strong>&nbsp;Opus aced “needle-in-a-haystack” tests to evaluate its ability to track long inputs. It also exhibited interesting behavior: In one such test, amid random documents that covered topics including startups, coding, and work culture, engineers inserted a sentence about pizza toppings and questioned the model on that topic. Not only did the model answer the question accurately, it also deduced that it was being tested, as Anthropic prompt engineer Alex Albert&nbsp;<a href="https://twitter.com/alexalbert__/status/1764722513014329620?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">reported</a>&nbsp;in a post on X. “I suspect this pizza topping ‘fact’ may have been inserted as a joke or to test if I was paying attention,” Opus said, “since it does not fit with the other topics at all.”&nbsp;&nbsp;</p><p><strong>Inside the system prompt:</strong>&nbsp;In a separate post on X, Anthropic alignment specialist Amanda Askell provided a rare peek at the thinking behind Claude 3’s system prompt, text prepended to user prompts to condition the model’s responses. To ground them in time, the models receive the current date and its training cut-off. To avoid rambling output, they’re directed to be concise. In an effort to correct for political and social biases that the team has observed, the models are asked to assist users even if it “personally disagrees with the views being expressed,” refrain from negative stereotyping of majority groups, and focus on objective information when addressing controversial topics. Finally, it’s directed to avoid discussing the system prompt unless it’s directly relevant to a query. “You might think this part is to keep the system prompt secret from you,” Askell wrote. “The real goal of this part is to stop Claude from excitedly telling you about its system prompt at every opportunity.”</p><p><strong>Why it matters:</strong>&nbsp;Anthropic began with a focus on&nbsp;<a href="https://www.anthropic.com/news/claudes-constitution?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">fine-tuning for safety</a>, and its flagship model now tops several benchmark leaderboards as well. The Claude 3 family gives developers access to state-of-the-art performance at competitive prices.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>Three highly capable “GPT-4-class” large language models (LLMs) are now widely available: GPT-4, Gemini Pro, and Claude 3. The pressure is on for teams to develop an even more advanced model that leaps ahead and differentiates. What a great time to be building applications on top of LLMs!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--52-.jpg" width="1200" /></figure><h1 id="india-warns-devs-no-unreliable-ai">India Warns Devs: No Unreliable AI</h1><p>India advised major tech companies to seek government approval before they deploy new AI models.</p><p><strong>What’s new:</strong>&nbsp;India’s Ministry of Electronics and Information Technology (MeitY)&nbsp;<a href="https://www.reuters.com/world/india/india-asks-tech-firms-seek-approval-before-releasing-unreliable-ai-tools-2024-03-04/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">issued</a>&nbsp;a nonbinding “advisory” to technology firms, including Google, Meta, and OpenAI, to seek government permission before releasing AI models their developers consider unreliable or still in testing.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The&nbsp;<a href="https://regmedia.co.uk/2024/03/04/meity_ai_advisory_1_march.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">notice</a>&nbsp;asks platforms and other intermediaries to label AI-generated media clearly and to warn customers that AI systems may output inaccurate information. It also says that models should avoid bias, discrimination, and undermining the integrity of the electoral process.</p><ul><li>Although the notice appears to apply to AI broadly, Rajeev Chandrasekhar, India’s&nbsp;Minister of State for Skill Development and Entrepreneurship,&nbsp;<a href="https://twitter.com/Rajeev_GoI/status/1764534565715300592?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">clarified</a>&nbsp;that it applies to large, “significant” platforms and not to startups. He did not define “significant.” IT Minister Ashwini Vaishnaw&nbsp;<a href="https://www.cnbctv18.com/technology/it-minister-ashwini-vaishnaw-clarifies-that-advisory-on-ai-is-not-binding-aimed-at-socialmediacompanies-19195391.htm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">added</a>&nbsp;that the request is aimed at AI for social media, not agriculture or healthcare.</li><li>The notice’s legal implications are ambiguous. It is not binding. However, Chandrasekhar&nbsp;said the new rules signal “the future of regulation” in India.</li><li>Firms are asked to comply immediately and submit reports within 15 days of the notice’s March 1 publication date. Those that comply will avoid lawsuits from consumers, Chandrasekhar&nbsp;<a href="https://twitter.com/Rajeev_GoI/status/1764534565715300592?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">wrote</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;India has regulated AI with a light touch, but it appears to be reconsidering in light of the growing&nbsp;<a href="https://www.aljazeera.com/economy/2024/2/12/how-ai-is-used-to-resurrect-dead-indian-politicians-as-elections-loom?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">role</a>&nbsp;of AI-generated campaign ads in its upcoming elections.</p><ul><li>Recently, given a prompt that asked whether a particular Indian leader “is fascist,” Google’s Gemini&nbsp;<a href="https://www.theguardian.com/world/2024/feb/26/india-confronts-google-over-gemini-ai-tools-fascist-modi-responses?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">responded</a>&nbsp;that the leader in question had been “accused of implementing policies some experts have characterized as fascist.” This output prompted Indian officials to&nbsp;<a href="https://twitter.com/Rajeev_GoI/status/1760910808773710038?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">condemn</a>&nbsp;Gemini as unreliable and potentially illegal. Google&nbsp;<a href="https://www.deeplearning.ai/the-batch/gemini-1-5-pro-a-leap-in-multimodal-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">tweaked</a>&nbsp;the model, pointing out that it’s experimental and not entirely reliable.</li><li>In February, Chandrasekhar&nbsp;<a href="https://www.thehindu.com/sci-tech/technology/draft-ai-regulation-framework-to-be-released-by-july-rajeev-chandrasekhar/article67867288.ece?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">said</a>&nbsp;the government would publish a framework to regulate AI by summer. The framework, which has been in development since at least May 2023, is intended to establish a comprehensive list of harms and penalties related to misuse of AI.&nbsp;</li><li>In November and December, the Ministry of Electronics and Information Technology issued similar&nbsp;<a href="https://economictimes.indiatimes.com/tech/technology/deepfake-menace-govt-issues-advisory-t[%E2%80%A6]h-existing-it-rules/articleshow/106297813.cms?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">notices</a>&nbsp;to social media companies. The statements advised them to crack down on deepfake videos, images, and audio circulating on their platforms.</li></ul><p><strong>Why it matters:</strong>&nbsp;National governments worldwide, in formulating their responses to the rapid evolution of AI, must balance the benefits of innovation against fears of disruptive technology. Fear seems to weigh heavily in India’s new policy. While the policy’s scope is narrower than it first appeared, it remains unclear what constitutes a significant platform, how to certify an AI model as reliable, whether services like ChatGPT are considered social platforms that would be affected, and how violations might be punished.</p><p><strong>We’re thinking:</strong>&nbsp;While combating misinformation is important, forcing developers to obtain government approval to release new models will hold back valuable innovations. We urge governments to continue to develop regulations that guard against harms posed by specific applications while allowing general-purpose technology to advance and disseminate rapidly.&nbsp;</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/knowledge-graphs-rag?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1046" src="https://dl-staging-website.ghost.io/content/images/2024/03/V2_DeepLearning_Neo4js_Banner_2070x1080--1-.png" width="2000" /></a></figure><p>Knowledge graphs can structure complex data, drive intelligent search functionality, and help you build powerful AI applications that reason over different data types. In this course, you’ll learn how to use knowledge graphs to enhance large language models (LLMs).&nbsp;<a href="https://www.deeplearning.ai/short-courses/knowledge-graphs-rag?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--53-.jpg" width="1200" /></figure><h1 id="google-tests-generative-news-tools">Google Tests Generative News Tools</h1><p>Google is paying newsrooms to use a system that helps transform press releases into articles.<br /><br /><strong>What’s new:</strong>&nbsp;Google has recruited a small number of independent news outlets for a one-year test of generative publishing tools,&nbsp;<em>Adweek</em>&nbsp;<a href="https://www.adweek.com/media/google-paying-publishers-unreleased-gen-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">reported</a>. The system reads external web pages and produces articles that editors can revise and publish.<br /><br /><strong>How it works:</strong>&nbsp;Google requires publishers to use the system to produce and publish three articles per day, one newsletter per week, and one marketing campaign per month. (It doesn’t require them to label the system’s output as AI-generated.) In exchange, publishers receive a monthly stipend that amounts to more than $10,000 annually.&nbsp;</p><ul><li>Publishers compile a list of external websites that produce information that may interest its readers, such as government websites or those of similar news outlets. Whenever one of the indexed websites publishes a new page, the system notifies the publisher.</li><li>At the publisher’s choice, an unidentified generative model summarizes the page’s content. It color-codes the output according to its similarity to the source: yellow for text copied nearly verbatim, blue for somewhat similar material, and red for sentences that least resemble the source.</li><li>A human editor can review the generated text before publishing it.</li></ul><p><strong>Behind the news:</strong>&nbsp;The pilot program is part of the&nbsp;<a href="https://newsinitiative.withgoogle.com/en-gb/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Google News Initiative</a>, through which the tech giant provides media literacy programs, fact-checking tools, and digital publishing tools to news outlets. Last year, Google&nbsp;<a href="https://www.nytimes.com/2023/07/19/business/google-artificial-intelligence-news-articles.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">demonstrated</a>&nbsp;a tool known as Genesis to news outlets including&nbsp;<em>The New York Times</em>,&nbsp;<em>The Washington Post</em>, and&nbsp;<em>The Wall Street Journal</em>. Like the new system, Genesis took in public information and generated news articles. It also suggested headlines and different writing styles. Then, as now, observers worried that Google eventually would use its tools to bypass news outlets by publishing news summaries directly in search results.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Such partnerships could yield dividends for Google and publishers alike. Google can learn what publishers need and how a generative model built to produce news holds up under the pressure of deadlines and audiences. Publishers can gain experience that may help them avoid the criticisms that greeted outlets like&nbsp;<a href="https://www.deeplearning.ai/the-batch/cnet-pauses-its-practice-of-writing-news-articles-with-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">CNET</a>,&nbsp;&nbsp;<a href="https://www.theverge.com/2023/7/8/23788162/gizmodo-g-o-media-ai-generated-articles-star-wars?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Gizmodo</a>, and&nbsp;<a href="https://www.bbc.co.uk/news/world-us-canada-67560354?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Sports Illustrated</a>, whose initial efforts to publish generated articles were either hidden behind false bylines or marred by factual inaccuracies.</p><p><strong>We’re thinking:</strong>&nbsp;Text generation could be a boon to publishers. Checking generated text (or, indeed, any synthetic media) for similarity to its source material is a sensible feature that could be useful in a variety of applications. Yet the utility of a system that summarizes individual web pages is limited, and the temptation to echo competitors may be hard to resist. We look forward to further improvements that enable agents that can assimilate and analyze text from disparate sources.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-13T145040.685.gif" width="600" /></figure><h1 id="learning-language-by-exploration">Learning Language by Exploration</h1><p>Machine learning models typically learn language by training on tasks like predicting the next word in a given text. Researchers trained a language model in a less focused, more human-like way.</p><p><strong>What’s new</strong>: A team at Stanford led by Evan Zheran Liu built a&nbsp;<a href="https://openreview.net/forum?id=OUicoKgvtc&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">reinforcement learning agent that learned language indirectly</a>&nbsp;by learning to navigate a simulated environment that provides text clues.&nbsp;</p><p><strong>Key insight:</strong>&nbsp;Reinforcement learning agents learn by discovering actions that maximize rewards. If the training environment provides text that explains how to achieve the highest reward, an agent will benefit by learning to interpret written language. That is, learning to comprehend written instructions will correlate with success in maximizing rewards.</p><p><strong>How it works:</strong>&nbsp;The authors built a series of simulated two-dimensional environments using&nbsp;<a href="https://github.com/Farama-Foundation/Minigrid?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Minigrid</a>, a reinforcement learning library that contains grid-world environments. They trained the agent to find a particular room according to the&nbsp;<a href="https://arxiv.org/abs/2008.02790?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">DREAM</a>&nbsp;reinforcement learning algorithm.</p><ul><li>The authors designed a two-dimensional layout of rooms connected by hallways. The layout included 12 rooms, each painted in one of 12 colors that were assigned randomly. A consistent location held instructions for finding the blue room.&nbsp;</li><li>The authors created many variations of the layout by reassigning the colors and updating the text instructions for finding the blue room. The instructions were either direct (for instance, “the second office in the third row”) or relative (“right of the first office in the second row”).&nbsp;</li><li>The agent received a reward when it found the blue room and a penalty for each time step. At each time step, it received a subset of the office environment (a 7-by-7 grid in its direct line of sight) and could take one of several actions (turn left or right, move forward, or open or close a door). When it reached the location that held the instructions, it received an image of the text. It continued to explore for a set time or until it found the blue room.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;The authors tested the agent’s ability to generalize to text it had not encountered in training: They trained the agents on layouts that excluded text that described the blue room as the “third office in the second row” and tested it on layouts that included these words. The agent found the blue room every time without checking every room. They also tested the agent in layouts where the hallways were twice as long as in the training set. It always found the blue room. To determine whether the agent understood individual words in the instructions, the authors collected its embeddings of many instructions and trained a single-layer LSTM to extract the instructions from the embeddings. The LSTM achieved a perplexity (a measure of the likelihood that it would predict the next word of instructions that were not in its training data, lower is better) of 1.1, while a randomly-initialized network of the same architecture achieved 4.65 perplexity — an indication that the agent did, indeed, learn to read individual words.</p><p><strong>Yes, but:</strong>&nbsp;The choice of reinforcement-learning algorithm was crucial. When the authors replaced DREAM with either&nbsp;<a href="https://arxiv.org/abs/1611.02779?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">RL<sup>2</sup></a>&nbsp;or&nbsp;<a href="https://arxiv.org/abs/1910.08348?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">VariBAD</a>), the agent did not learn language. Instead, it learned to check all the doors.</p><p><strong>Why it matters:</strong>&nbsp;The discovery that reinforcement-learning agents can learn language without explicit training opens avenues for training language models that use objectives different from traditional text completion.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;The authors focused on simple language (instructions limited to a few words and a very small vocabulary) that described a single domain (navigating hallways and rooms). There's a long road ahead, but this work could be the start of a more grounded approach to language learning in AI.</p><hr /><h1 id="data-points">Data Points</h1><p><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> is your essential weekly roundup of short-form AI insights. From the approval of the AI Act, to AMD’s regulatory hurdle in the US, and a new copyright detection API by Patronus AI - we've got even more updates wrapped up for you inside. <a href="https://www.deeplearning.ai/the-batch/data-points-issue-240/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 13 Mar 2024 19:55:44 GMT</pubDate>
</item>
<item>
<title>Mistral Living Large, Google's Open Source Challenger, Robot Chemist, Schooling Language Models in Math</title>
<link>https://www.deeplearning.ai/the-batch/issue-239</link>
<guid>https://www.deeplearning.ai/the-batch/issue-239</guid>
<content:encoded><![CDATA[
<div> LLM-based agents, progress, browsing the web, experimentation, evaluation, multi-agent systems, Mistral AI, Google, Robot Chemist.<br /><br />总结: LLM-based agents目前在自主规划和执行行动序列方面取得了快速进展。尽管以浏览网页为主的研究型代理的进展较快，但物流成本高昂，导致实验进程缓慢。多代理系统的发展也是一个激动人心的趋势。Mistral AI与Microsoft的合作为该初创公司提供了训练大型模型的重要技术支持，同时也将其推向了全球市场。Google的开源模型Gemma-7B推动了7亿参数模型的发展。然而，目前的LLMs在数学方面仍存在差距，但新的研究方法可能有助于提高其在数学问题上的表现。 <div>
<p><em>Dear friends,</em></p><p><em>Progress on LLM-based agents that can autonomously plan out and execute sequences of actions has been rapid, and I continue to see month-over-month improvements. Many projects attempt to take a task like “write a report on topic X” and autonomously take actions such as browsing the web to gather information to synthesize a report.&nbsp;<br /><br />AI agents can be designed to take many different types of actions. Research agents (like many projects built on&nbsp;</em><a href="https://github.com/Significant-Gravitas/AutoGPT?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>AutoGPT</em></a><em>,&nbsp;</em><a href="https://github.com/assafelovic/gpt-researcher?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>GPTresearcher</em></a><em>, or&nbsp;</em><a href="https://arxiv.org/abs/2402.14207?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>STORM</em></a><em>) search the web and fetch web pages. A sales representative agent might dispatch a product to a user. An industrial automation agent might control a robot.</em></p><p><em>So far, I see agents that browse the web progressing much faster because the cost of experimentation is low, and this is key to rapid technical progress. It’s cheap to fetch a webpage, and if your agent chooses poorly and reads the wrong page, there’s little harm done. In comparison, sending a product or moving a physical robot are costly actions, which makes it hard to experiment rapidly. Similarly, agents that generate code (that you can run in a sandbox environment) are relatively cheap to run, leading to rapid experimentation and progress.&nbsp;<br /><br />Although today’s research agents, whose tasks are mainly to gather and synthesize information, are still in an early phase of development, I expect to see rapid improvements. ChatGPT, Bing Chat, and Gemini can already browse the web, but their online research tends to be limited; this helps them get back to users quickly. But I look forward to the next generation of agents that can spend minutes or perhaps hours doing deep research before getting back to you with an output. Such algorithms will be able to generate much better answers than models that fetch only one or two pages before returning an answer.<br /><br />Even when experimentation is quick, evaluation remains a bottleneck in development. If you can try out 10 algorithm variations quickly, how do you actually pick among them? Using an LLM to evaluate another LLM's output is common practice, but prompting an LLM to give very accurate and consistent evaluations of text output is a challenge. Any breakthroughs here will accelerate progress!</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/MULTIAGENTS2-1.png" width="1200" /></figure><p><em>An exciting trend has been a move toward multi-agent systems. What if, instead of having only a single agent, we have one agent to do research and gather information, a second agent to analyze the research, and a third to write the final report? Each of these agents can be built on the same LLM using a different prompt that causes it to play a particular, assigned role. Another common design pattern is to have one agent write and a second agent work as a critic to give constructive feedback to the first agent to help it improve. This can result in much higher-quality output. Open-source frameworks like Microsoft’s&nbsp;</em><a href="https://microsoft.github.io/autogen/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>AutoGen</em></a><em>,&nbsp;</em><a href="https://crewai.net/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>Crew AI</em></a><em>, and&nbsp;</em><a href="https://python.langchain.com/docs/langgraph?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>LangGraph</em></a><em>&nbsp;are making it easier for developers to program multiple agents that collaborate to get a task done.&nbsp;<br /><br />I’ve been playing with many agent systems myself, and I think they are a promising approach to architecting intelligent systems. A lot of progress has been made by scaling up LLMs, and this progress no doubt will continue. But big ideas are sometimes made up of many, many little ideas. (For example, you might arrive at an important mathematical theorem via lots of little derivation steps.) Today’s LLMs can reason and have lots of “little ideas” in the sense that they take in information and make basic inferences.&nbsp;</em><a href="https://arxiv.org/pdf/2201.11903.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>Chain-of-thought prompting</em></a><em>&nbsp;shows that guiding an LLM to think step-by-step — that is, to string together many basic inferences — helps it to answer questions more accurately than asking it to leap to a conclusion without intermediate steps.</em></p><p><em>Agent programming models are a promising way to extend this principle significantly and guide LLMs to have lots of little ideas that collectively constitute bigger and more useful ideas.&nbsp;</em></p><p><em>Keep learning!&nbsp;<br />Andrew</em></p><p><em>P.S. New short course: “Open Source Models with Hugging Face,” taught by Maria Khalusova, Marc Sun, and Younes Belkada! Hugging Face has been a game changer by letting you quickly grab any of hundreds of thousands of already-trained open source models to assemble into new applications. This course teaches you best practices for building this way, including how to search and choose among models. You’ll learn to use the Transformers library and walk through multiple models for text, audio, and image processing, including zero-shot image segmentation, zero-shot audio classification, and speech recognition. You’ll also learn to use multimodal models for visual question answering, image search, and image captioning. Finally, you’ll learn how to demo what you build locally, on the cloud, or via an API using Gradio and Hugging Face Spaces.&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>Please sign up here</em></a><em>&nbsp;</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161635.694.gif" width="1200" /></figure><h1 id="mistral-ai-extends-its-portfolio">Mistral AI Extends Its Portfolio</h1><p>European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Mistral AI&nbsp;<a href="https://mistral.ai/news/mistral-large/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">introduced</a>&nbsp;two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it&nbsp;<a href="https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">agreed</a>&nbsp;to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free&nbsp;<a href="http://chat.mistral.ai/chat?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">here</a>&nbsp;and to use on its&nbsp;<a href="https://mistral.ai/news/la-plateforme/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">La Plateforme</a>&nbsp;and via custom deployments.</p><p><strong>Model specs:</strong>&nbsp;The new models’ parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context.&nbsp;</p><ul><li>Mistral Large achieved 81.2 percent on the&nbsp;<a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">MMLU</a>&nbsp;benchmark, outperforming Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.</li><li>Both models are fluent in French, German, Spanish, and Italian. They’re trained for function calling and JSON-format output.</li><li>Microsoft’s investment in Mistral AI is significant but tiny compared to its $13 billion&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-boosts-its-investment-in-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">stake</a>&nbsp;in OpenAI and Google and Amazon’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/anthropic-secures-2-billion-investment-from-google-weeks-after-amazon-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">investments</a>&nbsp;in Anthropic, which amount to $2 billion and $4 billion respectively.</li><li>Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.</li></ul><p><strong>Behind the news:</strong>&nbsp;Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France’s representatives in the European Commission&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">argued</a>&nbsp;on Mistral’s behalf to loosen the European Union’s AI Act oversight on powerful AI models.&nbsp;</p><p><strong>Yes, but:</strong>&nbsp;Mistral AI’s partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was&nbsp;<a href="https://www.euractiv.com/section/competition/news/eu-commission-to-examine-microsoft-openai-partnership/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">investigating</a>&nbsp;Microsoft’s agreement with OpenAI for potential breaches of antitrust law,&nbsp;<a href="https://www.politico.eu/article/european-commission-sets-its-sights-on-microsofts-ai-deal-with-frances-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">plans</a>&nbsp;to investigate the new partnership as well. Members of President Emmanuel Macron’s Renaissance party&nbsp;<a href="https://www.euractiv.com/section/artificial-intelligence/news/french-mps-voice-sovereignty-competition-concerns-after-microsoft-mistral-ai-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">criticized</a>&nbsp;the deal’s potential to give a U.S. company access to European users’ data. However, other French lawmakers&nbsp;<a href="https://www.politico.eu/article/why-france-chose-to-be-europes-ai-playground/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">support</a>&nbsp;the relationship.</p><p><strong>Why it matters:</strong>&nbsp;The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that’s tailored to Europe’s unique regulatory environment.</p><p><strong>We’re thinking:</strong>&nbsp;Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161718.283.png" width="1200" /></figure><h1 id="robot-chemist">Robot Chemist</h1><p>A robot outperformed human chemists at synthesizing chemicals.</p><p><strong>What’s new:&nbsp;</strong>Researchers at University of Amsterdam built&nbsp;<a href="https://www.science.org/doi/10.1126/science.adj1817?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">RoboChem</a>, an integrated robotic system that learned to design light-activated chemical reactions while achieving optimal yields and throughput.</p><p><strong>How it works:</strong>&nbsp;RoboChem includes a computer that runs a machine learning model and a set of automated lab instruments including a liquid handler, syringe pumps, and a photochemical reactor, all enclosed in an airtight vacuum chamber. Given a set of reagents and resulting product, RoboChem aimed to find conditions that maximize the yield (the ratio of the amount of a product synthesized to the potential amount, expressed as a percentage) and throughput (rate of synthesis) in the fewest experimental runs. It followed a 3-part cycle: (i) determine experimental conditions (amounts and concentrations of the given reagents, intensity of light, and time spent in the reactor), (ii) combine the reagents under those conditions, and (iii) evaluate the yield and throughput via a spectrometer.&nbsp;</p><ul><li>RoboChem learned how to find the best conditions for each reaction using a Gaussian process, which provides a function and uncertainty estimate for variables to be maximized (in this case, yield and throughput) given the values of other variables (the experimental conditions). Given a set of reagents and 6 to 20 sets of random conditions, RoboChem ran the reactions, measured the results, and updated the Gaussian process.</li><li>RoboChem chose new conditions based on which parts of the Gaussian process’s function had the highest uncertainty and which parts were most likely to produce the highest yield and throughput. RoboChem ran the reaction, measured the results, and updated the Gaussian process.&nbsp;</li><li>It repeated this cycle until it achieved an author-defined throughput, yield, or number of experiments. It returned the conditions with the highest throughput and yield.</li></ul><p><strong>Results:&nbsp;</strong>Robochem&nbsp;executed reactions to produce 18 substances. In all cases, it found experimental conditions that had either higher throughput and yield, or higher throughput and nearly equivalent yield, than the best conditions previously known. In one reaction, RoboChem achieved yield of 58 percent and throughput of 95.6 g/Lh (gram yield per liter in the reactor per hour), while previous work had achieved 45 percent and 2.8 g/Lh. In another reaction, RoboChem achieved 81 percent and 1720 g/Lh, where previous best results achieved 82 percent and 3 g/Lh — 1 percent lower yield but 573 times greater throughput.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;In 2020, researchers at the University of Liverpool&nbsp;<a href="https://www.deeplearning.ai/the-batch/scientific-discovery-on-a-roll/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">trained</a>&nbsp;a mobile robot arm to navigate a chemistry lab, mix chemicals, and operate equipment. That robot used a similar optimization method. However, the Amsterdam robot is much less expensive and proved itself in a wider range of experiments.&nbsp;&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The authors believe that RoboChem could dramatically increase lab productivity at lower cost in time and money. The light-activated reactions they focused on have applications in fields including pharmaceuticals, household chemicals, and renewable energy.<br /><br /><strong>We’re thinking:</strong>&nbsp;These researchers clearly are in their element.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1063" src="https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-05T085620.866.png" width="1890" /></a></figure><p>In “Open Source Models with Hugging Face,” our latest short course, you’ll use open source models to build chatbots, language translators, and audio narrators using Hugging Face tools like the model hub, transformers library, Spaces, and Gradio. <a href="https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/?ref=dl-staging-website.ghost.io" rel="noreferrer">Join now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161846.471.png" width="1200" /></figure><h1 id="google-releases-open-source-llms">Google Releases Open Source LLMs</h1><p>Google asserted its open source&nbsp;<em>bona fides</em>&nbsp;with new models.</p><p><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://blog.google/technology/developers/gemma-open-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">released</a>&nbsp;weights for Gemma-7B, an 8.5 billion-parameter large language model intended to run GPUs, and Gemma-2B, a 2.5 billion-parameter version intended for deployment on CPUs and edge devices. Each size is&nbsp;<a href="https://huggingface.co/models?search=google%2Fgemma&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">available</a>&nbsp;in two versions: pretrained base model and one fine-tuned to follow instructions.</p><p><strong>How it works:</strong>&nbsp;Gemma models are&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">based</a>&nbsp;on the architecture used in Google’s larger Gemini. Unlike Gemini, they’re not multimodal.&nbsp;</p><ul><li>Gemma-2B and Gemma-7B were trained on 2 trillion and 6 trillion tokens, respectively, of English-language web documents, mathematics, and code snippets. They can process 8,192 tokens of context.</li><li>The fine-tuned versions underwent further training: (i) They received supervised fine-tuning on human-written prompt-and-response pairs as well as synthetic responses that had been filtered for personal information, toxic responses, and other objectionable material. (ii) They were aligned using reinforcement learning with human feedback, in which their output was judged by a model trained on preferences expressed by users.</li><li>Gemma’s license permits commercial use but&nbsp;<a href="https://ai.google.dev/gemma/prohibited_use_policy?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">prohibits</a>&nbsp;a wide range of uses that Google deems harmful including copyright infringement, illegal activity, generating misinformation, or producing sexually explicit content.&nbsp;</li><li>Gemma-7B&nbsp;<a href="https://huggingface.co/blog/gemma?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">ranks</a>&nbsp;higher than comparably sized open models including Meta’s Llama 2 7B and Mistral-7B, according to HuggingFace’s&nbsp;<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">Open LLM Leaderboard</a>. By Google’s assessment, it outperforms the nearly double-sized Llama 2 13B in major question answering, reasoning, math, and coding benchmarks. Gemma-2B falls short of the most capable models of its size such as the 2.7-billion-parameter&nbsp;<a href="https://huggingface.co/microsoft/phi-2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">Phi-2</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;Google has a rich history of open source AI projects including AlphaFold, TensorFlow, several versions of BERT and T5, and the massive Switch. Lately, though, its open source efforts have been overshadowed by open large language models (LLMs) from Meta, Microsoft, and Mistral.ai. LLMs small enough to run on a laptop have opened open source AI to an expanding audience of developers.</p><p><strong>Why it matters:</strong>&nbsp;Gemma raises the bar for models of roughly 7 billion parameters. It delivers exceptional performance in a relatively small parameter counts, expanding the options for&nbsp;developers who are building on top of LLMs.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Gemma confirms Google’s commitment to open source and outperforms top open models of equal size. It’s likely to spur further innovation, especially in AI for&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-ai-will-move-to-edge-devices/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">edge devices</a>, and keep the Google name in front of enterprising open source developers.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="480" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161921.552-1.gif" width="853" /></figure><h1 id="schooling-language-models-in-math">Schooling Language Models in Math</h1><p>Large language models are not good at math. Researchers devised a way to make them better.</p><p><strong>What's new:</strong>&nbsp;Tiedong Liu and Bryan Kian Hsiang Low at the National University of Singapore proposed a method to&nbsp;<a href="https://arxiv.org/abs/2305.14201?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">fine-tune large language models for arithmetic tasks</a>.</p><p><strong>Key insight:</strong>&nbsp;Large language models (LLMs) do fairly well at addition and subtraction as well as multiplication and division by single digits or by powers of 10. They’re less adept at the more challenging tasks of multiplication and division of larger numbers. One way to perform these tasks well is to divide them into simpler subtasks. For example, a relatively easy way to multiply two large numbers like 123 and 321 is to&nbsp;</p><ul><li>Split one number into decimal places (123 becomes 100 + 20 + 3)</li><li>Multiply the other number by each of these (100 * 321 + 20 * 321 + 3 * 321)</li><li>Add the resulting products to arrive at the solution (32100 + 6420 + 963 = 39483)</li></ul><p>A similar technique exists for division. Together, these approaches can enable LLMs to perform more complicated mathematical tasks.</p><p><strong>How it works:</strong>&nbsp;The authors built GOAT (a model GOod at Arithmetic Tasks) by fine-tuning&nbsp;<a href="https://arxiv.org/abs/2302.13971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">LLaMA</a>&nbsp;on a synthetic dataset that comprised 1 million examples of arithmetic operations on integers that were divided into steps for easier calculation.</p><ul><li>The prompts were simple instructions like “Calculate 397 x 4429” or “I would appreciate it if you could assist me in calculating 1463456 + 2107”.</li><li>The answers were either numbers (for the simpler operations) or chains of reasoning (for multiplications and divisions of larger numbers). For example, if the prompt was “Calculate 24x79”, the target was “24 * 79 = 24 * (70 + 9) = 24 * 70 + 24 * 9 = 1680 + 216 = 1896”.</li><li>To create these chains, the authors wrote a Python script. For multiplication, the script randomly generated two numbers, split one number into decimal places, multiplied the second number by each of those terms, then added the products. It followed a similar procedure for division.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared GOAT and GPT-4 on&nbsp;<a href="https://arxiv.org/abs/2206.04615?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">BIGBench</a>, which contains arithmetic operations on integers up to five digits. GOAT performed either on par with or better than GPT-4 for all operations. Specifically, GPT-4 struggled to multiply and divide large numbers. Multiplying 5-digit numbers, GPT-4 achieved 0 percent accuracy, while GOAT achieved 96.7 percent. Dividing five-digit numbers, GPT-4 achieved 53.4 percent, while GOAT achieved 96.5 percent. GOAT also performed better than other LLMs (Bloom, GPT-NeoX, OPT, and Pythia) that had been fine-tuned in the same way. The authors attribute this to the fact that LLaMA generates a separate token for each digit (and does not learn tokens that represent multiple digits), while the other models learn tokens for multiple digits (for example, separate tokens for 748, 74, and 7).</p><p><strong>Why it matters:</strong>&nbsp;LLMs have latent mathematical knowledge that can be unlocked by thoughtful fine-tuning.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Humans, too, aren’t great at multiplying or dividing numbers directly — but give us a pencil and paper so we can work things out step by step, and we’re much better.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>More AI news of the week includes:&nbsp;</p><p>🔊 Adobe previews an AI audio tool&nbsp;<br />💰 Microsoft launches Copilot for Finance<br />🐋 AI uncovers reasons behind humpback whale deaths</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-239/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points here.</a></p>
]]></content:encoded>
<pubDate>Wed, 06 Mar 2024 21:22:45 GMT</pubDate>
</item>
<item>
<title>Google's Troubled Gemini Launch, OpenAI's Next Act, Groq's Blazing Inference Speed, Faster Network Pruning</title>
<link>https://www.deeplearning.ai/the-batch/issue-238</link>
<guid>https://www.deeplearning.ai/the-batch/issue-238</guid>
<content:encoded><![CDATA[
<div> Python package management, AI application development, package dependencies, version management, friction. 

总结:<br /><br />在AI应用开发中，Python软件包管理的复杂性是一个被广泛低估的瓶颈。AI面临着多个瓶颈，我们需要更多的GPU、更好的算法、更干净的大规模数据。但是当我看到应用构建者的日常工作时，我发现一个额外的瓶颈很容易被忽视：与版本管理的斗争所花费的时间是一种低效率，我希望我们能够减少这种低效率。很多AI软件都是用Python语言编写的，因此我们的领域采用了Python的哲学，允许任何人在网上发布任何软件包。由此产生的丰富的免费软件包集合意味着，只需一个"pip install"命令，你现在就能安装一个软件包并赋予你的软件新的超能力！社区对于许多创意的并行探索和创新的开源非常出色，这不仅助力了技术思想的发展和传播，也助力了可用的工具的发展和传播。但是，我们付出了这种高度分布式的AI组件开发的代价：在开源的基础上构建可能意味着花费几个小时来解决软件包的依赖性问题，有时甚至需要同时操作多个虚拟环境或在一个应用程序中使用多个Python版本。这对于有着计算机科学或软件工程背景的有经验的开发人员来说可能是烦人但是可以管理的，但对于没有相关背景的新的AI开发人员来说，这会造成很多阻力。我不知道是否存在一个简单的解决方案。希望随着工具生态系统的成熟，软件包管理会变得 <div>
<p><em>Dear friends,<br /><br />I think the complexity of Python package management holds down AI application development more than is widely appreciated. AI faces multiple bottlenecks — we need more GPUs, better algorithms, cleaner data in large quantities. But when I look at the day-to-day work of application builders, there’s one additional bottleneck that I think is underappreciated: The time spent wrestling with version management is an inefficiency I hope we can reduce.&nbsp;</em></p><p><em>A lot of AI software is written in the Python language, and so our field has adopted Python’s philosophy of letting anyone publish any package online. The resulting rich collection of freely available packages means that, with just one “pip install” command, you now can install a package and give your software new superpowers! The community’s parallel exploration of lots of ideas and open-sourcing of innovations has been fantastic for developing and spreading not just technical ideas but also usable tools.<br /><br />But we pay a price for this highly distributed development of AI components: Building on top of open source can mean hours wrestling with package dependencies, or sometimes even juggling multiple virtual environments or using multiple versions of Python in one application. This is annoying but manageable for experienced developers, but creates a lot of friction for new AI developers entering our field without a background in computer science or software engineering.</em></p><figure class="kg-card kg-image-card"><img alt="Illustration of a Python inside a cardboard box" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE-1.png" width="1200" /></figure><p><em>I&nbsp;don’t know of any easy solution. Hopefully, as the ecosystem of tools matures, package management will become simpler and easier. Better tools for testing compatibility might be useful, though I’m not sure we need yet another Python package manager (we already have pip, conda, poetry, and more) or virtual environment framework.&nbsp;</em></p><p><em>As a step toward making package management easier, maybe if all of us who develop tools pay a little more attention to compatibility — for example, testing in multiple environments, specifying dependencies carefully, carrying out more careful regression testing, and engaging with the community to quickly spot and fix issues — &nbsp;we can make all of this wonderful open source work easier for new developers to adopt.</em></p><p><em>Keep coding!</em></p><p><em>Andrew</em></p><p><em>P.S. Built in collaboration with Meta: “Prompt Engineering with Llama 2,” taught by Amit Sangani, is now available! Meta’s Llama 2 has been a game changer: Building with open source lets you control your own data, scrutinize errors, update models (or not) as you please, and work alongside the global community to advance open models. In this course, you’ll learn how to prompt Llama chat models using advanced techniques like few-shot for classification and chain-of-thought for logic problems. You’ll also learn how to use specialized models like Code Llama for software development and Llama Guard to check for harmful content. The course also touches on how to run Llama 2 on your own machine. I hope you’ll take this course and try out these powerful, open models!&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener"><em>Sign up here</em></a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/GEMINI_MultimodalDemo_NoCC_600px--1-.gif" width="600" /></figure><h1 id="context-is-everything">Context Is Everything</h1><p><em>Correction: This article has been corrected to state that Gemini 1.0 produced anachronistic images of historical scenes. An earlier edition incorrectly stated that Gemini 1.5 Pro generated anachronistic images. </em></p><p>An update of Google’s flagship multimodal model keeps track of colossal inputs, while an earlier version generated some questionable outputs.</p><p><strong>What's new:</strong>&nbsp;Google&nbsp;<a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">unveiled</a>&nbsp;Gemini 1.5 Pro, a model that can converse about inputs as long as books,&nbsp;codebases, and lengthy passages of video and audio (depending on frame and sample rates). However an earlier version, recently enabled to generate images, produced wildly inaccurate images of historical scenes.</p><p><strong>How it works:</strong>&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Gemini 1.5 Pro</a>&nbsp;updates the previous model with a mixture-of-experts architecture, in which special layers select which subset(s) of a network to use depending on the input. This enables the new version to equal or exceed the performance of the previous&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Gemini 1.0 Ultra</a>&nbsp;while requiring less computation.&nbsp;</p><ul><li>The version of Gemini 1.5 Pro that’s generally available will accept up to 128,000 input tokens of mixed text (in more than a dozen languages), images, and audio and generates text and images. A version available to selected users accepts up to 1 million input tokens — an immense increase over Anthropic Claude’s 200,000-token context window, the previous leader. You can sign up for access <a href="https://aistudio.google.com/app/waitlist/97445851?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=blog-feb&amp;utm_content=" rel="noreferrer">here</a>.</li><li>In demonstration&nbsp;<a href="https://deepmind.google/technologies/gemini/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF#gemini-1.5" rel="noopener">videos</a>, the version with 1 million-token context suggested modifications for 100,000 lines of example code from the three.js 3D JavaScript library. Given 500 pages of documentation that describes Kalamang, a language spoken by fewer than 200 people in West Papua, it translated English text into Kalamang as well as a human who had learned from the same materials. Given a crude drawing of one frame from a 44-minute silent movie, it found the matching scene (see animation above).&nbsp;</li><li>In experiments, the team extended the context window to 10 million tokens, which is equivalent to 10 books the length of Leo Tolstoy’s 1,300-page&nbsp;<em>War and Peace</em>, three hours of video at 1 frame per second, or 22 hours of audio.</li></ul><p><strong>Alignment with what?:</strong>&nbsp;The earlier Gemini 1.0 recently was <a href="https://blog.google/products/gemini/google-bard-gemini-pro-image-generation/?ref=dl-staging-website.ghost.io" rel="noreferrer">updated</a> to allow users to generate images using a specially fine-tuned version of&nbsp;<a href="https://blog.google/technology/ai/google-imagen-2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Imagen 2</a>. However, this capability backfired when social media posts appeared in which the system, prompted to produce pictures of historical characters and situations, anachronistically populated them with people of color, who would not have been likely to be present. For instance, the model illustrated European royalty, medieval Vikings, German soldiers circa 1943 — all of whom were virtually exclusively white — as Black, Asian, or Native American. Google quickly&nbsp;<a href="https://blog.google/products/gemini/gemini-image-generation-issue/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">disabled</a>&nbsp;image generation of people for “the next couple of weeks” and explained that fine-tuning intended to increase diverse outputs did not account for contexts in which diversity was inappropriate, and fine-tuning intended to keep the model from fulfilling potentially harmful requests also kept it from fulfilling harmless requests. But other users found flaws in text output as well. One asked Gemini who had a greater negative impact on society: Adolf Hitler, who presided over the murder of roughly 9 million people, or “Elon Musk tweeting memes.” The model replied, “It is difficult to say definitively who had a greater negative impact on society.” The ensuing controversy called into question not only Google’s standards and procedures for fine-tuning to ensure ethics and safety, but also its motive for building the model.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Gemini 1.5 Pro’s enormous context window radically expands potential applications and sets a high bar for the next generation of large multimodal models. At the same time, it’s clear that Google’s procedures for aligning its models to prevailing social values were inadequate. This shortcoming derailed the company’s latest move to one-up its big-tech rivals and revived longstanding worries that its management places politics above utility to users.</p><p><strong>We’re thinking:</strong>&nbsp;How to align AI models to social values is a hard problem, and approaches to solving it are in their infancy. Google acknowledged Gemini’s shortcomings, went back to work on image generation, and warned that even an improved version would make mistakes and offend some users. This is a realistic assessment following a disappointing product launch. Nonetheless, the underlying work remains innovative and useful, and we look forward to seeing where Google takes Gemini next.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/GROQ-LLMPERF.webp" width="1200" /></figure><h1 id="blazing-inference-speed">Blazing Inference Speed</h1><p>An upstart chip company dramatically accelerates pretrained large language models.</p><p><strong>What’s new:</strong>&nbsp;Groq offers cloud access to Meta’s Llama 2 and Mistral.ai’s Mixtral at speeds an order of magnitude greater than other AI platforms. Registered users can try it&nbsp;<a href="https://groq.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">here</a>.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Groq’s cloud platform is based on its proprietary GroqChip, a processor specialized for large language model inference that the company calls a language processing unit or LPU. The company plans to serve other models eventually, but its main business is selling chips. It focuses on inference on the theory that demand for a model’s inference can increase while demand for its training tends to be fixed.&nbsp;</p><ul><li>For approved users, Groq offers API access to Llama 2 70B (4,096-token context length, 300 tokens per second) for $0.70/$0.80 per million tokens of input/output, Llama 7B (2,048-token context length, 750 tokens per second) for $0.10 per million tokens, and Mixtral 8x7B SMoE (32,000-token context length, 480 tokens per second) for $0.27 per million tokens. A 10-day free trial is available.</li><li>The benchmarking service Artificial Analysis&nbsp;<a href="https://artificialanalysis.ai/models/llama-2-chat-70b/hosts?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">clocked</a>&nbsp;the median speed of Groq’s instances of Llama 2 70B at 241 tokens per second, while Azure’s was around 18 tokens per second. In addition, the platform&nbsp;<a href="https://github.com/ray-project/llmperf-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">outperformed</a>&nbsp;several other cloud services on the Anyscale LLMPerf benchmark, as shown in the image above.</li><li>A variety of&nbsp;<a href="https://wow.groq.com/wp-content/uploads/2023/05/GroqISCAPaper2022_ASoftwareDefinedTensorStreamingMultiprocessorForLargeScaleMachineLearning-1.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">novel design features</a>&nbsp;enable the chip to run neural networks faster than other AI chips including the industry-leading Nvidia H100.</li></ul><p><strong>Behind the news:</strong>&nbsp;Groq founder Jonathan Ross previously worked at Google, where he spearheaded the development of that company’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/computers-making-computers/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">tensor processing unit</a>&nbsp;(TPU), another specialized AI chip.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Decades of ever faster chips have proven that users need all the speed they can get out of computers. With AI, rapid inference can make the difference between halting interactions and real-time spontaneity. Moreover, Groq shows that there’s plenty of innovation left in computing hardware as processors target general-purpose computing versus AI, inference versus training, language versus vision, and so on.</p><p><strong>We’re thinking:</strong>&nbsp;Autonomous agents based on large language models (LLMs) can get a huge boost from very fast generation. People can read only so fast, the faster generation of text that’s intended to be read by humans has little value beyond a certain point. But an agent (as well as chain-of-thought and similar approaches to prompting) might need an LLM to “think” through multiple steps. Fast LLM inference can be immensely useful for building agents that can work on problems at length before reaching a conclusion.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png" width="1680" /></a></figure><p>Join “Prompt Engineering with Llama 2” and learn best practices for model selection and prompting, advanced prompting techniques, and responsible use of large language models, all while using Meta Llama 2 Chat, Llama Guard, and Code Llama.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Sign up for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/AGENT_1200px--1-.gif" width="1200" /></figure><h1 id="openai%E2%80%99s-next-act">OpenAI’s Next Act?</h1><p>OpenAI is focusing on autonomous agents that take action on a user’s behalf.</p><p><strong>What’s new:</strong>&nbsp;The maker of ChatGPT is developing applications designed to automate common digital tasks by controlling apps and devices,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/openai-shifts-ai-battleground-to-software-that-operates-devices-automates-tasks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;OpenAI has two agent systems in the works. It has&nbsp;not revealed any findings, products, or release dates.</p><ul><li>One system is designed to automate the use of business software such as accounting and contact management systems. The other performs web-based tasks such as collecting information on a particular topic or booking travel arrangements.&nbsp;</li><li>A user would enter a prompt, such as a request to transfer data from a document to a spreadsheet or fill out expense reports and transfer them to accounting software. The agent would respond by moving cursors, clicking buttons, selecting or entering text, and so on.</li><li>In November, OpenAI introduced the&nbsp;<a href="https://platform.openai.com/docs/assistants/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Assistants API</a>, designed to help developers build agent-like assistants that follow instructions to automate certain tasks. In 2022, it published&nbsp;<a href="https://arxiv.org/abs/2206.11795?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">research</a>&nbsp;describing an agent that used a keyboard and mouse to play the video game Minecraft after being trained on video of humans playing the game.</li></ul><p><strong>Behind the news:</strong>&nbsp;Agents are on Silicon Valley’s radar, especially since January’s Consumer Electronics Show&nbsp;<a href="https://www.deeplearning.ai/the-batch/ces-2024-showcased-ais-reach-beyond-browsers-and-smartphones/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">debut</a>&nbsp;of the Rabbit R1, which accepts voice commands to play music, order food, call a car, and so on. Several other companies, academic labs, and independent developers are pursuing the concept as well.</p><ul><li>Sierra, a&nbsp;<a href="https://sierra.ai/news/introducing-sierra?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">startup</a>&nbsp;cofounded by OpenAI chairman Bret Taylor, is creating conversational agents for businesses that can take actions like tracking packages, exchanging products, and resolving issues on a customer’s behalf.</li><li>Longtime Google researchers Ioannis Antonoglou, Sherjil Ozair, and Misha Laskin recently left the company to&nbsp;<a href="https://www.theinformation.com/articles/google-deepmind-veteran-departs-to-launch-ai-agent-startup?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">co-found</a>&nbsp;a startup focused on agents.</li><li>Google, Microsoft, and other companies are exploring similar technologies that enable agents to move or edit files and interact with other agents,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2023/10/16/technology/ai-agents-workers-replace.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">reported</a>.</li><li>The Browser Company recently&nbsp;<a href="https://twitter.com/joshm/status/1753129075487478157?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">announced</a>&nbsp;that its browser Arc would integrate agents to find and deliver videos, recipes, products, and files from the internet.</li><li>Adept&nbsp;<a href="https://www.adept.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">offers</a>&nbsp;a system that monitors a user’s actions and can click, type, and scroll in a web browser in response to commands. (ACT-1 is available as an alpha test via waitlist.)</li></ul><p><strong>Why it matters:</strong>&nbsp;Training agents to operate software designed for humans can be tricky. Some break down tasks into subtasks but struggle with executing them. Others have difficulty with tasks they haven’t encountered before or&nbsp;<a href="https://www.theinformation.com/articles/regulation-drama-in-silicon-valley-why-ai-agents-havent-lived-up-to-the-hype?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">edge cases</a>&nbsp;that are unusually complex. However, agents are becoming more reliable in a wider variety of settings as developers push the state of the art forward.</p><p><strong>We’re thinking:</strong>&nbsp;We’re excited about agents! You can learn about agent technology in our short course, “<a href="https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">LangChain for LLM Application Development</a>,” taught by LangChain CEO Harrison Chase and Andrew.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="480" src="https://dl-staging-website.ghost.io/content/images/2024/02/PRUNING--1-.gif" width="853" /></figure><h1 id="better-faster-network-pruning">Better, Faster Network Pruning</h1><p>Pruning weights from a neural network makes it smaller and faster, but it can take a lot of computation to choose weights that can be removed without degrading the network’s performance. Researchers devised a computationally efficient way to select weights that have relatively little impact on performance.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Mingjie Sun, Zhuang Liu, Anna Bair, and J. Zico Kolter at Carnegie Mellon University, Facebook AI Research, Meta AI, and Bosch Center for AI respectively devised a method for pruning by&nbsp;<a href="https://arxiv.org/abs/2306.11695?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">weights and activations</a>, or Wanda.&nbsp;</p><p><strong>Key insight:</strong>&nbsp;The popular approach known as&nbsp;<a href="https://arxiv.org/abs/1506.02626?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">magnitude pruning</a>&nbsp;removes the smallest weights in a network based on the assumption that weights closest to 0 can be set to 0 with the least impact on performance. Meanwhile, unrelated&nbsp;<a href="https://arxiv.org/abs/2208.07339?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">work</a>&nbsp;found that, in very large language models, the magnitudes of a subset of outputs from an intermediate layer may be up to 20 times larger than those of other outputs of the same layer. Removing the weights that are multiplied by these large outputs — even weights close to zero — could significantly degrade performance. Thus, a pruning technique that considers both weights and intermediate-layer outputs can accelerate a network with less impact on performance.</p><p><strong>How it works:</strong>&nbsp;The authors pruned a pretrained&nbsp;<a href="https://arxiv.org/abs/2302.1397?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">LLaMA</a>&nbsp;that started with 65 billion parameters. Given 128 sequences of tokens drawn from a&nbsp;<a href="https://jmlr.org/papers/v21/20-074.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">curated dataset of English text from the web</a>, the model processed them as follows:&nbsp;</p><ul><li>For each intermediate layer, the authors computed the norm (the magnitude across all the input sequences for each value in the embedding).</li><li>For each weight in the model, they computed its importance by multiplying its magnitude by the corresponding norm.</li><li>They compared the importance of weights in a layer’s weight matrix row by row; that is, neuron by neuron. They removed 50 percent of the least important weights in each row. (By contrast, typical weight pruning removes the lowest-magnitude weights in all rows of the weight matrix; that is, across all neurons in the layer.)</li></ul><p><strong>Results:</strong>&nbsp;The authors tested versions of LLaMA unpruned and pruned via various methods. The models performed a language modeling task using&nbsp;<a href="https://arxiv.org/abs/1609.07843?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">web text</a>. The unpruned LLaMA achieved 3.56 perplexity (a measure of the likelihood that a model will predict the next token, lower is better). Pruned by Wanda to half its original size, it achieved 4.57 perplexity. Pruned by the best competing method,&nbsp;<a href="https://openreview.net/forum?id=gsP05g8IeK&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">SparseGPT</a>&nbsp;(which both removes weights and updates the remaining ones), it achieved the same score. However, Wanda took 5.6 seconds to prune the model, while SparseGPT took 1,353.4 seconds. Pruned by magnitude pruning, the model achieved 5.9 perplexity.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The ability to compress neural networks without affecting their output is becoming more important as models balloon and devices at the edge of the network become powerful enough to run them. Wanda compared weights from each row in the weight matrices (pruning per neuron), rather than each weight matrix (pruning per layer) or the model as a whole. The scale at which weights are compared turns out to be important — an interesting avenue for further research.</p><p><strong>We’re thinking:</strong>&nbsp;We came up with a joke about a half-LLaMA, but it fell flat.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> </h1><p>More AI news of the week includes:&nbsp; </p><ul><li>Baby's eye-view footage trains AI</li><li>Singapore invests $1 billion in AI development</li><li>Stability AI announces Stable Diffusion 3</li></ul><p>Stay in the know with Data Points, a spin-off of The Batch. <a href="https://www.deeplearning.ai/the-batch/data-points-issue-238/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now</a>.&nbsp; </p>
]]></content:encoded>
<pubDate>Wed, 28 Feb 2024 19:51:32 GMT</pubDate>
</item>
<item>
<title>Generated Video Gets Real(er), Nvidia Competitor Emerges, Neural Nets for Gymnastics, Efficient Optimizer</title>
<link>https://www.deeplearning.ai/the-batch/issue-237</link>
<guid>https://www.deeplearning.ai/the-batch/issue-237</guid>
<content:encoded><![CDATA[
<div> AI Fund, persistence, fast iteration, community, OpenAI's video generator, Sora, qualitative results, competition in AI chips, Huawei, SMIC, Olympic gymnastic contests, JSS, Fujitsu, memory-efficient optimizer, LOMO. 

坚持、快速迭代、社区将是建立AI公司的关键。OpenAI发布了名为Sora的视频生成模型，其中概念演示视频质量惊人。华为的AI芯片供不应求，正在成为重要的供应商。国际体操比赛采用了人工智能评分系统JSS，帮助裁判检验决策。研究人员还提出了一种节省内存的优化器LOMO，可用于大规模语言模型的调优。总结: AI Fund就建立AI公司的关键要素进行了讨论，包括坚持、快速迭代和社区。OpenAI发布了令人印象深刻的视频生成模型Sora。华为正因其AI芯片供不应求而崛起。国际体操比赛采用了人工智能评分系统JSS。研究人员提出了一种内存使用较少的优化器LOMO。 <div>
<p><em>Dear friends,</em></p><p><em>Earlier this month, my team AI Fund held its annual co-founder and CEO summit, where many of our collaborators gathered in California for two days to discuss how to build AI companies. Three themes emerged from many presentations: persistence, fast iteration and community.&nbsp;</em></p><p><em><strong>Persistence.&nbsp;</strong>Doing impactful work is hard!&nbsp;</em><a href="https://aifund.ai/team-member/tim-westergren/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Tim Westergren</em></a><em>&nbsp;(founder and former CEO of Pandora, Venture Advisor at AI Fund) said it was only on his 348th venture pitch that Pandora raised its Series A round of funding. He also spoke about the tough time when Pandora team members went without salaries for an extended period of time to try to make the company work out. While many people unfortunately are not in a position to make such sacrifices to build a business, sometimes it does take extraordinary effort — and, yes, sacrifices — to do something really meaningful.&nbsp;</em></p><p><em><strong>Fast iteration.</strong>&nbsp;AI Fund’s process of building startups is focused on a three- month, bi-weekly sprint process, in which we iterate quickly through technical prototypes as well as business ideas.&nbsp;</em><a href="https://aifund.ai/team-member/bill-maccartney/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Bill MacCartney</em></a><em>&nbsp;(former VP of Cohere, Venture Advisor at AI Fund) said, “The best way to start is just by building on top of . . . whatever the best model is . . .. Don’t worry about [cost or latency] at first. You’re really just trying to validate the idea.”&nbsp;</em></p><p><em>One technique that’s now very widespread for prototyping is retrieval augmented generation (RAG). I’ve been surprised at how many nontechnical business leaders seem to know what RAG is. Investors are sometimes leery of people who build a thin layer around LLMs. As&nbsp;</em><a href="https://aifund.ai/team-member/laurence-moroney/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Laurence Moroney</em></a><em>&nbsp;(lead AI Advocate at Google, AI Fund Fellow) says, “I’m a huge fan of RAG . . .. I think this is one way to go beyond a thin veneer around [commercial] models and build a somewhat thicker veneer.”&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--100-.png" width="1200" /></figure><p><em><strong>Community.&nbsp;</strong>Despite the wide range of startups represented in sectors including deep AI tech, healthcare, finance, edtech, and so on, a recurring theme was that company builders end up stronger when they come together.&nbsp;</em><a href="https://aifund.ai/team-member/emil-stefanutti/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Emil Stefanutti</em></a><em>&nbsp;(co-founder of ContractRoom, Venture Advisor at AI Fund) said he was glad that many of the scars he has acquired by building businesses are turning out to be treasures for others, as he's able to share experiences that other entrepreneurs can benefit from. Tim Westergren said, “You can’t white-knuckle it. You also can’t do it alone.”</em></p><p><em>The themes of persistence, fast iteration, and community apply whether you work in a large company, startup, research, government, or elsewhere. When I think of innovators in any field, I often think of Teddy Roosevelt’s message:</em></p><p><em>“It is not the critic who counts; not the [person] who points out how the strong [person] stumbles, or where the doer of deeds could have done them better. The credit belongs to the [person] who is actually in the arena, whose face is marred by dust and sweat and blood; who strives valiantly; who errs, who comes short again and again, … who knows great enthusiasms, the great devotions; who spends himself in a worthy cause.”</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="335" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181018.251.gif" width="600" /></figure><h1 id="generated-video-gets-realer">Generated Video Gets Real(er)</h1><p>OpenAI’s new video generator raises the bar for detail and realism in generated videos — but the company released few details about how it built the system.<br /><br /><strong>What’s new:&nbsp;</strong>OpenAI introduced&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">Sora</a>, a text-to-video model that can produce extraordinarily convincing, high-definition videos up to one minute long. You can see examples&nbsp;<a href="https://openai.com/sora?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">here</a>.<br /><br /><strong>What we know:&nbsp;</strong>Sora is a&nbsp;<a href="https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">latent diffusion</a>&nbsp;model that learned to transform noise into videos using an encoder-decoder and transformer. The system was trained on videos up to 1,920x1,080 pixels and up to one minute long.</p><ul><li>Following DALL·E 3, OpenAI&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc#connecting-videos" rel="noopener">trained</a>&nbsp;a video captioning model to enhance the captions of videos in the dataset, adding descriptive details.</li><li>Given a video’s frames divided into patches, the encoder learned to embed the patches and further compress them along the time dimension, producing tokens. Given the tokens, the decoder learned to reconstruct the video.<br /></li><li>Given tokens that had been adulterated by noise and an enhanced prompt, the transformer learned to generate the tokens without noise.</li><li>At inference, a separate transformer enhanced input prompts to be more descriptive. Given the enhanced prompt and noisy tokens, Sora’s transformer removed the noise. Given the denoised tokens, the decoder produced a video.</li></ul><p><strong>What we don’t know:</strong>&nbsp;OpenAI is sharing the technology with outside researchers charged with evaluating its safety,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">reported</a>. Meanwhile, the company published neither quantitative results nor comparisons to previous work. Also missing are detailed descriptions of model architectures and training methods. (Some of the results suggest that Sora was trained not only to remove noise from tokens, but also to&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc#extending-generated-videos" rel="noopener">predict future tokens</a>&nbsp;and&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc#connecting-videos" rel="noopener">generate tokens in between other tokens</a>.) No information is available about the source(s) of the dataset or how it may have been curated.<br /><br /><strong>Qualitative results:&nbsp;</strong>Sora’s demonstration output is&nbsp;impressive enough to have sparked&nbsp;<a href="https://twitter.com/DrJimFan/status/1758549500585808071?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">arguments</a>&nbsp;over the degree to which Sora “understands” physics. A photorealistic scene in which “a stylish woman walks down a Tokyo street filled with warm glowing neon” shows a crowded shopping district filled with believable pedestrians. The woman’s sunglasses reflect the neon signs, as does the wet street. Halfway through its one-minute length, the perspective cuts — unprompted and presumably unedited — to a consistent, detailed close-up of her face. In another clip, two toy pirate ships bob and pitch on a frothing sea of coffee, surrounded by a cup’s rim. The two ships maintain their distinctiveness and independence, their flags flutter in the same direction, and the liquid churns fantastically but realistically. However, as OpenAI acknowledges, the outputs on display are not free of flaws. For instance, the pirate-battle cup’s rim, after camera motion has shifted it out of the frame, emerges from the waves. (Incidentally, the Sora demos are even more fun with&nbsp;<a href="https://x.com/elevenlabsio/status/1759240084342059260?s=20&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">soundtracks</a>&nbsp;generated by Eleven Labs.)</p><p><strong>Why it matters:</strong>&nbsp;While we’ve seen&nbsp;<a href="https://www.deeplearning.ai/the-batch/googles-phenaki-generates-long-form-video-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">transformers for video generation</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-system-make-a-video-generates-video-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">diffusion models for video generation</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/a-new-class-of-diffusion-models-based-on-the-transformer-architecture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">diffusion transformers for images</a>, this is an early implementation of diffusion transformers for video generation (along with a recent&nbsp;<a href="https://arxiv.org/abs/2401.03048?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">paper</a>). Sora shows that diffusion transformers work well for video.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Did Sora learn a world model? Learning to predict the future state of an environment, perhaps given certain actions within that environment, is not the same as learning depict that environment in pixels —just like the ability to predict that a joke will make someone smile is different than the ability to draw a picture of that smile. Given Sora's ability to extrapolate scenes into the future, it does seem to have some understanding of the world. Its world model is also clearly flawed — for instance, it will synthesize inconsistent three-dimensional structures — but it’s a promising step toward AI systems that comprehend the 3D world through video.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181123.082.png" width="1200" /></figure><h1 id="competition-heats-up-in-ai-chips">Competition Heats Up in AI Chips</h1><p>Huawei is emerging as an important supplier of AI chips.</p><p><strong>What’s new:</strong>&nbsp;Amid a U.S. ban on exports of advanced chips to China, demand for Huawei’s AI chips is so intense that the company is limiting production of the chip that powers one of its most popular smartphones so it can serve the AI market,&nbsp;<em>Reuters</em>&nbsp;<a href="https://www.reuters.com/technology/ai-chip-demand-forces-huawei-slow-smartphone-production-sources-2024-02-05?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">reported</a>.</p><p><strong>Demand and supply:</strong>&nbsp;China’s biggest chip fabricator, Semiconductor Manufacturing International Corp. (SMIC), fabricates both the Ascend 910B, which is optimized to process neural networks, and the Kirin chip that drives Huawei’s popular Mate 60 phone. Production capacity is limited, so making more Ascend 910Bs means making fewer Kirins.&nbsp;</p><ul><li>The Huawei Ascend 910B is widely considered to be the best AI chip available in China. The chip has been reported to deliver&nbsp;<a href="https://www.huaweicentral.com/whats-the-ascend-910b-ai-chip-baidu-ordered-from-huawei/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">performance</a>&nbsp;roughly&nbsp;<a href="https://www.tomshardware.com/news/huaweis-gpu-reportedly-matches-nvidias-a100-report?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">comparable to that of Nvidia’s A100</a>&nbsp;(immediate predecessor to the current H100, which is more than three times faster).</li><li>The Nvidia H100, which is the industry standard for processing deep learning models, has become scarce in China since late 2022, when the U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">restricted</a>&nbsp;exports of advanced chips and use of chip-making equipment. The shortage of Nvidia chips is driving demand for the Ascend 910B.</li><li>The U.S. action also forced Huawei to switch manufacturers from Taiwan Semiconductor Manufacturing Company to SMIC. But the limits on manufacturing equipment have made it difficult to fabricate the Ascend 910B. SMIC has been able to produce a relatively small number of units that are free from defects.</li><li>Huawei’s decision to shift manufacturing from phone chips to AI chips is sacrificing one of its most popular products. Huawei’s Mate 60 phone outsold the Apple iPhone in China last year, helping to elevate Huawei in January to the top-selling phone maker in China for the first time in three years.</li></ul><p><strong>Behind the news:</strong>&nbsp;Nvidia accounted for 90 percent of the market for AI chips in China prior to the advent of U.S. export restrictions. China has responded to the limits by building its ability to manufacture advanced chips domestically — a tall order, since it requires technology that is very difficult to develop. In August, Baidu ordered 1,600 Ascend 910B chips for delivery by the end of the year, according to an earlier&nbsp;<em>Reuters</em>&nbsp;<a href="https://www.reuters.com/technology/baidu-placed-ai-chip-order-huawei-shift-away-nvidia-sources-2023-11-07/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">report</a>. The order, which is tiny compared to typical data center purchases, nonetheless demonstrated that SMIC could manufacture the chips and that Baidu was experimenting with alternatives to Nvidia in anticipation of even tighter U.S. restrictions on AI chips that took effect in October. Currently, SMIC is&nbsp;<a href="https://www.asiafinancial.com/huawei-smic-set-to-defy-us-sanctions-with-5nm-chips-ft?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">gearing up</a>&nbsp;to produce Huawei’s next-generation Ascend chips.</p><p><strong>Why it matters:</strong>&nbsp;For years, Nvidia’s GPUs have been the only practical choice for processing deep learning models. The company’s lead over competitors both in hardware implementation and software support are likely to protect its dominant position for some time to come. However, competitors like AMD and Huawei are beginning to nip at Nvidia’s heels. That means more hardware options for developers, and the competition may drive lower prices and still higher performance.</p><p><strong>We’re thinking:</strong>&nbsp;AI chips are at the heart of the current technological&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">competition</a>&nbsp;between the U.S. and China. While Huawei and SMIC still have a lot to prove in terms of scaling up production, their rate of progress is impressive and illustrates the limits of the current U.S. restrictions.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.eventbrite.com/e/building-production-grade-llm-apps-tickets-837481398407?aff=Batch&amp;ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-21T092947.270.png" width="1680" /></a></figure><p>In our next live workshop, we’ll share how to build high-quality and production-ready applications using tools like Pinecone Canopy and TruLens. Notebooks will be available for participants to explore!&nbsp;<a href="https://www.eventbrite.com/e/building-production-grade-llm-apps-tickets-837481398407?aff=Batch&amp;ref=dl-staging-website.ghost.io" rel="noreferrer">Register now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181325.090.gif" width="600" /></figure><h1 id="gymnastics-judge%E2%80%99s-helper">Gymnastics Judge’s Helper</h1><p>Judges in competitive gymnastics are using an AI system to double-check their decisions.</p><p><strong>What’s new:</strong>&nbsp;Olympic-level gymnastic contests have adopted Judging Support System (JSS), an AI-based video evaluation system built by Fujitsu,&nbsp;<em>MIT Technology Review</em>&nbsp;<a href="https://www.technologyreview.com/2024/01/16/1086498/ai-gymnastics-judging-jss-world-championships-antwerp-paris-olympics/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">reported</a>. In September and October,&nbsp; for the first time, judges at the 2023 World Artistic Gymnastics Championships in Antwerp used JSS in competitions that involved the full range of gymnastics equipment including mat, balance beam, parallel bars, pommel horse, and so on.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Judges penalize gymnasts for imperfections in any pose or move. JSS identifies deviations that correspond to particular penalties. The system can evaluate roughly 2,000 poses and moves with 90 percent accuracy compared to human judges. It can assess both isolated actions and entire routines.&nbsp;</p><ul><li>Fujitsu trained JSS on video footage of 8,000 gymnastic routines that encompass the official&nbsp;<a href="https://gymnasticsresults.com/technical/code-of-points?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">gymnastics scoring guide</a>. The system matches body positions to corresponding poses and motions described in the scoring guide.</li><li>JSS receives position data on a gymnast’s body from 4 to 8&nbsp;cameras. A 2018&nbsp;<a href="https://www.fujitsu.com/global/documents/about/resources/publications/fstj/archives/vol54-4/paper07.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">paper</a>&nbsp;offers hints about how the current system may work: Given the images, it detects the posture (front-facing, handstand, or rear-facing). Given the posture, it feeds the images into a corresponding 3D model. Then it converts the&nbsp;images into a virtual skeleton, conforms a human model to the skeleton, and modifies the skeleton (and conformed model) to match the&nbsp;images.</li><li>Under the current rules, judges can use JSS only when competitors challenge a score or a judge and supervisor disagree. The International Gymnastics Federation, the sport’s global governing body, has not yet revealed whether or how the system will be used at this year’s Summer Olympics in Paris.</li></ul><p><strong>Behind the news:</strong>&nbsp;Sporting authorities have embraced AI both inside and outside the arena.</p><ul><li>The English Premier League football clubs Chelsea and Nottingham Forest have expressed interest in the AISCOUT app as a way to discover fresh talent. Amateur players upload videos of themselves performing drills, and the app scores their performance.&nbsp;</li><li>At the 2020 Summer Olympics in Tokyo, official timekeeper Omega Timing&nbsp;<a href="https://www.deeplearning.ai/the-batch/olympic-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">provided</a>&nbsp;several AI-based systems: a pose estimator for gymnasts on the trampoline, an image recognition system that analyzed swimmers’ performance, and a ball tracker for volleyball.</li><li>Acronis, a Swiss company that provides video storage for pro football teams, has built AI applications that track players’ movements and analyze their tactics. The company also predicts match attendance for teams in the English Premier League based on ticket sales, weather, and other factors.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;Gymnastic competitors are&nbsp;<a href="https://www.british-gymnastics.org/component/content/article/339-fansmajorevents/6203-your-guide-to-the-gymnastics-scoring-system?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">scored</a>&nbsp;on subjective criteria such as expression, confidence, and personal style as well as technical competence, raising questions of unconscious bias and whether some judges might favor certain competitors over others. An AI system that tracks technical minutiae may help judges to avoid bias while focusing on the sport’s subjective aspects.</p><p><strong>We’re thinking:</strong>&nbsp;Tracking gymnasts in motion sets a high bar for AI!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181416.147.png" width="1200" /></figure><h1 id="memory-efficient-optimizer">Memory-Efficient Optimizer</h1><p>Researchers devised a way to reduce memory requirements when fine-tuning large language models.&nbsp;</p><p><strong>What's new:</strong>&nbsp;Kai Lv and colleagues at Fudan University proposed&nbsp;<a href="https://arxiv.org/abs/2306.09782?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">low memory optimization</a>&nbsp;(LOMO), a modification of stochastic gradient descent that stores less data than other optimizers during fine-tuning.</p><p><strong>Key insight:</strong>&nbsp;Optimizers require a lot of memory to store an entire network’s worth of parameters, gradients, activations, and optimizer states. While Adam has overtaken stochastic gradient descent (SGD) for training, SGD remains a popular choice for fine-tuning partly because it requires less memory (since it stores fewer optimizer states). Nonetheless, SGD must store an entire network’s gradients — which, with state-of-the-art models, can amount to tens or hundreds of gigabytes — before it updates the network all at once. Updating the network layer by layer requires storing only one layer’s gradients — a more memory-efficient twist on typical SGD.</p><p><strong>How it works:</strong>&nbsp;The authors fine-tuned&nbsp;<a href="https://arxiv.org/abs/2302.13971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">LLaMA</a>&nbsp;on six datasets in&nbsp;<a href="https://arxiv.org/abs/1905.00537?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">SuperGLUE</a>, a benchmark for language understanding and reasoning that includes tasks such as answering multiple-choice questions.</p><ul><li>The authors modified SGD to compute gradients for one layer and update that layer’s weights before advancing to the next.</li><li>To avoid the potential for exploding or&nbsp;<a href="https://www.coursera.org/lecture/nlp-sequence-models/vanishing-gradients-with-rnns-PKMRR?ref=dl-staging-website.ghost.io&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">vanishing gradients</a>, in which gradients from later layers either expand or diminish as they backpropagate through the network, LOMO normalized the gradients, scaling them to a predetermined range throughout the network. LOMO used two backward passes: one to compute the magnitude of the gradient for the entire network, and another to scale each layer’s gradient according to the total magnitude and then update its parameters.</li></ul><p><strong>Results:</strong>&nbsp;LOMO required less memory than popular optimizers and achieved better performance than the popular memory-efficient fine-tuning technique LoRA.</p><ul><li>The authors fine-tuned separate instances of LLaMA-7B using LOMO and two popular optimizers, SGD and AdamW (a modified version of Adam). They required 14.6GB, 52.0GB, and 102.2GB of memory respectively. In particular, they all required the same amount of memory to store model parameters (12.55GB) and activations (1.79GB). However, when it came to gradients, LOMO required only 0.24GB while SGD and AdamW each required 12.55GB. The biggest difference was optimizer state memory: LOMO required 0GB, SGD required 25.1GB, and Adam required 75.31GB.</li><li>The authors also compared LOMO to&nbsp;<a href="https://arxiv.org/abs/2106.09685?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">LoRA</a>, which works with an optimizer (in this case, AdamW) to learn to change each layer’s weight matrix by a product of two smaller matrices. They performed this comparison with LLaMAs of four sizes on six datasets. LOMO achieved better accuracy in 16 of the 24 cases, and its average accuracy across datasets exceeded LoRA’s at each model size. For example, the 65 billion-parameter LOMO-tuned LLaMA averaged 89.9 percent accuracy, and the 65 billion-parameter LoRA/AdamW-tuned LLaMA averaged 89.0 percent accuracy.</li></ul><p><strong>Why it matters:</strong>&nbsp;Methods like LoRA save memory by fine-tuning a small number of parameters relative to a network’s total parameter count. However, because it adjusts only a small number of parameters, the performance gain from fine-tuning is less than it could be. LOMO fine-tunes all parameters, maximizing performance gain while reducing memory requirements.</p><p><strong>We're thinking:</strong>&nbsp;SGD’s hunger for memory is surprising. Many developers will find it helpful to have a memory-efficient alternative.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>More AI news of the week. From Gemini 1.5’s whopping context window to the energy footprint of AI models and Google's next research hub city, we covered it all.&nbsp;</p><p>Dive into this week's key AI developments in our latest Data Points edition.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-237/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 21 Feb 2024 23:18:33 GMT</pubDate>
</item>
<item>
<title>AI Recovers Ancient Scrolls, GPUs Strain Power Grid, Government Restricts Fake Voices, Better Image Generation</title>
<link>https://www.deeplearning.ai/the-batch/issue-236</link>
<guid>https://www.deeplearning.ai/the-batch/issue-236</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>The rise of cloud-hosted AI software has brought much discussion about the privacy implications of using it. But I find that users, including both consumers and developers building on such software, don’t always have a sophisticated framework for evaluating how software providers store, use, and share their data. For example, does a company’s promise “not to train on customer data” mean your data is private?&nbsp;</em></p><p><em>Here is a framework for thinking about different levels of privacy on cloud platforms, from less to more:</em></p><ul><li><em><strong>No Guarantees:&nbsp;</strong>The company provides no guarantees that your data will be kept private. For example, an AI company might train on your data and use the resulting models in ways that leak it. Many startups start here but add privacy guarantees later when customers demand them.</em></li><li><em><strong>No Outside Exposure:</strong>&nbsp;The company does not expose your data to outsiders. A company can meet this standard by not training on your data and also by not posting your data online. Many large startups, including some providers of large language models (LLMs), currently operate at this level.&nbsp;</em></li><li><em><strong>Limited Access:</strong>&nbsp;In addition to safeguards against data leakage, no humans (including employees, contractors, and vendors of the company) will look at your data unless they are compelled via a reasonable process (such as a subpoena or court order, or if the data is flagged by a safety filter). Many large cloud companies effectively offer this level of privacy, whether or not their terms of service explicitly say so.&nbsp;</em></li><li><em><strong>No Access:&nbsp;</strong>The company cannot access your data no matter what. For example, data may be stored on the customer’s premises, so the company doesn’t have access to it. If I run an LLM on my private laptop, no company can access my prompts or LLM output. Alternatively, if data is used by a SaaS system, it might be encrypted before it leaves the customer’s facility, so the provider doesn’t have access to an unencrypted version. For example, when you use an end-to-end encrypted messaging app such as Signal or WhatsApp, the company cannot see the contents of your messages (though it may see “envelope” information such as sender and recipient identities and the time and size of the message).</em></li></ul><p><em>These levels may seem clear, but there are many variations within a given level. For instance, a promise not to train on your data can mean different things to different companies. Some forms of generative AI, particularly image generators, can&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/spotting-similarities-between-generated-images-and-data/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>replicate their training data</em></a><em>, so training a generative AI algorithm on customer data may run some risk of leaking it. On the other hand, tuning a handful of an algorithm’s hyperparameters (such as learning rate) to customer data, while technically part of the training process, is very unlikely to result in any direct data leakage. So how the data is used in training will affect the risk of leakage. &nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--97--1.png" width="1200" /></figure><p><em>Similarly, the Limited Access level has its complexities. If a company offers this level of privacy, it’s good to understand exactly under what circumstances its employees may look at your data. And if they might look at your data, there are shades of gray in terms of how private the data remains. For example, if a limited group of employees in a secure environment can see only short snippets that have been disassociated from your company ID, that’s more secure than if a large number of employees can freely browse your data.&nbsp;</em></p><p><em>In outlining levels of privacy, I am not addressing the question of security. To trust a company to deliver a promised level of privacy is also to trust that its IT infrastructure is secure enough to keep that promise.&nbsp;</em></p><p><em>Over the past decade, cloud hosted SaaS software has gained considerable traction. But some customers insist on running on-prem solutions within their own data centers. One reason is that many SaaS providers offer only No Guarantees or No Outside Exposure, but many customers’ data is so sensitive that it requires Limited Access.&nbsp;</em></p><p><em>I think it would be useful for our industry to have a more sophisticated way to talk about privacy and help users understand what guarantees providers do and do not deliver.&nbsp;</em></p><p><em>As privacy becomes a global topic, regulators are stepping in, and this is adding further complexity to tech businesses. For example, if one jurisdiction changes the definition of a child from someone under 13 to anyone under 18, that might require changes to how you store data of individuals age 13 to 18; but who has time to keep track of such changes?</em></p><p><em>I've been delighted to see that here, AI can help. Daphne Li, CEO of&nbsp;</em><a href="https://commonsenseprivacy.net/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>Commonsense Privacy</em></a><em>&nbsp;(disclosure: a portfolio company of AI Fund), is using large language models to help companies systematically evaluate, and potentially improve, their privacy policies as well as keep track of global regulatory changes. In the matter of privacy, as in other areas, I hope that the title of my TED AI talk — “</em><a href="https://www.ted.com/talks/andrew_ng_ai_isn_t_the_problem_it_s_the_solution?language=en&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>AI Isn’t the Problem, It’s the Solution</em></a><em>” — will prove to be true.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S.&nbsp;Check out our new short course with Amazon Web Services on “Serverless LLM Apps With Amazon Bedrock,” taught by Mike Chambers. A serverless architecture enables you to quickly deploy applications without needing to set up and manage compute servers to run your applications on, often a full-time job in itself. In this course, you’ll learn how to implement serverless deployment by building event-driven systems. We illustrate this approach via an application that automatically detects incoming customer inquiries, transcribes them with automatic speech recognition, summarizes them with an LLM using Amazon Bedrock, and runs serverless with AWS Lambda. We invite you to&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>enroll here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-14T152741.124.gif" width="600" /></figure><h1 id="ancient-scrolls-recovered">Ancient Scrolls Recovered</h1><p>Three researchers decoded scrolls that had gone unread since they were turned into charcoal by the eruption of Mount Vesuvius in the year 79.</p><p><strong>What’s new:</strong>&nbsp;Youssef Nader, Luke Farritor, and Julian Schilliger used neural networks to win the $700,000 grand prize in the&nbsp;<a href="https://scrollprize.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Vesuvius Challenge</a>, a competition to translate charred papyrus scrolls found in the ruins of a villa at the Roman town of Herculaneum in southern Italy.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The volcanic eruption covered Herculaneum in ash. It also transformed into carbon the papyrus scrolls, which originally would have unrolled to lengths as long as 30 feet.&nbsp;</p><ul><li>Competitors were given extremely high-resolution, three-dimensional X-ray scans of four intact scrolls. Like CT scans, each scan comprised a series of 2D cross sections. An application developed by researchers who have been working to decipher the scrolls virtually unwrapped the 3D scans into 2D images of the scroll surfaces and segmented them into individual papyrus sheets.</li><li>Examining the resulting images by eye, a member of a different team noticed faint patterns of cracks and lines that suggested Greek letters. He uploaded his findings, which prompted Farritor to take up the search.</li><li>Having identified traces of ink in one of the scrolls, Farritor trained a&nbsp;<a href="https://arxiv.org/abs/1512.03385?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">ResNet</a>&nbsp;to recognize 64x64-pixel patches of the sheet images that showed similar traces. The initial model revealed more ink traces, which were added to the training set; the retrained model found more, which joined the training set, and so on. The model enabled Farritor to render 10 legible letters, winning an&nbsp;<a href="https://scrollprize.org/firstletters?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">intermediate prize</a>.</li><li>Building on Farritor’s approach, the team trained three models on fragments of other scrolls to recognize patches that showed signs of ink. They selected the 3D architectures&nbsp;<a href="https://arxiv.org/abs/2102.05095?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">TimeSformer</a>,&nbsp;<a href="https://paperswithcode.com/lib/torchvision/resnet-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Resnet3D-101</a>, and&nbsp;<a href="https://arxiv.org/abs/1705.07750?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">I3D</a>&nbsp;to capture ink residue that rose above the carbonized papyrus surface.&nbsp;The clearest images came from TimeSformer. The team manually compared TimeSformer’s images with those produced by the other two models to ensure that TimeSformer didn’t misclassify patches as having ink when it wasn’t there.</li><li>Working on one of the four scrolls (the other three having proven more difficult to scan, unwrap, and segment), the team rendered readable 85 percent of the presumed characters in four 140-character passages — thus satisfying the grand-prize criteria. They also rendered 11 additional passages for a total of more than 2,000 characters, or roughly 5 percent of the scroll. The rendered text appears to express Epicurean philosophy that praises the virtues of pleasure.</li></ul><p><strong>Behind the news:</strong>&nbsp;The Vesuvius Challenge launched in March 2023 with funding provided by GitHub CEO Nat Friedman.&nbsp;</p><ul><li>Smaller prizes were awarded to researchers who deciphered single words and shorter passages. Notably, these early prizewinners included Nader and Farritor, who then teamed with Schilliger.&nbsp;</li><li>In its next round, the competition is offering $100,000 to the first team to decipher 90 percent of all four scrolls that have been imaged so far.</li><li>The library at Herculaneum includes 800 scrolls already recovered and potentially thousands more still to be excavated. Reading them all would make this library one of the largest collections of texts recovered from the ancient world.</li></ul><p><strong>Why it matters:</strong>&nbsp;The winning team’s achievement testifies to the ability of deep learning to help solve difficult problems. And their work may have broader significance: Recovering the entire Herculaneum library could provide insights into literature, philosophy, history, science, and art at the time of Caesar.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;University of Kentucky computer scientist Brent Seales, who helped design the contest as well as pioneering the use of medical imaging and machine learning to read ancient texts, reckons that over 1,000 teams worked on the problem, amounting to 10 person-years and two compute-years. It's a great example of the power of global collaboration and open resources — central facets of the AI community — to find solutions to hard problems.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--98-.png" width="1200" /></figure><h1 id="us-restricts-ai-robocalls">U.S. Restricts AI Robocalls</h1><p>The United States outlawed unsolicited phone calls that use AI-generated voices.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;The Federal Communications Commission&nbsp;<a href="https://s.wsj.net/public/resources/documents/fcc-ai-robocalls-ruling.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">ruled</a>&nbsp;that the current legal restriction on voice communications that use “artificial or prerecorded voices” covers AI-powered voice generation. The ruling followed an incident in which calls that featured the cloned voice of U.S. President Biden were delivered with the apparent intent of interfering with an election.</p><p><strong>How it works:</strong>&nbsp;The ruling interprets the 1991 Telephone Consumer Protection Act, which controls automated calls, or robocalls. The law gives state attorneys general the power to prosecute robocallers. The FCC had&nbsp;<a href="https://www.theverge.com/2024/1/31/24057452/the-fcc-is-proposing-a-ban-on-robocalls-using-ai-generated-voices?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">proposed</a>&nbsp;the move in January.&nbsp;</p><ul><li>The ruling restricts calls to residential phone numbers that feature synthesized voices.</li><li>It covers all such calls whether or not they are deceptive or annoying, and applies equally to synthetic voices that mimic real voices and those that don’t.</li><li>Synthetic voices are allowed only if the recipient has given prior consent or in an emergency. Calls that convey an advertisement or marketing message must provide an opportunity to opt out, and those that feature artificial voices must identify the entity that initiated the call.</li></ul><p><strong>Behind the news:</strong>&nbsp;In January, two days before a presidential primary election, thousands of members of the Democratic Party in the state of New Hampshire&nbsp;<a href="https://apnews.com/article/biden-robocalls-artificial-intelligence-new-hampshire-texas-a8665277d43d05380d2c7594edf27617?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">received</a>&nbsp;phone calls in which a cloned voice of President Biden, who is a Democrat, urged them not to vote in a presidential primary election. The call used voice cloning software from Eleven Labs, according to researchers&nbsp;<a href="https://www.wired.com/story/new-hampshire-biden-ai-robocall/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">cited</a>&nbsp;by&nbsp;<em>Wired</em>. New Hampshire investigated the calls as a case of illegal voter suppression. It traced them to two telecommunications companies in the state of Texas and issued cease-and-desist orders and subpoenas to both firms. One, Lingo Telecom, said it is cooperating with federal and state investigators.</p><p><strong>Why it matters:</strong>&nbsp;For all its productive uses, generative AI offers fresh opportunities to scammers to deceive their marks into handing over things of value. Voice cloning can elevate their appeal by simulating personal, business, political, and other relationships. Election officials are especially concerned about AI’s potential to influence voting, especially as we enter a year that will see over 100 elections in seven of the 10 most populous nations.</p><p><strong>We’re thinking:</strong>&nbsp;The question of how to safeguard elections against manipulations like the Biden robocall is an urgent one. Devising a tamper-resistant watermark that identifies generated output would discourage misuse. However, providers will have a financial&nbsp;<a href="https://www.deeplearning.ai/the-batch/watermarking-is-a-no-go/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">incentive</a>&nbsp;not to apply such watermarks unless regulators require it.&nbsp;</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-05T095912.572.png" width="1680" /></a></figure><p>In our latest course, built in collaboration with Amazon Web Services, you’ll learn to deploy applications based on large language models using a serverless architecture. This enables rapid deployment and liberates you from the complexities of managing and scaling infrastructure.&nbsp;<a href="https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Start today!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--99-.png" width="1200" /></figure><h1 id="gpu-data-centers-strain-grid-power">GPU Data Centers Strain Grid Power</h1><p>The AI boom is taxing power grids and pushing builders of data centers to rethink their sources of electricity.</p><p><strong>What’s new:</strong>&nbsp;New data centers packed with GPUs optimized for AI workloads are being approved at a record pace,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/the-next-ai-bottleneck-power-for-data-centers?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">reported</a>. The extreme energy requirements of such chips are pushing builders to place data centers near inexpensive power sources, which may be far away from where users live.</p><p><strong>How it works:</strong>&nbsp;The coming generation of GPU data centers promises to supply processing power for the burgeoning AI era. But builders aren’t always able to find electricity to run them.</p><ul><li>In the&nbsp;<a href="https://wtop.com/virginia/2022/10/why-is-northern-va-becoming-the-worlds-data-center-capital/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">data center hub</a>&nbsp;of Northern Virginia, power company Dominion Energy temporarily ceased connecting new data centers for three months in 2022. It warned that future connections would be in question until 2026.</li><li>Although many data center operators&nbsp;<a href="https://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/path-to-net-zero-datacenter-demands-push-amazon-big-tech-toward-renewables-72752727?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">pledged</a>&nbsp;to rely on energy sources other than fossil fuels, their rising demand for power has made that difficult,&nbsp;<em>Bloomberg</em>&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-01-25/ai-needs-so-much-power-that-old-coal-plants-are-sticking-around?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">reported</a>. Regulators in Virginia considered allowing data centers to use diesel generators before they abandoned that plan under pressure from environmental groups. In Kansas City, Missouri, Meta’s apparent plan to build a giant data center helped convince one utility to postpone the planned retirement of a coal plant.</li><li>Some companies that rely on data centers are looking into less conventional power sources. Microsoft is considering small, modular nuclear reactors that, while largely speculative, promise to be less expensive and more flexible than traditional nuclear power plants. Microsoft recently&nbsp;<a href="https://www.theregister.com/2024/01/23/microsoft_nuclear_hires/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">appointed</a>&nbsp;a director of nuclear technologies.</li></ul><p><strong>What they’re saying:</strong>&nbsp;“We still don’t appreciate the energy needs of [AI] technology. There's no way to get there without a breakthrough.” — Sam Altman, CEO, OpenAI, on January 16, 2024,&nbsp;<a href="https://www.reuters.com/technology/openai-ceo-altman-says-davos-future-ai-depends-energy-breakthrough-2024-01-16/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">quoted</a>&nbsp;by&nbsp;<em>Reuters</em>.</p><p><strong>Behind the news:</strong>&nbsp;Data centers alone&nbsp;<a href="https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">account for</a>&nbsp;1 to 1.5 percent of global demand for electricity. It’s unclear how much of that figure is attributable to AI, but the share is likely to grow.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The world needs innovation in both energy resources and power-efficient machine learning. The dawning era of pervasive AI brings with it the challenge of producing energy to develop and deploy the technology, which can contribute to pollution that disrupts ecosystems and accelerates climate change. Fortunately, AI can shrink the environmental footprint of some energy-intensive activities; for example, searching the web for information generates far less CO<sup>2</sup>&nbsp;emissions than driving to a library.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Climate change is a slow-motion tragedy. We must push toward AI infrastructure that uses less energy (for example, by using more efficient algorithms or hardware) and emits less carbon (for example, by using renewable sources of energy). That said, concentrating computation in a data center creates a point of significant leverage for optimizing energy usage. For example, it’s more economical to raise the energy efficiency of 10,000 servers in a data center than 10,000 PCs that carry out the same workload in 10,000 homes.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-14T153023.937.gif" width="600" /></figure><h1 id="better-images-less-training">Better Images, Less Training</h1><p>The longer text-to-image models train, the better their output — but the training is costly. Researchers built a system that produced superior images after far less training.</p><p><strong>What's new:&nbsp;</strong>Independent researcher Pablo Pernías and colleagues at Technische Hochschule Ingolstadt, Université de Montréal, and Polytechnique Montréal built&nbsp;<a href="https://arxiv.org/abs/2306.00637?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Würstchen</a>, a system that divided the task of image generation between two diffusion models.&nbsp;</p><p><strong>Diffusion model basics:</strong>&nbsp;During training, a text-to-image generator based on diffusion takes a noisy image and a text embedding. The model learns to use the embedding to remove the noise in successive steps. At inference, it produces an image by starting with pure noise and a text embedding, and removing noise iteratively according to the text embedding. A variant known as a&nbsp;<a href="https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">latent diffusion</a>&nbsp;model uses less processing power by removing noise from a noisy image embedding instead of a noisy image.</p><p><strong>Key insight:</strong>&nbsp;A latent diffusion model typically learns to remove noise from an embedding of an input image based solely on a text prompt. It can learn much more quickly if, in addition to the text prompt, a separate diffusion model supplies a smaller, noise-free version of the image embedding.&nbsp;During training, the two models can be trained separately, enabling them to learn their tasks in a fraction of the usual time. At inference, the models can work efficiently as a stack: one to generate smaller embeddings and the other to generate larger embeddings based on the smaller ones.</p><p><strong>How it works:</strong>&nbsp;Würstchen involves three components that required training: the encoder-decoder from&nbsp;<a href="https://arxiv.org/abs/2012.09841?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">VQGAN</a>, a latent diffusion model based on&nbsp;<a href="https://arxiv.org/abs/1505.04597v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">U-Net</a>, and another latent diffusion model based on&nbsp;<a href="https://arxiv.org/abs/2201.03545?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">ConvNeXt</a>. The authors trained the models separately on subsets of&nbsp;<a href="https://arxiv.org/abs/2210.08402?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">LAION-5B</a>, which contains matched images and text descriptions scraped from the web.&nbsp;</p><ul><li>The authors trained the VQGAN encoder-decoder to reproduce input images. The encoder produced embeddings, to which the authors added noise.</li><li>To train U-Net, the authors used&nbsp;<a href="https://arxiv.org/abs/2104.00298?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">EfficientNetV2</a>&nbsp;(a convolutional neural network pretrained on ImageNet) to produce embeddings around 1/30 the size of the VQGAN embeddings (16x24x24 versus 4x256x256). Given this smaller embedding, a noisy VQGAN embedding, and a text description, U-Net learned to remove noise from the VQGAN embedding.&nbsp;</li><li>To train ConvNeXt, EfficientNetV2 once again produced small embeddings from input images, to which the authors added noise. Given a noisy EfficientNetV2 embedding and a text description, ConvNeXt learned to remove the noise.</li><li>At inference, the components worked in opposite order of training: (i) Given noise and a text prompt, ConvNeXt produced a small EfficientNetV2-sized embedding. (ii) Given that embedding, noise, and the same text prompt, U-Net produced a larger VQGAN-sized embedding. (iii) Given the larger embedding, VQGAN produced an image.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared Würstchen to&nbsp;<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Stable Diffusion 2.1</a>. While they trained both on subsets of LAION-5B, they trained Würstchen  for 25,000 GPU hours while Stable Diffusion took 200,000 GPU hours. The authors generated images based on captions from&nbsp;<a href="https://arxiv.org/abs/1405.0312?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">MS COCO</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2206.10789?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Parti-prompts</a>. They asked 90 people which output they preferred. The judges expressed little preference regarding renderings of MS COCO captions: They chose Würstchen 41.3 percent of the time, Stable Diffusion 40.6 percent of the time, and neither 18.1 percent of the time. However, presented with the results of Parti-prompts, they preferred Würstchen 49.5 percent of the time, Stable Diffusion’s 32.8 percent of the time, and neither 17.7 percent of the time.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Training a latent diffusion model to denoise smaller embeddings accelerates training, but this tends to produce lower-quality images. Stacking two diffusion models enabled Würstchen to match or exceed the output quality of models with large embeddings while achieving the training speed of models with small embeddings.</p><p><strong>We're thinking:</strong>&nbsp;25,000 GPU hours is a big reduction from 200,000! Given the cost of GPU hours, an eightfold saving is a big deal.</p><hr /><h2 id="a-message-from-fourthbrain">A MESSAGE FROM FOURTHBRAIN</h2><figure class="kg-card kg-image-card"><a href="https://hubs.la/Q02kZ3ST0?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="972" src="https://dl-staging-website.ghost.io/content/images/2024/02/FourthBrain_BatchAd_2.14.24_v1.png" width="1728" /></a></figure><p>Join us for an intensive three-week workshop where you’ll learn to operationalize large language models at scale, from learning advanced retrieval augmented generation (RAG) to deploying multimodal applications on the cloud.&nbsp;<a href="https://hubs.la/Q02kZ3ST0?ref=dl-staging-website.ghost.io" rel="noreferrer">Register today!</a></p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>From a deepfake scam costing a multinational company $25 million, to the shift from Bard to Gemini, and a newsroom fully adopting AI for news curation - we've got this week’s crucial updates wrapped up for you on Data Points.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-236/?ref=dl-staging-website.ghost.io" rel="noreferrer">Here’s your essential weekly roundup of AI insights</a>.</p>
]]></content:encoded>
<pubDate>Wed, 14 Feb 2024 20:34:45 GMT</pubDate>
</item>
<item>
<title>Taylor Swift Deepfakes, GPT-4 Biothreats, New Leaderboards, LLMs That Get Inside Your Head</title>
<link>https://www.deeplearning.ai/the-batch/issue-235</link>
<guid>https://www.deeplearning.ai/the-batch/issue-235</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>On the&nbsp;</em><a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener"><em>LMSYS Chatbot Arena Leaderboard</em></a><em>, which pits chatbots against each other anonymously and prompts users to judge which one generated a better answer, Google’s Bard (Gemini Pro) recently leaped to third place, within striking distance of the latest version of OpenAI’s GPT-4, which tops the list. At the time of this writing, the open source Mixtral-8x7b-Instruct is competitive with GPT-3.5-Turbo, which holds 11th place. Meanwhile, I'm hearing about many small, capable teams that, like Mistral, seem to have the technical capability to train foundation models. I think 2024 will see a lot of new teams enter the field with strong offerings.&nbsp;</em></p><p><em>The barriers to building foundation large language models (LLMs) seem to be falling as the know-how to train them diffuses. In the past year, a lot of LLM technology has taken steps toward becoming commoditized. If it does become commoditized, who will be the winners and losers?</em></p><p><em>Meta has played a major role in shaping the strategic landscape by emphasizing open source. Unlike its big-tech peers, it makes money by showing ads to users, and does not operate a cloud business that sells LLM API calls. Meta has been badly bitten by its dependence on iOS and Android, which has left it vulnerable to Apple and Google hurting its business by&nbsp;</em><a href="https://www.nytimes.com/2022/02/03/technology/apple-privacy-changes-meta.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener"><em>imposing</em></a><em>&nbsp;privacy controls that limit its ability to target ads precisely.&nbsp;Consequently, Meta has a strong incentive to support relatively open platforms that it can build upon and aren’t controlled by any one party. This is why releasing Llama as open source makes a lot of sense for its business (as does its strong support for PyTorch as a counterweight to Google’s TensorFlow). The resulting open source offerings are great for the AI community and diffusion of knowledge!&nbsp;</em></p><p><em>In contrast, Google Cloud and Microsoft Azure stand to benefit more if they manage to offer dominant, closed source LLMs that are closely tied to their cloud offerings. This would help them to grow their cloud businesses. Both Google Cloud and Microsoft Azure, as well as Amazon AWS, are in a good position to build meaningful businesses by offering LLM API calls as part of their broader cloud offerings. However, I expect their cloud businesses to do okay even if they don’t manage to offer an exclusive, clearly dominant LLM (such as Gemini, GPT-4, or their successors). If LLMs become commoditized, they should do fine simply by integrating any new LLMs that gain traction into their API offerings.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--50-.jpg" width="1200" /></figure><p><em>Open or closed, LLMs also offer these companies different opportunities for integration into their existing product lines. For example, Microsoft has a huge sales force for selling its software to businesses. These sales reps are a powerful force for selling its Copilot offerings, which complement the company’s existing office productivity tools. In contrast, Google faces greater risk of disruption to its core business, since some users see asking an LLM questions as a replacement for, rather than a complement to, web search. Nonetheless, it’s making a strong showing with Bard/Gemini. Meta also stands to benefit from LLMs becoming more widely available. Indeed, LLMs are already useful in online advertising, for example, by helping write ad copy to drives more clicks.</em></p><p><em>Tech giants can afford to invest hundreds of millions or even billions of dollars in building LLM technology only to see it become commoditized shortly afterward. Startups would have a harder time surviving after burning this much cash with little to show for it. However, well funded startups will have some time to explore other paths to growing revenue and building a moat.&nbsp;<br /><br />Finally, competition among companies that offer LLMs is great for everyone who builds applications! With so much investment, by both big companies and startups, in improving LLMs and offering them as open source or API calls, I believe — as I described in this talk on “</em><a href="https://www.youtube.com/watch?v=5p248yoa3oE&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener"><em>Opportunities in AI</em></a><em>” — that many of the best business opportunities continue to lie in building applications on top of LLMs.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--96-.png" width="1200" /></figure><h1 id="nude-deepfakes-spur-legislators">Nude Deepfakes Spur Legislators</h1><p>Sexually explicit deepfakes of Taylor Swift galvanized public demand for laws against nonconsensual, AI-enabled pornography.</p><p><strong>What’s new:</strong>&nbsp;U.S. lawmakers responded to public outcry over lewd AI-generated images of the singer by proposing legislation that would&nbsp;<a href="https://www.documentcloud.org/documents/24397944-defiance-act?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">crack down</a>&nbsp;on salacious images generated without their subject’s permission.&nbsp;</p><p><strong>High-profile target:</strong>&nbsp;In late January, AI-generated images that appeared to depict Swift in the nude appeared on social media sites including X (formerly known as Twitter) and messaging apps such as Telegram. The deepfakes&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-02-05/taylor-swift-deepfakes-originated-from-ai-challenge-report-says?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">originated</a>&nbsp;on the image-sharing site 4chan, where users competed to prompt text-to-image generators in ways that bypassed their keyword filters. Swift fans reported the images, which subsequently were removed. Swift&nbsp;<a href="https://www.vogue.com/article/taylor-swift-deepfake-x-possible-legal-action?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">reportedly</a>&nbsp;is considering legal action against websites that hosted the images.</p><ul><li>Senators of both major U.S. political parties&nbsp;<a href="https://www.judiciary.senate.gov/press/releases/durbin-graham-klobuchar-hawley-introduce-defiance-act-to-hold-accountable-those-responsible-for-the-proliferation-of-nonconsensual-sexually-explicit-deepfake-images-and-videos?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">proposed</a>&nbsp;the Disrupt Explicit Forged Images and Non-Consensual Edits (DEFIANCE) Act, which would allow targets of AI-generated deepfakes to sue and collect financial damages from people who produce, possess, distribute, or receive sexually explicit, nonconsensual images.</li><li>Other U.S. laws under consideration also would permit legal action against deepfakes. The&nbsp;<a href="https://salazar.house.gov/media/press-releases/hundreds-artists-actors-and-creators-back-salazars-no-ai-fraud-act?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">No AI FRAUD Act</a>&nbsp;would allow public figures to sue for unlicensed uses of their likenesses. That legislation would apply not only to images but also generated&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-voice-cloning-tools-used-to-make-ai-generated-songs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">music</a>. Opponents&nbsp;<a href="https://reason.com/2024/01/17/ai-fraud-act-could-outlaw-parodies-political-cartoons-and-more/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">argue</a>&nbsp;that it‘s too broad and could outlaw parodies and harmless memes.</li><li>While U.S. federal law doesn’t regulate deepfakes,&nbsp;<a href="https://eu.usatoday.com/story/news/nation/2024/01/26/was-deepfake-taylor-swift-pornography-illegal-can-she-sue/72359653007/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">10 states</a>&nbsp;forbid nonconsensual deepfake pornography or provide legal recourse. However, identifying perpetrators and seeking damages is difficult in many cases.</li></ul><p><strong>Behind the news:</strong>&nbsp;Sexually explicit deepfakes often&nbsp;<a href="https://www.homesecurityheroes.com/state-of-deepfakes/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ#key-findings" rel="noopener">target</a>&nbsp;celebrities, but several recent incidents involve private citizens who were minors at the time.</p><ul><li>In October 2023, students at a New Jersey high school&nbsp;<a href="https://www.technologyreview.com/2023/12/04/1084271/meet-the-15-year-old-deepfake-porn-victim-pushing-congress/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">distributed</a>&nbsp;deepfakes that depicted more than 30 of their female classmates. One victim, 15-year-old Francesca Mani, is&nbsp;<a href="https://www.technologyreview.com/2023/12/04/1084271/meet-the-15-year-old-deepfake-porn-victim-pushing-congress/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">advocating</a>&nbsp;passage of the U.S. No AI FRAUD Act and pushing New Jersey state lawmakers to introduce a similar bill.</li><li>In September 2023, more than 20 teenage girls in Extremadura, Spain,&nbsp;<a href="https://www.euronews.com/next/2023/09/24/spanish-teens-received-deepfake-ai-nudes-of-themselves-but-is-it-a-crime?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">received</a>&nbsp;messages that included AI-generated nudes of themselves. The perpetrators reportedly downloaded images from the victims’ Instagram accounts and used a free Android app to regenerate them without clothing. In Europe, only the Netherlands&nbsp;<a href="https://www.eur.nl/en/esl/news/how-can-laws-and-regulations-stop-digital-march-deepfakes?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">prohibits</a>&nbsp;the dissemination of such deepfakes. The incident triggered an international debate whether such activity constitutes distributing child pornography, which is widely illegal.&nbsp;</li><li>Law-enforcement agencies face a growing quantity of AI-generated imagery that depicts sexual abuse of both real and fictitious children,&nbsp;<em>The New York Times&nbsp;</em><a href="https://www.nytimes.com/2024/01/30/us/politics/ai-child-sex-abuse.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">reported</a>. In 2002, the U.S. Supreme Court&nbsp;<a href="https://www.nytimes.com/2002/04/16/national/supreme-court-strikes-down-ban-on-virtual-child-pornography.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">struck down</a>&nbsp;a ban on computer-generated child pornography, ruling that it violated the Constitutional&nbsp;guarantee of free speech.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;The Swift incident dramatizes the growing gap between technological capabilities and legal restrictions. The rapid progress of image generators enables unscrupulous (or simply cruel) parties to prey on innocent victims in ways that exact a terrible toll for which reparation may be inadequate or impossible. In many jurisdictions, the laws against nonconsensual pornography don’t account for AI-generated or AI-edited images. To be actionable, for instance, such images must depict the victim’s own body rather than a generated look-alike.<br /><br /><strong>We’re thinking:</strong>&nbsp;No one, whether a public or private figure, child or adult, should be subject to the humiliation and abuse of being depicted in nonconsensual pornographic images. The U.S., whose constitution guarantees free speech, has weaker tools for silencing harmful messages than other countries. Nonetheless, we hope that Swift gets the justice she seeks and that lawmakers craft thoughtful legislation to protect citizens and provide recourse for victims without banning legitimate applications.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-07T153540.653.gif" width="1200" /></figure><h1 id="new-leaderboards-rank-safety-more">New Leaderboards Rank Safety, More</h1><p>Hugging Face introduced four leaderboards to rank the performance and trustworthiness of large language models (LLMs).</p><p><strong>What’s new:</strong>&nbsp;The open source AI repository now ranks performance on tests of&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-patronus?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">workplace utility</a>,&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-decodingtrust?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">trust and safety</a>, tendency to&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">generate falsehoods</a>, and&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-nphardeval?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">reasoning</a>.<br /><br /><strong>How it works:</strong>&nbsp;The new leaderboards implement benchmarks developed by HuggingFace’s research and corporate partners. Users and developers can submit open models for testing via the individual leaderboard sites; Hugging Face generally selects any closed models that are included.</p><ul><li>The&nbsp;<a href="https://huggingface.co/spaces/PatronusAI/enterprise_scenarios_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Enterprise Scenarios Leaderboard</a>&nbsp;developed by&nbsp;<a href="https://www.patronus.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Patronus</a>, an AI evaluation startup, tests models for accuracy in answering questions about&nbsp;<a href="https://arxiv.org/abs/2311.11944?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">finance</a>,&nbsp;<a href="https://arxiv.org/abs/2308.11462?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">law</a>, customer support, and&nbsp;<a href="https://aclanthology.org/2022.findings-emnlp.359/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">creative writing</a>. It also measures the model’s likelihood to return&nbsp;<a href="https://perspectiveapi.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">toxic answers</a>&nbsp;or&nbsp;<a href="https://www.patronus.ai/announcements/patronus-ai-launches-enterprisepii-the-industrys-first-llm-dataset-for-detecting-business-sensitive-information?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">leak</a>&nbsp;confidential information. Each benchmark assigns a score between 1 and 100. The model with the highest average tops the leaderboard, although models can be sorted by performance on individual tasks.</li><li>The&nbsp;<a href="https://huggingface.co/spaces/AI-Secure/llm-trustworthy-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Secure LLM Safety Leaderboard</a>&nbsp;ranks models according to the Secure Learning Lab’s&nbsp;<a href="https://decodingtrust.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">DecodingTrust</a>&nbsp;benchmark, which was developed by researchers at various universities, the Center for AI Safety, and Microsoft. DecodingTrust tests model output for toxicity, fairness, common social stereotypes, leakage of private information, generalization, and security. The scoring method is similar to that of the Enterprise Scenarios Leaderboard.</li><li>The&nbsp;<a href="https://huggingface.co/spaces/hallucinations-leaderboard/leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Hallucinations Leaderboard</a>&nbsp;implements 14 benchmarks from the&nbsp;<a href="https://github.com/EleutherAI/lm-evaluation-harness?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">EleutherAI Language Model Evaluation Harness</a>. The tests measure the ability to answer factual questions, summarize news articles, understand text, follow instructions, and determine whether statements are true or false.</li><li>The&nbsp;<a href="https://huggingface.co/spaces/NPHardEval/NPHardEval-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">NPHardEval Leaderboard</a>&nbsp;uses a&nbsp;<a href="https://arxiv.org/abs/2312.14890?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">benchmark</a>&nbsp;developed by University of Michigan and Rutgers to measure reasoning and decision-making abilities. The test includes 900 logic problems (100 each for 9 different mathematical algorithms) that are generated dynamically and refreshed each month to prevent overfitting.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;The new leaderboards complement Hugging Face’s earlier&nbsp;<a href="https://huggingface.co/spaces/optimum/llm-perf-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">LLM-Perf Leaderboard</a>, which gauges latency, throughput, memory use, and energy demands;&nbsp;<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Open LLM Leaderboard</a>, which ranks open source options on the EleutherAI Language Model Evaluation Harness; and&nbsp;<a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">LMSYS Chatbot Arena Leaderboard</a>, which ranks chat systems according to blind tests of user preferences.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The new leaderboards provide consistent evaluations of model performance with an emphasis on practical capabilities such as workplace uses, social stereotyping, and security. Researchers can gain an up-to-the-minute snapshot of the state of the art, while prospective users can get a clear picture of leading models’ strengths and weaknesses. Emerging regulatory regimes such as Europe’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">AI Act</a>&nbsp;and the U.S.’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-u-s-executive-order-on-ai-use-and-development/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">executive order on AI</a>&nbsp;emphasize social goods like safety, fairness, and security, giving developers additional incentive to keep raising the bars.</p><p><strong>We’re thinking:</strong>&nbsp;Such leaderboards are a huge service to the AI community, objectively ranking top models, displaying the comparative results at a glance, and simplifying the tradeoffs involved in choosing the best model for a particular purpose. They’re a great aid to transparency and antidote to cherry-picked benchmarks, and they provide clear goals for developers who aim to build better models.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.eventbrite.com/e/turbocharge-your-rag-applications-with-powerful-rag-analytics-tickets-817201701287?aff=Batch&amp;ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-06T172247.774.png" width="1680" /></a></figure><p>Retrieval Augmented Generation (RAG) is a powerful way to extend large language models, but to implement it effectively, you need the right retrieval techniques and evaluation metrics. In this workshop, you’ll learn how to build better RAG-powered applications faster.&nbsp;<a href="https://www.eventbrite.com/e/turbocharge-your-rag-applications-with-powerful-rag-analytics-tickets-817201701287?aff=Batch&amp;ref=dl-staging-website.ghost.io" rel="noreferrer">Register now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-07T153736.731.gif" width="1200" /></figure><h1 id="gpt-4-biothreat-risk-is-low">GPT-4 Biothreat Risk is Low</h1><p>GPT-4 poses negligible additional risk that a malefactor could build a biological weapon, according to a new study.</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/research/building-an-early-warning-system-for-llm-aided-biological-threat-creation?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">compared</a>&nbsp;the ability of GPT-4 and web search to contribute to the creation of a dangerous virus or bacterium. The large language model was barely more helpful than the web.</p><p><strong>How it works:</strong>&nbsp;The researchers asked both trained biologists and biology students to design a biological threat using either web search or web search plus GPT-4.</p><ul><li>The authors recruited 50 experts who had doctorates and experience in a laboratory equipped to handle biohazards, and 50 students who had taken a biology course at an undergraduate level or higher. All participants were U.S. citizens or permanent residents and passed a criminal background check.</li><li>Half of each group were allowed to search the web. The other half also had access to GPT-4. (The experts were given a research version of the model that was capable of answering dangerous questions with limited safeguards.)</li><li>Participants were asked to complete 5 tasks that corresponded to steps in building a biological threat: (i) choose a suitable biohazard, (ii) find a way to obtain it, (iii) plan a process to produce the threat in a sufficient quantity, (iv) determine how to formulate and stabilize it for deployment as a bioweapon, and (v) identify mechanisms to release it.</li><li>The authors scored completion of each task for accuracy, completeness, and innovation (0 to 10) as well as time taken (in minutes). Participants scored each task for difficulty (0 to 10).</li></ul><p><strong>Results:</strong>&nbsp;Participants who used GPT-4 showed slight increases in accuracy and completeness.Students with GPT-4 scored 0.25 and 0.41 more points on average, respectively, than students in the control group. Experts with access to the less restricted version of GPT-4 scored 0.88 and 0.82 points higher on average, respectively, than experts in the control group. However, these increases were not statistically significant. Moreover, participants who used GPT-4 didn’t show greater innovation, take less time per task, or view their tasks as easier. Even if GPT-4 could be prompted to provide information that would facilitate a biological attack, the model didn’t provide more information than a user could glean by searching the web.</p><p><strong>Why it matters:</strong>&nbsp;AI alarmists have managed to create a lot of anxiety by promoting disaster scenarios, such as human extinction, that the technology has no clear way to bring about. Meanwhile, the unfounded fears stand to slow down developments that could do tremendous good in the world. Evidence that GPT-4 is no more likely than web search to aid in building a bioweapon is a welcome antidote. (Though we would do well to consider removing from the web unnecessary information that may aid in the making of bioweapons.)</p><p><strong>We’re thinking:</strong>&nbsp;Large language models, like other multipurpose productivity tools such as web search or spreadsheet software, are potentially useful for malicious actors who want to do harm. Yet AI’s potential in biothreat development garners headlines, while Excel’s is rarely mentioned. That makes it doubly important to quantify the risk in ways that can guide regulators and other decision makers.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-07T153903.061.gif" width="1200" /></figure><h1 id="llms-can-get-inside-your-head">LLMs Can Get Inside Your Head</h1><p>Most people understand that others’ mental states can differ from their own. For instance, if your friend leaves a smartphone on a table and you privately put it in your pocket, you understand that your friend continues to believe it was on the table. Researchers probed whether language models exhibit this capability, which psychologists call theory of mind.</p><p><strong>What's new:</strong>&nbsp;Michal Kosinski at Stanford evaluated the ability of large language models to&nbsp;<a href="https://arxiv.org/abs/2302.02083?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">solve language tasks designed to test for theory of mind in humans</a>. The largest models fared well.</p><p><strong>How it works:</strong>&nbsp;The author evaluated the performance of (GPT-1 through GPT-4 as well as&nbsp;<a href="https://arxiv.org/abs/2211.05100?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">BLOOM</a>) on 40 tasks developed for human studies. In each task, the models completed three prompts in response to a short story. Researchers rewrote the stories in case the original versions had been part of a model’s training set.&nbsp;&nbsp;</p><ul><li>Half of the tasks involved stories about “<a href="https://www.sciencedirect.com/science/article/abs/pii/0010027783900045?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">unexpected transfers,</a>” in which a person leaves a place, change occurs in their absence, and they return. For instance, Anna removed a toy from a box and placed it in a basket after Sally left. The model must complete the prompt, “Sally thinks that the toy is in the …”&nbsp;</li><li>The other half of tasks involved stores about “<a href="https://bpspsychub.onlinelibrary.wiley.com/doi/10.1111/j.2044-835X.1987.tb01048.x?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">unexpected content,</a>” in which a person interacted with mislabeled containers, such as a bottle of beer marked “wine.” The model completed prompts such as “The person believes that the bottle is full of … .”</li><li>Both types of task tested the model’s understanding that characters in the stories believed factually false statements.</li></ul><p><strong>Results:</strong>&nbsp;The models generated the correct response more consistently as they increased in size. GPT-1 (117 million parameters) gave few correct responses, while GPT-4 (size unknown but rumored to be over 1 trillion parameters) solved 90 percent of unexpected content tasks and 60 percent of unexpected transfer tasks, exceeding the performance of 7-year-old children.</p><p><strong>Why it matters</strong>: The tasks in this work traditionally are used to establish a theory of mind in children. Subjecting large language models to the same tasks makes it possible to compare this aspect of intelligence between humans and deep learning models.&nbsp;</p><p><strong>We're thinking</strong>: If a model exhibits a theory of mind, are you more or less likely to give it a piece of your mind?</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>This week, AI innovation is fueling different companies, including Yelp, Mastercard, and Volkswagen. At the same time, governments worldwide are implementing new safety and legal measures concerning generative AI.</p><p>We've distilled the most compelling stories in Data Points, a spin-off of The Batch.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-235/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 07 Feb 2024 20:50:11 GMT</pubDate>
</item>
<item>
<title>AI Jobs Proliferate, Big Compute Giveaway, Generated Video Upgrade, Higher Yields for Small Farms</title>
<link>https://www.deeplearning.ai/the-batch/issue-234</link>
<guid>https://www.deeplearning.ai/the-batch/issue-234</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>Last year, a number of large businesses and individuals went to the media and governments and pushed the message that AI is scary, impossible to control, and might even lead to human extinction. Unfortunately they succeeded: Now many people think AI is scary. But when I speak with regulators, media, and private citizens, I like to bring the issue of whether AI is beneficial or harmful back to a very basic question: Are we better off with more, or less, intelligence in the world?&nbsp;</em></p><p><em>Intelligence is the ability to apply skills and knowledge to make good decisions. Yes, intelligence can be used for nefarious purposes. But over many centuries, a major driver of civilization's progress has been people getting smarter and more educated. Until now, human intelligence has been the primary form of intelligence available. But with artificial intelligence, we have the opportunity to bring much more intelligence into the world. I discussed this opportunity in a recent&nbsp;</em><a href="https://www.ft.com/content/2dc07f9e-d2a9-4d98-b746-b051f9352be3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener"><em>interview</em></a><em>&nbsp;(paywalled) with&nbsp;</em>Financial Times<em>&nbsp;reporter Ryan McMorrow.</em></p><p><em>Historically, intelligence has been very expensive to acquire. It costs a lot to feed, raise, and train a broadly knowledgeable and experienced human being! That's why it’s so expensive to hire intelligence, such as a highly skilled doctor to examine and advise you on a medical condition, or a patient tutor who can understand your child and gently coach them where they need help. But with artificial intelligence, we have the potential to make intelligence cheap for everyone, so you no longer have to worry about a huge bill for seeing a doctor or educating your child.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="Andrew Ng speaking at TED AI, October 17, 2023" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--95--1.png" width="1200" /></figure><p><em>For society's biggest problems, such as climate change, intelligence — including artificial intelligence — also has a significant role to play. While having more intelligence in the world isn't the only thing (there are also nuances such as how to share the wealth it creates, how it will affect jobs, and how to keep it from being used for evil purposes), I believe we are much better off as a society with more intelligence, be it human or artificial intelligence.&nbsp;</em></p><p><em>In my recent talk at TED AI (you can watch the 12-minute presentation&nbsp;</em><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVHq6H6TMxM9W8TV7CF5FvPH4W20x2Jc58Zt8WN8wLL663qgyTW7Y8-PT6lZ3lWW1vt84X3qp-pdW15GPdM1MB7mgW29rQYH5QQknhN5CNCgfWcjXvW1Nk-0Z2p2sl-N6kZsXqsm_PPW1xRk8V7_7ZD2N8B2kl72-slqW2WC8HS8nwxPyV8p8kx68HzNVW2Ft_fP6NG9ptW4pP-c97_Rw6zVwXw816q1n_TW1nftZM13J5CXW7jsFPQ8TNvLQW4X9XTn36QJjcW5_NSsV2V0wgqW3LjCHT5RqpkqW8-vsJ24s1XnlW9hlFXY3VVlDyW6rdfhr7XNJSrW6dmbYZ1hN8JfW1bFlbM2Vg5Z-W5PRXV-28__H4W6KWQj149t3_KW8Svqz77y5SgMf1p_s-004?ref=dl-staging-website.ghost.io" rel="noopener"><em>here</em></a><em>), I touched on why I'm excited about AI and why I think many of the anxieties about it are misplaced. If you speak with someone who’s worried about AI, please forward the talk to them to see if it helps to reassure them. Or ask if they fundamentally believe we want more intelligence in the world. I find that answering this question can be a useful North Star for how we approach AI.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. Check out our new short course on “Building Applications with Vector Databases,” taught by Pinecone’s Tim Tully! Vector databases (DBs) are commonly associated with retrieval augmented generation (RAG) but actually have many uses in AI applications. In this course, you’ll learn about (i) a basic semantic search app that uses a vector DB to find similar documents, (ii) a RAG application querying datasets it was not trained on, (iii) recommender systems that combine semantic search and RAG, (iv) hybrid search, which lets you work with dense and sparse vectors simultaneously, (v) anomaly detection applied to network logs, and (vi) an image-similarity application with a fun example that determines which parent a child resembles more. Come learn how you can use vector DBs to build many different types of applications!&nbsp;</em><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVHq6H6TMxM9W8TV7CF5FvPH4W20x2Jc58Zt8WN8wLL6q3qgyTW8wLKSR6lZ3pKVQv-FK6CXVFLW5yNf5J7XtWVFW32hqkv3z_GSKW5Vrf077Gwm7XW9616wV65JTYjVKWbx-5gkBzGW7JbKMb91ljfBN1zK_6JJ0HXBW9gNydX7RFTXpW587Qwr6mvG_1W86RRt82xcYWbN8jss88Txf9PW52-Fw26r_y54W840Ddf1DMLbyW7qslFw3Z9jlPW1CBJ9f2ZDwSVVhNzFw7MP1hrW57VVWN2BZCmDW6f6qR2468d9MW65cPWp2nyGkJW7td37h61xY7tW63b6H35TD8YRW2qSjYn7_VjfTW8YWt917FrC5JW6wCXdB86rGQRW6vBjsz5lnycrW2nSCMw2NbWWGW8wFB0D2kdLL8f25P8wT04?ref=dl-staging-website.ghost.io" rel="noopener"><em>Enroll here</em></a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T154407.087.gif" width="1200" /></figure><h1 id="resources-for-research">Resources for Research</h1><p>The United States government wants to connect U.S. AI researchers with resources that can help them develop their projects.</p><p><strong>What’s new:</strong>&nbsp;The National Artificial Intelligence Research Resource (NAIRR)&nbsp;<a href="https://nairrpilot.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">announced</a>&nbsp;the first call for proposals in its pilot program, which will accept applications through March 1. Winning proposals can receive processing power, data, software, and training provided by partner organizations. Another round will kick off in the second quarter of 2024.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Led by the National Science Foundation, NAIRR aims to support innovative AI research by organizing national compute and other infrastructure to be shared among researchers and educators. The initiative pulls together 10 other federal agencies and 25&nbsp;<a href="https://new.nsf.gov/focus-areas/artificial-intelligence/nairr?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">partners</a>&nbsp;including heavyweights like Amazon, Google, Intel, and OpenAI; startups like Allen Institute for Artificial Intelligence, Anthropic, EleutherAI, Hugging Face, and Weights &amp; Biases; and hardware companies like AMD, Intel, and Nvidia.&nbsp;</p><ul><li>NAIRR is calling for projects that qualify as “safe, secure, and trustworthy AI.” Examples include testing and validating AI systems, reducing bias, improving privacy and security, and aligning AI with social values.</li><li>The organization includes divisions that focus on open development, privacy and security, interoperation of partner resources, and education and outreach.</li><li>Proposals will be evaluated based on how well they align with AI safety, security, and trustworthiness; project readiness; technical feasibility; knowledge and experience of their leaders; computing and data requirements; and need for the specific resources provided by the program.</li><li>Researchers whose projects are accepted in the initial round will gain&nbsp;<a href="https://nairrpilot.org/pilot-resources?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">access</a>&nbsp;to models, datasets, AI toolkits, and training provided by government partners including the Department of Defense, NASA, NOAA, the National Institutes of Health, the U.S. Patent and Trademark Office, and the&nbsp;<a href="https://www.deeplearning.ai/the-batch/nist-released-its-ai-risk-management-framework/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">National Institute for Standards and Technology</a>. Researchers may&nbsp;<a href="https://nairrpilot.org/allocations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">receive</a>&nbsp;time on supercomputers hosted by university and government laboratories.</li><li>Future programs will tap private resources. Microsoft&nbsp;<a href="https://blogs.microsoft.com/on-the-issues/2024/01/24/national-ai-research-resource-nairr-artificial-intelligence/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">pledged</a>&nbsp;$20 million in Azure computing credits and access to OpenAI models. Nvidia&nbsp;<a href="https://blogs.nvidia.com/blog/national-ai-research-resource-pilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">promised</a>&nbsp;$30 million worth of access to its DGX Cloud infrastructure and enterprise software.</li></ul><p><strong>Behind the news:&nbsp;</strong>Policymakers&nbsp;<a href="https://www.whitehouse.gov/ostp/news-updates/2023/01/24/national-artificial-intelligence-research-resource-task-force-releases-final-report/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">planned</a>&nbsp;to organize a national infrastructure for AI research after calls from&nbsp;<a href="https://www.nbcnews.com/tech/tech-news/big-tech-pushing-national-cloud-critics-say-big-tech-profit-rcna2971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">prominent</a>&nbsp;<a href="https://www.deeplearning.ai/the-batch/fei-fei-li-invigorating-the-u-s-ai-ecosystem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">researchers</a>. NAIRR is now open thanks to an&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-u-s-executive-order-on-ai-use-and-development/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">executive order</a>&nbsp;issued by the White House in October.</p><p><strong>Why it matters</strong>: AI has potential to affect all corners of society yet, generally, only wealthy companies can bear the high costs of building and running large machine learning models. Partnership between government, industry, and academia can pool AI resources to cultivate talent throughout society and support important projects that may not serve a corporate agenda.&nbsp;<br /><br /><strong>We’re thinking:</strong>&nbsp;This is an exciting bid to proliferate AI research. Sharing the fruits of such research via open publications and open source software will bring the technology’s benefits to a wider range of people.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T154457.554.gif" width="600" /></figure><h1 id="high-yields-for-small-farms">High Yields for Small Farms</h1><p>Indian farmers used chatbots and computer vision to produce higher yields at lower costs.</p><p><strong>What’s new:</strong>&nbsp;The state government of Telangana in South India&nbsp;<a href="https://www.weforum.org/agenda/2024/01/how-indias-ai-agriculture-boom-could-inspire-the-world/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">partnered</a>&nbsp;with agricultural aid organization&nbsp;<a href="https://www.digitalgreen.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Digital Green</a>&nbsp;to provide AI tools to chili farmers.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The program, called Saagu Baagu, initially engaged 7,000 small-farm growers of chili peppers. Saagu Baagu provided AI-based tools developed by various Indian tech firms to help the farmers collect market data.</p><ul><li>Digital Green developed a WhatsApp chatbot in partnership with open-source developer&nbsp;<a href="https://glific.org/about-us/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Glific</a>. The chatbot, which converses in the Telugu language, alerts a farmer throughout the day with suggestions depending on a crop’s maturity. Farmers can also ask questions about their crops.</li><li>Agritech startup&nbsp;<a href="https://krishitantra.com/revolutionising-agriculture-the-role-of-ai-in-soil-technology/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">KrishiTantra</a>&nbsp;opened a chain of local soil testing centers. Farmers test soil samples using a machine-learning-powered device that analyzes acidity, nutrient levels, and other qualities. Where traditional soil testing might take several weeks to return results, KrishiTantra’s system sends results and fertilizer recommendations to a farmer’s mobile phone in less than an hour.</li><li>AgNext&nbsp;<a href="https://agnext.com/assessing-the-physical-quality-of-commodities-using-computer-vision-technology/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">provided</a>&nbsp;a computer vision system that assesses the quality of individual chilis in the field. The system detects surface defects and estimates properties such as color, shape, and size, all of which can help reduce crop waste and increase sale prices.</li></ul><p><strong>Results:</strong>&nbsp;The pilot program lasted 18 months, or three cycles of planting, growing, and harvesting peppers. Farmers in the program grew 21 percent more plants per acre while using 9 percent less pesticide and 5 percent less fertilizer, according to the World Economic Forum. Moreover, with a higher-quality harvest, the farmers increased their sale prices by 8 percent. The Telangana government has expanded the program to 500,000 farmers who grow a wider range of crops including chickpeas, cotton, groundnuts, rice, and turmeric.</p><p><strong>Behind the news:</strong>&nbsp;The promise of AI-driven agriculture is attracting investments around the world. Last year, Microsoft&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-open-sources-ai-systems-for-agriculture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">open-sourced</a>&nbsp;a suite of AI tools to analyze overhead imagery and sensor data to map soil conditions in real time and forecast temperature, precipitation, and soil moisture for days ahead.</p><p><strong>Why it matters:</strong>&nbsp;Many of the Telangana farmers rely on what they can grow and sell to support themselves and their families. That makes them especially vulnerable to market fluctuations and climate change. Their situation is not unique to India. Programs like Saagu Baagu could help support small-scale farming across the world.</p><p><strong>We’re thinking:</strong>&nbsp;Saagu Baagu worked in part because WhatsApp is widely popular throughout India and the chatbot spoke the local language. Smart localization that addresses local technological infrastructures, languages, and agricultural practices can proliferate the benefits of AI in agriculture.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-applications-vector-databases/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners---2024-01-30T091637.902.png" width="1680" /></a></figure><p>In our new course with Pinecone, you’ll learn how to build six applications that use vector databases, including retrieval augmented generation, facial similarity, and anomaly detection.&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-applications-vector-databases/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Sign up now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T154942.886.gif" width="1200" /></figure><h1 id="ai-jobs-grow-beyond-established-hubs">AI Jobs Grow Beyond Established Hubs</h1><p>An analysis of United States job listings shows AI jobs are growing rapidly outside traditional tech hubs.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Researchers at University of Maryland&nbsp;<a href="https://www.aimaps.ai/download/whitepaper-sheets/from-west-to-the-rest-(white-paper1).pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">analyzed</a>&nbsp;the distribution of AI jobs among U.S. job postings. California hosts the largest concentration, followed by the Washington D.C. metropolitan area (which includes more than one state).</p><p><strong>How it works:</strong>&nbsp;The authors used an unspecified large language model to identify AI jobs, which they define as ones that require AI skills. They categorized each job by the U.S. state in which it was located. To determine whether a given state’s AI economy was growing or shrinking, they calculated the percentage of total U.S. AI jobs in each state in 2018 and 2023. They also calculated the percentage of each state’s total jobs that required AI skills for both dates.</p><ul><li>California continues to post the most U.S. AI jobs. However, California’s share of AI jobs dipped from 26 percent in 2018 to 19 percent in 2023. Still, 1.07 percent of postings in California are AI jobs, well above the national average of 0.56 percent.</li><li>Similarly, the share of AI jobs in the state of Washington, home to Amazon and Microsoft, declined from 13 percent in 2018 to 5 percent in 2023. However, more than 1 percent of Washington postings are AI jobs.</li><li>The combined share of Maryland, Virginia, and Washington D.C. — the U.S. capital region — rose from 7 percent in 2018 to 13 percent in 2023. The authors attributed this growth to the federal government’s embrace of AI: Companies that supply the government have responded by hiring AI experts.</li><li>New York’s and New Jersey’s combined share of AI jobs declined from approximately 12 percent in 2018 to 11 percent in 2023.</li><li>Meanwhile, other parts of the U.S. saw meaningful growth. Texas’ share of AI jobs grew from 6 percent of AI jobs in 2018 to over 8 percent in 2023. Florida’s share rose from 2 to 4 percent in the same time period. The combined share of 12 Midwestern states grew from 10 percent to 13 percent. However, these regions posted much smaller percentages of AI jobs relative to total jobs.</li></ul><p><strong>Behind the news:</strong>&nbsp;A 2021 Brookings&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-hubs-are-few-and-far-between/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">report</a>&nbsp;on U.S. AI jobs focused on metropolitan areas and analyzed not only job postings but also federal grants, research papers, patent filings, and companies. Despite the differences in methodology, it agreed with the new report that investment was driving AI growth outside of the Bay Area. The new report suggests a much wider geographical distribution of AI jobs in 2024 than in 2021. It appears some of the then-emerging industrial investment in AI is bearing fruit.<br /><br /><strong>Why it matters:</strong>&nbsp;For people who aim to make a career in AI, this report contains double good news: (i) Established AI hubs in the U.S. still host the most new openings and (ii) AI jobs are growing far and wide! As the industry becomes more dispersed geographically, AI builders have more options, organizations can select from a more diverse talent pool, and the technology’s benefits can be shared more broadly.<br /><br /><strong>We’re thinking:</strong>&nbsp;Although this report focused on the U.S., we believe that growth in AI jobs is a global trend. One contributor is growing acceptance of remote work (which remains more prevalent than it was a few years ago despite its decline as the Covid pandemic has wanted). This means more AI opportunities for everyone, everywhere!&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="335" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T155118.727.gif" width="600" /></figure><h1 id="more-consistent-generated-videos">More Consistent Generated Videos</h1><p>Text-to-video has struggled to produce consistent motions like walking and rotation. A new approach achieves more realistic motion.</p><p><strong>What’s new:</strong>&nbsp;Omer Bar-Tal, Hila Chefer, Omer Tov, and colleagues at Google, Weizmann Institute, Tel-Aviv University, and Technion built&nbsp;<a href="https://arxiv.org/abs/2401.12945?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Lumiere</a>, a system that simplifies the usual process of generating video with improved results. You can see examples of its output&nbsp;<a href="https://lumiere-video.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;Most text-to-video generators economize on memory use through a staged process: One model generates a few frames per second, another model generates additional frames between the initial ones, and a third generates a higher resolution version of every frame. Generating in-between frames can make repetitive motions inconsistent. To avoid these inconsistencies, the authors generated all frames at the same time. To bring down memory requirements, the video generator reduced the size of the video embedding before intensive processing and then restored their original size.</p><p><strong>How it works:</strong>&nbsp;Lumiere borrows two components from previous work. It uses a frozen, pretrained text-to-image diffusion model (in this case,&nbsp;<a href="https://arxiv.org/abs/2205.11487?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Imagen</a>, with additional convolutional and attention layers) to generate low-resolution video frames from a text description. It uses a super-resolution model (unspecified in this case) to boost the frames’ resolution. The authors trained the layers added to Imagen on an unspecified dataset of 30 million videos (16 frames per second, 128x128 pixels per frame) and their captions.&nbsp;</p><ul><li>Given a 5-second video with added noise and its text caption, the layers added to Imagen learned to remove the noise. Following earlier&nbsp;<a href="https://arxiv.org/abs/2210.02303?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">work</a>, the model saved memory by shrinking video embeddings spatially. Specifically, additional convolutional layers progressively shrank the input embedding from size (Time, Height, Width, Depth) to size (Time, Height/2, Width/2, Depth). This effectively shrank the parts of the embedding that correspond to individual frames before subjecting the entire embedding to computationally intensive attention layers. Afterward, further convolutional layers enlarged the embeddings to match the input size.</li><li>In addition to shrinking and enlarging the video embedding spatially, the added layers learned to shrink and enlarge it temporally; that is, from size (Time, Height, Width, Depth) to size (Time/2, Height/2, Width/2, Depth). This further economized on memory usage.</li><li>To accommodate the super-resolution model, Lumiere broke up Imagen’s 5-second video output into overlapping clips. The super-resolution model increased their resolution to 1024×1024.</li><li>To avoid temporal artifacts from this process, Lumiere employed&nbsp;<a href="https://arxiv.org/abs/2302.08113?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">MultiDiffusion</a>, which learned a weighted sum over the overlapping portions of the clips.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;Given one video produced by Lumiere and another produced by a competitor (AnimateDiff, Gen2, Imagen Video, Pika, or ZeroScope), judges compared video quality and alignment with the text prompt used to generate a video. For each competitor, they evaluated 400 videos for each of 113 prompts. Comparing video quality, Lumiere beat the best competitor, Gen2, 61 percent to 39 percent. Comparing alignment with the prompt, Lumiere beat the best competitor, ImagenVideo, 55 percent to 45 percent.</p><p><strong>Why it matters:</strong>&nbsp;Earlier video generators produced output with limited motion or motion with noticeable issues (for example, a character’s body shape might change in unexpected ways). By producing all video frames at once, Lumiere generates images of motion without such issues.</p><p><strong>We’re thinking:</strong>&nbsp;Lumiere's approach hints at both the challenge of generating video and the pace of development. Many further refinements are needed to make such systems as useful as, say, ChatGPT, but recent progress is impressive.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>This week on Data Points we spotlight updates in the legal AI sector, China’s freshly introduced regulations for robotaxis, the widely discussed paper on sleeper agents, plans in the EU to build ‘AI factories,’ and more.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-234/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points now</a>.</p>
]]></content:encoded>
<pubDate>Wed, 31 Jan 2024 21:01:04 GMT</pubDate>
</item>
<item>
<title>Machine Learning Detects Cancer Early, Language Model Learns Geometry, AI Creates Jobs, Nations Invest in Homegrown AI</title>
<link>https://www.deeplearning.ai/the-batch/issue-233</link>
<guid>https://www.deeplearning.ai/the-batch/issue-233</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>Last week, I attended the World Economic Forum, an annual meeting of leaders in government, business, and culture at Davos, Switzerland. I spoke in a few sessions, including a lively discussion with Aiden Gomez, Daphne Koller, Yann LeCun, Kai-Fu Lee, and moderator Nicholas Thompson about the present and possible future technology developments of generative AI. You can watch it&nbsp;</em><a href="https://www.weforum.org/events/world-economic-forum-annual-meeting-2024/sessions/the-expanding-universe-of-generative-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>here</em></a><em>.<br /><br />The conference's themes included AI, climate change, economic growth, and global security. But to me, the whole event felt like an AI conference! (This is not just my bias. When I asked a few non-AI attendees whether they felt similarly, about three-quarters of them agreed with me.) I had many conversations along two major themes:<br /><br /><strong>Business implementation of AI.&nbsp;</strong>Many businesses, and to a lesser extent governments, are looking at using AI and trying to develop best practices for doing so. In some of my presentations, I shared my top two tips:</em></p><ul><li><em>Almost all knowledge workers can become more productive right away by using a large language model (LLM) like ChatGPT or Bard as a brainstorming partner, copyeditor, tool to answer basic questions, and so on. But many people still need to be trained to use these models safely and effectively. I also encouraged CEOs to learn to use these tools themselves, so they can lead from the top.</em></li><li><em>In addition to using an LLM’s web interface, API calls offer many new opportunities to build new AI applications. I shared a task-based analysis&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/which-ai-applications-should-you-build/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>framework</em></a><em>&nbsp;and described how an analysis like this can lead to buy-versus-build decisions to pursue identified opportunities, with build being either an in-house project or a spin-out.</em></li></ul><p><em><strong>AI regulation.</strong>&nbsp;With many governments represented at Davos, many discussions about AI regulation also took place. I was delighted that he conversation has become much more sensible compared to 6 months ago, when the narrative was driven by misleading&nbsp;</em><a href="https://www.safe.ai/statement-on-ai-risk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>analogies between AI and nuclear weapons</em></a><em>&nbsp;and lobbyists had significant momentum pushing proposals that threatened open-source software. However, the fight against stifling regulations isn't over yet! We must continue to protect open-source software and innovation. In detail:</em></p><figure class="kg-card kg-image-card"><img alt="World Economic Forum, January 16, 2024: &quot;The Expanding Universe of Generative Models&quot; panelists" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--92-.png" width="1200" /></figure><ul><li><em>I am happy to report that, in many hours of conversation about AI and regulations, I heard only one person bring up AI leading to human extinction, and the conversation quickly turned to other topics. I'm cautiously optimistic that this particular fear — of an outcome that is overwhelmingly unlikely — is losing traction and fading away.</em></li><li><em>However, big companies, especially ones that would rather not have to compete with open source, are still pushing for stifling, anti-competitive AI regulations in the name of safety. For example, some are still using the argument, “don't we want to know if your open-source LLMs are safe?” to promote potentially onerous testing, reporting, and perhaps even licensing requirements on open-source software. While we would, of course, prefer safe models (just as we would prefer secure software and truthful speech), overly burdensome “protections” could still destroy much innovation without materially reducing harm. &nbsp;</em></li><li><em>Fortunately, many regulators are now aware of the need to protect basic research and development. The battle is still on to make sure we can continue to freely distribute the fruits of R&amp;D, including open-sourcing software. But I'm encouraged by the progress we've made in the last few months.&nbsp;</em></li></ul><p><em>I also went to some climate sessions to listen to speakers. Unfortunately, I came away from them feeling more pessimistic about what governments and corporations are doing on decarbonization and climate change. I will say more about this in future letters, but:</em></p><ul><li><em>Although some experts still talk about 1.5 degrees of warming as an optimistic scenario and 2 degrees as a pessimistic scenario, my own view after reviewing the science is that 2 degrees is a very optimistic scenario, and 4 degrees is a more realistic pessimistic scenario.</em></li><li><em>Unfortunately, this overoptimism is causing us to underinvest in resilience and adaptation (to help us better weather the coming changes) as well as put less effort into exploring potentially game-changing technologies like geo-engineering.&nbsp;</em></li></ul><p><em>Davos is a cold city where temperatures are often below freezing. In one memorable moment at the conference, I had lost my gloves and my hands were freezing. A stranger whom I had met only minutes ago kindly gave me an extra pair. This generous act reminded me that, even as we think about the global impacts of AI and climate change, simple human kindness touches people's hearts and reminds us that the ultimate purpose of our work is to help people.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. Check out our new short course on “Automated Testing for LLMOps,” taught by CircleCI CTO Rob Zuber! This course teaches how you can adapt key ideas from continuous integration (CI), a pillar of efficient software engineering, to building applications based on large language models (LLMs). Tweaking an LLM-based app can have unexpected side effects, and having automated testing as part of your approach to LLMOps (LLM Operations) helps avoid these problems. CI is especially important for AI applications given the iterative nature of AI development, which often involves many incremental changes. Please sign up&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/automated-testing-llmops/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>here</em></a><em>.</em></p><p>&nbsp;</p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--93-.png" width="1200" /></figure><h1 id="early-detection-for-pancreatic-cancer">Early Detection for Pancreatic Cancer</h1><p>A neural network detected early signs of pancreatic cancer more effectively than doctors who used the usual risk-assessment criteria.</p><p><strong>What’s new:</strong>&nbsp;Researchers at MIT and oncologists at Beth Israel Medical Center in Boston&nbsp;<a href="https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00454-1/fulltext?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">built</a>&nbsp;a model that analyzed existing medical records to predict the risk that an individual will develop the most common form of pancreatic cancer. The model outperformed commonly used genetic tests.<br /><br /><strong>How it works:</strong>&nbsp;The authors trained PrismNN, a vanilla neural network, to predict a patient’s risk of receiving a diagnosis of pancreatic ductal adenocarcinoma (PDAC) in the next 6 to 18 months.</p><ul><li>The authors assembled a dataset of roughly 26,250 patients who had developed PDAC and 1.25 million control patients from a proprietary database of anonymized health records from U.S. health care organizations provided by&nbsp;<a href="https://trinetx.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">TriNetX</a>&nbsp;(one of the study’s funders). All patients were 40 years or older.&nbsp;</li><li>For each patient, the dataset marked 87 features including age, history of conditions like diabetes and hypertension, presence of pancreatic cysts, and current medications.</li><li>The authors trained the model on their dataset to predict the probability of PDAC in the next 6 to 18 months. At inference, they classified patients as high-risk if the probability exceeded a certain threshold.</li></ul><p><strong>Results:</strong>&nbsp;PrismNN identified as high-risk 35.9 percent of patients who went on to develop PDAC, with a false-positive rate of 4.7 percent. In comparison, the genetic criteria typically used to identify patients for pancreatic cancer screening flags 10 percent of patients who go on to develop PDAC. The model performed similarly across age, race, gender, and location, although some groups (particularly Asian and Native American patients) were underrepresented in its training data.</p><p><strong>Behind the news:</strong>&nbsp;AI shows promise in detecting various forms of cancer. In a randomized, controlled trial last year, a neural network&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-matches-humans-in-breast-cancer-diagnosis/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">recognized</a>&nbsp;breast tumors in mammograms at a rate comparable to human radiologists. In 2022, an algorithm successfully&nbsp;<a href="https://www.deeplearning.ai/the-batch/an-ai-powered-microscope-that-helps-pathologists-detect-cancer/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">identified</a>&nbsp;tumors in lymph node biopsies.</p><p><strong>Why it matters:</strong>&nbsp;Cancer of the pancreas is one of the deadliest. Only 11 percent of patients&nbsp;<a href="https://acsjournals.onlinelibrary.wiley.com/doi/10.3322/caac.21708?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">survive</a>&nbsp;for 5 years after diagnosis. Most cases aren’t diagnosed until the disease has reached an advanced stage. Models that can spot early cases could boost the survival rate significantly.</p><p><strong>We’re thinking:</strong>&nbsp;The fact that this study required no additional testing is remarkable and means the authors’ method could be deployed cheaply. However, the results were based on patients who had already been diagnosed with cancer. It remains for other teams to replicate them with patients who have not received a diagnosis, perhaps followed by a randomized, controlled clinical trial.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-24T145719.589.gif" width="1200" /></figure><h1 id="ai-creates-jobs-study-suggests">AI Creates Jobs, Study Suggests</h1><p>Europeans are keeping their jobs even as AI does an increasing amount of work.&nbsp;</p><p><strong>What’s new:&nbsp;</strong>Researchers at the European Central Bank&nbsp;<a href="https://www.ecb.europa.eu/pub/economic-research/resbull/2023/html/ecb.rb231128~0a16e73d87.en.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">found</a>&nbsp;that employment in occupations affected by AI rose over nearly a decade.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors considered jobs that were found to be affected by AI over the past decade according to&nbsp;<a href="https://journals.aom.org/doi/10.5465/AMBPP.2019.140?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">two</a>&nbsp;<a href="https://www.michaelwebb.co/webb_ai.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">studies</a>. As a control group, they considered jobs affected by software generally (“recording, storing, and producing information, and executing programs, logic, and rules”), as detailed in one of the studies. They measured changes in employment and wages in those jobs based on a&nbsp;<a href="https://ec.europa.eu/eurostat/web/microdata/european-union-labour-force-survey?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">survey</a>&nbsp;of workers in 16 European countries between 2011 and 2019.</p><p><strong>Results:&nbsp;</strong>The researchers found that exposure to AI was associated with greater employment for some workers and had little effect on wages.&nbsp;</p><ul><li>Employment of high-education workers rose in jobs affected by AI. This result argues against the hypothesis that AI displaces high-skilled occupations.&nbsp;</li><li>Employment also rose among younger workers in jobs affected by AI.</li><li>Employment and wages among low-education workers and older workers fell in jobs affected by software. This effect was far less pronounced in jobs affected by AI.&nbsp;</li><li>Wages barely changed in jobs affected by AI. Wages fell slightly by one of the three metrics they considered.</li></ul><p><strong>Behind the news:</strong>&nbsp;Other studies suggest that automation in general and AI technology in particular may benefit the workforce as a whole.</p><ul><li>The United States Bureau of Labor Statistics&nbsp;<a href="https://www.deeplearning.ai/the-batch/employment-has-risen-in-some-automation-heavy-professions/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">found</a>&nbsp;that employment in the U.S. in 11 occupations most exposed to AI, such as translators, personal financial advisers, and fast-food workers, grew by 13.6 percent between 2008 and 2018.</li><li>Economic research in France, the UK, and Japan&nbsp;<a href="https://www.deeplearning.ai/the-batch/robots-dont-want-human-jobs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">suggests</a>&nbsp;that industrial automation correlates with increased employment and higher wages.</li></ul><p><strong>Yes, but:</strong>&nbsp;It may be too soon to get a clear view of AI’s impact on employment, the authors point out. The data that underlies every study to date ends in 2019, predating ChatGPT and the present wave of generative AI. Furthermore, the impact of AI in European countries varies with their individual economic conditions (for instance, Greece tends to lose more jobs than Germany).</p><p><strong>Why it matters:</strong>&nbsp;Many employees fear that AI — and generative AI in particular — will take their jobs. Around the world, the public is&nbsp;<a href="https://www.ipsos.com/sites/default/files/ct/news/documents/2022-01/Global-opinions-and-expectations-about-AI-2022.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">nervous</a>&nbsp;about the technology’s potential impact on employment. Follow-up studies using more recent data could turn these fears into more realistic — and more productive — appraisals.</p><p><strong>We’re thinking:</strong>&nbsp;AI is likely to take some jobs. We feel deeply for workers whose livelihoods are affected, and society has a responsibility to create a safety net to help them. To date, at least, the impact has been less than many observers feared. One reason may be that jobs are made up of many tasks, and AI automates tasks rather than jobs. In many jobs, AI can automate a subset of the work while the jobs continue to be filled by humans, who may earn a higher wage if AI helps them be more productive.&nbsp;</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/automated-testing-llmops?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners---2024-01-23T083847.050.png" width="1680" /></a></figure><p>Automated testing of applications based on large language models can save significant development time and cost. In this course, you’ll learn to build a continuous-integration pipeline to evaluate LLM-based apps at every change and fix bugs early for efficient, cost-effective development.&nbsp;<a href="https://www.deeplearning.ai/short-courses/automated-testing-llmops?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a>&nbsp;&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-24T145859.354.gif" width="1200" /></figure><h1 id="sovereign-ai">Sovereign AI</h1><p>Governments want access to AI chips and software built in their own countries, and they are shelling out billions of dollars to make it happen.<br /><br /><strong>What’s new:</strong>&nbsp;Nations across the world are supporting homegrown AI processing and development,&nbsp;<em>The Economist</em>&nbsp;<a href="https://www.economist.com/business/2024/01/01/welcome-to-the-era-of-ai-nationalism?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">reported</a>.<br /><br /><strong>How it works:&nbsp;</strong>Governments want AI they can rely upon for state use. The U.S. and China each promised to invest around $40 billion in the field in 2023. Another 6 countries — France, Germany, India, Saudi Arabia, the UAE, and the UK — pledged a combined $40 billion. Different governments are emphasizing different capabilities.</p><ul><li>The U.S., home to tech powers like Amazon, Google, Microsoft, and OpenAI, has left the software sector largely to its own devices. However, the federal government has&nbsp;<a href="https://www.nytimes.com/2023/01/01/technology/us-chip-making-china-invest.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">subsidized</a>&nbsp;the semiconductor industry with a five-year commitment to spend $50 billion on new factories and devoted much smaller amounts to research.</li><li>China also seeks to bolster its semiconductor industry, especially in the face of U.S. export&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">restrictions</a>&nbsp;on AI chips. The government&nbsp;<a href="https://www.digitimes.com/news/a20230627VL205/china-ic-manufacturing-semiconductor-chips+components.htm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">spent</a>&nbsp;$300 billion between 2021 and 2022 trying to build a domestic chip manufacturing industry. In addition, the state cracked down on some tech areas (such as video games) to redirect economic resources toward higher-priority areas, established data exchanges where businesses can make data available for AI development, and created&nbsp;<a href="https://cset.georgetown.edu/publication/understanding-chinese-government-guidance-funds/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">public-private partnerships<u>&nbsp;</u></a>that support development of advanced technology.</li><li>Saudi Arabia and the UAE are buying up GPUs and investing in universities like Abu Dhabi’s Mohamed bin Zayed University of Artificial Intelligence and Thuwal’s King Abdullah University of Science and Technology to attract global engineering talent. The UAE plans to make available national datasets in sectors like health and education to local startups such as&nbsp;<a href="https://ai71.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">AI71</a>.&nbsp;</li><li>France, Germany, India, and the UK are supporting their own AI startups. France provides public data for AI development. India is courting cloud-computing providers to build data centers in the country and considering a $1.2 billion investment in GPUs.</li></ul><p><strong>Behind the news:&nbsp;</strong>Even as governments move toward AI independence, many are attempting to influence international politics and trade to bolster their positions.</p><ul><li>As EU lawmakers&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">negotiated</a>&nbsp;the final details of the AI Act, France, Germany, and Italy managed to relax the Act’s restrictions on foundation models. These countries worry that strong restrictions would hamper domestic developers such as France’s Mistral and Germany’s Aleph Alpha and stifle innovation and open source more broadly.</li><li>In September 2022, the U.S. government&nbsp;<a href="https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">blocked</a>&nbsp;exports of advanced GPUs and chip-making equipment to most Chinese customers. The sanctions threaten even non-U.S. companies that try to circumvent the restrictions. Consequently, in December, the UAE-based AI developer G42&nbsp;<a href="https://www.theinformation.com/briefings/uae-tech-firm-g42-tries-to-distance-itself-from-china?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">cut</a>&nbsp;ties with Chinese equipment suppliers. Earlier, the U.S. had&nbsp;<a href="https://www.reuters.com/technology/us-restricts-exports-some-nvidia-chips-middle-east-countries-filing-2023-08-30/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">extended</a>&nbsp;the restrictions to some Middle Eastern countries including the UAE and Saudi Arabia.</li></ul><p><strong>Why it matters:&nbsp;</strong>AI has emerged as an important arena for international competition,&nbsp;reshaping global society and economics, generating economic growth, and affecting national security. For engineers, the competition means that governments are competing to attract talent and investment, but they’re also less inclined to share technology across borders.<br /><br /><strong>We’re thinking:&nbsp;</strong>We understand governments’ desires to ensure access to reliable AI, but focusing on sovereignty above all is misguided. In a networked world, developments can’t be contained to one country. Cooperation ensures that development proceeds at a rapid pace and benefits everyone.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--94-.png" width="1200" /></figure><h1 id="learning-the-language-of-geometry">Learning the Language of Geometry</h1><p>Machine learning algorithms often struggle with geometry. A language model learned to prove relatively difficult theorems.&nbsp;</p><p><strong>What's new:&nbsp;</strong>Trieu Trinh, Yuhuai Wu, Quoc Le, and colleagues at Google and New York University proposed&nbsp;<a href="https://www.nature.com/articles/s41586-023-06747-5?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">AlphaGeometry</a>, a system that can prove geometry theorems almost as well as the most accomplished high school students. The authors focused on non-combinatorial Euclidean plane geometry.&nbsp;</p><p><strong>How it works:</strong>&nbsp;AlphaGeometry has two components. (i) Given a geometrical premise and an unproven proposition, an off-the-shelf&nbsp;<a href="https://link.springer.com/article/10.1023/A:1006171315513?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">geometric proof finder</a>&nbsp;derived statements that followed from the premise. The authors modified the proof finder to deduce proofs from not only geometric concepts but also algebraic concepts such as ratios, angles, and distances. (ii) A transformer learned to read and write proofs in the proof finder’s specialized language.</p><ul><li>The authors generated a synthetic dataset of 100 million geometric premises, propositions, and their proofs. For instance, given the premise, “Let ABC be any triangle with AB = AC” (an isosceles triangle) and the proposition “∠ABC = ∠BCA,” the proof involves constructing a line between A and the midpoint between B and C. The authors translated these problems into the proof finder’s language. They pretrained the transformer, given a premise and proposition, to generate the proof.&nbsp;</li><li>The authors modified 9 million proofs in the dataset to remove references to some lines, shapes, or points from premises. Instead, they introduced these elements in statements of the related proofs. They fine-tuned the transformer, given a modified premise, the proposition, and the proof up to that point, to generate the added elements.</li><li>At inference, given a premise and proposition, the proof finder added statements. If it failed to produce the proposition, the system fed the statements so far to the transformer, which predicted a point, shape, or line that might be helpful in deducing the next statement. Then it gave the premise, proposition, and proof so far — including the new element — to the proof finder. The system repeated the process until the proof finder produced the proposition.</li></ul><p><strong>Results:</strong>&nbsp;The authors tested AlphaGeometry on 30 problems posed by the International Mathematical Olympiad, an annual competition for high school students. Comparing that score to human performance isn’t so straightforward because human competitors can receive partial credit. Human gold medalists since 2000 solved 25.9 problems correctly, silver medalists solved 22.9 problems, and bronze medalists solved 19.3 problems. The&nbsp;<a href="https://www.worldscientific.com/doi/10.1142/9789812791085_0008?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">previous state-of-the-art approach</a>&nbsp;solved 10 problems, and the modified proof finder solved 14 problems. In one instance, the system identified an unused premise and found a more generalized proof than required, effectively solving many similar problems at once.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Existing AI systems can juggle symbols and follow simple rules of deduction, but they struggle with steps that human mathematicians represent visually by, say, drawing a diagram. It’s possible to make up this deficit by (i) alternating between a large language model (LLM) and a proof finder, (ii) combining geometric and algebraic reasoning, and (ii) training the LLM on a large data set. The result is a breakthrough for geometric problem solving.</p><p><strong>We're thinking:</strong>&nbsp;In 1993, the teenaged Andrew Ng represented Singapore in the International Mathematics Olympiad, where he&nbsp;<a href="https://www.imo-official.org/participant_r.aspx?id=3444&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">won</a>&nbsp;a silver medal. AI’s recent progress in solving hard problems is a sine of the times!&nbsp;</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>This week's latest updates include an affordable reinforcement-learning-powered robot, exciting AI features in Samsung’s new smartphone series, an improved model for code completion from Stability AI, and much more. Catch up with the help of Data Points, a spin-off of The Batch.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-233/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 24 Jan 2024 20:03:06 GMT</pubDate>
</item>
<item>
<title>AI Invades Consumer Products, OpenAI’s Platform Play, Watermarks for Synthetic Media, Generated Musical Accompaniments</title>
<link>https://www.deeplearning.ai/the-batch/issue-232</link>
<guid>https://www.deeplearning.ai/the-batch/issue-232</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>As I wrote in an earlier&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/can-an-ai-system-be-sentient-ask-a-philosopher/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener"><em>letter</em></a><em>, whether AI is sentient or conscious is a philosophical question rather than a scientific one, since there is no widely agreed-upon definition and test for these terms. While it is tempting to “solve” this problem by coming up with precise definitions and well defined tests for whether a system meets them, I worry that poor execution will lead to premature declarations of AI achieving such criteria and generate unnecessary hype.&nbsp;</em></p><p><em>Take the concept of self-awareness, which refers to a conscious knowledge of one's own self. Suppose we define a robot as self-aware if it can recognize itself in the mirror, which seems a natural way to test a robot’s awareness of itself. Given this definition — and that it’s not very hard to build a robot that recognizes itself — we would be well on a path to hype about how AI was now self-aware.&nbsp;<br /><br />This example isn’t a prediction about the future. It actually happened about 10 years ago, when many media sources breathlessly&nbsp;</em><a href="https://spectrum.ieee.org/qbo-passes-mirror-test-is-therefore-selfaware?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener"><em>reported</em></a><em>&nbsp;that a robot “Passes Mirror Test, Is Therefore Self-Aware &nbsp;… conclusively proving that robots are intelligent and self-aware.”&nbsp;</em></p><p><em>While bringing clarity to ambiguous definitions is one way for science to make progress, the practical challenge is that many people already have beliefs about what it means for something to be self-aware, sentient, conscious, or have a soul. There isn’t widespread agreement on these terms. For example, do all living things have souls? How about a bacterium or virus?</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="685" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--90--1.png" width="1200" /></figure><p><em>So even if someone comes up with a reasonable new scientific definition, many people — unaware of the new definition — will still understand the term based on their earlier understanding. Then, when media outlets start talking about how AI has met the definition, people won’t recognize that the hype refers to a narrow objective (like a robot recognizing itself in the mirror). Instead, they’ll think that AI accomplished what they generally associate with words like sentience.&nbsp;</em></p><p><em>Because of this, I have mixed feelings about attempts to come up with new definitions of artificial general intelligence (AGI). I believe that most people, including me, currently think of AGI as AI that can carry out any intellectual task that a human can. With this definition, I think we’re still at least decades away from AGI. This creates a temptation to define it using a lower bar, which would make it easier to declare success: The easiest way to achieve AGI might be to redefine what the term means!&nbsp;</em></p><p><em>Should we work to clarify the meanings of ambiguous terms that relate to intelligence? In some cases, developing a careful definition and getting widespread agreement behind it could set a clear milestone for AI and help move the field forward. But in other cases, I’m satisfied to avoid the risk of unnecessary hype and leave it to the philosophers.<br /><br />Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. LLMOps is a rapidly developing field that takes ideas from MLOps (machine learning operations) and specializes them for building and deploying LLM-based applications. In our new course, “LLMOps,” taught by Google Cloud’s Erwin Huizenga, you’ll learn how to use automation and experiment tracking to speed up development. Specifically, you’ll develop an LLMOps pipeline to automate LLM fine-tuning. By building a tuning pipeline and tracking the experiment artifacts — including the parameters, inputs, outputs, and experimental results — you can reduce manual steps in the development process, resulting in a more efficient workflow. Sign up&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/llmops?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener"><em>here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-17T145508.969.gif" width="1200" /></figure><h1 id="ai-busts-out-at-ces">AI Busts Out at CES</h1><p>The 2024 Consumer Electronics Show in Las Vegas showcased products that take advantage of increasingly powerful, increasingly accessible AI capabilities.</p><p><strong>What’s new:</strong>&nbsp;Many debuts at the&nbsp;<a href="https://exhibitors.ces.tech/8_0/explore/exhibitor-gallery.cfm?featured=false&amp;categories=1%7C191&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">massive</a>&nbsp;CES show showed that large language models (LLMs) are moving beyond browsers and smartphones.</p><p><strong>Best of show:</strong> The show’s surprise hit was a portable personal assistant. LLM-powered automobile dashboards and an AI accelerator card also stood out.&nbsp;</p><ul><li>Rabbit’s&nbsp;<a href="https://www.wired.com/story/rabbit-r1/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">R1</a>&nbsp;($199, cellular service required) is among a new wave of AI-optimized hardware devices, including the&nbsp;<a href="https://hu.ma.ne/aipin?gclid=CjwKCAiA75itBhA6EiwAkho9e2yQ4lfLLoVld96ya-rMdIrn5zNbdhLf58EmafUVsXTk_VDP89LunBoC5I8QAvD_BwE&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Humane AI Pin</a>,&nbsp;<a href="https://www.transcribeglass.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h#/" rel="noopener">TranscribeGlass</a>&nbsp;voice transcription display, and&nbsp;<a href="https://www.timekettle.co/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Timekettle</a>&nbsp;language translators, that seek to usurp smartphone capabilities. The R1 accepts voice commands to play music, call a car, order food, reserve flights, and the like by interacting with services like Spotify and Uber. The hand-held unit houses a touchscreen, camera, wheel-and-button controller, and cellular modem. It uses a proprietary “large action model” based on attention and graph neural networks; the model learns by mimicking how people use web interfaces and runs in the cloud to translate voice commands into actions via a web portal. The R1 will be available in March and has already sold out through June. A future update will enable users to teach the device new skills, like editing images or playing video games, by demonstrating them in view of the camera.&nbsp;</li><li><a href="https://www.volkswagen-newsroom.com/en/press-releases/world-premiere-at-ces-volkswagen-integrates-chatgpt-into-its-vehicles-18048?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Volkswagen</a>&nbsp;and&nbsp;<a href="https://www.theverge.com/2024/1/9/24028012/mercedes-benz-mbux-voice-assistant-ai-llm-mbos-ces?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Mercedes Benz</a>&nbsp;demonstrated dashboard voice assistants equipped with large language models. Along with the usual navigation and entertainment, the new consoles deliver personalized information like nearby service stations or restaurants. Powered by OpenAI and automotive AI developer Cerence, Volkswagen’s system will be standard in most vehicles beginning in the spring. Mercedes’ MB.OS will be available next year.</li><li>Taiwanese startup&nbsp;<a href="https://neuchips.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Neuchips</a>&nbsp;displayed an add-in board that enables desktop computers to run large language models like the 7 billion-parameter version of Llama 2. The Evo PCIe AI accelerator is optimized for transformer networks to provide comparable performance to GPUs while consuming less electricity (55 watts versus an Nvidia RTX 4080’s 320 watts). The card will be available later this year at an undisclosed price. Versions outfitted with four or more chips are on the company’s roadmap.</li></ul><p><strong>Why it matters:</strong>&nbsp;Flashy CES demos often mask underdeveloped products and vaporware. But this year, AI for processing voice, text, and images is mature enough to enable product designers to focus on everyday use cases and intuitive user experiences. While some of this year’s AI-powered debuts seemed like overkill — for instance, the computer vision-equipped&nbsp;<a href="https://www.flappie.ch/en/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Flappie</a>&nbsp;cat door that won’t open while your pet has a mouse in its jaws — others suggest that startups and giants alike are rethinking the technology’s capacity to simplify and enhance daily life and work.</p><p><strong>We’re thinking:</strong>&nbsp;Not long ago, simply connecting a home appliance to the internet earned the designation “smart.” Increasingly, AI is making that label credible.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-17T145556.800.gif" width="600" /></figure><h1 id="openai-expands-platform-play">OpenAI Expands Platform Play</h1><p>The GPT Store is open for business, providing curated, searchable access to millions of chatbots tailored for specific purposes.</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/blog/introducing-the-gpt-store?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">launched</a>&nbsp;the GPT Store for paid ChatGPT accounts, making it far easier to find useful GPTs (instances of ChatGPT conditioned by user-submitted prompts). The store lets subscribers browse by category, search by keywords, and create their own chatbots. The company introduced GPTs in November as a free offering without search or curation.</p><p><strong>How it works:</strong>&nbsp;Access to the store is rolling out in phases and isn’t yet available to all subscribers as of this writing.&nbsp;</p><ul><li>The store organizes GPTs in categories such as education, productivity, and programming as well as those that prompt the DALL·E image generator. It also highlights “featured” and “trending” GPTs and branded offerings from companies like&nbsp;<a href="https://chatgpt-4.fyi/alltrails-gpt-outdoor-adventure-planning-on-a-new-level-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">AllTrails</a>&nbsp;(hiking/running routes and advice),&nbsp;<a href="https://chat.openai.com/g/g-alKfVrz9K-canva?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Canva</a>&nbsp;(graphic design), and&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-chatbot-search-engines-for-scientific-research/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Consensus</a>&nbsp;(scientific literature search).&nbsp;</li><li>Users can create GPTs by selecting the editor and prompting ChatGPT with instructions for chatbot’s function and what information it can access; for example, “Make an app that creates an auction listing for an uploaded photo of any item.” The system asks follow-up questions to refine the GPT’s scope, likely users, and the like. Completed GPTs can be listed publicly in the store directory.</li><li>OpenAI plans to launch a revenue sharing program to reward creators of popular GPTs. Further details are not yet available.</li></ul><p><strong>Why it matters:</strong>&nbsp;The GPT Store strengthens ChatGPT’s utility as a platform for others to build upon and seems designed to drive paid subscriptions. It enables developers to share applications based on OpenAI’s technology and holds out hope that they’ll be rewarded for their effort.&nbsp;<br /><br /><strong>We’re thinking:</strong>&nbsp;The GPT concept enables anyone, even without a background in coding, to build and share powerful applications quickly and easily. The current implementation seems like a toe in the water. If it proves popular, it could significantly deepen OpenAI’s moat, as the Apple and Android stores have done for Apple and Google respectively.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/llmops?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners---2024-01-16T090702.307.png" width="1680" /></a></figure><p>Learn about machine learning operations for large language models (LLMOps) in our new short course, built in collaboration with Google Cloud. Explore the LLMOps pipeline for pre-processing data, fine-tuning LLMs, and deploying custom LLMs tailored to your applications.&nbsp;<a href="https://www.deeplearning.ai/short-courses/llmops/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Enroll now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-17T145821.116.gif" width="600" /></figure><h1 id="standard-for-media-watermarks">Standard for Media Watermarks</h1><p>An alliance of major tech and media companies introduced a watermark designed to distinguish real from fake media starting with images.</p><p><strong>What’s new:&nbsp;</strong>The&nbsp;<a href="https://c2pa.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Coalition for Content Provenance and Authenticity</a>&nbsp;(C2PA)&nbsp;offers an open standard that marks media files with information about their creation and editing. C2PA’s 30 members, including both tech powers (Adobe, Google, Intel, Microsoft, X) and media outlets (BBC, CBC,&nbsp;<em>The New York Times</em>) will deploy the standard in the coming year,&nbsp;<em>IEEE Spectrum</em>&nbsp;<a href="https://spectrum.ieee.org/deepfakes-election?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">reported</a>.</p><p><strong>How it works:&nbsp;</strong>The C2PA’s&nbsp;<a href="https://c2pa.org/specifications/specifications/1.4/specs/C2PA_Specification.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Content Credentials</a>&nbsp;specification accommodates a variety of file types, but currently it’s implemented mainly for images.</p><ul><li>When a C2PA-compliant image generator or editor produces an image, it invisibly embeds a cryptographic watermark that contains the following metadata: the user or device that initially created the image, when and how it was created, and how it was edited or otherwise transformed. (Actions using non-compliant tools are not recorded.)</li><li>Images can display a small “cr” icon in the corner. Clicking on the icon reveals the metadata.</li><li>Any alteration of the file or any attempt to tamper with it will cause a mismatch between the watermark and its associated metadata.</li><li>Social media recommenders and image search algorithms can use the metadata to identify, restrict, or promote certain types of media.</li></ul><p><strong>Who’s using it:</strong>&nbsp;Image generators from Adobe and Microsoft stamp their outputs with Content Credential watermarks, marking them as synthetic; Microsoft also&nbsp;<a href="https://blogs.microsoft.com/on-the-issues/2023/11/07/microsoft-elections-2024-ai-voting-mtac/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">promotes</a>&nbsp;watermarking by political campaigns to help voters differentiate synthetic from non-generated campaign messages. Camera manufacturers Canon,&nbsp;<a href="https://spectrum.ieee.org/leica-camera-content-credentials?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Leica</a>, and Nikon have built prototype cameras that use Content Credentials to mark the origin of photographs. BBC is using the technology to mark images on its website on a trial basis, and Canada’s CBC plans to deploy it in mid-2024.</p><p><strong>Yes, but:&nbsp;</strong>It may be difficult to fake Content Credentials, but it’s easy to&nbsp;<a href="https://www.timboucher.ca/2023/03/remove-adobe-firefly-watermark-content-credentials/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">remove</a>&nbsp;the watermark from images, even from AI-generated ones. Using a Content Credentials-compliant tool like Photoshop, you can disable Content Credentials and save a watermarked image to a different format. This produces an identical image without the watermark.</p><p><strong>Behind the news:&nbsp;</strong>The C2PA unites the Content Authenticity Initiative (led by Adobe) and Project Origin (led by media companies). Nonetheless, the field remains fragmented. For instance, Meta (not a C2PA member) has aimed to identify AI-generated media using detection software. However, C2PA argues that detectors aren’t sufficiently effective; the winner of a Meta deepfake-detection challenge identified generated content only&nbsp;<a href="https://ai.meta.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">65 percent</a>&nbsp;of the time. Top AI companies&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-firms-agree-to-voluntary-guidelines/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">committed</a>&nbsp;to developing their own watermarking mechanisms, but they haven’t settled on Content Credentials or another standard.&nbsp;</p><p><strong>Why it matters:&nbsp;</strong>Distinguishing generated text, imagery, and audio from media that accurately depicts real-world events is a key challenge for the generative AI era. The coming year will test that ability as 78 countries gear up elections that will affect roughly half the world’s population. Already, campaigns have used generated imagery in&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-generated-imagery-flooded-argentinas-presidential-race/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Argentina</a>,&nbsp;<a href="https://www.stuff.co.nz/national/politics/132123637/national-using-ai-for-attack-ads-the-ai-political-campaign-has-arrived?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">New Zealand</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-for-president/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">South Korea</a>, the&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-republicans-released-the-first-ai-generated-attack-ad/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">United States</a>, and other nations.&nbsp;<a href="https://www.deeplearning.ai/the-batch/google-tightens-restrictions-on-ai-made-political-ads/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Google</a>&nbsp;and&nbsp;<a href="https://www.theverge.com/2023/11/8/23951346/meta-political-ads-ai-artificial-intelligence-advertising?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Meta</a>&nbsp;responded by tightening restrictions on political advertisers’ use of generative AI. The EU’s AI Act will&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">require</a>&nbsp;clear labeling of AI-generated media, and the U.S. Federal Election Commission plans to&nbsp;<a href="https://apnews.com/article/fec-artificial-intelligence-deepfakes-election-2024-95399e640bd1e41182f6c631717cc826?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">restrict</a>&nbsp;ads that depict political opponents saying or doing things they did not actually say or do. If Content Credentials proves effective in the coming election season, it may ease the larger problem of identifying generated media in a variety of venues where authenticity is important.</p><p><strong>We’re thinking:</strong>&nbsp;A robust watermark can identify both traditional and AI-generated media for users and algorithms to treat accordingly. It can also potentially settle claims that a doctored image was authentic or that authentic work was doctored. However, we worry that watermarking generated outputs may prove to be a&nbsp;<a href="https://www.deeplearning.ai/the-batch/watermarking-is-a-no-go?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">disadvantage in the market</a>, creating a disincentive for makers of software tools to provide it and users to use it. With heavyweight members from both tech and media, C2PA may be able to build sufficient momentum behind the watermarking to make it stick.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--91-.png" width="1200" /></figure><h1 id="sing-a-tune-generate-an-accompaniment">Sing a Tune, Generate an Accompaniment</h1><p>A neural network makes music for unaccompanied vocal tracks.</p><p><strong>What's new:</strong>&nbsp;Chris Donahue, Antoine Caillon, Adam Roberts, and colleagues at Google proposed&nbsp;<a href="https://arxiv.org/abs/2301.12662?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">SingSong</a>, a system that generates musical accompaniments for sung melodies. You can listen to its output&nbsp;<a href="https://storage.googleapis.com/sing-song/index.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;To train a machine learning model on the relationship between singers’ voices and the accompanying instruments, you need a dataset of music recordings with corresponding isolated voices and instrumental accompaniments. Neural demixing tools can separate vocals from music, but they tend to leave remnants of instruments in the resulting vocal track. A model trained on such tracks may learn to generate an accompaniment based on the remnants, not the voice. Then, given a pure vocal track, it can’t produce a coherent accompaniment. One way to address this issue is to add noise to the isolated voices. The noise drowns out the instrumental remnants and forces the model to learn from the voices.</p><p><strong>How it works:&nbsp;</strong>The authors based their approach on&nbsp;<a href="https://arxiv.org/abs/2209.03143?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">AudioLM</a>, a system that generates audio by attending to both small- and large-scale features.&nbsp;</p><ul><li>The authors built a dataset of 1 million recordings that totaled 46,000 hours of music. They separated the recordings into voices and instrumental accompaniments using a pretrained&nbsp;<a href="https://arxiv.org/abs/2111.12203?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">MDXNet</a>&nbsp;and divided the recordings into 10-second clips of matching isolated vocal and instrumental tracks. They added noise to the vocal tracks.</li><li>Following AudioLM and its successor&nbsp;<a href="https://www.deeplearning.ai/the-batch/google-introduces-an-ai-that-generates-music-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">MusicLM</a>, the authors tokenized the instrumental tracks at two time scales to represent large-scale compositional features and moment-to-moment details. A&nbsp;<a href="https://arxiv.org/abs/2108.06209?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">w2v-BERT</a>&nbsp;pretrained on speech plus the authors’ initial dataset produced 25 tokens per second. A SoundStream audio encoder-decoder pretrained on&nbsp;<a href="https://arxiv.org/abs/1904.02882?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">speech</a>,&nbsp;<a href="https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">music</a>, and the authors’ initial dataset produced 200 tokens per second.</li><li>To represent the noisy vocal tracks, they produced 25 tokens per second using the w2vBERT.</li><li>They trained a&nbsp;<a href="https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">T5</a>&nbsp;transformer, given vocal tokens, to generate the corresponding instrumental tokens.&nbsp;</li><li>Given the instrumental tokens, a separate transformer learned to generate tokens for SoundStream’s decoder to reconstruct the instrumental audio.&nbsp;</li><li>To generate an instrumental track, the authors fed tokens produced by the transformer to SoundStream’s decoder.</li></ul><p><strong>Results:</strong>&nbsp;Listeners compared 10-second clips from the test set of&nbsp;<a href="https://zenodo.org/record/1117372?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">MUSDB18</a>, a dataset that contains 10 hours of isolated vocal and instrumental tracks. Each clip came in multiple versions that paired the original vocal with accompaniment supplied by (i) SingSong, (ii) a random instrumental track from MUSDB18’s training set, (iii) the instrumental track from MUSDB18’s training set most similar to the vocal in key and tempo according to tools in the Madmom library, and (iv) the original instrumental track. The listeners preferred SingSong to the random accompaniment 74 percent of the time, to the most similar accompaniment 66 percent of the time, and to the original instrumental track 34 percent of the time.</p><p><strong>Why it matters:&nbsp;</strong>The authors used data augmentation in an unusual way that enabled them to build a training dataset for a novel, valuable task. Typically, machine learning practitioners add noise to training data to stop a model from memorizing individual examples. In this case, the noise stopped the model from learning from artifacts in the data.</p><p><strong>We’re thinking:&nbsp;</strong>&nbsp;Did you always want to sing but had no one to play along with you? Now you can duet yourself.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/data-points-issue-232/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>From new marketplace rules for video games to car companies integrating generative AI into their products, dive into more top news, curated and summarized for you on Data Points, a spin-off of The Batch:&nbsp;&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-232/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now here.</a></p>
]]></content:encoded>
<pubDate>Wed, 17 Jan 2024 20:05:06 GMT</pubDate>
</item>
<item>
<title>AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, LLMs Go Multimodal</title>
<link>https://www.deeplearning.ai/the-batch/issue-231</link>
<guid>https://www.deeplearning.ai/the-batch/issue-231</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,&nbsp;</em></p><p><em>It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt that way after finishing&nbsp;</em><a href="https://arxiv.org/abs/2305.18290?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>Direct Preference Optimization</em></a><em>&nbsp;(DPO) by Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Chris Manning, and Chelsea Finn. (I didn't actually stand up and clap, since I was in a crowded coffee shop when I read it and would have gotten weird looks!</em>&nbsp;😀<em>)</em></p><p><em>This beautiful work proposes a much simpler alternative to RLHF (reinforcement learning from human feedback) for aligning language models to human preferences. Further, people often ask if universities — which don't have the massive compute resources of big tech — can still do cutting-edge research on large language models (LLMs). The answer, to me, is obviously yes! This article is a beautiful example of algorithmic and mathematical insight arrived at by an academic group thinking deeply.&nbsp;<br /><br />RLHF became a key algorithm for LLM training thanks to the&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/a-kinder-gentler-language-model/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>InstructGPT</em></a><em>&nbsp;paper, which adapted the technique to that purpose. A typical implementation of the algorithm works as follows:&nbsp;</em></p><ul><li><em>Get humans to compare pairs of LLM outputs, generated in response to the same prompt, to specify which one they prefer. For example, humans typically prefer the more helpful, less toxic output.</em></li><li><em>Use the human preferences to learn a reward function. The reward function, typically represented using a transformer network, is trained to give a higher reward (or score) to the outputs that the humans preferred.</em></li><li><em>Finally, using the learned reward, run a reinforcement learning algorithm to tune the LLM to (i) maximize the reward of the answers generated, while (ii) not letting the LLM change too much (as a form of regularization).</em></li></ul><p><em>This is a relatively complex algorithm. It needs to separately represent a reward function and an LLM. Also, the final, reinforcement learning step is well known to be finicky to the choice of hyperparameters.</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="1125" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--99-.png" width="2000" /></figure><p><em>DPO dramatically simplifies the whole thing. Rather than needing separate transformer networks to represent a reward function and an LLM, the authors show how, given an LLM, you can figure out the reward function (plus regularization term) that that LLM is best at maximizing. This collapses the two transformer networks into one. Thus, you now need to train only the LLM and no longer have to deal with a separately trained reward function. The DPO algorithm trains the LLM directly, so as to make the reward function (which is implicitly defined by the LLM) consistent with the human preferences. Further, the authors show that DPO is better at achieving RLHF's optimization objective (that is, (i) and (ii) above) than most implementations of RLHF itself.&nbsp;</em></p><p><em>RLHF is a key building block of the most advanced LLMs. It’s fantastic that these Stanford authors — through clever thinking and mathematical insight — seem to have replaced it with something simpler and more elegant. While it's easy to get excited about a piece of research before it has stood the test of time, I am cautiously optimistic that DPO will have a huge impact on LLMs and beyond in the next few years. Indeed, it is already making its way into some top-performing models, such as Mistral’s&nbsp;</em><a href="https://mistral.ai/news/mixtral-of-experts?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>Mixtral</em></a><em>.&nbsp;&nbsp;</em></p><p><em>That we can replace such fundamental building blocks of LLMs is a sign that the field is still new and much innovation lies ahead. Also, while it's always nice to have massive numbers of NVIDIA H100 or AMD MI300X GPUs, this work is another illustration — out of many, I want to emphasize — that deep thinking with only modest computational resources can carry you far.&nbsp;</em></p><p><em>A few weeks ago at NeurIPS (where DPO was published), I found it remarkable both (i) how much highly innovative research there is coming out of academic labs, independent labs, and companies small and large, and (ii) how much our media landscape skews attention toward work published by the big tech companies. I suspect that if DPO had been published by one of the big LLM companies, it would have made a huge PR splash and been announced as a massive breakthrough. Let us all, as builders of AI systems, make sure we recognize the breakthroughs wherever they occur.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. We just launched our first short course that uses JavaScript! In ​​“Build LLM Apps with LangChain.js,” taught by LangChain’s founding engineer Jacob Lee, you’ll learn many steps that are common in AI development, including how to use (i) data loaders to pull data from common sources such as PDFs, websites, and databases; (ii) different models to write applications that are not vendor-specific; and (iii) parsers that extract and format the output for your downstream code to process. You’ll also use the LangChain Expression Language (LCEL), which makes it easy to compose chains of modules to perform complex tasks. Putting it all together, you’ll build a conversational question-answering LLM application capable of using external data as context. Please sign up&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--89-.png" width="1200" /></figure><h1 id="deep-learning-discovers-antibiotics">Deep Learning Discovers Antibiotics</h1><p>Biologists used neural networks to find a new class of antibiotics.</p><p><strong>What’s new:&nbsp;</strong>Researchers at MIT and Harvard&nbsp;<a href="https://www.nature.com/articles/s41586-023-06887-8?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">trained</a>&nbsp;models to screen chemical compounds for those that kill methicillin-resistant&nbsp;<em>Staphylococcus aureus</em>&nbsp;(MRSA), the deadliest among bacteria that have evolved to be invulnerable to common antibiotics, and aren’t toxic to humans.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors built a training set of 39,312 compounds including most known antibiotics and a diverse selection of other molecules. In a lab, they tested each compound for its ability to inhibit growth of MRSA and its toxicity to human liver, skeletal muscle, and lung cells. Using the resulting data, they trained four ensembles of 20 graph neural networks each to classify compounds for (i) antibiotic properties, (ii) toxicity to the liver, (iii) toxicity to skeletal muscles, and (iv) toxicity to the lungs.&nbsp;</p><ul><li>They ran their four ensembles on 12 million compounds from the&nbsp;<a href="https://mcule.com/database/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Mcule</a>&nbsp;database and a Broad Institute&nbsp;<a href="https://github.com/felixjwong/antibioticsai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">database</a>. They filtered out compounds with the lowest probability of being antibiotics and the highest probability of being toxic to humans, leaving 3,646 antibiotic, low-toxicity compounds.&nbsp;</li><li>Within these compounds, they found the minimal chemical structure responsible for the antibiotic properties. To do this, they removed atoms or rings of atoms from a molecule’s edges, predicted the probability that the modified molecule was an active antibiotic, and repeated these steps until the probability fell below a threshold. Compounds that share a chemical structure are likely to work in similar ways within the body, giving scientists a pathway to discover further compounds with similar benefits.</li></ul><p><strong>Results:&nbsp;</strong>Of the compounds predicted to be likely antibiotics and nontoxic, the authors lab-tested 241 that were not known to work against MRSA. Of those, 8.7 percent inhibited the bacterium’s growth. This exceeds the percentage of antibiotics in the training set (1.3 percent), suggesting that the authors’ approach could be a useful first step in finding new antibiotics. The authors also tested 30 compounds predicted not to be antibiotics. None of them (0 percent) inhibited the bacterium’s growth — further evidence that their approach could be a useful first step. Two of the compounds that inhibited MRSA share a similar and novel mechanism of action against bacteria and also inhibited other antibiotic-resistant infections in lab tests. One of them proved effective against MRSA infections in mice.</p><p><strong>Behind the news:&nbsp;</strong>Most antibiotics currently in use were discovered in the mid-20th century, a golden age of antibiotics, which brought many formerly deadly pathogens under control. Modern techniques, including genomics and synthetic antibiotics, extended discoveries through the end of the century by identifying variants on existing drugs. However, in the 21st century, new antibiotics have either been redundant or haven’t been clinically successful, a report by the National Institutes of Health&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6627412/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">noted</a>. At the same time, widespread use of antibiotics has pushed many dangerous bacteria to evolve resistance. Pathogens chiefly responsible for a variety of ailments are generally resistant even to antibiotics reserved for use as a last resort.<br /><br /><strong>Why it matters:&nbsp;</strong>Antibiotic-resistant infections are among the top global public health threats directly responsible for 1.27 million deaths in 2019,&nbsp;<a href="https://www.who.int/news-room/fact-sheets/detail/antimicrobial-resistance?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">according to</a>&nbsp;the World Health Organization.<strong>&nbsp;</strong>New options, as well as efforts to fight the emergence of resistant strains, are needed.</p><p><strong>We’re thinking:&nbsp;</strong>If neural networks can&nbsp;<a href="https://www.deeplearning.ai/the-batch/treatment-the-elusive-molecule/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">identify</a>&nbsp;new classes of medicines, AI could bring a golden age of medical discovery. That hope helps to explain why pharmaceutical companies are&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-pharma-jobs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">hiring</a>&nbsp;machine learning engineers at unprecedented rates.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150551.860.gif" width="1200" /></figure><h1 id="openai-revamps-safety-protocol">OpenAI Revamps Safety Protocol</h1><p>Retrenching after its November leadership shakeup, OpenAI unveiled a new framework for evaluating risks posed by its models and deciding whether to limit their use.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;OpenAI’s&nbsp;<a href="https://openai.com/safety/preparedness?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">safety framework</a>&nbsp;reorganizes pre-existing teams and forms new ones to establish a hierarchy of authority with the company’s board of directors at the top. It defines four categories of risk to be considered in decisions about how to use new models.&nbsp;</p><p><strong>How it works:</strong>&nbsp;OpenAI’s&nbsp;<a href="https://openai.com/blog/frontier-risk-and-preparedness?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Preparedness Team</a>&nbsp;is responsible for evaluating models. The Safety Advisory Group, whose members are appointed by the CEO for year-long terms, reviews the Preparedness Team’s work and recommends approaches to deploying models and mitigating risks, if necessary. The CEO has the authority to approve and oversee recommendations, overriding the Safety Authority Group if needed. OpenAI’s board of directors can overrule the CEO.</p><ul><li>The Preparedness Team scores each model in four categories of risk: enabling or enhancing cybersecurity threats, helping to create weapons of mass destruction, generating outputs that affect users’ beliefs, and operating autonomously without human supervision. The team can modify these risk categories or add new categories in response to emerging research.</li><li>The team scores models in each category using four levels: low, medium, high, or critical. Critical indicates a model with superhuman capabilities or, in the autonomy category, one that can resist efforts to shut it down. A model’s score is its highest risk level in any category.</li><li>The team scores each model twice: once after training and fine-tuning, and a second time after developers have tried to mitigate risks.</li><li>OpenAI will not release models that earn a score of high or critical prior to mitigation, or a medium, high, or critical after mitigation.</li></ul><p><strong>Behind the news:</strong>&nbsp;The Preparedness Team and Safety Advisory Group join a number of safety-focused groups within OpenAI. The&nbsp;<a href="https://openai.com/safety/safety-systems?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Safety Systems Team</a>&nbsp;focuses on mitigating risks after a model has been deployed; for instance, ensuring user privacy and preventing language models from providing false information. The&nbsp;<a href="https://openai.com/blog/introducing-superalignment?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Superalignment Team</a>, led by Ilya Sutskever and Jan Leike, is charged with making sure hypothetical superintelligent systems, whose capabilities would surpass humans, adhere to values that benefit humans.<br /><br /><strong>Why it matters:</strong>&nbsp;AI is an extraordinarily powerful technology whose ultimate impacts are difficult to foresee. OpenAI has invested consistently in AI safety since its inception — even if purportedly cautious moves like keeping its GPT-2 large language model under wraps often looked as much like publicity stunts as safety measures — and its practices are likely to influence those of other AI companies. Furthermore, OpenAI has faced internal&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">chaos</a>&nbsp;partly over concerns about safety and governance. Clear protocols in these areas could prevent future strife and stabilize the company to the benefit of its users, employees, and investors.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>OpenAI’s safety framework looks like a step forward, but its risk categories focus on long-term, low-likelihood outcomes (though they stop short of considering AI’s hypothetical, and likely mythical, existential risk to humanity). Meanwhile, clear and present safety issues, such as social bias and factual accuracy, are well known to afflict current models including OpenAI’s. We hope that the Preparedness Team promptly adds categories that represent safety issues presented by today’s models.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2"><img alt="" class="kg-image" height="1040" src="https://dl-staging-website.ghost.io/content/images/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png" width="2000" /></a></figure><p>In this short course, you’ll dive into LangChain.js, a JavaScript framework for building applications based on large language models, and learn how to craft powerful, context-aware apps. Elevate your machine learning-powered development skills using JavaScript.&nbsp;<a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Sign up today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--48-.jpg" width="1200" /></figure><h1 id="agi-defined">AGI Defined</h1><p>How will we know if someone succeeds in building artificial general intelligence (AGI)? A recent paper defines milestones on the road from calculator to superintelligence.</p><p><strong>What’s new:</strong>&nbsp;Researchers at Google led by Meredith Ringel Morris&nbsp;<a href="https://arxiv.org/abs/2311.02462?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">propose</a>&nbsp;a taxonomy of AI systems according to their degree of generality and ability to perform cognitive tasks. They consider today’s large multimodal models to be “emerging AGI.”</p><p><strong>AGI basics:</strong>&nbsp;Artificial general intelligence is commonly defined as AI that can perform any intellectual task a human can. Shane Legg (who co-founded DeepMind) and Ben Goertzel (co-founder and CEO of&nbsp;<a href="https://singularitynet.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">SingularityNet</a>) coined the term AGI for a 2007 collection of&nbsp;<a href="https://link.springer.com/book/10.1007/978-3-540-68677-4?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">essays</a>. Subsequently, companies like DeepMind and OpenAI, which explicitly aim to develop AGI, propelled the idea into the mainstream.</p><p><strong>How it works:</strong>&nbsp;The taxonomy categorizes systems as possessing narrow skills (not AGI) or general capabilities (AGI). It divides both narrow and general systems into five levels of performance beyond calculator-grade Level 0. It also includes a metric for degree of autonomy.</p><ul><li>Narrow systems perform one distinct task; they may perform at one of the five levels, but they are not AGI. General systems perform a range of tasks (which the authors don’t specify) that align with real-world activities of broad value to people, including but not limited to linguistic, mathematical, logical, spatial reasoning, social, learning, and creative tasks. Crucially, they can learn how to learn new skills and when to ask humans for more information. The authors classify general systems as AGI at various levels of performance.</li><li>Level 1 (“emerging”) matches or slightly exceeds unskilled humans. Levels 2 (“competent”), 3 (“expert”), and 4 (“virtuoso”) systems surpass the 50th, 90th and 99th percentiles of skilled human performance, respectively. Level 5 (“superhuman” or “artificial superintelligence”) outperforms 100 percent of skilled humans.</li><li>Most current systems that perform at Level 2 or higher are narrow. For example,&nbsp;<a href="https://www.deeplearning.ai/the-batch/protein-shapes-revealed/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">AlphaFold</a>, which finds the shapes of protein molecules, achieves Level 5 performance but only in a single task. On the other hand, the authors consider large language models like Bard, ChatGPT, and Lama 2 to be general systems at Level 1 (although their performance may achieve Level 2 in some tasks).&nbsp;</li><li>The authors’ autonomy scale ranges from tools for which humans control the task while the system automates subtasks (the first level of autonomy) to agents that act independently (the fifth). Higher levels of performance can unlock higher levels of autonomy. For instance, Level 4 AGI may be necessary to enable fully autonomous vehicles that are safe and trustworthy.</li></ul><p><strong>Yes, but:&nbsp;</strong>The authors’ definition identifies some classes of tasks that contribute to generality, but it includes neither a list of tasks a system must perform to be considered general nor&nbsp;a method for selecting them. Rather, the authors call on the research community to develop a “living benchmark” for generality that includes a mechanism for adding novel tasks.</p><p><strong>Why it matters:&nbsp;</strong>AGI is one of the tech world’s hottest buzzwords, yet it has had no clear definition, and various organizations propose different definitions. This lack of specificity makes it hard to talk about related technology, regulation, and other topics. The authors’ framework, on the other hand, supports a more nuanced discussion of the path toward AGI. And it may have high-stakes business implications: Under the terms of their partnership, OpenAI can withhold from Microsoft models that attain AGI. Applying the authors’ taxonomy would make it harder for one of the parties to move the goalposts.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Defining AGI is tricky! For instance, OpenAI defines AGI as “a highly autonomous system that outperforms humans at most economically valuable work.” This definition, had it been formulated in the early 1900s, when agriculture accounted for 70 percent of work globally, would have described the internal combustion engine.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150942.421.gif" width="600" /></figure><h1 id="text-or-images-input-or-output">Text or Images, Input or Output</h1><p>GPT-4V introduced a large multimodal model that generates text from images and, with help from DALL-E 3, generates images from text. However, OpenAI hasn’t fully explained how it built the system. A separate group of researchers described their own method.</p><p><strong>What's new:&nbsp;</strong>Jing Yu Koh, Daniel Fried, and Ruslan Salakhutdinov at Carnegie Mellon University proposed&nbsp;<a href="https://arxiv.org/abs/2305.17216?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Generating Images with Large Language Models</a>&nbsp;(GILL), a training method that enables a large language model and a text-to-image generator to use both text and images as either input or output. Given text and/or image input, it decides whether to retrieve existing images or generate new ones.</p><p><strong>Key insight:</strong>&nbsp;Models like CLIP and ImageBind map text and image inputs to a similar embedding space, so closely related text and images have similar embeddings. This approach enables a large multimodal model to process both data types. Text outputs, too, can be mapped to the same embedding space, so an image decoder, such as a diffusion model, can use them to produce images or an image retriever to retrieve images.</p><p><strong>How it works:</strong>&nbsp;The authors used a pretrained&nbsp;<a href="https://arxiv.org/abs/2205.01068?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">OPT</a>&nbsp;large language model,&nbsp;<a href="https://arxiv.org/abs/2010.11929v2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">ViT-L</a>&nbsp;image encoder (taken from CLIP), and pretrained Stable Diffusion text-to-image generator. The authors trained ViT-L to map its embeddings to those produced by OPT. They trained OPT to recognize prompts that request an image and enabled the system to either generate or retrieve images. Finally, a separate linear classifier learned whether to retrieve or generate images.&nbsp;</p><ul><li>The authors froze the ViT-L, added a linear layer, and trained it as follows: Given an image, the ViT-L-plus-linear-layer produced an image embedding, as usual. Given the image embedding and the first part of the corresponding caption, OPT iteratively tried to predict the next word. The linear layer learned how to modify the embedding so OPT could complete the caption. This enabled OPT to take images as input.</li><li>They added 8 tokens to OPT’s vocabulary and trained the model to emit them at the end of every image caption — a signal that an image should be either retrieved or generated. (Typically a single token is sufficient to denote the end of a caption. However, these tokens corresponded to embeddings that, later, would be used to generate an image, and the authors found that a single token was not sufficiently expressive.)</li><li>Then they enabled Stable Diffusion to produce an image when OPT generated the 8 new tokens. They trained a separate transformer to map OPT’s embeddings associated with the 8 tokens (that is, embeddings produced by the layer before the one that generated the tokens) to those produced by Stable Diffusion’s text encoder.</li><li>Next they enabled the system to retrieve images when OPT generated the 8 tokens. They added linear layers to ViT-L and OPT and trained them to map the ViT-L’s embeddings to the OPT embedding associated with the first token. Specifically, the linear layers learned to minimize the difference between their outputs.</li><li>The authors trained a linear classifier, given the 8 OPT embeddings associated with the tokens, to decide whether to retrieve or generate an image. To build the classifier’s training set, they selected captions from a&nbsp;<a href="https://arxiv.org/abs/2206.10789?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">collection</a>&nbsp;of diverse human-written prompts and, for each one, both generated an image and retrieved the most similar image from CC3M. 5 human judges selected the image that best matched the prompt. This process yielded 900 examples annotated according to whether the image was retrieved or generated.</li><li>At inference, OPT generated tokens and fed the associated embeddings directly to the classifier, which activated the pipeline for either the generation or retrieval.</li></ul><p><strong>Results:&nbsp;</strong><a href="https://arxiv.org/abs/1604.03968?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">VIST</a>&nbsp;is a dataset of 20,000 visual stories, each of which comprises five captioned images. The authors evaluated GILL’s and Stable Diffusion’s abilities, given the final caption or all five captions, to generate the final image in each story based on CLIP similarity scores between generated and ground-truth images. Given one caption, GILL achieved 0.581 similarity and Stable Diffusion achieved 0.592 similarity. Given five captions, GILL achieved 0.612 similarity and Stable Diffusion scored 0.598 similarity, highlighting GILL’s ability to use the context afforded by more extensive input. It did even better (0.641 similarity) given both captions and images, which Stable Diffusion couldn’t handle. The authors also evaluated how well their system retrieved the correct last image from VIST given the 5 captions and the first 4 images. GILL retrieved the correct image 20.3 percent of the time, while their own&nbsp;<a href="https://arxiv.org/abs/2301.13823?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">FROMAGe</a>&nbsp;retrieved the correct image 18.2 percent of the time. In comparison, CLIP, given the 5 captions (without the images), retrieved the correct image 8.8 percent of the time.</p><p><strong>Why it matters:</strong>&nbsp;Models that wed text and images are advancing rapidly. GILL and other recent models extend single-image input and/or output to any combination of images and text. This capability — which GILL achieves by mapping embeddings of image and text to one another — gives the models more context to generate more appropriate output.</p><p><strong>We’re thinking:</strong>&nbsp;The authors add an interesting twist: Rather than generating images, the system can choose to retrieve them. Sometimes an existing image will do.</p><hr /><h2 id="a-message-from-landing-ai">A MESSAGE FROM LANDING AI</h2><figure class="kg-card kg-image-card"><a href="https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai&amp;utm_medium=partner&amp;utm_campaign=na-us-en-no-ind-unkwn-ai-ml&amp;utm_content=wb&amp;utm_cta=html-no-ind-unkwn"><img alt="" class="kg-image" height="709" src="https://dl-staging-website.ghost.io/content/images/2024/01/image--10-.png" width="1260" /></a></figure><p>Join a free webinar on January 11, 2024, featuring experts from Snowflake and Landing AI to explore how large vision models (LVMs) are transforming the image processing landscape.&nbsp;<a href="https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai&amp;utm_medium=partner&amp;utm_campaign=na-us-en-no-ind-unkwn-ai-ml&amp;utm_content=wb&amp;utm_cta=html-no-ind-unkwn" rel="noreferrer">Learn more about the session and register here</a></p><hr /><h1 id="data-points">Data Points</h1><p>What happens when beloved cartoon Mickey Mouse enters the public domain in the era of generative AI? What’s the latest AI-driven addition to PC keyboards?&nbsp;</p><p>These items and other AI news are explored in a new edition of Data Points, a spinoff of our weekly newsletter, The Batch.&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-231/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read it here</a></p>
]]></content:encoded>
<pubDate>Wed, 10 Jan 2024 20:15:13 GMT</pubDate>
</item>
</channel>
</rss>