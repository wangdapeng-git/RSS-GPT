<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>The Batch - a new weekly newsletter from deeplearning.ai</title>
<link>https://www.deeplearning.ai/the-batch/</link>

<item>
<title>Apple's Tiny LLMs, Amazon Rethinks Cashier-Free Stores, Predicting Scientific Discoveries</title>
<link>https://www.deeplearning.ai/the-batch/issue-247</link>
<guid>https://www.deeplearning.ai/the-batch/issue-247</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、预训练、大规模数据、生成数据、苹果公司
总结:
- 语言模型通过预训练和Fine-tuning进行训练，但需要大规模的数据作为预训练数据。
- 生成的数据通常不能用于直接训练模型，但结合自主工作流程可能产生更高质量的数据。
- 苹果公司推出了新的开源大规模语言模型OpenELM，适用于手机等边缘设备，并在多个任务上获得了良好表现。
- AI在科学研究中的应用，如预测材料性质，可以通过构建科学家及其研究对象的关系图来实现。

总结: 语言模型可以通过自主工作流程产生高质量的数据，开源大规模语言模型OpenELM适用于手机等边缘设备，在科学研究中AI能够预测材料性质等。 <div>
<p>Dear friends,</p><p>Inexpensive token generation and agentic workflows for large language models (LLMs) open up intriguing new possibilities for training LLMs on synthetic data. Pretraining an LLM on its own directly generated responses to prompts doesn't help. But if an agentic workflow implemented with the LLM results in higher quality output than the LLM can generate directly, then training on that output becomes potentially useful.</p><p>Just as humans can learn from their own thinking, perhaps LLMs can, too. For example, imagine a math student who is learning to write mathematical proofs. By solving a few problems — even without external input — they can reflect on what does and doesn’t work and, through practice, learn how to more quickly generate good proofs.&nbsp;</p><p>Broadly, LLM training involves (i) pretraining (learning from unlabeled text data to predict the next word) followed by (ii) instruction fine-tuning (learning to follow instructions) and (iii) RLHF/DPO tuning to align the LLM’s output to human values. Step (i) requires many orders of magnitude more data than the other steps. For example,&nbsp;<a href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Llama 3</a>&nbsp;was pretrained on over 15 trillion tokens, and LLM developers are still hungry for more data. Where can we get more text to train on?&nbsp;</p><p>Many developers train smaller models directly on the output of larger models, so a smaller model learns to mimic a larger model’s behavior on a particular task. However, an LLM can’t learn much by training on data it generated directly, just like a supervised learning algorithm can’t learn from trying to predict labels it generated by itself. Indeed, training a model repeatedly on the output of an earlier version of itself can result in&nbsp;<a href="https://www.deeplearning.ai/the-batch/study-reveals-serious-defects-in-models-trained-on-their-own-content/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">model collapse</a>.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed--57-.jpg" width="1200" /></figure><p>However, an LLM wrapped in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">agentic workflow</a>&nbsp;may produce higher-quality output than it can generate directly. In this case, the LLM’s higher-quality output might be useful as pretraining data for the LLM itself.&nbsp;</p><p>Efforts like these have precedents:</p><ul><li>When using&nbsp; reinforcement learning to play a game like chess, a model might learn a function that evaluates board positions. If we apply game tree search along with a low-accuracy evaluation function, the model can come up with more accurate evaluations. Then we can train that evaluation function to mimic these more accurate values.</li><li>In the alignment step, Anthropic’s&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">constitutional AI</a>&nbsp;method uses RLAIF (RL from AI Feedback) to judge the quality of LLM outputs, substituting feedback generated by an AI model for human feedback.&nbsp;</li></ul><p>A significant barrier to using LLMs prompted via agentic workflows to produce their own training data is the cost of generating tokens. Say we want to generate 1 trillion tokens to extend a pre-existing training dataset. Currently, at publicly announced prices, generating 1 trillion tokens using GPT-4-turbo ($30 per million output tokens), Claude 3 Opus ($75), Gemini 1.5 Pro ($21), and Llama-3-70B on Groq ($0.79) would cost, respectively, $30M, $75M, $21M and $790K. Of course, an agentic workflow that uses a design pattern like&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Reflection</a>&nbsp;would require generating more than one token per token that we would use as training data. But budgets for training cutting-edge LLMs easily surpass $100M, so spending a few million dollars more for data to boost performance is quite feasible.</p><p>That’s why I believe agentic workflows will open up intriguing new opportunities for high-quality synthetic data generation.&nbsp;</p><p>Keep learning!</p><p>Andrew</p><p>P.S. In “Prompt Engineering for Vision Models,” taught by Abby Morgan, Jacques Verré, and Caleb Kaiser of Comet, you’ll learn how to prompt and fine-tune a variety of vision models for image generation, image editing, object detection, and&nbsp; segmentation. For example, you’ll use OWL-ViT to detect an object you describe in a text prompt, pass the bounding box to SAM to create a segmentation mask, and feed the mask into Stable Diffusion with a text prompt to replace the original object with a new one. Controlling vision models can be tricky, and this course will teach you the techniques to control their output. Get started&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-01T152036.759.gif" width="1200" /></figure><h1 id="think-different-small">Think<strong>&nbsp;<s>Different</s>&nbsp;</strong>Small</h1><p>Apple is thinking small — very small — with a new family of open large language models.</p><p><strong>What's new:&nbsp;</strong>Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, and colleagues at Apple released&nbsp;<a href="https://arxiv.org/abs/2404.14619?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Open Source Efficient LLM</a>&nbsp;(OpenELM), a family of smaller large language models. OpenELM ranges from 270 million parameters — plenty small enough to fit on a phone — to 3 billion parameters.&nbsp;</p><p><strong>How it works:</strong>&nbsp;OpenELM comes in pretrained and instruction-tuned versions with parameter counts of 270 million, 450 million, 1.1 billion, and 3 billion. They can process 2,048 tokens of context. The&nbsp;<a href="https://github.com/apple/corenet?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">release</a>&nbsp;includes weights, code for training and inference, and code for running the models on Apple chips.&nbsp;</p><ul><li>The authors pretrained OpenELM on 1.8 trillion tokens drawn from subsets of&nbsp;<a href="https://arxiv.org/abs/2306.01116?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">publicly</a>&nbsp;<a href="https://www.together.ai/blog/redpajama?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">available</a>&nbsp;<a href="https://arxiv.org/abs/2101.00027?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">text</a>&nbsp;<a href="https://arxiv.org/abs/2402.00159?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">datasets</a>.</li><li>They fine-tuned the instruction-tuned models on the&nbsp;<a href="https://arxiv.org/abs/2310.01377?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">UltraFeedback</a>&nbsp;dataset of 60 thousand prompts.</li><li>OpenELM follows most of the architecture choices of current state-of-the-art transformer models with a major exception: The number of attention heads and size of fully connected layers increase the deeper in the network they are, following the idea that layers later in the network learn more complex representations of the input than early ones. This architecture contrasts to the current common practice, in which a transformer’s number of attention heads and size of fully connected layers remains consistent throughout the network.</li></ul><p><strong>Results:&nbsp;</strong>OpenELM beat a number of other open-source models trained solely on publicly available data.</p><ul><li>For example, on average across five tasks on the&nbsp;<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Open LLM Leaderboard</a>, a 1.08 billion parameter OpenELM beat a 1.18 billion parameter&nbsp;<a href="https://arxiv.org/abs/2402.00838?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">OLMo</a>&nbsp;45.93 percent to 43.57 percent, although OLMo trained on twice as much data. The 270 million-parameter OpenELM achieved 38.72 percent.</li><li>Comparing speed between OpenELM models that ran on consumer-grade computers, the 270 million-parameter model was over twice as fast as the 3 billion-parameter version. Apple did not present results obtained on phones.</li><li>OpenELM fell short on&nbsp;<a href="https://arxiv.org/abs/2009.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MMLU</a><strong>&nbsp;</strong>(multiple choice questions from mathematics to microeconomics), achieving within 2.05 percent of random chance (25 percent) for all model sizes. To be fair, the other models chosen for comparison didn’t do much better. It’s possible that publicly available data isn’t sufficient for learning to solve MMLU. By comparison, Microsoft’s Phi-3-mini (3.8 billion parameters trained on web data filtered according to “educational level” plus generated data) achieved 68.8 percent accuracy.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;After years of becoming only larger, neural networks lately have also been getting smaller. The smallest OpenELMs are tiny compared to, say, Microsoft’s Phi-3-mini. Apple has an extra incentive to make models capable of running on edge devices like phones. The company makes a major selling point of user privacy, and models run entirely on a smartphone (as opposed to in the cloud) keep the user’s activity under wraps.</p><p><strong>We're thinking:</strong>&nbsp;<a href="https://arxiv.org/pdf/2008.00623?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">DeLighT</a>&nbsp;introduced this layer-scaling approach in 2020. Sometimes it takes a while for good ideas to catch on!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/05/AIINDEX_1200px_14secHolds--1-.gif" width="1200" /></figure><h1 id="ai-trends-in-depth">AI Trends in Depth</h1><p>More expensive models, superhuman performance, growing impacts on society — an extensive report takes stock of developments in machine learning over the past year.&nbsp;</p><p><strong>What's new:</strong>&nbsp;Stanford’s Institute for Human-Centric AI&nbsp;<a href="https://aiindex.stanford.edu/report/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">published</a>&nbsp;the seventh “AI Index Report,” its annual overview of the state of AI. The report documents rising costs and capabilities, a shift from academic to corporate dominance, and the public’s anxiety as the technology becomes ever more embedded in daily life.</p><p><strong>Themes and findings:</strong>&nbsp;The 500-page report collates a wide variety of papers, benchmarks, market research, and surveys published in 2023. It delves deeply into AI technology, economics, governance, and impact. Among its key conclusions:&nbsp;</p><ul><li>Foundation models, defined as versatile models trained on very large datasets, ballooned in number and cost. The Index counted 149 foundation models released in 2023 (including Google’s Gemini Ultra, which cost $191.4 million to train). That’s up from 32 foundation models in 2022, 9 in 2021, and 2 in 2020 (when OpenAI’s GPT-3 175B cost an estimated $4.3 million to train).</li><li>Open foundation models, too, are on the rise: 66 percent of last year’s foundation models were open, up from 33 percent in 2021.</li><li>State-of-the-art models approached or surpassed human performance on several popular benchmarks. These include&nbsp;<a href="https://arxiv.org/pdf/2009.03300v3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MMLU</a>&nbsp;(multitask language understanding),&nbsp;<a href="https://arxiv.org/pdf/2308.06595?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">VisIT-Bench</a>&nbsp;(vision-language instructions), and&nbsp;<a href="https://arxiv.org/pdf/2103.03874?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">MATH</a>&nbsp;(difficult math problems).&nbsp;</li><li>Industry was the primary driver of innovation, contributing 57 percent of “notable” machine learning models. Partnerships between industry and academia accounted for 23 percent and academia alone for 17 percent. Corporate dominance in model building was a significant shift from previous years; in 2016, academia and industry contributed AI models equally.</li><li>New models have achieved dramatic results in the sciences. For instance,&nbsp;<a href="https://www.nature.com/articles/s41586-023-06004-9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">AlphaDev</a>&nbsp;found superior sorting algorithms.&nbsp;<a href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">GraphCast</a>&nbsp;generated mid-range weather forecasts more accurately than conventional methods.&nbsp;<a href="https://www.nature.com/articles/s41586-023-06735-9?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">GNoME</a>&nbsp;discovered new materials, and&nbsp;<a href="https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">AlphaMissense</a>&nbsp;pinpointed genetic mutations that cause human diseases.</li></ul><p><strong>Behind the news:</strong>&nbsp;The differences between the new one and the initial, 2018 edition highlight the field’s rapid pace of change. For instance, the 2018 report opened by trumpeting the nearly 9x growth of AI research papers published between 2000 and 2017. The new one opened not with the annual rate of research publications (though it has roughly doubled since 2017) but with a graph of industry’s growing dominance in innovation.&nbsp;<em>The Batch</em>&nbsp;has&nbsp;<a href="https://www.deeplearning.ai/the-batch/tag/ai-index/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">covered</a>&nbsp;several editions.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The “AI Index Report” offers a detailed snapshot of AI as it advances at an unprecedented rate and shows potential to revolutionize virtually every field of human endeavor. It dives deeply into areas of special concern to researchers (such as Gemini’s nearly $200 million training cost), practitioners (for instance, the slightly narrowing gender gap among computer science PhDs), businesses (the sharply rising number of regulations), and users (half of those who are aware of ChatGPT use it weekly). This year’s report includes new emphases on public opinion and geopolitics.</p><p><strong>We're thinking:</strong>&nbsp;It’s heartening to see AI thriving. The field faces daunting challenges, yet the report highlights achievements in foundation models, science, medicine, and elsewhere that portend greater benefits directly ahead. What an exciting time for AI!</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/05/The-Batch-ads-and-exclusive-banners---2024-04-29T162119.517.png" width="1680" /></a></figure><p>Expand your prompting skills with our new short course, “Prompt Engineering for Vision Models.” Learn how to prompt and fine-tune vision models to accomplish tasks from image generation to object detection.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models?ref=dl-staging-website.ghost.io" rel="noreferrer">Start learning today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/05/unnamed---2024-05-01T152511.553.png" width="1200" /></figure><h1 id="amazon-rethinks-cashier-free-stores">Amazon Rethinks Cashier-Free Stores</h1><p>Amazon is removing grab-and-go shopping from its cart.</p><p><strong>What’s new:</strong>&nbsp;Amazon withdrew Just Walk Out, an AI-driven checkout service, from most of its Amazon Fresh grocery stores,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/amazons-grocery-stores-to-drop-just-walk-out-checkout-tech?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">reported</a>. Instead, the stores will provide smart shopping carts. (Disclosure: Andrew Ng is a member of Amazon’s Board of Directors.)<br /><br /><strong>Checking out:</strong>&nbsp;<a href="https://www.deeplearning.ai/the-batch/no-cashier-no-problem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Just Walk Out</a>&nbsp;enables shoppers to scan a payment method upon entering a store, take items from shelves tracked by computer vision and weight-detection sensors, and simply exit with their purchases, bypassing the checkout counter. Amazon had installed the system in 47 Amazon Fresh stores in the U.S. and UK. In most of those locations. Amazon will replace Just Walk Out with&nbsp;<a href="https://www.aboutamazon.com/news/retail/amazon-dash-cart-new-features-whole-foods?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Dash Cart</a>, a shopping cart that enables customers to scan purchases as they shop. Amazon will retain Just Walk Out in its Amazon Go convenience stores and an unspecified number of smaller, UK-based Amazon Fresh stores. It has licensed the system to other retailers including Hudson Markets and plans to install in more third-party stores this year.</p><ul><li>Just Walk Out isn’t well suited to grocery shopping, in which customers may buy large numbers of items, since customers may not be aware of their total spending until they receive a receipt via email after leaving the store, Amazon executive Tony Hoggett said. Dash Cart enables users to see the bill in real time.</li><li>Just Walk Out&nbsp;<a href="https://www.theinformation.com/articles/how-amazons-big-bet-on-just-walk-out-stumbled?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">relied on</a>&nbsp;more than 1,000 remote employees to label video for training and review cases where it failed, and Amazon wasn’t able to improve the system as quickly as it expected, according to an earlier report by&nbsp;<em>The Information</em>. As of mid-2022, the system required about 700 human reviews per 1,000 sales, compared to a target between 20 and 50 per 1,000 sales. Amazon said the percentage of sales that require human review has declined since then.</li><li>Training the models required 2,000 technologists and cost hundreds of millions of dollars in cloud computing resources to train and run.</li><li>Just Walk Out’s cameras and sensors can be difficult to install in existing stores and sometimes requires extensive remodeling. The system also&nbsp;<a href="https://www.theverge.com/2019/9/10/20857921/amazon-go-rollout-delay-cashierless-convenience-stores-whole-foods?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">requires</a>&nbsp;high ceilings, which existing stores may not have.</li></ul><p><strong>Behind the news:</strong>&nbsp;Amazon&nbsp;<a href="https://www.deeplearning.ai/the-batch/retailers-spend-on-smarter-stores/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">introduced</a>&nbsp;Just Walk Out in 2016 at its first Amazon Go convenience store in Seattle. It&nbsp;<a href="https://www.deeplearning.ai/the-batch/no-cashier-no-problem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">extended</a>&nbsp;the system to Amazon Fresh in 2020. Between September 2020 and September 2022, Amazon opened 44 Fresh stores in the U.S. and 19 in the UK, most of which included Just Walk Out. But Amazon’s brick-and-mortar locations&nbsp;<a href="https://www.cnbc.com/2022/02/19/amazons-sprawling-grocery-business-has-become-an-expensive-hobby.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">suffered</a>&nbsp;during the COVID-19 pandemic. From September 2022 to mid-2024, amid broader cost-cutting efforts, the company&nbsp;<a href="https://www.theinformation.com/articles/zombie-amazon-grocery-stores-pile-up-as-openings-grind-to-a-halt?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">paused</a>&nbsp;opening new grocery stores.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Grab-and-go shopping seems like a solid bet, given the increasing focus of retailing on immediate gratification. Yet Amazon’s retreat from Just Walk Out in larger stores suggests that the technology is less well suited to such environments. In addition, shoppers may not have adjusted easily to grab-and-go behavior, which removes social interactions with cashiers and encourages customers to spend without reviewing the bill.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;AI has the potential to revolutionize every field, including retailing, and it’s important to find productive uses for it. Not all experiments will succeed, but patient investment and experimentation can illuminate productive paths forward.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/05/SCIENCE-FIX.gif" width="600" /></figure><h1 id="predicting-scientific-discoveries">Predicting Scientific Discoveries</h1><p>A new AI method directs scientists toward promising avenues of inquiry.</p><p><strong>What's new:</strong>&nbsp;Jamshid Sourati and James A. Evans at University of Chicago proposed a&nbsp;<a href="https://www.nature.com/articles/s41562-023-01648-z?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">method to predict new scientific discoveries</a>&nbsp;by building a graph that connects researchers, their objects of study, and the scientific properties thereof. They evaluated their approach using data from materials science.</p><p><strong>Key insight:</strong>&nbsp;Overlapping interests among researchers may indicate areas where further research would be fruitful. For example, if one group of researchers studies a material A and its property P, a second group studies materials A and B, and another group studies materials B and C, it may turn out that material C exhibits property P.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors tried to predict whether certain inorganic materials have certain electrical properties based on&nbsp;<a href="https://europepmc.org/article/med/31270483?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">scientific literature</a>&nbsp;through the year 2000. From 1.5 million articles that described 100,000 inorganic compounds, they extracted the author names, materials mentioned (for example, sodium nitrite), and their properties (for example, thermoelectricity, the ability to convert heat into electricity and vice versa). They used this data to construct a graph whose nodes were authors, materials, and properties. Edges connected the nodes that appeared in the same paper, for example a particular author whose paper covered specific material or property.</p><ul><li>The authors conducted random walks through the graph, stepping from node to node, to produce sequences of authors, materials, and properties. Then they removed the authors from the sequences, because they were interested mainly in establishing possible connections between materials and properties.&nbsp;</li><li>They trained&nbsp;<a href="https://arxiv.org/abs/1301.3781?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8k0LiZQvRWFPDGgDt43tNF902ROx3dTDBEvtdF-XpX81iwHOkMt0-y9vAGM94bcVF8ZSYc" rel="noopener">Word2Vec</a>, which computes word embeddings, on their sequences, treating materials and properties as words and sequences as documents. This yielded an embedding for each material and property.</li><li>To predict possible discoveries — that is, which material might exhibit a given property — the authors scored each material based on (i) the similarity between the material’s embedding and the given property’s embedding and (ii) the smallest number of edges in the path that connected each material and the property. Then they summed scores (i) and (ii). The 50 highest-scoring materials were predicted to have the property (that weren’t directly connected in the graph; that is, excluding materials that already were known to have the property).&nbsp;&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;The authors predicted which materials possessed each of three properties. They compared their results with predictions obtained in a similar way using a Word2Vec model trained exclusively on text from scientific papers. They used papers from 2001 through 2018 to evaluate the predictions. For thermoelectricity, the cumulative precision (percentage of predicted discoveries proven correct) was 76 percent, while the cumulative precision of the alternative method was 48 percent. The cumulative precision of random guesses was about 3 percent. The authors obtained similar results for the other two properties.</p><p><strong>Why it matters:</strong>&nbsp;Science is a social endeavor, where the connections between people and their work can be represented as a graph that reflects the collective attention of the scientific community. The collective attention acts as a signal that predicts promising avenues for further research — a signal that machine learning can help to tease out.&nbsp;</p><p><strong>We're thinking:</strong>&nbsp;The authors also predicted drug discoveries with similarly good results. Their method may be useful for identifying fruitful directions in other scientific areas, and perhaps in other domains entirely.</p><hr /><h1 id="data-points">Data Points</h1><p>This week's <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> features these highlights: Adobe's latest Firefly Image 3 model, enhanced smart glasses with Meta’s AI assistant, an AI-powered gene editor, and more.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-247/?ref=dl-staging-website.ghost.io" rel="noreferrer">Catch up on the latest in AI now.</a></p>
]]></content:encoded>
<pubDate>Wed, 01 May 2024 20:39:36 GMT</pubDate>
<pubDate>Wed, 01 May 2024 20:39:36 GMT</pubDate>
</item>

<item>
<title>Pop Song Generators, 3D Mesh Generators, Real-World Benchmarks, AI for Manufacturing</title>
<link>https://www.deeplearning.ai/the-batch/issue-246</link>
<guid>https://www.deeplearning.ai/the-batch/issue-246</guid>
<content:encoded><![CDATA[
<div> 大规模语言模型，生成token的速度，计算力成本下降，AI在制造业的应用，基于单张图像生成3D模型 <br /><br />总结:<br />本文介绍了大规模语言模型在训练和推理过程中所需的计算力以及生成token的速度对于人工智能的重要性。作者指出，除了训练外，推理过程也需要更多的计算资源。而在今天的应用场景中，大量的token生成是十分有价值的，生成速度慢会成为利用基础模型的瓶颈。此外，作者也表示，计算力成本正在快速下降，这对于应用构建者和AI工作流有着积极的影响。文章还介绍了一些相关的技术进展，如基于文本的音乐生成和基于单张图像的3D模型生成。最后，文章提到了制造业中的AI应用，并指出了技能和数据的瓶颈可能是制造业中推广AI的挑战。总的来说，本文探讨了AI技术在各个领域的不断发展和应用前景。 <div>
<p>Dear friends,</p><p>Much has been said about many companies’ desire for more compute (as well as data) to train larger foundation models. I think it’s under-appreciated that we have nowhere near enough compute available for inference on foundation models as well.</p><p>Years ago, when I was leading teams at Google, Baidu, and Stanford that focused on scaling up deep learning algorithms, many semiconductor manufacturers, data center operators, and academic researchers asked me whether I felt that AI technology would continue to make good use of more compute if they kept on delivering it. For many normal desktop processing workloads, like running a web browser or a text editor, having a faster CPU doesn’t help that much beyond a certain point. So do we really need faster and faster AI processors to train larger and larger models? Each time, I confidently replied “yes!” and encouraged them to keep scaling up compute. (Sometimes, I added half-jokingly that I had never met a machine learning engineer who felt like they had enough compute. 😀)</p><p>Fortunately, this prediction has been right so far.&nbsp;However, beyond training, I believe we are also far from exhausting the benefits of faster and higher volumes of inference.</p><p>Today, a lot of LLM output is primarily for human consumption. A human might read around 250 words per minute, which is around 6 tokens per second (250 words/min / (0.75 words/token) / (60 secs/min)). So it might initially seem like there’s little value to generating tokens much faster than this. &nbsp;</p><p>But in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">agentic workflow</a>, an LLM might be prompted repeatedly to reflect on and improve its output, use tools, plan and execute sequences of steps, or implement multiple agents that collaborate with each other. In such settings, we might easily generate hundreds of thousands of tokens or more before showing any output to a user. This makes fast token generation very desirable and makes slower generation a bottleneck to taking better advantage of existing foundation models.</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/TOKEN-GENERATION.png" width="1200" /></figure><p>That’s why I’m excited about the work of companies like&nbsp;<a href="https://groq.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Groq</a>, which can generate hundreds of tokens per second. Recently,&nbsp;<a href="https://fast.snova.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">SambaNova</a>&nbsp;published an impressive demo that hit hundreds of tokens per second.</p><p>Incidentally, faster, cheaper token generation will also help make running evaluations (evals), a step that can be slow and expensive today since it typically involves iterating over many examples, more palatable. Having better evals will help many developers with the process of tuning models to improve their performance.</p><p>Fortunately, it appears that both training and inference are rapidly becoming cheaper. I recently spoke with Cathie Wood and Charles Roberts of the investment firm ARK, which is famous for its bullish predictions on tech. They&nbsp;<a href="https://www.ark-invest.com/big-ideas-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">estimate</a>&nbsp;that AI training costs are falling at 75% a year. If they are right, a foundation model that costs $100M to train this year might cost only $25M to train next year. Further, they report that for “enterprise scale use cases, inference costs seem to be falling at an annual rate of ~86%, even faster than training costs.”</p><p>I don’t know how accurate these specific predictions will turn out to be, but with improvements in both semiconductors and algorithms, I do see training and inference costs falling rapidly. This will be good for application builders and help AI agentic workflows lift off.</p><p>Keep learning!</p><p>Andrew</p><p>P.S. New short course with Mistral AI! Mistral’s open-source Mixtral 8x7B model uses a mixture of experts (MoE) architecture. Unlike a standard transformer, MoE uses multiple expert feed-forward networks with a gating network that selects a number of experts at inference time. This enables MoE to match the performance of larger models but with faster inference. Mixtral 8x7B has 46.7B parameters but activates only 12.9B at inference time to predict the next token. In “Getting Started with Mistral,” taught by Sophia Yang, you’ll explore Mistral’s open-source (Mistral 7B, Mixtral 8x7B) and commercial models, learn about function calling for tool use with Mistral, and build a Mistral-powered chat interface that can reference external documents. Please sign up&nbsp;<a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-24T134335.199.gif" width="1200" /></figure><h1 id="songs-made-to-order">Songs Made to Order</h1><p>A new breed of audio generator produces synthetic performances of songs in a variety of popular styles.</p><p><strong>What’s new:</strong>&nbsp;Udio&nbsp;<a href="https://www.udio.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">launched</a>&nbsp;a web-based, text-to-song generator that creates songs in styles from barbershop to heavy metal.&nbsp;<a href="https://suno.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Suno</a>, which debuted its service late last year with similar capabilities, upgraded to its offering.</p><p><strong>How it works:</strong>&nbsp;Both services take text prompts and generate full-band productions complete with lyrics, vocals, and instrumental solos, two separate generations per prompt. Users can generate lyrics to order or upload their own words, and they can download, share, and/or post the results for others to hear. Leaderboards rank outputs according to plays and likes.&nbsp;</p><ul><li>Founded by alumni of Google’s DeepMind division, Udio lets registered users generate up to 1,200 songs monthly for free and expects to offer paid services at an unspecified future date. Users enter a text prompt and/or choose style tags. The system automatically replaces artist names with stylistic descriptions but sometimes produces results that sound uncannily&nbsp;<a href="https://youtu.be/7U57R_icuOg?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">like</a>&nbsp;the artists requested. Users can choose to generate an instrumental track or add lyrics, allocating them to verse, chorus, or background vocals. Udio generates audio segments 33 seconds long, which users can extend, remix, and modify. The company has not released information about the underlying technology.&nbsp;</li><li>Suno lets users generate 10 songs daily for free or pay to generate more. Enter a prompt, and the system generates complete songs up to 2 minutes long; alternatively, users can specify lyrics, style, and title in separate prompts. The system refuses to generate music from prompts that include the name of a real-world artist. Suno hasn’t disclosed technical information, but last year it&nbsp;<a href="https://github.com/suno-ai/bark?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">released</a>&nbsp;an open-source model called Bark that turns a text prompt into synthetic music, speech, and/or sound effects.</li></ul><p><strong>Behind the news:</strong>&nbsp;Most earlier text-to-music generators were designed to produce relatively free-form instrumental compositions rather than songs with structured verses, choruses, and vocals. Released earlier this month,&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Stable Audio 2</a>&nbsp;generates instrumental tracks up to three minutes long that have distinct beginnings, middles, and endings. Users can also upload audio tracks and use Stable Audio 2.0 to modify them.</p><p><strong>Yes, but:&nbsp;</strong>Like text-to-image generators circa last year, current text-to-music models offer little ability to steer their output. They don’t respond consistently to basic musical terminology such as “tempo” and “harmony,” and requesting a generic style like “pop” can summon a variety of subgenres from the last 50 years of popular music.</p><p><strong>Why it matters:</strong>&nbsp;With the advent of text-to-music models that produce credible songs, audio generation seems primed for a Midjourney moment, when the public realizes that it can produce customized music at the drop of a prompt. Already Udio’s and Suno’s websites are full of whimsical paeans to users’ pets and hobbies. The technology has clear implications for professional performers and producers, who, regrettably, have little choice but to&nbsp;<a href="https://www.deeplearning.ai/the-batch/grimes-released-a-voice-cloning-tool/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">adapt</a>&nbsp;to increasing automation. But for now fans have fun, new toys to play with.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;You can dance to these algo-rhythms!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/VALS-4Leaderboards_1200px--1-.gif" width="1200" /></figure><h1 id="benchmarks-for-industry">Benchmarks for Industry</h1><p>How well do large language models respond to professional-level queries in various industry domains? A new company aims to find out.</p><p><strong>What’s new:</strong>&nbsp;<a href="https://www.vals.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Vals.AI</a>, an independent model testing service, developed benchmarks that rank large language models’ performance of tasks associated with income taxes, corporate finance, and contract law; it also maintains a pre-existing legal benchmark. Open AI’s GPT-4 and Anthropic’s Claude 3 Opus did especially well in recent tests.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Vals AI hosts leaderboards that compare the performance of several popular large language models (LLMs) with respect to accuracy, cost, and speed, along with with analysis of the results. The company worked with independent experts to develop multiple-choice and open-ended questions in industrial domains. The datasets are not publicly available.&nbsp;</p><ul><li><a href="https://www.vals.ai/contractlaw?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">ContractLaw</a>&nbsp;includes questions related to contracts. They ask models to retrieve parts of contracts that are relevant to particular terms, edit excerpts, and determine whether excerpts meet legal standards.</li><li><a href="https://www.vals.ai/corpfin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">CorpFin</a>&nbsp;tests accuracy in answering corporate finance questions. It feeds to models a public commercial credit agreement — terms of a business loan or a line of credit — and poses questions that require extracting information and reasoning over it.</li><li><a href="https://www.vals.ai/taxeval?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">TaxEval</a>&nbsp;tests accuracy on tax-related prompts. Half of the questions test skills like calculating taxable income, marginal rate, and the like. The other half cover knowledge such as how different accounting methods impact taxes or how taxes apply to various types of assets.</li><li>Vals AI also tracks&nbsp;<a href="https://www.vals.ai/legalbench?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">performance</a>&nbsp;on&nbsp;<a href="https://arxiv.org/abs/2308.11462?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">LegalBench</a>, an open benchmark that evaluates legal reasoning.</li></ul><p><strong>Results:</strong>&nbsp;Among 15 models, GPT-4 and Claude 3 Opus dominated Vals.AI’s leaderboards as of April 11, 2024. GPT-4 topped CorpFin and TaxEval, correctly answering 64.8 and 54.5 percent of questions, respectively. Claud 3 Opus narrowly beat GPT-4 on ContractLaw and LegalBench, achieving 74.0 and 77.7 percent, respectively. The smaller Claude 3 Sonnet took third place in ContractLaw, CorpFin, and TaxEval with 67.6, 61.4, and 37.1 percent. Google’s Gemini Pro 1.0 took third place in LegalBench with 73.6 percent.</p><p><strong>Behind the news:</strong>&nbsp;Many practitioners in&nbsp;<a href="https://www.deeplearning.ai/the-batch/new-report-on-the-ai-capabilities-of-major-banks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">finance</a>&nbsp;and&nbsp;<a href="https://www.clio.com/blog/lawyer-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">law</a>&nbsp;use LLMs in applications that range from processing documents to&nbsp;<a href="https://www.deeplearning.ai/the-batch/jpmorgan-trained-ai-to-interpret-the-federal-reserves-intent/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">predicting interest rates</a>. However, LLM output in such applications requires oversight. In 2023, a New York state judge&nbsp;<a href="https://www.deeplearning.ai/the-batch/attorney-faces-disciplinary-action-for-using-chatgpts-fictional-brief/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">reprimanded</a>&nbsp;a lawyer for submitting an AI-generated brief that referred to fictitious cases.</p><p><strong>Why it matters:</strong>&nbsp;Typical AI benchmarks are designed to evaluate general knowledge and cognitive abilities. Many developers would like to measure more directly performance in real-world business contexts, where specialized knowledge may come into play.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Open benchmarks can benefit from public scrutiny, and they’re available to all developers. However, they can be abused when developers cherry-pick benchmarks on which their models perform especially well. Moreover, they may find their way into training sets, making for unfair comparisons. Independent testing on proprietary benchmarks is one way to address these issues.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-23T091059.531.png" width="1680" /></a></figure><p>Join “Getting Started with Mistral” and access Mistral AI’s open source and commercial models via API calls. Learn to select the right model for your use case and get hands-on with features like JSON mode, function calling, and effective prompting techniques.&nbsp;<a href="https://www.deeplearning.ai/short-courses/getting-started-with-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Enroll for free</a>!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/MANUFACTURING_14-SecHolds_1200px--1---1-.gif" width="1200" /></figure><h1 id="ai-progress-report-manufacturing">AI Progress Report: Manufacturing</h1><p>Manufacturers are embracing AI even as they struggle to find the talent and data required.</p><p><strong>What’s new:</strong>&nbsp;The market-research arm of&nbsp;<em>MIT Technology Review</em>&nbsp;<a href="https://www.technologyreview.com/2024/04/09/1090880/taking-ai-to-the-next-level-in-manufacturing/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">surveyed</a>&nbsp;manufacturers’ use of AI in engineering, design, procurement, and production. All respondents were at least experimenting with AI, and many expect to launch their first deployments in the next year or two. Microsoft sponsored the research.</p><p><strong>How it works:</strong>&nbsp;The authors interviewed executives at 300 manufacturers in aerospace, automotive, chemicals, electronics, and heavy equipment. All were either applying or considering AI in product design or factory operations.&nbsp;</p><ul><li>The most common uses of AI in production involved designing products, creating content such as technical documentation, and building chatbots. The most common uses in earlier stages were knowledge management and quality control.</li><li>35 percent of respondents had deployed AI in production. Another 37 percent were experimenting with AI, while 27 percent were conducting preliminary research.</li><li>45 percent of respondents in electronics and 39 percent in automotive had deployed AI in production. Larger companies were more likely to have deployed AI (77 percent of companies with revenues over $10 billion compared to 4 percent of those with revenues under $500 million). Larger companies were also more likely to forecast increases in AI spending in the next two years.</li><li>Asked to name the biggest challenges to scaling up uses of AI, respondents most often pointed to shortages of skills and talent. Asked to name challenges their company faced with respect to data, they pointed to maintaining data quality, integrating data from different parts of an organization, and governing data.</li></ul><p><strong>Behind the news:</strong>&nbsp;Manufacturers are using AI to help&nbsp;<a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/generative-ai-fuels-creative-physical-product-design-but-is-no-magic-wand?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">design products</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/super-human-quality-control/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">visually inspect goods</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/if-it-aint-broke-fix-it/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">maintain equipment</a>. The field has attracted major players: Last year, Microsoft and Siemens&nbsp;<a href="https://www.deeplearning.ai/the-batch/siemens-and-microsoft-launch-gpt-powered-copilot-for-manufacturing-machinery/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">launched</a>&nbsp;a pilot of Industrial Copilot, which enables users to interact in natural language with software that drives assembly lines.</p><p><strong>Why it matters:</strong>&nbsp;Manufacturers want to use AI, but many face obstacles of talent and data. That spells opportunities for budding practitioners as well as for manufacturers that lack infrastructure for collecting and managing data.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;One key to successful implementation of AI in manufacturing is tailoring systems to the unique circumstances of each individual facility. The highly heterogeneous tasks, equipment, and surroundings in different factories mean that one model doesn’t fit all. Developers who can solve this long-tail problem stand to reap rewards.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-24T134817.631.gif" width="600" /></figure><h1 id="a-3d-model-from-one-2d-image">A 3D Model From One 2D Image</h1><p>Video diffusion provides a new basis for generating 3D models.<br /><strong>What's new:&nbsp;</strong>Vikram Voleti, Chun-Han Yao, Mark Boss, Varun Jampani, and colleagues at Stability AI produced a&nbsp;<a href="https://arxiv.org/abs/2403.12008?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">method</a>&nbsp;that generates a 3D model from a single image based on Stability’s video diffusion model. You can see its output&nbsp;<a href="https://stability.ai/news/introducing-stable-video-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">here</a>.<br /><br /><strong>Key insight:</strong>&nbsp;The approach known as a&nbsp;<a href="https://arxiv.org/abs/2003.08934?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Neural Radiance Field</a>&nbsp;(NeRF) learns to create a 3D model from images of the same object shot at various angles. Given a single image of an object, a video diffusion model can learn to generate videos that orbit around it. The frames from such orbital videos give NeRF the information it needs to produce a 3D model.&nbsp;<br /><br /><strong>How it works:</strong>&nbsp;To generate an image, the authors took one step before and two steps during inference. Before inference: Learn to generate an orbital video. During inference: (i) Train a NeRF model on an orbital video. (ii) Improve the 3D model using diffusion following&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-dreamfusion-generates-3d-images-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">DreamFusion</a>.&nbsp;</p><ul><li>The authors fine-tuned a pretrained&nbsp;<a href="https://arxiv.org/abs/2311.15127?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Stable Video Diffusion</a>, given an image of an object, to generate an orbital video. They fine-tuned the model on orbital views of synthetic objects in the&nbsp;<a href="https://arxiv.org/abs/2212.08051?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Objaverse</a>&nbsp;dataset, first without and then with information about the camera’s orbit. They called the fine-tuned model Stable Video 3D (SV3D).</li><li>At inference, SV3D generated an orbital video from an image, where the orbit periodically went up and down to ensure the top and bottom of the object were visible. From these images, the authors trained an&nbsp;<a href="https://arxiv.org/abs/2201.05989?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">Instant-NGP</a>&nbsp;NeRF model, which learned to represent the object as a 3D model and generate pictures from new camera angles based on different views of the same object.&nbsp;</li><li>To improve the 3D model, the authors first represented it using DMTet&nbsp;instead of Instant-NGP. DMTet is a system of networks built to refine 3D shapes from rough point clouds or low-resolution 3D models. The authors rendered images of DMTet’s 3D model along random camera orbits. For each image, the authors added noise to the image’s representation and removed it using SV3D. DMTet learned to update its 3D model to minimize the difference between the rendered image and the updated version from SV3D.</li></ul><p><strong>Results:</strong>&nbsp;The authors produced 3D models from images of 50 objects in&nbsp;<a href="https://arxiv.org/abs/2204.11918?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">GSO</a>, a 3D object dataset of scanned household items. They compared their 3D models to those produced by other methods including&nbsp;<a href="https://arxiv.org/abs/2402.03908?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">EscherNet</a>, a method that uses an image diffusion model to generate images of an object from different angles that are used to train a&nbsp;<a href="https://arxiv.org/abs/2106.10689?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8p1gYrpU0XxUFNfmSS3kol8W5-7e4O-CZDhoB8qzXDRMbt3ivdmVgXC7rhNTbUafmUHpkI" rel="noopener">pair of vanilla neural networks</a>&nbsp;to produce a 3D model. Evaluated according to Chamfer distance, a measure of the distance between the points on the ground truth and generated 3D models (lower is better), their method achieved .024, while EscherNet achieved .042.</p><p><strong>Why it matters:</strong>&nbsp;Video diffusion models must generate different views of the same object, so they require a greater understanding of 3D objects than image diffusion models, which need to generate only one view at a time. Upgrading from an image diffusion model to a video diffusion model makes for better 3D object generation.<br /><br /><strong>We’re thinking:</strong>&nbsp;Building 3D models used to be difficult, but with models like this, it's becoming less of a mesh.</p>
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 18:50:15 GMT</pubDate>
</item>
<item>
<title>AI Agents With Low/No Code, Hallucinations Create Security Holes, Tuning for RAG Performance, GPT Store's Lax Moderation</title>
<link>https://www.deeplearning.ai/the-batch/issue-245</link>
<guid>https://www.deeplearning.ai/the-batch/issue-245</guid>
<content:encoded><![CDATA[
<div> 多智能体协作, LLM, 复杂任务, 分解子任务, 多种角色, 结果表明, LLM的能力, <div>
<p>Dear friends,</p><p>Multi-agent collaboration is the last of the four&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">key AI agentic design patterns</a>&nbsp;that I’ve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles — such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on — and have different agents accomplish different subtasks.</p><p>Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: “You are an expert in writing clear, efficient code. Write code to perform the task . . ..”&nbsp;</p><p>It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I’d like to offer a few reasons:</p><ul><li>It works! Many teams are getting good results with this method, and there’s nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.&nbsp;</li><li>Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role’s subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.</li><li>Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.</li></ul><figure class="kg-card kg-image-card"><img alt="Proposed ChatDev architecture, illustrated." class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T155856.845-1.png" width="1200" /></figure><p>In many companies, managers routinely decide what roles to hire, and then how to split complex projects — like writing a large piece of software or preparing a research report — into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.&nbsp;</p><p>While managing people is hard, it's a sufficiently familiar idea that it gives us a mental framework for how to "hire" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!&nbsp;</p><p>Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you're interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their&nbsp;<a href="https://github.com/OpenBMB/ChatDev?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">GitHub repo</a>&nbsp;and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does.&nbsp;</p><p>Like the design pattern of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Planning</a>, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Reflection</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Tool Use</a>&nbsp;are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!&nbsp;</p><p>If you're interested in learning more, I recommend:&nbsp;</p><ul><li>“<a href="https://arxiv.org/abs/2307.07924?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Communicative Agents for Software Development</a>,” Qian et al. (2023) (the ChatDev paper)</li><li>“<a href="https://arxiv.org/abs/2308.08155?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a>,” Wu et al. (2023)&nbsp;</li><li>“<a href="https://arxiv.org/abs/2308.00352?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">MetaGPT: Meta Programming for a Multi-Agent Collaborative Framework</a>,” Hong et al. (2023)</li></ul><p>Keep learning!</p><p>Andrew</p><p>P.S. Large language models (LLMs) can take gigabytes of memory to store, which limits your ability to run them on consumer hardware. Quantization can reduce model size by 4x or more while maintaining reasonable performance. In our new short course “Quantization Fundamentals,” taught by Hugging Face's Younes Belkada and Marc Sun, you’ll learn how to quantize LLMs and how to use int8 and bfloat16 (Brain Float 16) data types to load and run LLMs using PyTorch and the Hugging Face Transformers library. You’ll also dive into the technical details of linear quantization to map 32-bit floats to 8-bit integers. I hope you’ll&nbsp;<a href="https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">check it out</a>!&nbsp;</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T160143.589.gif" width="1200" /></figure><h1 id="custom-agents-little-coding">Custom Agents, Little Coding</h1><p>Google is empowering developers to build autonomous agents using little or no custom code.</p><p><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://cloud.google.com/blog/products/ai-machine-learning/build-generative-ai-experiences-with-vertex-ai-agent-builder?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">introduced</a>&nbsp;Vertex AI Agent Builder, a low/no-code toolkit that enables Google’s AI models to run external code and ground their responses in Google search results or custom data.<br /><br /><strong>How it works:</strong>&nbsp;Developers on Google’s Vertex AI platform can build agents and integrate them into multiple applications. The service&nbsp;<a href="https://cloud.google.com/products/agent-builder?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">costs</a>&nbsp;$12 per 1,000 queries and can use Google Search for $2 per 1,000 queries.</p><ul><li>You can set an agent’s goal in natural language (such as “You are a helpful assistant. Return your responses in markdown format.”) and provide instructions (such as “Greet the user, then ask how you can help them today”).&nbsp;</li><li>Agents can ground their outputs in external resources including information retrieved from Google’s&nbsp;<a href="https://cloud.google.com/enterprise-search?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Enterprise Search</a>&nbsp;or&nbsp;<a href="https://cloud.google.com/bigquery?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">BigQuery</a>&nbsp;data warehouse. Agents can generate a confidence score for each grounded response. These scores can drive behaviors such as enabling an agent to decide whether its confidence is high enough to deliver a given response.</li><li>Agents can use tools, including a code interpreter that enables agents to run Python scripts. For instance, if a user asks about popular tourist locations, an agent can call a tool that retrieves a list of trending attractions near the user’s location. Developers can define their own tools by providing instructions to call a function, built-in&nbsp;<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/extensions/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">extension</a>, or external API.</li><li>The system integrates custom code via the open source library<a href="https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua"><u>&nbsp;</u>LangChain</a>&nbsp;including the&nbsp;<a href="https://blog.langchain.dev/langgraph-multi-agent-workflows/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">LangGraph</a>&nbsp;extension for building multi-agent workflows. For example, if a user is chatting with a conversational agent and asks to book a flight, the agent can route the request to a subagent designed to book flights.</li></ul><p><strong>Behind the news:&nbsp;</strong>Vertex AI Agent Builder consolidates agentic features that some of Google’s competitors have rolled out in recent months. For instance, OpenAI’s&nbsp;<a href="https://platform.openai.com/docs/assistants/overview?context=with-streaming&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Assistants API</a>&nbsp;lets developers build agents that respond to custom instructions, retrieve documents (limited by file size), call functions, and access a code interpreter. Anthropic recently&nbsp;<a href="https://docs.anthropic.com/claude/docs/tool-use?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">launched</a>&nbsp;Claude Tools, which lets developers instruct Claude language models to call customized tools. Microsoft’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-extends-copilot-365-windows/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Windows Copilot</a>&nbsp;and&nbsp;<a href="https://support.microsoft.com/en-us/topic/microsoft-copilot-gpt-builder-overview-65499971-a502-4a96-a5c3-265cb59c012d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">Copilot Builder</a>&nbsp;can call functions and retrieve information using Bing search and user documents stored via Microsoft Graph.</p><p><strong>Why it matters:&nbsp;</strong>Making agents practical for commercial use can require grounding, tool use, multi-agent collaboration, and other capabilities. Google’s new tools are a step in this direction, taking advantage of investments in its hardware infrastructure as well as services such as search. As tech analyst Ben Thompson&nbsp;<a href="https://stratechery.com/2024/gemini-1-5-and-googles-nature/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua">writes</a>, Google’s combination of scale, interlocking businesses, and investment in AI infrastructure makes for a compelling synergy.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>Big-tech offerings like Vertex Agent Builder compete with an expanding universe of open source tools such as AutoGen, CrewAI, and LangGraph. The race is on to provide great agentic development frameworks!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T170803.947.png" width="1200" /></figure><h1 id="hallucination-creates-security-holes">Hallucination Creates Security Holes</h1><p>Language models can generate code that erroneously points to software packages, creating vulnerabilities that attackers can exploit.</p><p><strong>What’s new:</strong>&nbsp;A cybersecurity researcher noticed that large language models, when used to generate code, repeatedly produced a command to install a package that was not available on the specified path,&nbsp;<em>The Register</em>&nbsp;<a href="https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">reported</a>. He created a dummy package of the same name and uploaded it to that path, and developers duly installed it.<br /><br /><strong>How it works:</strong>&nbsp;Bar Lanyado, a researcher at Lasso Security, found that the erroneous command&nbsp;<em>pip install huggingface-cli</em>&nbsp;appeared repeatedly in generated code. The package&nbsp;<em>huggingface-cli</em>&nbsp;does exist, but it is installed using the command&nbsp;<em>pip install -U “huggingface_hub[cli]"</em>. The erroneous command attempts to download a package from a different repository. Lanyado published some of his findings in a&nbsp;<a href="https://www.lasso.security/blog/ai-package-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">blog post</a>.&nbsp;</p><ul><li>Lanyado uploaded a harmless package with that name. Between December 2023 and March 2024, the dummy package was downloaded more than 15,000 times. It is not clear whether the downloads resulted from generated code, mistaken advice on bulletin boards, or user error.&nbsp;</li><li>Several repositories on Github used or recommended the dummy package, including&nbsp;<a href="https://github.com/alibaba/graphtranslator?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">GraphTranslator</a>, which has been updated to remove the reference. Hugging Face itself called the package in one of its own projects; the company&nbsp;<a href="https://github.com/huggingface/diffusers/commit/56b68459f50f7d3af383a53b02e298a6532f3084?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">removed</a>&nbsp;the call after Lanyado notified it.</li><li>In research published last year, Lanyado&nbsp;<a href="https://vulcan.io/blog/ai-hallucinations-package-risk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">described</a>&nbsp;ChatGPT’s tendency to recommend a nonexistent Node.js package called arangodb. (<a href="https://arangodb.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">ArangoDB</a>&nbsp;is a real database query system, but its official Node.js package is arangojs.) Lanyado demonstrated that it was possible to create a new package with the erroneous name and install it using ChatGPT’s instructions.</li></ul><p><strong>Testing:</strong>&nbsp;Lanyado&nbsp;<a href="https://www.lasso.security/blog/ai-package-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">tested</a>&nbsp;Cohere AI’s Coral, Google’s Gemini Pro, and OpenAI’s GPT-4 and GPT-3.5. His aim was to determine how often they hallucinated packages and how often they referred repeatedly to the same hallucinated package. First he collected roughly 47,000 “how to” questions related to over 100 subjects in Go, .NET, Node.js, Python, and Ruby. Then he identified questions that produced hallucinated packages from a zero-shot prompt. He selected 20 of these questions at random and prompted each model 100 times to see whether it would refer to the same package every time.</p><ul><li>Of the models tested, Gemini Pro hallucinated packages most often, while Coral hallucinated packages most repeatedly. Here's (a) how often each model hallucinated packages and (b) how often it hallucinated the same package repeatedly. Coral: (a) 29.1 percent, (b) 24.2 percent. Gemini Pro: (a) 64.5 percent, (b) 14 percent. GPT-4: (a) 24.2 percent, (b) 19.6 percent. GPT-3.5 (a) 22.2 percent, (b) 13.6 percent.</li><li>The percentage of references to hallucinated packages also varied depending on the programming language. Using GPT-4, for example, 30.9 percent of Go queries referred to a hallucinated package compared to 28.7 percent of .NET queries, 19.3 percent of Node.js queries, 25 percent of Python queries, and 23.5 percent of Ruby queries.</li><li>Generally, Python and Node.js are more vulnerable to this type of attack than Go and .NET, which block access to certain paths and filenames. Of the Go and .NET prompts that returned a hallucinated package name, 2.9 percent and 21.2 percent were exploitable, respectively.</li></ul><p><strong>Why it matters:</strong>&nbsp;Lanyado’s method is not known to have been used in an attack, but it may be only a matter of time given its similarity to&nbsp;<a href="https://blog.gitguardian.com/protecting-your-software-supply-chain-understanding-typosquatting-and-dependency-confusion-attacks/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">hacks</a>&nbsp;like typosquatting, dependency confusion, and masquerading.</p><p><strong>We’re thinking:</strong>&nbsp;Improved AI-driven coding tools should help to address this issue. Meanwhile, the difference between a command like pip install huggingface-cli and pip install -U "huggingface_hub[cli]" is subtle. In cases like this, package providers can look out for potential doppelgangers and warn users from being misled.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-16T091800.593.png" width="1680" /></figure><p>In the short course “Quantization Fundamentals with Hugging Face,” you’ll learn how to cut the computational and memory costs of AI models through quantization. Learn to quantize nearly any open source model!&nbsp;<a href="https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Join today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T171422.978.gif" width="600" /></figure><h1 id="gpt-store-shows-lax-moderation">GPT Store Shows&nbsp;Lax Moderation</h1><p>OpenAI has been moderating its GPT Store with a very light touch.</p><p><strong>What’s new:</strong>&nbsp;In a survey of the GPT Store’s offerings,&nbsp;<em>TechCrunch</em>&nbsp;<a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">found</a>&nbsp;numerous examples of custom ChatGPT instances that appear to violate the store’s own&nbsp;<a href="https://openai.com/policies/usage-policies?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">policies</a>.</p><p><strong>How it works:</strong>&nbsp;The GPT Store has a low bar for entry by design — any paid ChatGPT user can create a custom-prompted variation of the chatbot, known as a GPT, and include it in the store. The store lists GPTs in several categories, such as Writing, Productivity, Programming, and Lifestyle. While many are useful, some are questionable.</p><ul><li>Some GPTs purported to jailbreak ChatGPT. In&nbsp;<em>TechCrunch</em>’s survey, some of them were able to circumvent OpenAI’s own guardrails. Since then, they have been tamed. The GPT Store’s terms of use prohibit efforts to thwart OpenAI’s safeguards and safety measures.</li><li>GPTs like Humanizer Pro, the second-ranked instance in the Writing category at the time of writing, purport to rewrite text and make it undetectable to programs designed to detect generated text. These GPTs may violate OpenAI’s ban on GPTs that enable academic dishonesty.</li><li>Many GPTs purport to allow users to chat with trademarked characters without clear authorization from the trademark owners. The store prohibits use of content owned by third parties without their permission.</li><li>Other GPTs purport to represent real-life figures such as Elon Musk, Donald Trump, and Joe Rogan, or companies such as Microsoft and Apple (many of them obviously satirical). OpenAI allows GPTs to respond in the style of a real person if they do not impersonate that person. However, many such GPTs don’t indicate that they are not associated with the genuine person.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;OpenAI&nbsp;<a href="https://www.deeplearning.ai/the-batch/openai-releases-the-gpt-store-a-curated-chatbot-marketplace/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">launched</a>&nbsp;the GPT Store in January. Since then, users have uploaded more than 3 million GPTs that include enhanced search engines, creative writing aids, and tools that produce short videos. The most popular GPTs have millions of downloads. Despite its “store” name, the GPT Store’s contents are free to download. OpenAI is&nbsp;<a href="https://help.openai.com/en/articles/9119255-monetizing-your-gpt-faq?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">piloting</a>&nbsp;a program in which U.S.-based uploaders of popular GPTs can earn money.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The GPT Store is the chatbot era’s answer to Apple’s App Store or Android’s Google Play Store. If it succeeds, it could democratize chatbot development just as the App Store helped to popularize building smartphone applications. How OpenAI moderates the store may have real financial and reputational impacts on developers in the years ahead.<br /><br /><strong>We’re thinking:</strong>&nbsp;The GPT Store’s low barrier to entry is a boon to well-meaning developers, but it may encourage less responsible actors to take advantage of lax moderation. We applaud OpenAI’s willingness to execute an ambitious vision and hope it finds a workable balance.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-17T171539.453.gif" width="600" /></figure><h1 id="tuning-llms-for-better-rag">Tuning LLMs for Better RAG</h1><p>Retrieval-augmented generation (RAG) enables large language models to generate better output by retrieving documents that are relevant to a user’s prompt. Fine-tuning further improves RAG performance.</p><p><strong>What’s new:</strong>&nbsp;Xi Victoria Lin, Xilun Chen, Mingda Chen, and colleagues at Meta proposed&nbsp;<a href="https://arxiv.org/abs/2310.01352?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">RA-DIT</a>, a fine-tuning procedure that trains an LLM and retrieval model together to improve the LLM’s ability to capitalize on retrieved content.</p><p><strong>Retrieval augmented generation (RAG) basics:</strong>&nbsp;When a user prompts an LLM, RAG supplies documents that are relevant to the prompt. A separate retrieval model computes the probability that each chunk of text in a separate dataset is relevant to the prompt. Then it grabs the chunks with the highest probability and provides them to the LLM to append to the prompt. The LLM generates each token based on the chunks plus the prompt and tokens generated so far.</p><p><strong>Key insight:</strong>&nbsp;Typically LLMs are not exposed to retrieval-augmented inputs during pretraining, which limits how well they can use retrieved text to improve their output.&nbsp;<a href="https://proceedings.mlr.press/v119/guu20a.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Such</a>&nbsp;<a href="https://proceedings.mlr.press/v162/borgeaud22a.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">methods</a>&nbsp;have been proposed, but they’re costly because they require processing a lot of data. A more data-efficient, and therefore compute-efficient, approach is to (i) fine-tune the LLM to better use retrieved knowledge and then (ii) fine-tune the retrieval model to select more relevant text.</p><p><strong>How it works:</strong>&nbsp;The authors fine-tuned&nbsp;<a href="https://arxiv.org/abs/2307.09288?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">Llama 2</a>&nbsp;(65 billion parameters) and&nbsp;<a href="https://arxiv.org/abs/2302.07452?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">DRAGON+</a>, a retriever. They call the system RA-DIT 65B.</p><ul><li>The authors fine-tuned Llama 2 on prompts that consist of retrieved text and a question or instruction. They used 20 datasets including&nbsp;<a href="https://arxiv.org/abs/2304.0732?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">dialogue</a>,&nbsp;<a href="https://huggingface.co/datasets/yahoo_answers_qa?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">question-answering</a>,&nbsp;<a href="https://arxiv.org/abs/1806.03822?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">answering questions about a given text passage</a>,&nbsp;<a href="https://proceedings.neurips.cc/paper/2015/hash/afdec7005cc9f14302cd0474fd0f3c96-Abstract.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">summarization</a>, and datasets in which the model must answer questions and&nbsp;<a href="https://aclanthology.org/P17-1015/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">explain its reasoning</a>.&nbsp;</li><li>They fine-tuned DRAGON+’s encoder to increase the probability that it retrieved a given chunk if the chunk improved the LLM’s chance of generating the correct answer. Fine-tuning was supervised for the tasks listed above. Fine-tuning was self-supervised for completion of&nbsp;<a href="https://arxiv.org/abs/2208.03299?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">37 million text chunks</a>&nbsp;from Wikipedia and 362 million text chunks from&nbsp;<a href="https://commoncrawl.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">CommonCrawl</a>.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;On average, across four collections of questions from datasets such as&nbsp;<a href="https://arxiv.org/abs/2009.03300?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">MMLU</a>&nbsp;that cover topics like elementary mathematics, United States history, computer science, and law, RA-DIT 65B achieved 49.1 percent accuracy, while the combination of LLaMA 2 65B and DRAGON+ without fine-tuning achieved 45.1 percent accuracy, and LLaMA 2 65B without retrieval achieved 32.9 percent accuracy. When the input included five examples that showed the model how to perform the task, RA-DIT 65B achieved 51.8 percent accuracy, LLaMA 2 65B combined with DRAGON+ achieved 51.1 percent accuracy, and LLaMA 2 65B alone achieved 47.2 percent accuracy. On average, over eight common-sense reasoning tasks such as&nbsp;<a href="https://arxiv.org/abs/1803.05457?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8TZzur2df1qdnGx09b-Fg94DTsc3-xXao4StKvKNU2HR51el3n8yOm0CPSw6GiAoLQNKua" rel="noopener">ARC-C</a>, which involves common-sense physics such as the buoyancy of wood, RA-DIT 65B achieved 74.9 percent accuracy, LLaMA 2 65B with DRAGON+ achieved 74.5 percent accuracy, and LLaMA 2 achieved 72.1 percent accuracy.</p><p><strong>Why it matters:</strong>&nbsp;This method offers an inexpensive way to improve LLM performance with RAG.</p><p><strong>We’re thinking:</strong>&nbsp;Many developers have found that putting more effort into the retriever, to make sure it provides the most relevant text, improves RAG performance. Putting more effort into the LLM helps, too.</p><hr /><h1 id="data-points">Data Points</h1><p>In this week’s <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, find new model and feature releases from Google, Microsoft, Mistral, OpenAI, and Spotify, plus AI art projects and government investments.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-245/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read your short-form digest of this week’s AI news now</a></p>
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 22:19:54 GMT</pubDate>
</item>
<item>
<title>Autonomous Coding Agents, Instability at Stability AI, Mamba Mania, What Users Do With GenAI</title>
<link>https://www.deeplearning.ai/the-batch/issue-244</link>
<guid>https://www.deeplearning.ai/the-batch/issue-244</guid>
<content:encoded><![CDATA[
<div> 关键词: Planning, AI Agentic moment, large language models (LLMs), tasks, coding agents.

总结:
Planning is an important aspect of using large language models (LLMs) to accomplish tasks. It allows an agent to break down a larger task into smaller subtasks and decide on the steps to execute. The article highlights the author's surprise when an agent autonomously switched to a different search tool during a live demo, showcasing the AI Agentic moment. Planning enables agents to dynamically decide on the steps to take, making it a powerful capability. However, it can also lead to less predictable results. The article also mentions the emergence of coding agents, which automate programming tasks, and the common uses of generative AI, such as brainstorming and text editing. Furthermore, it discusses the challenges faced by Stability AI and introduces an alternative architecture called Mamba, which improves upon transformers. <div>
<p>Dear friends,</p><p>Planning is a key&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">agentic AI design pattern</a>&nbsp;in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute to accomplish a larger task. For example, if we ask an agent to do online research on a given topic, we might use an LLM to break down the objective into smaller subtasks, such as researching specific subtopics, synthesizing findings, and compiling a report.&nbsp;</p><p>Many people had a “ChatGPT moment” shortly after ChatGPT was released, when they played with it and were surprised that it significantly exceeded their expectation of what AI can do. If you have not yet had a similar “AI Agentic moment,” I hope you will soon. I had one several months ago, when I presented a live demo of a research agent I had implemented that had access to various online search tools.&nbsp;</p><p>I had tested this agent multiple times privately, during which it consistently used a web search tool to gather information and wrote up a summary. During the live demo, though, the web search API unexpectedly returned with a rate limiting error. I thought my demo was about to fail publicly, and I dreaded what was to come next. To my surprise, the agent pivoted deftly to a Wikipedia search tool — which I had forgotten I’d given it — and completed the task using Wikipedia instead of web search.&nbsp;</p><p>This was an AI Agentic moment of surprise for me. I think many people who haven’t experienced such a moment yet will do so in the coming months. It’s a beautiful thing when you see an agent autonomously decide to do things in ways that you had not anticipated, and succeed as a result!</p><p>Many tasks can’t be done in a single step or with a single tool invocation, but an agent can decide what steps to take. For example, to simplify an example from the HuggingGPT paper (cited below), if you want an agent to consider a picture of a boy and draw a picture of a girl in the same pose, the task might be decomposed into two distinct steps: (i) detect the pose in the picture of the boy and (ii) render a picture of a girl in the detected pose. An LLM might be fine-tuned or prompted (with few-shot prompting) to specify a plan by outputting a string like&nbsp;<em>"{tool: pose-detection, input: image.jpg, output: temp1 } {tool: pose-to-image, input: temp1, output: final.jpg}"</em>.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T140722.194.png" width="1200" /></figure><p>This structured output, which specifies two steps to take, then triggers software to invoke a pose detection tool followed by a pose-to-image tool to complete the task. (This example is for illustrative purposes only; HuggingGPT uses a different format.)&nbsp;</p><p>Admittedly, many agentic workflows do not need planning. For example, you might have an agent reflect on, and improve, its output a fixed number of times. In this case, the sequence of steps the agent takes is fixed and deterministic. But for complex tasks in which you aren’t able to specify a decomposition of the task into a set of steps ahead of time, Planning allows the agent to decide dynamically what steps to take.&nbsp;</p><p>On one hand, Planning is a very powerful capability; on the other, it leads to less predictable results. In my experience, while I can get the agentic design patterns of&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Reflection</a>&nbsp;and&nbsp;<a href="http://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Tool use</a>&nbsp;to work reliably and improve my applications’ performance, Planning is a less mature technology, and I find it hard to predict in advance what it will do. But the field continues to evolve rapidly, and I'm confident that Planning abilities will improve quickly.&nbsp;</p><p>If you’re interested in learning more about Planning with LLMs, I recommend:</p><ul><li>“<a href="https://arxiv.org/abs/2201.11903?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>,” Wei et al. (2022)</li><li>“<a href="https://arxiv.org/abs/2303.17580?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a>,” Shen et al. (2023)</li><li>“<a href="https://arxiv.org/pdf/2402.02716.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Understanding the planning of LLM agents: A survey</a>,” by Huang et al. (2024)</li></ul><p>Keep learning!<br /><br />Andrew<br /><br />P.S. Making sure your RAG system has access to the data it needs to answer questions is an important, but often laborious, step for good performance. Our new short course “Preprocessing Unstructured Data for LLM Applications,” taught by Matt Robinson of Unstructured, teaches you how to build systems that can easily ingest data from a wide range of formats (like text, images, and tables) and from many different sources (like PDF, PowerPoint, and HTML). You’ll learn practical ways to extract and normalize content from diverse formats, enrich your content with metadata to enable more powerful retrieval and reasoning, and use document layout analysis and vision transformers to process embedded images and tables. Putting these components together, you’ll build a RAG bot that draws from multiple document types, demonstrating how high-quality data ingestion and preprocessing affect the quality of RAG output. <a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Sign up here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/DEVIN-PLUS-v6_1200px.gif" width="1200" /></figure><h1 id="coding-agents-proliferate">Coding Agents Proliferate</h1><p>New coding tools act like agents to automate software programming tasks.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;A wave of open source software-development tools based on large language models take advantage of the ability of large language models to plan, critique their own work, and extend themselves by calling functions.&nbsp;</p><p><strong>How it works:</strong>&nbsp;These projects follow hot on the heels of Cognition’s&nbsp;<a href="https://www.cognition-labs.com/introducing-devin?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Devin</a>, a commercial system billed as a semi-autonomous software developer that’s available to selected customers upon request. Some, like Devin, provide sandboxed chat for natural-language commands, command line shell, code editor, and/or a web browser through which the agent can test code or find documentation. Given a prompt, they generate a step-by-step plan and execute it. They may ask for further information or instructions, and users can interrupt to modify their requests.&nbsp;</p><ul><li><a href="https://github.com/stitionai/devika?tab=readme-ov-file&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY#readme" rel="noopener">Devika</a>&nbsp;uses Anthropic’s Claude 3, OpenAI’s GPT-4 and GPT-3.5, and models supported by&nbsp;<a href="https://ollama.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Ollama</a>, a tool that runs large language models locally. Like Devin, Devika runs in a web browser and includes an agent that performs planning and reasoning. A persistent knowledge base and database recalls active projects.</li><li><a href="https://github.com/opendevin/opendevin?tab=readme-ov-file&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY#readme" rel="noopener">OpenDevin</a>&nbsp;is based on GPT-4 but has access to more than 100 models via&nbsp;<a href="https://github.com/BerriAI/litellm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">litellm</a>, a package that simplifies API calls. OpenDevin’s developers aim to match Devin’s user interface and enable the system to evaluate its own accuracy.&nbsp;</li><li><a href="https://swe-agent.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">SWE-agent</a>&nbsp;addresses bugs and issues in Github repositories. It can use any language model. Using GPT-4, it resolved 12.3 percent of tasks in the&nbsp;<a href="https://www.swebench.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">SWE-bench</a>&nbsp;dataset of real-world GitHub issues. (Devin&nbsp;<a href="https://www.cognition-labs.com/post/swe-bench-technical-report?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">resolved</a>&nbsp;13.9 percent of SWE-bench tasks. Claude 3, the highest-scoring model not specifically trained for coding, resolved 4.8 percent of SWE-bench tasks.)</li></ul><p><strong>Behind the News:&nbsp;</strong>Code-completion tools like Github Copilot and Code Llama quickly have become&nbsp;<a href="https://www.deeplearning.ai/the-batch/code-generation-services-took-off-in-2022?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">ubiquitous</a>.&nbsp;<a href="https://docs.agpt.co/autogpt/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">AutoGPT</a>, released in 2023, is an open-source generalist AI agent based on GPT-4 that has been used to write and debug code. Recently Replit, known for its Ghostwriter code-completion and chatbot applications, began building&nbsp;<a href="https://blog.replit.com/code-repair?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">its own LLMs</a>&nbsp;for automated code repair.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Agentic coding tools are distinguished by&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">techniques</a>&nbsp;that enable large language models to plan, reflect on their work, call tools, and collaborate with one another. Users&nbsp;<a href="https://leaddev.com/process/what-devin-and-can-it-really-replace-developers?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">report</a>&nbsp;that, unlike previous coding assistants, the new tools are better at sustaining extended tasks and correcting their own work.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Many software developers worry that large language models will make human coders obsolete. We doubt that AI will replace coders, but we believe that coders who use AI will replace those who don’t. Agent-based tools still have a long way to go, but they seem likely to augment programmers’ abilities in a larger development pipeline.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141020.606.png" width="1200" /></figure><h1 id="what-users-do-with-generative-ai">What Users Do With Generative AI</h1><p>Generative AI is being used mostly to generate ideas.</p><p><strong>What’s new:</strong>&nbsp;The tech consultancy Filtered&nbsp;<a href="https://hbr.org/2024/03/how-people-are-really-using-genai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">studied</a>&nbsp;the most common uses for generative AI. While most gen AI users produced text, the study surprisingly found that users were slightly more likely to generate videos than images.<br /><br /><strong>How it works:&nbsp;</strong>The analysts sifted through tens of thousands of posts on popular online forums for anecdotes that described uses of generative AI. The analysts grouped the posts into a list of 100 most popular uses of generative AI and ranked each one by reach and value added.&nbsp;</p><ul><li>Most often, individuals used generative AI as an aid to brainstorming, both at work and otherwise. They also turned to generative AI for specific suggestions, like recommending movies, suggesting holiday destinations, and generating characters for role-playing games.</li><li>Other uses in the top five: text editing, emotional support, deep dives into niche subjects, and searching for information. (One poster used a chatbot to track down the brand of cookie his grandmother liked.)</li><li>Many users employed generative AI to revise their own work, for example troubleshooting or optimizing code, editing emails before sending them, improving marketing copy, or tweaking images.</li><li>Workplace-related uses included drafting cover letters, creating notes in preparation for meetings, summarizing meetings after they happened, and analyzing sales data. Many students found generative AI useful as a learning aid to review course materials or create personalized ways to learn.</li><li>Many users found that generative AI helped them better understand technical information, such as legal advice or medical expertise. Users relied on chatbots for tasks that might have required them to consult a human expert, like drafting legal complaints, summarizing jargon-filled documents, and seeking information on medical test results.</li></ul><p><strong>Behind the news:</strong>&nbsp;The range of use cases reflects the huge number of people, from all walks of life and all parts of the world, who are using generative AI tools. In a given week in November 2023, more than 100 million people&nbsp;<a href="https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">used</a>&nbsp;ChatGPT, the most popular of these tools. Independently, in February 2024, Pew Research&nbsp;<a href="https://www.pewresearch.org/short-reads/2024/03/26/americans-use-of-chatgpt-is-ticking-up-but-few-trust-its-election-information/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">found</a>&nbsp;that 23 percent of U.S. adults had used ChatGPT at least once, including 43 percent of respondents under 30 years old and 37 percent of those with postgraduate degrees. According to the Pew report, 20 percent of all Americans had used ChatGPT for work, and 17 percent had used it for entertainment, with younger and more educated users leading the way.<br /><br /><strong>Why it matters:</strong>&nbsp;It’s clear that millions of people use generative AI but less clear how they use it. Understanding how and where they actually apply it is helpful for anyone who aims to develop new generative AI products and services or plans to integrate the tech into their organization.</p><p><strong>We’re thinking:</strong>&nbsp;While it’s encouraging that more than a fifth of U.S. adults have tried ChatGPT,&nbsp; it also suggests huge room for growth in generative AI at large.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-09T091357.311.png" width="1680" /></a></figure><p>Integrate diverse data types into your LLM applications in our new short course built in collaboration with Unstructured. Learn techniques to extract and normalize data from PDFs, tables, and images into a structured format.&nbsp;<a href="https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Sign up today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141216.341.gif" width="1200" /></figure><h1 id="instability-at-stability-ai">Instability at Stability AI</h1><p>The CEO of Stability AI resigned as the company faces an increasingly competitive market.</p><p><strong>What’s new:</strong>&nbsp;Emad Mostaque stepped down from Stability AI, developer of the Stable Diffusion image generator among other models, amid financial woes, uncertain direction, and sinking confidence from investors and employees alike,&nbsp;<em>Forbes</em>&nbsp;<a href="https://www.forbes.com/sites/kenrickcai/2024/03/29/how-stability-ais-founder-tanked-his-billion-dollar-startup/?sh=2e53d2e3e630&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">reported</a>. Mostaque’s departure followed the exits of numerous executives and key employees.</p><p><strong>How it works:&nbsp;</strong>Stability&nbsp;<a href="https://stability.ai/news/stabilityai-announcement?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">confirmed</a>&nbsp;Mostaque’s departure in a blog post. The company’s chief operating officer Shan Shan Wong and chief technology officer Christian Laforte will act as co-CEOs until its directors find a permanent replacement. They inherit a company with troubles beyond leadership.&nbsp;</p><ul><li>Stability faces serious cash-flow issues. In 2023, it projected $11 million in revenue against $153 million in costs. Currently it&nbsp;<a href="https://www.ft.com/content/d7bbb769-20f1-4242-bd15-201741c90720?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">spends</a>&nbsp;$8 million monthly compared to revenue of $3 million in November and $5.4 million in February.</li><li>The company’s bill for processing power provided by Amazon Web Services, Google, and CoreWeave amounts to $99 million annually. It often failed to pay on time. Stability contemplated reselling access to its leased GPUs to make up for its revenue shortfall.</li><li>Stability struggled to commercialize its models. It tried to strike deals with companies such as Samsung, Snap, and Canva and governments such as Singapore, but the parties couldn’t agree on terms.</li><li>Throughout 2023, it tried to raise funds by courting investors like Nvidia and Google. Negotiations failed partly over questions about the company’s finances. Ultimately it sought a buyer, but no deal emerged.</li><li>Stability faces unpredictable liabilities due to&nbsp;<a href="https://www.deeplearning.ai/the-batch/artists-file-a-lawsuit-against-stability-ai-and-midjourney/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">lawsuits</a>&nbsp;over its alleged use of copyrighted images as training data and its models’ ability to produce images in the styles of human artists.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;Despite its troubles, Stability continued to release new models. In February, it&nbsp;<a href="https://stability.ai/news/stable-diffusion-3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">opened</a>&nbsp;the waitlist for the third-generation version of Stable Diffusion. Last month, it&nbsp;<a href="https://stability.ai/news/introducing-stable-video-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">released</a>&nbsp;Stable Video 3D, a project in which the team produced three-dimensional objects from images. This month, it&nbsp;<a href="https://stability.ai/news/stable-audio-2-0?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">released</a>&nbsp;Stable Audio 2.0, which can produce music files up to three minutes long from a text prompt.<br /><br /><strong>Why it matters:</strong>&nbsp;Stability has been a standard bearer for open-source AI in a field where tech giants aim to dominate with closed models. Effective leadership could have a major impact on the models available to developers in the years ahead.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Stability helped capture the public imagination during the generative AI boom of 2022, and its open models, particularly its diffusion models, have been a huge benefit to the AI community. We hope new leadership puts the company on firm footing.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-10T141759.545.gif" width="1200" /></figure><h1 id="a-transformer-alternative-emerges">A Transformer Alternative Emerges</h1><p>An architectural innovation improves upon transformers — up to 2 billion parameters, at least.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Albert Gu at Carnegie Mellon University and Tri Dao at Princeton University developed the&nbsp;<a href="https://arxiv.org/abs/2312.00752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Mamba</a>&nbsp;architecture, a refinement of the earlier state space sequence architecture. A relatively small Mamba produced tokens five times faster and achieved better accuracy than a vanilla transformer of similar size while processing input up to a million tokens long.</p><p><strong>Structured State Space Sequence (S4) basics:</strong>&nbsp;<a href="https://arxiv.org/abs/2111.00396?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">S4s</a>, also known as structured SSMs, can be functionally similar to recurrent neural networks (RNNs): They can accept one token at time and produce a linear combination of the current token and an embedding that represents all previous tokens. Unlike RNNs and their extensions including LSTMs — but like transformers — they can also perform an equivalent computation in parallel during training. In addition, they are more computationally efficient than transformers. An S4’s computation and memory requirements rise linearly with input size, while a vanilla transformer’s rise quadratically — a heavy burden with long input sequences.</p><p><strong>Key insight:</strong>&nbsp;S4s are more efficient than transformers but, while a transformer’s input length is limited only by processing and memory, an S4’s input length is limited by how well its hidden state can represent previously input tokens as new tokens arrive. A&nbsp;<a href="https://arxiv.org/abs/1612.08083?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">gating mechanism</a>&nbsp;that lets the model process the most important parts of an input and ignore the rest can enable it to process longer inputs. One viable gate: Typically S4s apply the same mathematical function to all input tokens, whose parameters consist of four learned matrices. Changing the matrices for each input enables the model to learn which tokens or parts of tokens are least important and can be ignored (set to zero). This condenses the input, enabling the modified S4 to process very long input sequences.</p><p><strong>How it works:</strong>&nbsp;Mamba is made up of blocks, each of which includes a modified S4 (which the authors call a selective SSM). The authors pretrained different instances on a variety of tasks including generating tokens from&nbsp;<a href="https://arxiv.org/abs/2101.00027?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">The Pile</a>&nbsp;(a collection of text from the web) and predicting DNA base pairs in&nbsp;<a href="https://www.nature.com/articles/s41592-021-01252-x?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HG38</a>&nbsp;(a single human genome) in sequences up to 1 million tokens long.&nbsp;</p><ul><li>In each block, the authors replaced three of the S4’s four fixed matrices with learned linear functions of the input. That is, they replaced each of three learned matrices with a learned matrix multiplied by the input. (The authors hypothesized that modifying the fourth matrix would not help, so they didn’t change it.)</li><li>The following layer multiplied the model’s output with a linear projection of the block’s input. This acted as a gate to filter out irrelevant parts of the embedding.</li></ul><p><strong>Results:</strong>&nbsp;Mamba achieved better speed and accuracy than transformers of similar size, including tasks that involved inputs of 1 million tokens.&nbsp;</p><ul><li>Running on an Nvidia A100 GPU with 80GB, a Mamba of 1.4 billion parameters produced 1,446 tokens per second, while a transformer of 1.3 billion parameters produced 344 tokens per second.</li><li>In sizes from 130 million parameters to 2.8 billion parameters, Mamba outperformed the transformer&nbsp;<a href="https://arxiv.org/abs/2304.01373?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Pythia</a>&nbsp;and the S4&nbsp;<a href="https://arxiv.org/abs/2212.14052?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">H3</a>&nbsp;on many tasks. It was better at predicting the next word of The Pile, and it was better at question-answering tasks such as&nbsp;<a href="https://arxiv.org/abs/1907.10641?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">WinoGrande</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/1905.07830?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">HellaSwag</a>. For instance, on WinoGrande, using models of roughly 2.8 billion parameters, Mamba achieved 63.5 percent accuracy, Pythia 59.7 percent accuracy, and H3 61.4 percent accuracy.&nbsp;</li><li>After fine-tuning on Great Apes DNA Classification (classifying DNA segments up to 1 million tokens long as belonging to one of five species of great ape), using models of 1.4 million parameters, Mamba achieved 70 percent accuracy, while&nbsp;<a href="https://arxiv.org/abs/2306.15794?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Hyena DNA</a>&nbsp;achieved 55 percent accuracy.</li></ul><p><strong>Yes, but:</strong>&nbsp;The authors tested model sizes much smaller than current state-of-the-art large language models.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Google’s transformer-based Gemini 1.5 Pro offers context lengths up to 1 million tokens, but methods for building such models aren’t yet widely known. Mamba provides an alternative architecture that can accommodate very long input sequences while processing them more efficiently. Whether it delivers compelling benefits over large transformers and variations that provide higher efficiency and larger context is a question for further research</p><p><strong>We're thinking:</strong>&nbsp;Research on Mamba is gaining momentum. Other teams are probing the architecture in projects like&nbsp;<a href="https://arxiv.org/abs/2403.07487?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Motion Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.09417?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Vision Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.04081?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">MoE-Mamba</a>,&nbsp;<a href="https://arxiv.org/abs/2401.13660?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">MambaByte</a>, and&nbsp;<a href="https://arxiv.org/abs/2403.19887?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY" rel="noopener">Jamba</a>.</p><hr /><h1 id="data-points">Data Points</h1><p>Read <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> to find the latest AI updates of the week, including:&nbsp;</p><p>👉 Advanced new editing tools by DALL·E<br />👉 Command R+, a new LLM by Cohere<br />👉 An update on big tech's hunt for AI training</p><p>And more!&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-244/?ref=dl-staging-website.ghost.io" rel="noreferrer">Check out Data Points now.</a></p>
]]></content:encoded>
<pubDate>Wed, 10 Apr 2024 19:58:19 GMT</pubDate>
</item>
<item>
<title>Microsoft Absorbs Inflection, Nvidia's New GPUs, Managing AI Bio Risk, More Factual LLMs</title>
<link>https://www.deeplearning.ai/the-batch/issue-243</link>
<guid>https://www.deeplearning.ai/the-batch/issue-243</guid>
<content:encoded><![CDATA[
<div> GPT-4, LLM, tool use, Inflection AI, Microsoft<br />
工具使用是LLM的关键设计模式，允许LLM调用函数以获取信息、执行操作或操作数据。Inflection AI被微软收购并加入Microsoft AI，注重大型企业客户。Nvidia发布了新一代AI芯片，提高了AI的速度和能源效率。科学家承诺控制使用能够设计蛋白质的AI生成模型的风险。研究人员提出了一种方法来提高LLM的事实性输出。总结：LLM工具使用 <div>
<p>Dear friends,</p><p>Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design pattern of&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">AI agentic workflows</a>. You may be familiar with LLM-based systems that can perform a web search or execute code. Indeed, some of the large, consumer-facing LLMs already incorporate these features. But tool use goes well beyond these examples.&nbsp;<br /><br />If you prompt an online LLM-based chat system, “What is the best coffee maker according to reviewers?”, it might decide to carry out a web search and download one or more web pages to gain context. Early on, LLM developers realized that relying only on a pre-trained transformer to generate output tokens is limiting, and that giving an LLM a tool for web search lets it do much more. With such a tool, an LLM is either fine-tuned or prompted (perhaps with few-shot prompting) to generate a special string like {tool: web-search, query: "coffee maker reviews"} to request calling a search engine. (The exact format of the string depends on the implementation.) A post-processing step then looks for strings like these, calls the web search function with the relevant parameters when it finds one, and passes the result back to the LLM as additional input context for further processing.&nbsp;</p><p>Similarly, if you ask, “If I invest $100 at compound 7% interest for 12 years, what do I have at the end?”, rather than trying to generate the answer directly using a transformer network — which is unlikely to result in the right answer — the LLM might use a code execution tool to run a Python command to compute 100 * (1+0.07)**12 to get the right answer. The LLM might generate a string like this: {tool: python-interpreter, code: "100 * (1+0.07)**12"}.&nbsp;</p><p>But tool use in agentic workflows now goes much further. Developers are using functions to search different sources (web, Wikipedia, arXiv, etc.), to interface with productivity tools (send email, read/write calendar entries, etc.), generate or interpret images, and much more. We can prompt an LLM using context that gives detailed descriptions of many functions. These descriptions might include a text description of what the function does plus details of what arguments the function expects. And we’d expect the LLM to automatically choose the right function to call to do a job.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/04/TOOL-USE-3.png" width="1200" /></figure><p>Further, systems are being built in which the LLM has access to hundreds of tools. In such settings, there might be too many functions at your disposal to put all of them into the LLM context, so you might use heuristics to pick the most relevant subset to include in the LLM context at the current step of processing. This technique, which is described in the Gorilla paper cited below, is reminiscent of how, if there is too much text to include as context, retrieval augmented generation (RAG) systems offer heuristics for picking a subset of the text to include.&nbsp;</p><p>Early in the history of LLMs, before widespread availability of large multimodal models (LMMs) &nbsp;like LLaVa, GPT-4V, and Gemini, LLMs could not process images directly, so a lot of work on tool use was carried out by the computer vision community. At that time, the only way for an LLM-based system to manipulate an image was by calling a function to, say, carry out object recognition or some other function on it. Since then, practices for tool use have exploded. GPT-4’s function calling capability, released in the middle of last year, was a significant step toward general-purpose tool use. Since then, more and more LLMs are being developed to similarly be facile with tool use.&nbsp;</p><p>If you’re interested in learning more about tool use, I recommend:&nbsp;</p><ul><li>“<a href="https://arxiv.org/abs/2305.15334?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Gorilla: Large Language Model Connected with Massive APIs</a>,” Patil et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2303.11381?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action</a>,” Yang et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2401.17464?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Efficient Tool Use with Chain-of-Abstraction Reasoning</a>,” Gao et al. (2024)&nbsp; &nbsp;</li></ul><p>Both Tool Use and Reflection, which I described in last week’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">letter</a>, are design patterns that I can get to work fairly reliably on my applications — both are capabilities well worth learning about. In future letters, I’ll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies.&nbsp;<br /><br />Keep learning!</p><p>Andrew</p><p>P.S. Learn to carry out red-teaming attacks against your own LLM-based applications to spot and patch vulnerabilities! In our new short course, “Red Teaming LLM Applications,” Matteo Dora and Luca Martial of LLM testing company Giskard teach how to simulate malicious actions to discover vulnerabilities and improve security. We start with prompt injection, which can trick an LLM into bypassing safeguards to reveal private information or say something inappropriate. There is no one-size-fits-all approach to security, but this course will help you identify some scenarios to protect against.</p><p>We believe that widespread knowledge of red-teaming capabilities will result in greater transparency and safer LLM-based systems. However, we ask you to use the skills you gain from this course ethically.</p><p><a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Sign up here</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed--56-.jpg" width="1200" /></figure><h1 id="microsoft-absorbs-inflection">Microsoft Absorbs Inflection</h1><p>Microsoft took over most of the once high-flying chatbot startup Inflection AI in an unusual deal.</p><p><strong>What’s new:&nbsp;</strong>Microsoft hired Inflection CEO Mustafa Suleyman and much of the startup’s staff and paid roughly $650 million for access to its models and legal protections,&nbsp;<em>Bloomberg</em>&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-03-21/microsoft-to-pay-inflection-ai-650-million-after-scooping-up-most-of-staff?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">reported</a>. Inflection will&nbsp;<a href="https://inflection.ai/the-new-inflection?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">shift</a>&nbsp;from serving consumers to focusing on large companies.<br /><br /><strong>How it works:&nbsp;</strong>Microsoft did not formally purchase any assets of Inflection, which remains a separate, independent company. $650 million is significantly less than the $1.3 billion in investment that Inflection&nbsp;<a href="https://techcrunch.com/2023/06/29/inflection-ai-lands-1-3b-investment-to-build-more-personal-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">received</a>&nbsp;last year at a $4 billion valuation.</p><ul><li>Microsoft paid $620 million for a non-exclusive license to serve Inflection’s models, including the&nbsp;<a href="https://inflection.ai/inflection-2-5?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Inflection-2.5</a>&nbsp;large language model, which will be available on the Microsoft Azure cloud service. Inflection said APIs will be available soon on Azure and other services.</li><li>Microsoft hired most of Inflection’s 70-person staff, including Suleyman and co-founder Karén Simonyan. The ex-Inflection hires joined a new Microsoft division&nbsp;<a href="https://blogs.microsoft.com/blog/2024/03/19/mustafa-suleyman-deepmind-and-inflection-co-founder-joins-microsoft-to-lead-copilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">called</a>&nbsp;Microsoft AI. Inflection waived legal rights related to Microsoft’s hiring activity in return for a roughly $30 million payment.</li><li>Inflection will use its gains plus cash on hand to compensate its investors at $1.10 or $1.50 per dollar invested. Investors will retain their equity in Inflection.</li><li>The new organization, which includes some of Microsoft’s prior AI teams, will oversee the company’s AI efforts. Microsoft AI will develop and deploy consumer AI products like the Bing search engine and the company’s various Copilot assistants. Former Bing chief Mikhail Parakhin, who would have reported to Suleyman,&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-03-26/microsoft-bing-chief-exiting-role-after-suleyman-named-ai-leader?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">departed</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;Inflection was co-founded in 2022 by Suleyman (a founder of DeepMind, now a division of Google), Simonyan, and LinkedIn chairman Reed Hoffman with funding partly from Microsoft. The startup initially positioned itself as a competitor to OpenAI and Anthropic, seeking to develop AI assistants for consumers. Its flagship product was&nbsp;<a href="https://www.nytimes.com/2023/05/03/technology/personaltech/ai-chatbot-pi-emotional-support.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Pi</a>, a chatbot trained to provide emotional support. Microsoft CEO Satya Nadella began courting Suleyman several months ago, and Suleyman wanted to bring Inflection’s staff along with him. Microsoft made a similar offer to OpenAI in November, during that company’s leadership&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">shakeup</a>, when the tech giant proposed hiring briefly-ousted CEO Sam Altman and many of his co-workers to staff a new organization at Microsoft.</p><p><strong>Yes, but:</strong>&nbsp;The unusual nature of the deal — with Microsoft absorbing most of Inflection’s staff while leaving the startup intact as a company — may have been&nbsp;<a href="https://www.ft.com/content/4fd00a0e-3d5c-4e73-90a4-46abe5b5d40f?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">designed</a>&nbsp;to avoid the antitrust scrutiny that comes with acquisitions. The deal doesn’t automatically trigger a&nbsp;<a href="https://www.ftc.gov/advice-guidance/competition-guidance/guide-antitrust-laws/mergers/premerger-notification-merger-review-process?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">review</a>&nbsp;by U.S. regulators because Microsoft did not acquire Inflection assets. Microsoft’s close relationship with OpenAI has attracted attention from regulators in the&nbsp;<a href="https://www.politico.com/news/2024/01/19/doj-ftc-microsoft-openai-antitrust-00136624?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">U.S.</a>,&nbsp;<a href="https://www.gov.uk/government/news/cma-seeks-views-on-microsofts-partnership-with-openai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">UK</a>, and&nbsp;<a href="https://ec.europa.eu/commission/presscorner/detail/en/mex_24_101?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">EU</a>.<br /><br /><strong>Why it matters:</strong>&nbsp;Tech giants are searching for an edge in AI development after being briefly leapfrogged in the market by large language model startups. Microsoft invested $13 billion in&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-boosts-its-investment-in-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">OpenAI</a>, and Nadella says that partnership remains a strategic priority. This year, Microsoft has sought to diversify its AI interests, sealing deals with&nbsp;<a href="https://www.deeplearning.ai/the-batch/mistral-enhances-ai-landscape-in-europe-with-microsoft-partnership-and-new-language-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Mistral</a>&nbsp;and now Inflection, while also beefing up its internal efforts. The distribution channel for AI models increasingly runs through large companies and their cloud services.<br /><br /><strong>We’re thinking:</strong>&nbsp;Even with strong talent, powerful backing, and a multibillion-dollar valuation, Inflection struggled to gain traction. Its journey from hot consumer startup to streamlined enterprise software provider shows how competitive the chatbot sector has become.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="669" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-03T133929.961.png" width="1200" /></figure><h1 id="nvidia-revs-ai-engine">Nvidia Revs AI Engine</h1><p>Nvidia’s latest chip promises to boost AI’s speed and energy efficiency.</p><p><strong>What’s new:</strong>&nbsp;The market leader in AI chips&nbsp;<a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">announced</a>&nbsp;the B100 and B200 graphics processing units (GPUs) designed to eclipse its in-demand H100 and H200 chips. The company will also offer systems that integrate two, eight, and 72 chips.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The new chips are based on Blackwell, an updated chip architecture specialized for training and inferencing transformer models. Compared to Nvidia’s earlier Hopper architecture, used by H-series chips, Blackwell features hardware and firmware upgrades intended to cut the energy required for model training and inference.</p><ul><li>Training a 1.8-trillion-parameter model (the estimated size of OpenAI’s GPT-4 and Beijing Academy of Artificial Intelligence’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/large-language-models-for-chinese/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">WuDao</a>) would require 2,000 Blackwell GPUs using 4 megawatts of electricity, compared to 8,000 Hopper GPUs using 15 megawatts, the company said.</li><li>Blackwell includes a second-generation&nbsp;<a href="https://www.deeplearning.ai/the-batch/transformer-accelerator/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Transformer Engine</a>. While the first generation used 8 bits to process each neuron in a neural network, the new version can use as few as 4 bits, potentially doubling compute bandwidth.</li><li>A dedicated engine devoted to reliability, availability, and serviceability monitors the chip to identify potential faults. Nvidia hopes the engine can reduce compute times by minimizing chip downtime.</li><li>An upgraded version of the NVLink switch, which allows GPUs to communicate with each other, accommodates up to 1.8 terabytes of traffic in each direction, compared to Hopper’s maximum of 900 gigabytes. The architecture can handle up to 576 GPUs in combination, compared to Hopper’s&nbsp;<a href="https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">cap</a>&nbsp;of 256.</li><li>Nvidia doesn’t make it easy to compare the B200 with rival AMD’s top offering, the&nbsp;<a href="https://www.amd.com/en/products/accelerators/instinct/mi300/mi300x.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">MI300X</a>. Here are a few comparisons based on specs&nbsp;<a href="https://www.nvidia.com/en-us/data-center/hgx/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">reported</a>&nbsp;for Nvidia’s eight-GPU system: The B200 processes 4.5 dense/9 sparse PFLOPS at 8-bit precision, while the MI300X processes 2.61 dense/5.22 sparse PFLOPS at 8-bit precision. The B200 has 8TB/s peak memory bandwidth and 192GB of memory, while the MI300X has 5.3TB/s peak memory bandwidth and 192GB of memory. &nbsp;</li></ul><p><strong>Price and availability:</strong>&nbsp;The B200 will cost between $30,000 and $40,000, similar to the&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">going rate</a>&nbsp;for H100s today, Nvidia CEO Jensen Huang&nbsp;<a href="https://www.cnbc.com/2024/03/19/nvidias-blackwell-ai-chip-will-cost-more-than-30000-ceo-says.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">told</a>&nbsp;<em>CNBC</em>. Nvidia did not specify when the chip would be available. Google, Amazon, and Microsoft&nbsp;<a href="https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">stated</a>&nbsp;intentions to offer Blackwell GPUs to their cloud customers.</p><p><strong>Behind the news:</strong>&nbsp;Demand for the H100 chip has been so intense that the chip has been&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-nvidia-gpu-shortage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">difficult</a>&nbsp;to find, driving some users to adopt alternatives such as AMD’s MI300X. Moreover, in 2022, the U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">restricted</a>&nbsp;the export of H100s and other advanced chips to China. The B200 also falls under the ban.<br /><br /><strong>Why it matters:</strong>&nbsp;Nvidia&nbsp;<a href="https://www.reuters.com/technology/nvidia-chases-30-billion-custom-chip-market-with-new-unit-sources-2024-02-09/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">holds</a>&nbsp;about 80 percent of the market for specialized AI chips. The new chips are primed to enable developers to continue pushing AI’s boundaries, training multi-trillion-parameter models and running more instances at once.&nbsp;<br /><br /><strong>We’re thinking:</strong>&nbsp;Cathie Wood, author of ARK Invest’s “<a href="https://www.ark-invest.com/big-ideas-2024?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Big Ideas 2024”</a>&nbsp;report, estimated that training costs are falling at a very rapid 75 percent annually, around half due to algorithmic improvements and half due to compute hardware improvements. Nvidia’s progress paints an optimistic picture of further gains. It also signals the difficulty of trying to use model training to build a moat around a business. It’s not easy to maintain a lead if you spend $100 million on training and next year a competitor can replicate the effort for $25 million.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/04/The-Batch-ads-and-exclusive-banners---2024-04-02T085923.011.png" width="1680" /></a></figure><p>In our new short course “Red Teaming LLM Applications,” you will learn industry-proven manual and automated techniques to proactively test, attack, and improve the robustness of your large language model (LLM) applications.&nbsp;<a href="https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">Join now!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-03T133956.061.gif" width="1200" /></figure><h1 id="toward-managing-ai-bio-risk">Toward Managing AI Bio Risk</h1><p>Scientists pledged to control their use of AI to produce potentially hazardous biological materials.</p><p><strong>What’s new:</strong>&nbsp;More than 150 biologists in Asia, Europe, and North America&nbsp;<a href="https://responsiblebiodesign.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">signed</a>&nbsp;a voluntary commitment to internal and external oversight of machine learning models that can be used to design proteins.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The scientists made 10 voluntary commitments regarding synthetic biology research. They promised broadly to avoid research likely to enable harm and to promote research that responds to infectious disease outbreaks or similar emergencies.</p><ul><li>The signatories committed to evaluating the risks of AI models that generate protein structures based on user-defined characteristics such as shape or length. They also promised to improve methods for evaluating and mitigating risks.</li><li>They vowed to acquire synthetic DNA — fabricated gene sequences that can instruct cells to produce proteins designed by AI — only from providers that rigorously screen the DNA for potential to create hazardous molecules. They agreed to support development of new screening methods.</li><li>They promised to disclose potential benefits, risks, and efforts to mitigate the risks of their research. They pledged to review the capabilities of synthetic biology at regular, secure meetings and report unethical or concerning research practices.</li><li>They also agreed to revise their commitments “as needed.”</li></ul><p><strong>Behind the news:</strong>&nbsp;The potential role of AI in producing bioweapons is a major focus of research in AI safety. The current pledge arose from a University of Washington meeting on responsible AI and protein design held late last year. The&nbsp;<a href="https://www.deeplearning.ai/the-batch/countries-and-tech-giants-collaborate-on-global-ai-safety-regulation/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">AI Safety Summit</a>, which took place at around the same time, also addressed the topic, and Helena, a think tank devoted to solving global problems, convened a similar meeting&nbsp;in mid-2023.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;DeepMind’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/biomedical-treasure-chest/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">AlphaFold</a>, which finds the structures of proteins, has&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S2405471223002983?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">spawned</a>&nbsp;models that enable users to design proteins with specific properties. Their output could help scientists cure diseases, boost agricultural production, and craft enzymes that aid industrial processes. However, their potential for misuse has led to scrutiny by&nbsp;<a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">national</a>&nbsp;and&nbsp;<a href="https://www.who.int/news/item/18-01-2024-who-releases-ai-ethics-and-governance-guidance-for-large-multi-modal-models?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">international</a>&nbsp;organizations. The biology community’s commitment to use such models safely may reassure the public and forestall onerous regulations.</p><p><strong>We’re thinking:</strong>&nbsp;The commitments are long on general principles and relatively short on concrete actions. We’re glad they call for ongoing revision and action, and we hope they lead to the development of effective safeguards.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/04/unnamed---2024-04-03T133938.278.png" width="1200" /></figure><h1 id="more-factual-llms">More Factual LLMs</h1><p>Large language models sometimes generate false statements. New work makes them more likely to produce factual output.</p><p><strong>What’s new:</strong>&nbsp;Katherine Tian, Eric Mitchell, and colleagues at Stanford and University of North Carolina proposed&nbsp;<a href="https://arxiv.org/abs/2311.08401?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">FactTune</a>, a procedure that fine-tunes large language models (LLMs) to increase their truthfulness without collecting human feedback.</p><p><strong>Key insight:</strong>&nbsp;Just as fine-tuning based on feedback has made LLMs less harmful, it can make them more factual. The typical method for such fine-tuning is reinforcement learning from human feedback (RLHF). But a combination of&nbsp;<a href="https://www.deeplearning.ai/the-batch/human-feedback-without-reinforcement-learning/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">direct preference optimization</a>&nbsp;(DPO) and&nbsp;<a href="https://arxiv.org/abs/2212.08073?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">reinforcement learning from AI feedback</a>&nbsp;(RLAIF) is far more efficient. DPO replaces cumbersome reinforcement learning with a simpler procedure akin to supervised learning. RLAIF eliminates the cost of collecting human feedback by substituting model-generated preferences for human preferences.</p><p><strong>How it works:</strong>&nbsp;The authors built models designed to deliver factual output within a specific domain.&nbsp;</p><ul><li>The authors asked GPT-3.5 to prompt&nbsp;<a href="https://arxiv.org/abs/2302.13971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">LLaMA-7B</a>&nbsp;to generate 10 biographies of roughly 300 people profiled by Wikipedia.&nbsp;</li><li>Instead of human fact checking, which would be prohibitively expensive, they relied on&nbsp;<a href="https://aclanthology.org/2023.emnlp-main.741/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">FActScore</a>, an automated fact checker that uses a separate LLaMA fine-tuned for fact-checking to determine whether a separate model’s output is supported by Wikipedia. FActScore asked GPT-3.5 to extract claims in the biographies and determined whether each claim was supported by Wikipedia. Then it scored the biographies according to the percentage of supported claims.</li><li>The authors built a dataset by choosing two biographies of the same person at random. They annotated the one with the higher factuality score as preferred and the one with the lower score as not preferred.&nbsp;&nbsp;</li><li>They used the dataset to fine-tune the LLaMA-7B via Direct Preference Optimization (DPO).</li></ul><p><strong>Results:</strong>&nbsp;Fine-tuning by the authors’ method improved the factuality of models in two domains.&nbsp;</p><ul><li>The authors generated biographies of people in the test set using LLaMA-7B before and after fine-tuning via their method. Human judges who used Wikipedia as a reference deemed factual 58 percent of the claims generated by the model without fine-tuning and 85 percent of claims generated by the fine-tuned model.</li><li>The authors generated answers to a wide variety of medical questions drawn from Wikipedia using LLaMA-7B before and after fine-tuning via their method. Judges gave factual ratings to 66 percent of answers generated by the model without fine-tuning and 84 percent of answers generated by the fine-tuned model.</li></ul><p><strong>Why it matters:</strong>&nbsp;LLMs are known to hallucinate, and the human labor involved in fact checking their output is expensive and time-consuming. The authors applied well tested methods to improve the factuality of texts while keeping human involvement to a minimum.</p><p><strong>We’re thinking:</strong>&nbsp;This work, among others, shows how LLMs can bootstrap their way to better results. We’ve only just begun to explore combinations of LLMs working together as well as individual LLMs working iteratively in an&nbsp;<a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--9ARMthd09q0ABUi-abo6BH62BLbcwPo13LrXs9hUezs-L050Ay7b_rHdWuRIqBVOD6k_S" rel="noopener">agentic workflow</a>.</p><hr /><h1 id="data-points">Data Points</h1><p>The latest AI news in brief is yours with <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, a spinoff of The Batch:</p><p>OpenAI is cautiously probing the synthetic voice market with Voice Engine.</p><p>Also, a city in California is testing an AI tool to identify homeless encampments.&nbsp;</p><p>Plus, a tech coalition plans on challenging Nvidia's lock-in of its chip users by developing new open-source cloud software..</p><p>Find these stories and more. <a href="https://www.deeplearning.ai/the-batch/data-points-issue-243/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points now</a>.</p>
]]></content:encoded>
<pubDate>Wed, 03 Apr 2024 19:37:07 GMT</pubDate>
</item>
<item>
<title>One Agent For Many Worlds, Cross-Species Cell Embeddings, U.S. Deploys AI Targeting, Robo Football Gets Real</title>
<link>https://www.deeplearning.ai/the-batch/issue-242</link>
<guid>https://www.deeplearning.ai/the-batch/issue-242</guid>
<content:encoded><![CDATA[
<div> Reflection, Tool use, Planning, Multi-agent collaboration, agentic workflow<br /><br />总结: 本文介绍了AI agentic workflows的四种设计模式：反思、工具使用、规划和多智能体协作。其中介绍了反思的设计模式，即模型对自己的输出进行批判性反馈并改进。通过给LLM提供产生代码、写文本或回答问题的任务，并提示其对输出进行反思和改进，可以提高模型的输出质量。使用自我反思和工具评估的方法可以帮助模型在多个任务上实现更好的表现。此外，作者还介绍了通过多智能体框架实现反思的方法。反思是一种相对基础的agentic workflow，但在一些案例中，它已经取得了显著的效果提升。 <div>
<p>Dear friends,</p><p>Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. In this letter, I'd like to discuss Reflection. For a design pattern that’s relatively quick to implement, I've seen it lead to surprising performance gains.&nbsp;<br /><br />You may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.&nbsp;<br /><br />Take the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. After that, we can prompt it to reflect on its own output, perhaps as follows:</p><p><em>Here’s code intended for task X:&nbsp;[previously generated code]&nbsp; &nbsp;&nbsp;<br />Check the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.</em><br /><br />Sometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and the constructive feedback and (ii) ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.&nbsp;</p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/AGENTS-REFLECTION-1.jpg" width="1200" /></figure><p>And we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.</p><p>Further, we can implement Reflection using a multi-agent framework. I've found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent's output. The resulting discussion between the two agents leads to improved responses.</p><p>Reflection is a relatively basic type of agentic workflow, but I've been delighted by how much it improved my applications’ results in a few cases. I hope you will try it in your own work. If you’re interested in learning more about reflection, I recommend these papers:</p><ul><li>“<a href="https://arxiv.org/abs/2303.17651?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Self-Refine: Iterative Refinement with Self-Feedback</a>,” Madaan et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2303.11366?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Reflexion: Language Agents with Verbal Reinforcement Learning</a>,” Shinn et al. (2023)</li><li>“<a href="https://arxiv.org/abs/2305.11738?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing</a>,” Gou et al. (2024)</li></ul><p>I’ll discuss the other agentic design patterns in future letters.</p><p>Keep learning!</p><p>Andrew&nbsp;</p><p>P.S. New JavaScript short course! Learn to build full-stack web applications that use RAG in “JavaScript RAG Web Apps with LlamaIndex,” taught by Laurie Voss, VP of Developer Relations at LlamaIndex and co-founder of npm.&nbsp;</p><ul><li>Build a RAG application for querying your own data.</li><li>Develop tools that interact with multiple data sources and use an agent to autonomously select the right tool for a given query.</li><li>Create a full-stack web app step by step that lets you chat with your data.&nbsp;</li><li>Dig further into production-ready techniques like how to persist your data, so you don’t need to reindex constantly.</li></ul><p><a href="https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Sign up here</a>!</p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/SIMA.jpg" width="1200" /></figure><h1 id="one-agent-many-environments">One Agent, Many Environments</h1><p>AI agents are typically designed to operate a particular software environment. Recent work enabled a single agent to take actions in a variety of three-dimensional virtual worlds.</p><p><strong>What's new:</strong>&nbsp;A team of 90 people at Google and University of British Columbia announced&nbsp;<a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Scalable Instructable Multiworld Agent</a>&nbsp;(SIMA), a system that learned to follow text instructions (such as “make a pile of rocks to mark this spot” or “see if you can jump over this chasm”) in seven commercial video games and four research environments.&nbsp;</p><p><strong>How it works:</strong>&nbsp;SIMA’s architecture consists of several transformers and a vanilla neural network. The authors trained it to mimic human players using a dataset of gameplay broken into 10 second tasks, including onscreen images, text instructions, keyboard presses, and mouse motions. The video games included Goat Simulator 3 (a third-person game in which the player takes the form of a goat), No Man’s Sky (a first- or third-person game of exploration and survival in outer space), Hydroneer (a first-person game of mining and building), and others.&nbsp;&nbsp;</p><ul><li>Given a text instruction and a frame of onscreen imagery,&nbsp;<a href="https://arxiv.org/abs/2401.09865?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">SPARC</a>&nbsp;(a pair of transformers pretrained on text-image pairs to produce similar embeddings of similar text and images) produced text and image embeddings. Given recent frames,&nbsp;<a href="https://www.deeplearning.ai/the-batch/googles-phenaki-generates-long-form-video-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Phenaki</a>&nbsp;(a transformer pretrained to predict future frames in a video) generated a video embedding.</li><li>Given the image, text, and video embeddings, a collection of transformers learned to produce a representation of the game. (The authors don’t fully describe this part of the architecture.)&nbsp;</li><li>Given the game representation, a vanilla neural network learned to produce the corresponding keyboard and mouse actions.</li></ul><p><strong>Results:</strong>&nbsp;Judges evaluated SIMA’s success or failure at completing nearly 1,500 instructions that spanned tasks in nine categories like action (“jump”), navigation (“go to your ship”), and gathering resources (“get raspberries”). In Goat Simulator 3, SIMA completed 40 percent of the tasks. In No Man’s Sky, the judges compared SIMA’s performance to that of the human players whose gameplay produced the training data. SIMA was successful 34 percent of the time, while the players were successful 60 percent of the time. Judges also compared SIMA to versions that were trained to be experts in a single game. SIMA was successful more than 1.5 times more often than the specialized agents.</p><p><strong>Behind the news:</strong>&nbsp;SIMA extends Google’s earlier successes building agents that rival or beat human players at individual games including&nbsp;<a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Go</a>,&nbsp;<a href="https://deepmind.google/discover/blog/agent57-outperforming-the-human-atari-benchmark/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">classic Atari games</a>, and&nbsp;<a href="https://deepmind.google/discover/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">StarCraft II</a>.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Training agents to follow directions in various environments, seeing the same things humans would, is a step toward building instructable agents that can work in any situation. The authors point to potential applications in robotics, simulations, and gaming; wherever an agent might need to be guided through diverse challenges.&nbsp;</p><p><strong>We're thinking:</strong>&nbsp;This work shows that an agent trained on multiple games can perform better than an agent trained on just one, and that the richer the language inputs in a gameworld, the better the agent can perform. With only a handful of training environments under its belt, SIMA doesn’t demonstrate superhuman performance, but it gets the job done a surprising amount of the time!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="630" src="https://dl-staging-website.ghost.io/content/images/2024/03/CELLS.jpg" width="1120" /></figure><h1 id="cross-species-cell-embeddings">Cross-Species Cell Embeddings</h1><p>Researchers used an AI system to identify animal cell types from gene sequences, including a cell type that conventional approaches had discovered only in the past year.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Biologists at Stanford trained a&nbsp;<a href="https://www.biorxiv.org/content/10.1101/2023.11.28.568918v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">system</a>&nbsp;to produce embeddings that represent individual cells in an organism. This enabled them to find cell types that have common function in different animals; for instance, the Norn cell, a type of kidney cell that biologists had previously theorized but&nbsp;<a href="https://www.nature.com/articles/s41591-023-02314-7?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">discovered</a>&nbsp;only in 2023.</p><p><strong>How it works:</strong>&nbsp;Universal Cell Embedding (UCE) comprises two transformers that produce embeddings of genes and cells respectively, plus a classifier based on a vanilla neural network. The authors trained the classifier, given embeddings of a gene and cell, to classify whether or not the cell produces the protein coded by that gene. The training dataset included RNA sequences of 36.2 million cells from eight animal species (humans and mice accounted for 33.9 million) along with related protein structures.&nbsp;</p><ul><li>The authors represented each cell as a sequence of gene embeddings, laid out in the order in which they appear in the cell’s genome. Instead of including all of a cell’s genes, the authors sampled 1,024 genes known to encode proteins. A pretrained&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/36927031/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">ESM-2</a>&nbsp;transformer computed each gene’s embedding based on the protein(s) — that is, amino acid sequence(s) — it produces.&nbsp;</li><li>The authors randomly masked 20 percent of the gene embeddings. Given the masked sequence, a vanilla transformer learned to compute an embedding of the cell.&nbsp;</li><li>For each gene in the cell, the authors concatenated its embedding with the cell embedding. Given the combined embeddings, the vanilla neural network learned to classify whether the genes encoded a protein.</li></ul><p><strong>Results:</strong>&nbsp;Cell embeddings produced by UCE enabled the authors to identify cell types in animal species that weren’t in the training set. For instance, the authors embedded a dataset of mouse cells and applied&nbsp;<a href="https://arxiv.org/abs/1802.03426?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">UMAP</a>&nbsp;clustering to differentiate the types. They labeled the clusters as specific cell types (including Norn cells, which biologists took more than a century to find) based on the presence of certain genes that distinguish one cell type from another. Using the labels, they trained a logistic classifier. They applied the classifier to their training dataset and found Norn cells, among other cell types, in species other than mice. They verified the findings by looking for genes that tend to show up only in Norn cells.</p><p><strong>Why it matters:</strong>&nbsp;UCE’s embeddings encode biologically meaningful information about individual cells, enabling a clustering algorithm to group them into recognized cell types. The fact that the recently discovered Norn cell was among those clusters suggests that UCE may yield further discoveries that accelerate development of new medicines, lab processes, and research methods. In fact, the model found Norn cells — which are known to occur in the kidney — in organs where they have not been seen before. If this result turns out to be valid, UCE will have made a discovery that has eluded biologists to date.</p><p><strong>We’re thinking:</strong>&nbsp;It’s a truism that a machine learning model is only as good as its data. That makes this work all the more impressive: Its training data included a handful of species, yet it generalized to others.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1125" src="https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-25T154251.995.png" width="2000" /></a></figure><p>Join our short course on “JavaScript RAG Web Apps with LlamaIndex” to learn how to build full-stack JavaScript web applications that let you chat with your data. Harness the capabilities of large language models and retrieval augmented generation (RAG)!&nbsp;<a href="https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex/?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/MAVEN.jpg" width="1200" /></figure><h1 id="us-deploys-ai-assisted-targeting">U.S. Deploys AI-Assisted Targeting</h1><p>The United States military is using computer vision to target enemy positions in the Red Sea and elsewhere.<br /><br /><strong>What’s new:</strong>&nbsp;Maven, a system that analyzes satellite and geolocation data, has been used to identify targets in real-world conflicts,&nbsp;<em>Bloomberg</em>&nbsp;<a href="https://www.bloomberg.com/features/2024-ai-warfare-project-maven/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">reported</a>. The system was developed primarily by&nbsp;<a href="https://www.deeplearning.ai/the-batch/a-military-chatbot-can-create-battle-plans/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Palantir</a>&nbsp;and integrates technology from Amazon, Microsoft, information technology firms ECS Federal and L3Harris, aerospace firms Maxar and Sierra Nevada, and other unnamed companies.<br /><br /><strong>How it works:</strong>&nbsp;The 18th Airborne Corps, a U.S. Army unit organized for rapid deployment around the world, used Maven in live-fire training exercises. The system helped locate surface vessels in the Red Sea, rocket launchers in Yemen, and potential airstrike targets in Iraq and Syria. The U.S. used it to help Ukraine’s armed forces to locate Russian equipment, anonymous sources said.&nbsp;</p><ul><li>Maven melds various data streams into a top-down image of a geographic area. Satellites provide still images and video, and radar and infrared observations enable the system to see through clouds and other obstructions. It can also integrate non-visual information such as location data from mobile devices and social media posts.</li><li>Computer vision models identify military equipment such as aircraft and tanks, highlighting significant changes to object locations. They can register a buildup of equipment that may indicate a new, or newly active, military base.&nbsp;</li><li>The system displays a map that outlines potential targets in yellow and friendly forces, schools, hospitals, and other no-strike zones outlined in blue. Human decision-makers review output and authorize responses.</li></ul><p><strong>Behind the news:</strong>&nbsp;Google initially developed Maven for the U.S. Defense Department around 2017. Palantir&nbsp;<a href="https://www.businessinsider.com/palantir-took-over-from-google-on-project-maven-2019-12?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">inherited</a>&nbsp;the project after Google, facing protests by employees who did not want to contribute to government intelligence systems,&nbsp;<a href="https://www.nytimes.com/2018/06/01/technology/google-pentagon-project-maven.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">declined</a>&nbsp;to renew its contract in 2018. The U.S. military now has more than 800 active AI projects with a wide range of technology partners and contractors. Other countries are deploying similar technology:&nbsp;<a href="https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Israel</a>&nbsp;and&nbsp;<a href="https://www.deeplearning.ai/the-batch/ukraines-drone-industry-takes-flight-amidst-conflict/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Ukraine</a>&nbsp;have used AI-assisted targeting in their ongoing conflicts.</p><p><strong>Yes, but:</strong>&nbsp;Some U.S. military experts worry about Maven’s accuracy. In tests, Maven successfully identified objects about 60 percent of the time, while human analysts working with the 18th Airborne Corps did so 84 percent of time. Moreover, the system’s training data emphasizes deserts, and its success rate drops in other types of environments.<br /><br /><strong>Why it matters:</strong>&nbsp;Maven and similar systems offer some advantages over human analysts. They can observe and integrate multiple data streams simultaneously, and they can identify potential targets much more quickly. It’s likely that more data will make these systems more accurate. On the other hand, they represent a further step toward automated warfare in which automated assistance could come to displace human decision-making.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Automated targeting is increasingly used in military applications, and less-sophisticated systems have been in&nbsp;<a href="https://www.jstor.org/stable/pdf/resrep32146.4.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">use</a>&nbsp;for decades. However, humans should always be in control of decisions to fire. We support a global&nbsp;<a href="https://news.un.org/en/story/2023/10/1141922?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">ban</a>&nbsp;on fully autonomous weapons.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="335" src="https://dl-staging-website.ghost.io/content/images/2024/03/SOCCER-ezgif.com-optimize.gif" width="600" /></figure><h1 id="robo-football-from-simulation-to-reality">Robo-Football From Simulation to Reality</h1><p>Humanoid robots can play football (known as soccer in the United States) in the real world, thanks to reinforcement learning.</p><p><strong>What’s new:&nbsp;</strong>Tuomas Haarnoja and colleagues at Google and University of Oxford trained an&nbsp;<a href="https://arxiv.org/abs/2304.13653?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">agent</a>&nbsp;to play one-on-one football in a simulated environment. They applied the agent to 20-inch hardware robots on a scaled-down field. You can see it in action&nbsp;<a href="https://sites.google.com/view/op3-soccer?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;In reinforcement learning, an agent improves as it explores various motions. However, such exploration risks damaging expensive hardware. By training in a simulation, the agent can attempt a diversity of motions without risking a physical robot. Once the agent is trained, it can make the leap from simulation to reality.</p><p><strong>How it works:</strong>&nbsp;The agent learned in a&nbsp;<a href="https://ieeexplore.ieee.org/document/6386109?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">virtual world</a>&nbsp;to control the robot’s motion given (i) a simulated robot’s state (including the position, velocity, and acceleration of each of 20 joints), (ii) the current game state (including the location and velocity of the ball and opponent), (iii) the game state at each of the last five time steps, and (iv) the agent’s five previous actions. Training proceeded via reinforcement learning in two stages.&nbsp;</p><ul><li>During the first stage of training, the authors trained two teachers, both of which were vanilla neural networks. (i) The first teacher learned to predict movements that help a simulated robot score goals against an untrained opponent that immediately fell over. The teacher earned rewards for scoring and was penalized for falling over or letting the opponent score, among other rewards and penalties. (ii) The second teacher learned to make a fallen simulated robot stand up. It received larger rewards for smaller differences, and smaller rewards for larger differences, between the robot’s joint positions and the joint positions for key robot poses&nbsp;<a href="https://github.com/ROBOTIS-GIT/ROBOTIS-OP3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">recorded</a>&nbsp;during a manually designed process of standing up.</li><li>The second stage of training involved another agent, also a vanilla neural network. This agent played a match against a previous version of itself in which each agent controlled a simulated robot. It received rewards for moving the robot’s joints in ways that helped it win the match or resembled the two teachers’ movements; this encouraged the agent to score goals and stand up after falling. To better approximate real-world conditions, the authors randomly perturbed the simulation, adding noise to the sensors that measured the robot’s actions and delaying parts of the simulation. They also restricted the joints’ range of motion to prevent the simulated robot from acting in ways that would damage a hardware robot.</li><li>At inference, the trained agent controlled an off-the-shelf&nbsp;<a href="https://emanual.robotis.com/docs/en/platform/op3/introduction/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">Robotis OP3</a>&nbsp;humanoid robot, which costs around $14,000.</li></ul><p><strong>Results:</strong>&nbsp;The agent learned not only to turn and kick but also to anticipate the ball’s motion and block an opponent’s shots. It scored penalties against a stationary goalie with 90 percent success in simulation and 70 percent success in the physical world. It stood up in 0.9 seconds on average, while a manually designed agent stood up in 2.5 seconds. Its maximum walking speed of 0.69 meters per second beat the manually designed agent’s 0.27 meters per second. However, its kicks propelled the ball at 2.0 meters per second on average, slower than the manually designed agent’s 2.1 meters per second.</p><p><strong>Why it matters:</strong>&nbsp;Controlling humanoid robots is challenging, as they’re less stable than&nbsp;<a href="https://arxiv.org/abs/2304.01159?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">quadrupeds</a>. Just getting them to do one type of motion, such as&nbsp;<a href="https://arxiv.org/abs/2302.09450?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B" rel="noopener">jumping</a>, can require dedicated research. This work drives humanoid robots in complex motions by combining established training methods: training in a noisy simulation, self-play, and using teacher agents to reward particular actions.</p><p><strong>We’re thinking:</strong>&nbsp;This work demonstrates that robots get a kick out of machine learning.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>The latest AI updates of the week include: </p><p>👉 Stability AI’s Stable Video 3D<br />👉 Sakana’s evolution-inspired model merging technique<br />👉 The new Blackwell B200 GPU by Nvidia </p><p>And much more. </p><p>Read <a href="https://www.deeplearning.ai/the-batch/data-points-issue-242/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, your weekly AI news digest.</p>
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 17:36:33 GMT</pubDate>
</item>
<item>
<title>Robots Talk Back, AI Security Risks, Political Deepfakes, Pretrained Models on the Cheap</title>
<link>https://www.deeplearning.ai/the-batch/issue-241</link>
<guid>https://www.deeplearning.ai/the-batch/issue-241</guid>
<content:encoded><![CDATA[
<div> AI agent workflows, LLMs, massive progress, foundation models, iterative process, agent loop, design patterns, security risk, Hugging Face, deepfakes, Indian elections, cost-saving method
总结:<br /><br />今年，AI代理工作流程将推动AI的巨大进展，可能甚至超过下一代基础模型。这是一个重要的趋势，我敦促所有从事AI的人关注此事。LLM在当前主要以零-shot模式使用，一次性生成最终输出的代码。但是，通过使用代理工作流程，可以使LLM多次迭代文档。这种迭代过程对于大多数人类作家来说都是至关重要的，通过AI完成这个过程，可以比一次性写作取得更好的结果。Covariant推出了RFM-1，可以使机器人对指令作出反应，回答关于所见的问题，并请求进一步指令。然而，Hugging Face的平台存在安全漏洞，部分模型可以攻击用户设备。 Deepfakes在印度选举中也变得非常常见。斯坦福大学的研究人员提出了一种节省成本的方法，通过顺序调用LLM，可以减少开销但保持质量。这些都是本文的要点。 <div>
<p><em>Dear friends,</em></p><p><em>I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it. </em></p><p><em>Today, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!&nbsp;</em></p><p><em>With an agent workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:</em></p><ul><li><em>Plan an outline.</em></li><li><em>Decide what, if any, web searches are needed to gather more information.</em></li><li><em>Write a first draft.</em></li><li><em>Read over the first draft to spot unjustified arguments or extraneous information.</em></li><li><em>Revise the draft taking into account any weaknesses spotted.</em></li><li><em>And so on.</em></li></ul><p><em>This iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.&nbsp;</em></p><p><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVvVhS90hnNhW8PzczX33Rs2tW61z83B5bWrzYN2K0T3n3qgyTW7lCdLW6lZ3m0W58_lW-6R-sR5W8Wfq2H7p9nZkN5QkgcFkL5nsW83Wxt393rnQ8W9jQM7t7nptmvW59WLNt7hFQVcW1vyStQ1HbrL8W6q6Mb-44YQnPW3fYZZW8qF7FSW4JDLSC4G4pGXVtf5md3gLz4CW1ky80g2Smw8FW5TCSvB7P0x_mW17TSGH2k2JhsW7H4QSb3BHvgqN4Q0XzXfmjznW8bsvSf8L6SrNW6Fn_sS3nHzgrW76DN-T3wtmF5N13tFYHDckM-W3y1yY298N14kW5mVnt612LQmkW7fK7S42W2Xd6N87C8gl-Z4KPdvVnKH04?ref=dl-staging-website.ghost.io" rel="noopener">Devin</a><em>’s splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm’s ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--55-.jpg" width="1200" /></figure><p><em>GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.&nbsp;</em></p><p><em>Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I’d like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.</em></p><ul><li><em>Reflection: The LLM examines its own work to come up with ways to improve it.&nbsp;</em></li><li><em>Tool use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.</em></li><li><em>Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).</em></li><li><em>Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.</em></li></ul><p><em>Next week, I’ll elaborate on these design patterns and offer suggested readings for each.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. Build an optimized large language model (LLM) inference system from the ground up in our new short course “Efficiently Serving LLMs,” taught by Predibase CTO Travis Addair.</em></p><ul><li><em>Learn techniques like KV caching, continuous batching, and quantization to speed things up and optimize memory usage.</em></li><li><em>Benchmark LLM optimizations to explore the trade-offs between latency and serving many users at once.</em></li><li><em>Use low-rank adaptation (LoRA) to serve hundreds of custom fine-tuned models on a single device efficiently.</em></li></ul><p><a href="https://www.deeplearning.ai/short-courses/efficiently-serving-llms?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Sign up now!</a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-20T163430.388.gif" width="600" /></figure><h1 id="conversational-robots">Conversational Robots</h1><p>Robots equipped with large language models are asking their human overseers for help.</p><p><strong>What's new:</strong>&nbsp;Andrew Sohn and colleagues at Covariant&nbsp;<a href="https://covariant.ai/insights/introducing-rfm-1-giving-robots-human-like-reasoning-capabilities/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">launched</a>&nbsp;RFM-1, a model that enables robots to respond to instructions, answer questions about what they see, and request further instructions. The model is available to Covariant customers.</p><p><strong>How it works:</strong>&nbsp;RFM-1 is a transformer that comprises 8 billion parameters. The team started with a pretrained large language model and further trained it, given text, images, videos, robot actions, and/or robot sensor readings, to predict the next token of any of those types. Images and videos are limited to 512x512 pixels and 5 frames per second.</p><ul><li>Proprietary models embed non-language inputs.&nbsp;&nbsp;</li><li>RFM-1 responds conversationally to text and/or image inputs. Given an image of a bin filled with fruit and the question “Are there any fruits in the bin?” the model can respond yes or no. If yes, it can answer follow-up questions about the fruit’s type, color, and so on.</li><li>Given a robotic instruction, the model generates tokens that represent a combination of high-level actions and low-level commands. For example, asked to “pick all the red apples,” it generates the tokens required to pluck the apples from a bin.</li><li>If the robot is unable to fulfill an instruction, the model can ask for further direction. For instance, in one demonstration, it asks, “I cannot get a good grasp. Do you have any suggestions?” When the operator responds, “move 2 cm from the top of the object and knock it over gently,” the robot knocks over the item and automatically finds a new way to pick it up.</li><li>RFM-1 can predict future video frames. For example, if the model is instructed to remove a particular item from a bin, prior to removing the item, it can generate an image of the bin with the item missing.</li></ul><p><strong>Behind the news:</strong>&nbsp;Covariant’s announcement follows a wave of&nbsp;<a href="https://arxiv.org/abs/2210.03094?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">robotics</a>&nbsp;<a href="https://arxiv.org/abs/2204.06252?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">research</a>&nbsp;<a href="https://arxiv.org/abs/2307.15818?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">in</a>&nbsp;<a href="https://arxiv.org/abs/2202.02005?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">recent</a>&nbsp;<a href="https://proceedings.mlr.press/v205/shridhar23a/shridhar23a.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">years</a>&nbsp;that enables robots to take action in response to&nbsp;<a href="https://openreview.net/pdf?id=U0jfsqmoV-4&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">text</a>&nbsp;<a href="https://arxiv.org/abs/2109.01115?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">instructions</a>.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Giving robots the ability to respond to natural language input not only makes them easier to control, it also enables them to interact with humans in new ways that are surprising and useful. In addition, operators can change how the robots work by issuing text instructions rather than programming new actions from scratch.</p><p><strong>We're thinking:</strong>&nbsp;Many people fear that robots will make humans obsolete. Without downplaying such worries, Covariant’s conversational robot illustrates one way in which robots can work alongside humans without replacing them.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="339" src="https://dl-staging-website.ghost.io/content/images/2024/03/BACKDOOR2.gif" width="600" /></figure><h1 id="some-models-pose-security-risk">Some Models Pose Security Risk</h1><p>Security researchers sounded the alarm about holes in Hugging Face’s platform.<br /><br /><strong>What’s new:</strong>&nbsp;Models in the Hugging Face open source AI repository can attack users’ devices,&nbsp;<a href="https://jfrog.com/blog/data-scientists-targeted-by-malicious-hugging-face-ml-models-with-silent-backdoor/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">according to</a>&nbsp;cybersecurity experts at JFrog, a software firm. Meanwhile, a different team discovered a&nbsp;<a href="https://hiddenlayer.com/research/silent-sabotage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">vulnerability</a>&nbsp;in one of Hugging Face’s own security features.<br /><br /><strong>Compromised uploads:</strong>&nbsp;JFrog developed scanned models on Hugging Face for known exploits. They flagged around 100 worrisome models. Flagged models may have been uploaded by other security researchers but pose hazards nonetheless, JFrog said.</p><ul><li>Around 50 percent of the flagged models were capable of hijacking objects on users’ devices. Around 20 percent opened a reverse shell on users’ devices, which theoretically allows an attacker to access them remotely. 95 percent of the flagged models were built using PyTorch, and the remainder were based on TensorFlow Keras.&nbsp;</li><li>For instance, a model called goober2 (since deleted) took advantage of a vulnerability in&nbsp;<a href="https://docs.python.org/3/library/pickle.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Pickle</a>, a Python module that serializes objects by a list or array into a byte stream and back again. The model, which had been uploaded to Hugging Face by a user named baller23, used Pickle to insert code into PyTorch that attempted to start a reverse shell connection to a remote IP address.&nbsp;</li><li>The apparent origin of goober2 and many other flagged models — the South Korean research network&nbsp;<a href="https://wiki.kreonet.net/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK#all-updates" rel="noopener">KREONET</a>&nbsp;—&nbsp;suggests that it may be a product of security researchers.&nbsp;</li></ul><p><strong>Malicious mimicry:</strong>&nbsp;Separately, HiddenLayer, a security startup,&nbsp;<a href="https://hiddenlayer.com/research/silent-sabotage/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">demonstrated</a>&nbsp;a way to compromise&nbsp;<a href="https://huggingface.co/docs/safetensors/en/index?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Safetensors</a>, an alternative to Pickle that stores data arrays more securely. The researchers built a malicious PyTorch model that enabled them to mimic the Safetensors conversion bot. In this way, an attacker could send pull requests to any model that gives security clearance to the Safetensors bot, making it possible to execute arbitrary code; view all repositories, model weights, and other data; and replace users’ models.&nbsp;</p><p><strong>Behind the News:</strong>&nbsp;Hugging Face implements a variety of security measures. In most cases, it flags potential issues but does not remove the model from the site; users download at their own risk. Typically, security issues on the site arise when users inadvertently make their own information available. For instance, in December 2023, Lasso Security&nbsp;<a href="https://www.lasso.security/blog/1500-huggingface-api-tokens-were-exposed-leaving-millions-of-meta-llama-bloom-and-pythia-users-for-supply-chain-attacks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">discovered</a>&nbsp;available API tokens that afforded access to over 600 accounts belonging to organizations like Google, Meta, and Microsoft.&nbsp;&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;As the AI community grows, AI developers and users become more attractive targets for malicious attacks. Security teams have discovered vulnerabilities in popular platforms, obscure models, and essential modules like Safetensors.</p><p><strong>We’re thinking:&nbsp;</strong>Security is a top priority whenever private data is concerned, but the time is fast approaching when AI platforms, developers, and users must harden their models, as well as their data, against attacks.</p><hr /><h2 id="new-from-deeplearningai">NEW FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/efficiently-serving-llms/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-18T100446.882.png" width="1680" /></a></figure><p>In our new short course “Efficiently Serving Large Language Models,” you’ll pop the hood on large language model inference servers. Learn how to increase the performance and efficiency of your LLM-powered applications!&nbsp;<a href="https://www.deeplearning.ai/short-courses/efficiently-serving-llms?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Enroll today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="674" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-20T163811.726.png" width="1200" /></figure><h1 id="deepfakes-become-politics-as-usual">Deepfakes Become Politics as Usual</h1><p>Synthetic depictions of politicians are taking center stage as the world’s biggest democratic election kicks off.</p><p><strong>What’s new:</strong>&nbsp;India’s political parties have&nbsp;<a href="https://www.aljazeera.com/news/2024/2/20/deepfake-democracy-behind-the-ai-trickery-shaping-indias-2024-elections?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">embraced</a>&nbsp;AI-generated campaign messages ahead of the country’s parliamentary elections, which will take place in April and May,&nbsp;<em>Al Jazeera</em>&nbsp;<a href="https://www.aljazeera.com/news/2024/2/20/deepfake-democracy-behind-the-ai-trickery-shaping-indias-2024-elections?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;Prime Minister Narendra Modi, head of the ruling Bharatiya Janata Party (BJP), helped&nbsp;<a href="https://www.deeplearning.ai/the-batch/untitled-4/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">pioneer</a>&nbsp;the use of AI in campaign videos in 2020. They’ve become common in recent state elections.&nbsp;</p><ul><li>The party that governs the state of Tamil Nadu&nbsp;<a href="https://www.aljazeera.com/economy/2024/2/12/how-ai-is-used-to-resurrect-dead-indian-politicians-as-elections-loom?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">released</a>&nbsp;videos that feature an AI-generated likeness of a leader who died in 2018. The Indian media firm Muonium built the model by training a voice model on the politician’s speeches from the 1990s.</li><li>In a December state election, the Congress party circulated a video in which its chief opponent, the leader of a rival BRS party, tells voters to choose Congress. BRS said the video was deepfaked.</li><li>A startup called&nbsp;<a href="https://theindiandeepfaker.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">The Indian Deepfaker</a>&nbsp;has cloned candidates’ voices and produced younger-looking images of them for several parties. In November, the firm cloned the voice of a state leader of the Congress party to send personalized audio messages to potential voters. It rejected more than 50 requests to alter video and audio to target political opponents, including calls to create pornographic material.</li></ul><p><strong>Meanwhile, in Pakistan:</strong>&nbsp;Neighboring Pakistan was deluged with deepfakes in the run-up to its early-February election. Former prime minister Imran Khan, who has been imprisoned on&nbsp;<a href="https://www.bbc.com/news/world-asia-65541518?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">controversial</a>&nbsp;charges since last year,&nbsp;<a href="https://www.nytimes.com/2024/02/11/world/asia/imran-khan-artificial-intelligence-pakistan.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">communicated</a>&nbsp;with followers via a clearly marked AI-generated likeness. However, he found himself victimized by deepfakery when an AI-generated likeness of him, source unknown,&nbsp;<a href="https://www.voanews.com/a/deepfakes-internet-access-cuts-make-election-coverage-hard-journalists-say-/7498917.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">urged</a>&nbsp;his followers to boycott the polls.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;Deepfakes have proliferated in India in the absence of comprehensive laws or regulations that govern them. Instead of regulating them directly, government officials have pressured social media operators like Google and Meta to moderate them.</p><p><strong>What they’re saying:</strong>&nbsp;“Manipulating voters by AI is not being considered a sin by any party,” an anonymous Indian political consultant told&nbsp;<em>Al Jazeera</em>. “It is just a part of the campaign strategy.”</p><p><strong>Why it matters:</strong>&nbsp;Political deepfakes are quickly becoming a global phenomenon. Parties from&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-generated-imagery-flooded-argentinas-presidential-race/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">Argentina</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-republicans-released-the-first-ai-generated-attack-ad/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">the United States</a>, and&nbsp;<a href="https://www.theguardian.com/world/2023/may/24/new-zealand-national-party-admits-using-ai-generated-people-in-ads?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">New Zealand</a>&nbsp;have distributed AI-generated imagery or video. But the sheer scale of India’s national election — in which more than&nbsp;<a href="https://www.thehindu.com/news/national/india-has-nearly-97-crore-voters-now-says-ec/article67828780.ece?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">900 million people</a>&nbsp;are eligible to vote — has made it an active laboratory for synthetic political messages.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Synthetic media has legitimate political uses, especially in a highly multilingual country like India, where it can enable politicians to communicate with the public in a variety of languages and dialects. But unscrupulous parties can also use it to sow misinformation and&nbsp;<a href="https://gvu.gatech.edu/research/projects/liars-dividend-impact-deepfakes-and-fake-news-politician-support-and-trust-media?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">undermine</a>&nbsp;trust in politicians and media. Regulations are needed to place guardrails around deepfakes in politics. Requiring identification of generated campaign messages would be a good start.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-20T163859.691.gif" width="600" /></figure><h1 id="cutting-the-cost-of-pretrained-models">Cutting the Cost of Pretrained Models</h1><p>Research aims to help users select large language models that minimize expenses while maintaining quality.</p><p><strong>What's new:</strong>&nbsp;Lingjiao Chen, Matei Zaharia, and James Zou at Stanford proposed&nbsp;<a href="https://arxiv.org/abs/2305.05176?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">FrugalGPT</a>, a cost-saving method that calls pretrained large language models (LLMs) sequentially, from least to most expensive, and stops when one provides a satisfactory answer.&nbsp;</p><p><strong>Key insight:</strong>&nbsp;In many applications, a less-expensive LLM can produce satisfactory output most of the time. However, a more-expensive LLM may produce satisfactory output more consistently. Thus, using multiple models selectively can save substantially on processing costs. If we arrange LLMs from least to most expensive, we can start with the least expensive one. A separate model can evaluate its output, and if it’s unsatisfactory, another algorithm can automatically call a more expensive LLM, and so on.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors used a suite of 12 commercial LLMs, a model that evaluated their output, and an algorithm that selected and ordered them. At the time, the LLMs’ costs (which are subject to change) spanned two orders of magnitude: GPT-4 cost $30/$60 per 1 million tokens of input/output, while GPT-J hosted by Textsynth cost $0.20/$5 per 10 million tokens of input/output.&nbsp;</p><ul><li>To classify an LLM’s output as satisfactory or unsatisfactory, the authors fine-tuned separate&nbsp;<a href="https://arxiv.org/abs/1910.01108?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">DistilBERTs</a>&nbsp;on a diverse selection of datasets:&nbsp;<a href="https://arxiv.org/abs/2009.04202?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">one</a>&nbsp;that paired news headlines and subsequent changes in the price of gold,&nbsp;<a href="https://arxiv.org/abs/2104.08671?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">another</a>&nbsp;that labeled excerpts from court documents according to whether they rejected a legal precedent, and a&nbsp;<a href="https://arxiv.org/abs/1808.07042?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--QGCoaEh42QGUTnfoPl5an-ds0dVuJeNXLRxVO4h72DKVH187SV0hJ06VkEN-DlSHanUDK" rel="noopener">third</a>&nbsp;dataset of questions and answers. Given an input/output pair (such as a question and answer), they fine-tuned DistilBERT to produce a high score if the output was correct and low score if it wasn’t. The output was deemed satisfactory if its score exceeded a threshold.</li><li>A custom algorithm (which the authors don’t describe in detail) learned to choose three LLMs and put them in order. For each dataset, it maximized the percentage of times a sequence of three LLMs generated the correct output within a set budget.&nbsp;</li><li>The first LLM received an input. If its output was unsatisfactory, the second LLM received the input. If the second LLM’s output was unsatisfactory, the third LLM received the input.</li></ul><p><strong>Results:</strong>&nbsp;For each of the three datasets, the authors found the accuracy of each LLM. Then they found the cost for FrugalGPT to match that accuracy. Relative to the most accurate LLM, FrugalGPT saved 98.3 percent, 73.3 percent, and 59.2 percent, respectively.</p><p><strong>Why it matters:</strong>&nbsp;Many teams choose a single model to balance cost and quality (and perhaps speed). This approach offers a way to save money without sacrificing performance.</p><p><strong>We're thinking:</strong>&nbsp;Not all queries require a GPT-4-class model. Now we can pick the right model for the right prompt.</p><hr /><h1 id="data-points">Data Points</h1><p>Find more AI news of the week in <a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a>, including:&nbsp;</p><p>◆ AI takes over hockey and racing<br />◆ An advanced brain surgery assistant<br />◆ Google’s measures for the Indian General Election<br />◆ OpenAI’s licensing agreement with Le Monde and Prisa&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-241/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points now</a>.</p>
]]></content:encoded>
<pubDate>Wed, 20 Mar 2024 21:41:36 GMT</pubDate>
</item>
<item>
<title>Anthropic Ups the Ante, India Warns Developers, Google Tests Generative News, Learning Language Without Language Training</title>
<link>https://www.deeplearning.ai/the-batch/issue-240</link>
<guid>https://www.deeplearning.ai/the-batch/issue-240</guid>
<content:encoded><![CDATA[
<div> 关键词：数据吸引力、生成AI应用、数据传输成本、云计算

总结:
数据吸引力是指数据或围绕数据的活动会吸引和产生更多数据的概念。然而，对于许多生成AI应用来说，处理数据的成本远远高于传输数据的成本。这导致数据与存储它的云服务提供商或数据中心的联系变得弱化，因此在不同的服务器之间传输数据包变得更加实际。这意味着即使我们主要在特定的云平台上构建软件，也可以将LLM提示传输到其他服务提供商以获取响应。对于开发人员和企业来说，数据吸 <div>
<p><em>Dear friends,</em></p><p><em>I’ve noticed a trend in how generative AI applications are built that might affect both big companies and developers: The gravity of data is decreasing. </em></p><p><em>Data gravity is the idea, proposed by IT engineer Dave McCrory in 2010, that data, or activity around data, attracts and creates more data. With traditional software workloads, data gravity is strong. If you have terabytes of data stored in a particular cloud, the cost to transmit it elsewhere for processing is high. So many teams pick a cloud such as AWS, Azure, or Google Cloud and build on it.</em></p><p><em>However, for many generative AI applications, the cost of processing is much greater than the cost of transmission. This weakens data gravity because data is more weakly bound to the cloud provider or data center where it’s stored, so it’s more practical to build systems that send packets to different servers all over the internet.&nbsp;</em></p><p><em>Let’s say transmitting 1GB of data costs $0.10. 1GB of text might correspond to about 250 million inputs tokens (if we average four characters per token), which costs about $125 to process using the relatively inexpensive gpt-3.5-turbo-0125 model. (With gpt-4-0125-preview, the cost would be 20x higher.) The cost of processing the data is significantly higher than the cost of transmission. Also, given the computationally intensive nature of using an LLM to read and generate tokens, the latency is high enough that sending your text or image tokens across the internet usually doesn’t add that much further latency.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--51--1.jpg" width="1200" /></figure><p><em>This means that, even if we’re building software primarily on a particular cloud provider, it’s still quite feasible to transmit LLM prompts to OpenAI, Anthropic, Anyscale, or Together.ai — or, for that matter, AWS, Azure, or Google Cloud — to get a response. The incentive to build only on a single, monolithic cloud platform is lower than before. &nbsp;</em></p><p><em>This situation has implications for stakeholders:</em></p><ul><li><em>For developers, it means we’re increasingly assembling AI applications from lots of SaaS providers all across the internet, and stitching their services together.</em></li><li><em>For CIOs, it’s creating headaches in terms of managing where their data goes and how to maintain lists of trusted vendors.</em></li><li><em>For the big cloud companies, it’s changing the basis of competition, since the generative AI portions of their customer workloads look quite different from traditional software workloads.</em></li><li><em>For new tool developers, it’s creating new opportunities for users to use their services, even if they aren’t bundled into one of cloud environments.</em></li></ul><p><em>To be clear, many applications have large traditional software components (that serve up a websites, maintain databases, and so on) as well as new generative AI components (say, a chatbot built on top of the traditional infrastructure). My remarks here apply only to the generative AI portion, and the competitive dynamics of the traditional software components haven’t changed much.</em></p><p><em>Further, as new types of AI components emerge, I expect their gravity to evolve as well. For example, right now it appears reasonably easy to change LLM providers; if you’ve built a system on one LLM, it’s annoying but not impossible to switch to a different LLM provider. In comparison, shifting databases is much harder, and once you’ve stored a lot of data in one vector database, the complexity of migrating to a different one can be high.&nbsp;</em></p><p><em>The gravity of data has been a fundamental tenet of cloud computing, and a major factor of competition for many companies. Decreasing data gravity is decreasing is a complex, exciting trend that will affect many developers and businesses.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S.&nbsp;Our new short course “Knowledge Graphs for RAG” is now available, taught by Andreas Kollegger of Neo4j! Knowledge graphs are a data structure that’s great at capturing complex relationships among data of multiple types. They can improve the context you pass to the LLM and the performance of your RAG applications by enabling more sophisticated retrieval of text than similarity search alone. In this course, you’ll build a knowledge graph&nbsp;from scratch and see how it improves chat applications by providing both text and graph data to an LLM.&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener"><em>Sign up here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-13T144706.378.gif" width="1200" /></figure><h1 id="anthropic-ups-the-ante">Anthropic Ups the Ante</h1><p>Anthropic announced a suite of large multimodal models that set new states of the art in key benchmarks.</p><p><strong>What’s new:</strong>&nbsp;Claude 3 comprises three language-and-vision&nbsp;<a href="https://www.anthropic.com/news/claude-3-family?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">models</a>: Opus (the largest and most capable), Sonnet (billed as the most cost-effective for large-scale deployments), and Haiku (the smallest, fastest, and least expensive to use). Opus and Sonnet are available via the Claude API, on&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-multi-billion-dollar-deal-between-amazon-and-anthropic/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Amazon Bedrock</a>, and in a private preview on&nbsp;<a href="https://www.deeplearning.ai/the-batch/anthropic-secures-2-billion-investment-from-google-weeks-after-amazon-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Google Cloud</a>. Opus also is&nbsp; available with the Claude Pro chatbot, which costs $20 monthly. Sonnet powers Claude’s free chatbot.</p><p><strong>How it works:</strong>&nbsp;The models, whose parameter counts are undisclosed, were trained on public, proprietary, and synthetic data ending in August 2023. They can process 200,000 tokens of context. Opus can accommodate up to 1 million tokens of context, comparable to&nbsp;<a href="https://www.deeplearning.ai/the-batch/gemini-1-5-pro-a-leap-in-multimodal-ai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Google’s Gemini 1.5 Pro</a>, upon request.</p><ul><li>Opus costs $15 per 1 million tokens of input and $75 per 1 million tokens of output; Sonnet costs $3/$15 per 1 million tokens of input/output. Haiku, which is not yet available, will cost $0.25/$1.25 per 1 million tokens of&nbsp; input/output.</li><li>Opus achieved state-of-the-art performance on several benchmarks that cover language, mathematics, reasoning, common knowledge, and code generation, outperforming OpenAI's GPT-4 and Google’s Gemini 1.0 Ultra. It ranks above Gemini 1.0 Pro on the&nbsp;<a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">LMSYS Chatbot Arena Leaderboard</a>, which reflects crowdsourced human preferences.</li><li>Sonnet set a new state of the art in AI2D (interpreting science diagrams). It outperforms GPT-4 and Gemini 1.0 Pro on several benchmarks.</li><li>Haiku achieved top marks in Chart Q&amp;A (answering questions about charts) via zero-shot, chain-of-thought prompting. Generally, it outperforms Gemini 1.0 Pro and GPT-3.5.</li></ul><p><strong>Test recognition:</strong>&nbsp;Opus aced “needle-in-a-haystack” tests to evaluate its ability to track long inputs. It also exhibited interesting behavior: In one such test, amid random documents that covered topics including startups, coding, and work culture, engineers inserted a sentence about pizza toppings and questioned the model on that topic. Not only did the model answer the question accurately, it also deduced that it was being tested, as Anthropic prompt engineer Alex Albert&nbsp;<a href="https://twitter.com/alexalbert__/status/1764722513014329620?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">reported</a>&nbsp;in a post on X. “I suspect this pizza topping ‘fact’ may have been inserted as a joke or to test if I was paying attention,” Opus said, “since it does not fit with the other topics at all.”&nbsp;&nbsp;</p><p><strong>Inside the system prompt:</strong>&nbsp;In a separate post on X, Anthropic alignment specialist Amanda Askell provided a rare peek at the thinking behind Claude 3’s system prompt, text prepended to user prompts to condition the model’s responses. To ground them in time, the models receive the current date and its training cut-off. To avoid rambling output, they’re directed to be concise. In an effort to correct for political and social biases that the team has observed, the models are asked to assist users even if it “personally disagrees with the views being expressed,” refrain from negative stereotyping of majority groups, and focus on objective information when addressing controversial topics. Finally, it’s directed to avoid discussing the system prompt unless it’s directly relevant to a query. “You might think this part is to keep the system prompt secret from you,” Askell wrote. “The real goal of this part is to stop Claude from excitedly telling you about its system prompt at every opportunity.”</p><p><strong>Why it matters:</strong>&nbsp;Anthropic began with a focus on&nbsp;<a href="https://www.anthropic.com/news/claudes-constitution?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">fine-tuning for safety</a>, and its flagship model now tops several benchmark leaderboards as well. The Claude 3 family gives developers access to state-of-the-art performance at competitive prices.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>Three highly capable “GPT-4-class” large language models (LLMs) are now widely available: GPT-4, Gemini Pro, and Claude 3. The pressure is on for teams to develop an even more advanced model that leaps ahead and differentiates. What a great time to be building applications on top of LLMs!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--52-.jpg" width="1200" /></figure><h1 id="india-warns-devs-no-unreliable-ai">India Warns Devs: No Unreliable AI</h1><p>India advised major tech companies to seek government approval before they deploy new AI models.</p><p><strong>What’s new:</strong>&nbsp;India’s Ministry of Electronics and Information Technology (MeitY)&nbsp;<a href="https://www.reuters.com/world/india/india-asks-tech-firms-seek-approval-before-releasing-unreliable-ai-tools-2024-03-04/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">issued</a>&nbsp;a nonbinding “advisory” to technology firms, including Google, Meta, and OpenAI, to seek government permission before releasing AI models their developers consider unreliable or still in testing.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The&nbsp;<a href="https://regmedia.co.uk/2024/03/04/meity_ai_advisory_1_march.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">notice</a>&nbsp;asks platforms and other intermediaries to label AI-generated media clearly and to warn customers that AI systems may output inaccurate information. It also says that models should avoid bias, discrimination, and undermining the integrity of the electoral process.</p><ul><li>Although the notice appears to apply to AI broadly, Rajeev Chandrasekhar, India’s&nbsp;Minister of State for Skill Development and Entrepreneurship,&nbsp;<a href="https://twitter.com/Rajeev_GoI/status/1764534565715300592?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">clarified</a>&nbsp;that it applies to large, “significant” platforms and not to startups. He did not define “significant.” IT Minister Ashwini Vaishnaw&nbsp;<a href="https://www.cnbctv18.com/technology/it-minister-ashwini-vaishnaw-clarifies-that-advisory-on-ai-is-not-binding-aimed-at-socialmediacompanies-19195391.htm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">added</a>&nbsp;that the request is aimed at AI for social media, not agriculture or healthcare.</li><li>The notice’s legal implications are ambiguous. It is not binding. However, Chandrasekhar&nbsp;said the new rules signal “the future of regulation” in India.</li><li>Firms are asked to comply immediately and submit reports within 15 days of the notice’s March 1 publication date. Those that comply will avoid lawsuits from consumers, Chandrasekhar&nbsp;<a href="https://twitter.com/Rajeev_GoI/status/1764534565715300592?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">wrote</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;India has regulated AI with a light touch, but it appears to be reconsidering in light of the growing&nbsp;<a href="https://www.aljazeera.com/economy/2024/2/12/how-ai-is-used-to-resurrect-dead-indian-politicians-as-elections-loom?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">role</a>&nbsp;of AI-generated campaign ads in its upcoming elections.</p><ul><li>Recently, given a prompt that asked whether a particular Indian leader “is fascist,” Google’s Gemini&nbsp;<a href="https://www.theguardian.com/world/2024/feb/26/india-confronts-google-over-gemini-ai-tools-fascist-modi-responses?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">responded</a>&nbsp;that the leader in question had been “accused of implementing policies some experts have characterized as fascist.” This output prompted Indian officials to&nbsp;<a href="https://twitter.com/Rajeev_GoI/status/1760910808773710038?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">condemn</a>&nbsp;Gemini as unreliable and potentially illegal. Google&nbsp;<a href="https://www.deeplearning.ai/the-batch/gemini-1-5-pro-a-leap-in-multimodal-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">tweaked</a>&nbsp;the model, pointing out that it’s experimental and not entirely reliable.</li><li>In February, Chandrasekhar&nbsp;<a href="https://www.thehindu.com/sci-tech/technology/draft-ai-regulation-framework-to-be-released-by-july-rajeev-chandrasekhar/article67867288.ece?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">said</a>&nbsp;the government would publish a framework to regulate AI by summer. The framework, which has been in development since at least May 2023, is intended to establish a comprehensive list of harms and penalties related to misuse of AI.&nbsp;</li><li>In November and December, the Ministry of Electronics and Information Technology issued similar&nbsp;<a href="https://economictimes.indiatimes.com/tech/technology/deepfake-menace-govt-issues-advisory-t[%E2%80%A6]h-existing-it-rules/articleshow/106297813.cms?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">notices</a>&nbsp;to social media companies. The statements advised them to crack down on deepfake videos, images, and audio circulating on their platforms.</li></ul><p><strong>Why it matters:</strong>&nbsp;National governments worldwide, in formulating their responses to the rapid evolution of AI, must balance the benefits of innovation against fears of disruptive technology. Fear seems to weigh heavily in India’s new policy. While the policy’s scope is narrower than it first appeared, it remains unclear what constitutes a significant platform, how to certify an AI model as reliable, whether services like ChatGPT are considered social platforms that would be affected, and how violations might be punished.</p><p><strong>We’re thinking:</strong>&nbsp;While combating misinformation is important, forcing developers to obtain government approval to release new models will hold back valuable innovations. We urge governments to continue to develop regulations that guard against harms posed by specific applications while allowing general-purpose technology to advance and disseminate rapidly.&nbsp;</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/knowledge-graphs-rag?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1046" src="https://dl-staging-website.ghost.io/content/images/2024/03/V2_DeepLearning_Neo4js_Banner_2070x1080--1-.png" width="2000" /></a></figure><p>Knowledge graphs can structure complex data, drive intelligent search functionality, and help you build powerful AI applications that reason over different data types. In this course, you’ll learn how to use knowledge graphs to enhance large language models (LLMs).&nbsp;<a href="https://www.deeplearning.ai/short-courses/knowledge-graphs-rag?ref=dl-staging-website.ghost.io" rel="noreferrer">Sign up for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed--53-.jpg" width="1200" /></figure><h1 id="google-tests-generative-news-tools">Google Tests Generative News Tools</h1><p>Google is paying newsrooms to use a system that helps transform press releases into articles.<br /><br /><strong>What’s new:</strong>&nbsp;Google has recruited a small number of independent news outlets for a one-year test of generative publishing tools,&nbsp;<em>Adweek</em>&nbsp;<a href="https://www.adweek.com/media/google-paying-publishers-unreleased-gen-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">reported</a>. The system reads external web pages and produces articles that editors can revise and publish.<br /><br /><strong>How it works:</strong>&nbsp;Google requires publishers to use the system to produce and publish three articles per day, one newsletter per week, and one marketing campaign per month. (It doesn’t require them to label the system’s output as AI-generated.) In exchange, publishers receive a monthly stipend that amounts to more than $10,000 annually.&nbsp;</p><ul><li>Publishers compile a list of external websites that produce information that may interest its readers, such as government websites or those of similar news outlets. Whenever one of the indexed websites publishes a new page, the system notifies the publisher.</li><li>At the publisher’s choice, an unidentified generative model summarizes the page’s content. It color-codes the output according to its similarity to the source: yellow for text copied nearly verbatim, blue for somewhat similar material, and red for sentences that least resemble the source.</li><li>A human editor can review the generated text before publishing it.</li></ul><p><strong>Behind the news:</strong>&nbsp;The pilot program is part of the&nbsp;<a href="https://newsinitiative.withgoogle.com/en-gb/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Google News Initiative</a>, through which the tech giant provides media literacy programs, fact-checking tools, and digital publishing tools to news outlets. Last year, Google&nbsp;<a href="https://www.nytimes.com/2023/07/19/business/google-artificial-intelligence-news-articles.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">demonstrated</a>&nbsp;a tool known as Genesis to news outlets including&nbsp;<em>The New York Times</em>,&nbsp;<em>The Washington Post</em>, and&nbsp;<em>The Wall Street Journal</em>. Like the new system, Genesis took in public information and generated news articles. It also suggested headlines and different writing styles. Then, as now, observers worried that Google eventually would use its tools to bypass news outlets by publishing news summaries directly in search results.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Such partnerships could yield dividends for Google and publishers alike. Google can learn what publishers need and how a generative model built to produce news holds up under the pressure of deadlines and audiences. Publishers can gain experience that may help them avoid the criticisms that greeted outlets like&nbsp;<a href="https://www.deeplearning.ai/the-batch/cnet-pauses-its-practice-of-writing-news-articles-with-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">CNET</a>,&nbsp;&nbsp;<a href="https://www.theverge.com/2023/7/8/23788162/gizmodo-g-o-media-ai-generated-articles-star-wars?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Gizmodo</a>, and&nbsp;<a href="https://www.bbc.co.uk/news/world-us-canada-67560354?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Sports Illustrated</a>, whose initial efforts to publish generated articles were either hidden behind false bylines or marred by factual inaccuracies.</p><p><strong>We’re thinking:</strong>&nbsp;Text generation could be a boon to publishers. Checking generated text (or, indeed, any synthetic media) for similarity to its source material is a sensible feature that could be useful in a variety of applications. Yet the utility of a system that summarizes individual web pages is limited, and the temptation to echo competitors may be hard to resist. We look forward to further improvements that enable agents that can assimilate and analyze text from disparate sources.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-13T145040.685.gif" width="600" /></figure><h1 id="learning-language-by-exploration">Learning Language by Exploration</h1><p>Machine learning models typically learn language by training on tasks like predicting the next word in a given text. Researchers trained a language model in a less focused, more human-like way.</p><p><strong>What’s new</strong>: A team at Stanford led by Evan Zheran Liu built a&nbsp;<a href="https://openreview.net/forum?id=OUicoKgvtc&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">reinforcement learning agent that learned language indirectly</a>&nbsp;by learning to navigate a simulated environment that provides text clues.&nbsp;</p><p><strong>Key insight:</strong>&nbsp;Reinforcement learning agents learn by discovering actions that maximize rewards. If the training environment provides text that explains how to achieve the highest reward, an agent will benefit by learning to interpret written language. That is, learning to comprehend written instructions will correlate with success in maximizing rewards.</p><p><strong>How it works:</strong>&nbsp;The authors built a series of simulated two-dimensional environments using&nbsp;<a href="https://github.com/Farama-Foundation/Minigrid?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">Minigrid</a>, a reinforcement learning library that contains grid-world environments. They trained the agent to find a particular room according to the&nbsp;<a href="https://arxiv.org/abs/2008.02790?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">DREAM</a>&nbsp;reinforcement learning algorithm.</p><ul><li>The authors designed a two-dimensional layout of rooms connected by hallways. The layout included 12 rooms, each painted in one of 12 colors that were assigned randomly. A consistent location held instructions for finding the blue room.&nbsp;</li><li>The authors created many variations of the layout by reassigning the colors and updating the text instructions for finding the blue room. The instructions were either direct (for instance, “the second office in the third row”) or relative (“right of the first office in the second row”).&nbsp;</li><li>The agent received a reward when it found the blue room and a penalty for each time step. At each time step, it received a subset of the office environment (a 7-by-7 grid in its direct line of sight) and could take one of several actions (turn left or right, move forward, or open or close a door). When it reached the location that held the instructions, it received an image of the text. It continued to explore for a set time or until it found the blue room.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;The authors tested the agent’s ability to generalize to text it had not encountered in training: They trained the agents on layouts that excluded text that described the blue room as the “third office in the second row” and tested it on layouts that included these words. The agent found the blue room every time without checking every room. They also tested the agent in layouts where the hallways were twice as long as in the training set. It always found the blue room. To determine whether the agent understood individual words in the instructions, the authors collected its embeddings of many instructions and trained a single-layer LSTM to extract the instructions from the embeddings. The LSTM achieved a perplexity (a measure of the likelihood that it would predict the next word of instructions that were not in its training data, lower is better) of 1.1, while a randomly-initialized network of the same architecture achieved 4.65 perplexity — an indication that the agent did, indeed, learn to read individual words.</p><p><strong>Yes, but:</strong>&nbsp;The choice of reinforcement-learning algorithm was crucial. When the authors replaced DREAM with either&nbsp;<a href="https://arxiv.org/abs/1611.02779?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">RL<sup>2</sup></a>&nbsp;or&nbsp;<a href="https://arxiv.org/abs/1910.08348?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8inrvPcSiotzMx3NHE0OcmB185WpTlIzg8uKR9JkmAMTY7ElVDkpgDZKqiIJORN5C08z5y" rel="noopener">VariBAD</a>), the agent did not learn language. Instead, it learned to check all the doors.</p><p><strong>Why it matters:</strong>&nbsp;The discovery that reinforcement-learning agents can learn language without explicit training opens avenues for training language models that use objectives different from traditional text completion.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;The authors focused on simple language (instructions limited to a few words and a very small vocabulary) that described a single domain (navigating hallways and rooms). There's a long road ahead, but this work could be the start of a more grounded approach to language learning in AI.</p><hr /><h1 id="data-points">Data Points</h1><p><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> is your essential weekly roundup of short-form AI insights. From the approval of the AI Act, to AMD’s regulatory hurdle in the US, and a new copyright detection API by Patronus AI - we've got even more updates wrapped up for you inside. <a href="https://www.deeplearning.ai/the-batch/data-points-issue-240/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 13 Mar 2024 19:55:44 GMT</pubDate>
</item>
<item>
<title>Mistral Living Large, Google's Open Source Challenger, Robot Chemist, Schooling Language Models in Math</title>
<link>https://www.deeplearning.ai/the-batch/issue-239</link>
<guid>https://www.deeplearning.ai/the-batch/issue-239</guid>
<content:encoded><![CDATA[
<div> LLM-based agents, progress, browsing the web, experimentation, evaluation, multi-agent systems, Mistral AI, Google, Robot Chemist.<br /><br />总结: LLM-based agents目前在自主规划和执行行动序列方面取得了快速进展。尽管以浏览网页为主的研究型代理的进展较快，但物流成本高昂，导致实验进程缓慢。多代理系统的发展也是一个激动人心的趋势。Mistral AI与Microsoft的合作为该初创公司提供了训练大型模型的重要技术支持，同时也将其推向了全球市场。Google的开源模型Gemma-7B推动了7亿参数模型的发展。然而，目前的LLMs在数学方面仍存在差距，但新的研究方法可能有助于提高其在数学问题上的表现。 <div>
<p><em>Dear friends,</em></p><p><em>Progress on LLM-based agents that can autonomously plan out and execute sequences of actions has been rapid, and I continue to see month-over-month improvements. Many projects attempt to take a task like “write a report on topic X” and autonomously take actions such as browsing the web to gather information to synthesize a report.&nbsp;<br /><br />AI agents can be designed to take many different types of actions. Research agents (like many projects built on&nbsp;</em><a href="https://github.com/Significant-Gravitas/AutoGPT?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>AutoGPT</em></a><em>,&nbsp;</em><a href="https://github.com/assafelovic/gpt-researcher?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>GPTresearcher</em></a><em>, or&nbsp;</em><a href="https://arxiv.org/abs/2402.14207?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>STORM</em></a><em>) search the web and fetch web pages. A sales representative agent might dispatch a product to a user. An industrial automation agent might control a robot.</em></p><p><em>So far, I see agents that browse the web progressing much faster because the cost of experimentation is low, and this is key to rapid technical progress. It’s cheap to fetch a webpage, and if your agent chooses poorly and reads the wrong page, there’s little harm done. In comparison, sending a product or moving a physical robot are costly actions, which makes it hard to experiment rapidly. Similarly, agents that generate code (that you can run in a sandbox environment) are relatively cheap to run, leading to rapid experimentation and progress.&nbsp;<br /><br />Although today’s research agents, whose tasks are mainly to gather and synthesize information, are still in an early phase of development, I expect to see rapid improvements. ChatGPT, Bing Chat, and Gemini can already browse the web, but their online research tends to be limited; this helps them get back to users quickly. But I look forward to the next generation of agents that can spend minutes or perhaps hours doing deep research before getting back to you with an output. Such algorithms will be able to generate much better answers than models that fetch only one or two pages before returning an answer.<br /><br />Even when experimentation is quick, evaluation remains a bottleneck in development. If you can try out 10 algorithm variations quickly, how do you actually pick among them? Using an LLM to evaluate another LLM's output is common practice, but prompting an LLM to give very accurate and consistent evaluations of text output is a challenge. Any breakthroughs here will accelerate progress!</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/03/MULTIAGENTS2-1.png" width="1200" /></figure><p><em>An exciting trend has been a move toward multi-agent systems. What if, instead of having only a single agent, we have one agent to do research and gather information, a second agent to analyze the research, and a third to write the final report? Each of these agents can be built on the same LLM using a different prompt that causes it to play a particular, assigned role. Another common design pattern is to have one agent write and a second agent work as a critic to give constructive feedback to the first agent to help it improve. This can result in much higher-quality output. Open-source frameworks like Microsoft’s&nbsp;</em><a href="https://microsoft.github.io/autogen/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>AutoGen</em></a><em>,&nbsp;</em><a href="https://crewai.net/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>Crew AI</em></a><em>, and&nbsp;</em><a href="https://python.langchain.com/docs/langgraph?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>LangGraph</em></a><em>&nbsp;are making it easier for developers to program multiple agents that collaborate to get a task done.&nbsp;<br /><br />I’ve been playing with many agent systems myself, and I think they are a promising approach to architecting intelligent systems. A lot of progress has been made by scaling up LLMs, and this progress no doubt will continue. But big ideas are sometimes made up of many, many little ideas. (For example, you might arrive at an important mathematical theorem via lots of little derivation steps.) Today’s LLMs can reason and have lots of “little ideas” in the sense that they take in information and make basic inferences.&nbsp;</em><a href="https://arxiv.org/pdf/2201.11903.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>Chain-of-thought prompting</em></a><em>&nbsp;shows that guiding an LLM to think step-by-step — that is, to string together many basic inferences — helps it to answer questions more accurately than asking it to leap to a conclusion without intermediate steps.</em></p><p><em>Agent programming models are a promising way to extend this principle significantly and guide LLMs to have lots of little ideas that collectively constitute bigger and more useful ideas.&nbsp;</em></p><p><em>Keep learning!&nbsp;<br />Andrew</em></p><p><em>P.S. New short course: “Open Source Models with Hugging Face,” taught by Maria Khalusova, Marc Sun, and Younes Belkada! Hugging Face has been a game changer by letting you quickly grab any of hundreds of thousands of already-trained open source models to assemble into new applications. This course teaches you best practices for building this way, including how to search and choose among models. You’ll learn to use the Transformers library and walk through multiple models for text, audio, and image processing, including zero-shot image segmentation, zero-shot audio classification, and speech recognition. You’ll also learn to use multimodal models for visual question answering, image search, and image captioning. Finally, you’ll learn how to demo what you build locally, on the cloud, or via an API using Gradio and Hugging Face Spaces.&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener"><em>Please sign up here</em></a><em>&nbsp;</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161635.694.gif" width="1200" /></figure><h1 id="mistral-ai-extends-its-portfolio">Mistral AI Extends Its Portfolio</h1><p>European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Mistral AI&nbsp;<a href="https://mistral.ai/news/mistral-large/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">introduced</a>&nbsp;two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it&nbsp;<a href="https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">agreed</a>&nbsp;to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free&nbsp;<a href="http://chat.mistral.ai/chat?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">here</a>&nbsp;and to use on its&nbsp;<a href="https://mistral.ai/news/la-plateforme/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">La Plateforme</a>&nbsp;and via custom deployments.</p><p><strong>Model specs:</strong>&nbsp;The new models’ parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context.&nbsp;</p><ul><li>Mistral Large achieved 81.2 percent on the&nbsp;<a href="https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">MMLU</a>&nbsp;benchmark, outperforming Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.</li><li>Both models are fluent in French, German, Spanish, and Italian. They’re trained for function calling and JSON-format output.</li><li>Microsoft’s investment in Mistral AI is significant but tiny compared to its $13 billion&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-boosts-its-investment-in-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">stake</a>&nbsp;in OpenAI and Google and Amazon’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/anthropic-secures-2-billion-investment-from-google-weeks-after-amazon-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">investments</a>&nbsp;in Anthropic, which amount to $2 billion and $4 billion respectively.</li><li>Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.</li></ul><p><strong>Behind the news:</strong>&nbsp;Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France’s representatives in the European Commission&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">argued</a>&nbsp;on Mistral’s behalf to loosen the European Union’s AI Act oversight on powerful AI models.&nbsp;</p><p><strong>Yes, but:</strong>&nbsp;Mistral AI’s partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was&nbsp;<a href="https://www.euractiv.com/section/competition/news/eu-commission-to-examine-microsoft-openai-partnership/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">investigating</a>&nbsp;Microsoft’s agreement with OpenAI for potential breaches of antitrust law,&nbsp;<a href="https://www.politico.eu/article/european-commission-sets-its-sights-on-microsofts-ai-deal-with-frances-mistral/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">plans</a>&nbsp;to investigate the new partnership as well. Members of President Emmanuel Macron’s Renaissance party&nbsp;<a href="https://www.euractiv.com/section/artificial-intelligence/news/french-mps-voice-sovereignty-competition-concerns-after-microsoft-mistral-ai-deal/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">criticized</a>&nbsp;the deal’s potential to give a U.S. company access to European users’ data. However, other French lawmakers&nbsp;<a href="https://www.politico.eu/article/why-france-chose-to-be-europes-ai-playground/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">support</a>&nbsp;the relationship.</p><p><strong>Why it matters:</strong>&nbsp;The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that’s tailored to Europe’s unique regulatory environment.</p><p><strong>We’re thinking:</strong>&nbsp;Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161718.283.png" width="1200" /></figure><h1 id="robot-chemist">Robot Chemist</h1><p>A robot outperformed human chemists at synthesizing chemicals.</p><p><strong>What’s new:&nbsp;</strong>Researchers at University of Amsterdam built&nbsp;<a href="https://www.science.org/doi/10.1126/science.adj1817?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">RoboChem</a>, an integrated robotic system that learned to design light-activated chemical reactions while achieving optimal yields and throughput.</p><p><strong>How it works:</strong>&nbsp;RoboChem includes a computer that runs a machine learning model and a set of automated lab instruments including a liquid handler, syringe pumps, and a photochemical reactor, all enclosed in an airtight vacuum chamber. Given a set of reagents and resulting product, RoboChem aimed to find conditions that maximize the yield (the ratio of the amount of a product synthesized to the potential amount, expressed as a percentage) and throughput (rate of synthesis) in the fewest experimental runs. It followed a 3-part cycle: (i) determine experimental conditions (amounts and concentrations of the given reagents, intensity of light, and time spent in the reactor), (ii) combine the reagents under those conditions, and (iii) evaluate the yield and throughput via a spectrometer.&nbsp;</p><ul><li>RoboChem learned how to find the best conditions for each reaction using a Gaussian process, which provides a function and uncertainty estimate for variables to be maximized (in this case, yield and throughput) given the values of other variables (the experimental conditions). Given a set of reagents and 6 to 20 sets of random conditions, RoboChem ran the reactions, measured the results, and updated the Gaussian process.</li><li>RoboChem chose new conditions based on which parts of the Gaussian process’s function had the highest uncertainty and which parts were most likely to produce the highest yield and throughput. RoboChem ran the reaction, measured the results, and updated the Gaussian process.&nbsp;</li><li>It repeated this cycle until it achieved an author-defined throughput, yield, or number of experiments. It returned the conditions with the highest throughput and yield.</li></ul><p><strong>Results:&nbsp;</strong>Robochem&nbsp;executed reactions to produce 18 substances. In all cases, it found experimental conditions that had either higher throughput and yield, or higher throughput and nearly equivalent yield, than the best conditions previously known. In one reaction, RoboChem achieved yield of 58 percent and throughput of 95.6 g/Lh (gram yield per liter in the reactor per hour), while previous work had achieved 45 percent and 2.8 g/Lh. In another reaction, RoboChem achieved 81 percent and 1720 g/Lh, where previous best results achieved 82 percent and 3 g/Lh — 1 percent lower yield but 573 times greater throughput.&nbsp;</p><p><strong>Behind the news:</strong>&nbsp;In 2020, researchers at the University of Liverpool&nbsp;<a href="https://www.deeplearning.ai/the-batch/scientific-discovery-on-a-roll/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">trained</a>&nbsp;a mobile robot arm to navigate a chemistry lab, mix chemicals, and operate equipment. That robot used a similar optimization method. However, the Amsterdam robot is much less expensive and proved itself in a wider range of experiments.&nbsp;&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The authors believe that RoboChem could dramatically increase lab productivity at lower cost in time and money. The light-activated reactions they focused on have applications in fields including pharmaceuticals, household chemicals, and renewable energy.<br /><br /><strong>We’re thinking:</strong>&nbsp;These researchers clearly are in their element.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="1063" src="https://dl-staging-website.ghost.io/content/images/2024/03/The-Batch-ads-and-exclusive-banners---2024-03-05T085620.866.png" width="1890" /></a></figure><p>In “Open Source Models with Hugging Face,” our latest short course, you’ll use open source models to build chatbots, language translators, and audio narrators using Hugging Face tools like the model hub, transformers library, Spaces, and Gradio. <a href="https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/?ref=dl-staging-website.ghost.io" rel="noreferrer">Join now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161846.471.png" width="1200" /></figure><h1 id="google-releases-open-source-llms">Google Releases Open Source LLMs</h1><p>Google asserted its open source&nbsp;<em>bona fides</em>&nbsp;with new models.</p><p><strong>What’s new:</strong>&nbsp;Google&nbsp;<a href="https://blog.google/technology/developers/gemma-open-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">released</a>&nbsp;weights for Gemma-7B, an 8.5 billion-parameter large language model intended to run GPUs, and Gemma-2B, a 2.5 billion-parameter version intended for deployment on CPUs and edge devices. Each size is&nbsp;<a href="https://huggingface.co/models?search=google%2Fgemma&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">available</a>&nbsp;in two versions: pretrained base model and one fine-tuned to follow instructions.</p><p><strong>How it works:</strong>&nbsp;Gemma models are&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">based</a>&nbsp;on the architecture used in Google’s larger Gemini. Unlike Gemini, they’re not multimodal.&nbsp;</p><ul><li>Gemma-2B and Gemma-7B were trained on 2 trillion and 6 trillion tokens, respectively, of English-language web documents, mathematics, and code snippets. They can process 8,192 tokens of context.</li><li>The fine-tuned versions underwent further training: (i) They received supervised fine-tuning on human-written prompt-and-response pairs as well as synthetic responses that had been filtered for personal information, toxic responses, and other objectionable material. (ii) They were aligned using reinforcement learning with human feedback, in which their output was judged by a model trained on preferences expressed by users.</li><li>Gemma’s license permits commercial use but&nbsp;<a href="https://ai.google.dev/gemma/prohibited_use_policy?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">prohibits</a>&nbsp;a wide range of uses that Google deems harmful including copyright infringement, illegal activity, generating misinformation, or producing sexually explicit content.&nbsp;</li><li>Gemma-7B&nbsp;<a href="https://huggingface.co/blog/gemma?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">ranks</a>&nbsp;higher than comparably sized open models including Meta’s Llama 2 7B and Mistral-7B, according to HuggingFace’s&nbsp;<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">Open LLM Leaderboard</a>. By Google’s assessment, it outperforms the nearly double-sized Llama 2 13B in major question answering, reasoning, math, and coding benchmarks. Gemma-2B falls short of the most capable models of its size such as the 2.7-billion-parameter&nbsp;<a href="https://huggingface.co/microsoft/phi-2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">Phi-2</a>.</li></ul><p><strong>Behind the news:</strong>&nbsp;Google has a rich history of open source AI projects including AlphaFold, TensorFlow, several versions of BERT and T5, and the massive Switch. Lately, though, its open source efforts have been overshadowed by open large language models (LLMs) from Meta, Microsoft, and Mistral.ai. LLMs small enough to run on a laptop have opened open source AI to an expanding audience of developers.</p><p><strong>Why it matters:</strong>&nbsp;Gemma raises the bar for models of roughly 7 billion parameters. It delivers exceptional performance in a relatively small parameter counts, expanding the options for&nbsp;developers who are building on top of LLMs.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Gemma confirms Google’s commitment to open source and outperforms top open models of equal size. It’s likely to spur further innovation, especially in AI for&nbsp;<a href="https://www.deeplearning.ai/the-batch/why-ai-will-move-to-edge-devices/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">edge devices</a>, and keep the Google name in front of enterprising open source developers.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="480" src="https://dl-staging-website.ghost.io/content/images/2024/03/unnamed---2024-03-06T161921.552-1.gif" width="853" /></figure><h1 id="schooling-language-models-in-math">Schooling Language Models in Math</h1><p>Large language models are not good at math. Researchers devised a way to make them better.</p><p><strong>What's new:</strong>&nbsp;Tiedong Liu and Bryan Kian Hsiang Low at the National University of Singapore proposed a method to&nbsp;<a href="https://arxiv.org/abs/2305.14201?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">fine-tune large language models for arithmetic tasks</a>.</p><p><strong>Key insight:</strong>&nbsp;Large language models (LLMs) do fairly well at addition and subtraction as well as multiplication and division by single digits or by powers of 10. They’re less adept at the more challenging tasks of multiplication and division of larger numbers. One way to perform these tasks well is to divide them into simpler subtasks. For example, a relatively easy way to multiply two large numbers like 123 and 321 is to&nbsp;</p><ul><li>Split one number into decimal places (123 becomes 100 + 20 + 3)</li><li>Multiply the other number by each of these (100 * 321 + 20 * 321 + 3 * 321)</li><li>Add the resulting products to arrive at the solution (32100 + 6420 + 963 = 39483)</li></ul><p>A similar technique exists for division. Together, these approaches can enable LLMs to perform more complicated mathematical tasks.</p><p><strong>How it works:</strong>&nbsp;The authors built GOAT (a model GOod at Arithmetic Tasks) by fine-tuning&nbsp;<a href="https://arxiv.org/abs/2302.13971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">LLaMA</a>&nbsp;on a synthetic dataset that comprised 1 million examples of arithmetic operations on integers that were divided into steps for easier calculation.</p><ul><li>The prompts were simple instructions like “Calculate 397 x 4429” or “I would appreciate it if you could assist me in calculating 1463456 + 2107”.</li><li>The answers were either numbers (for the simpler operations) or chains of reasoning (for multiplications and divisions of larger numbers). For example, if the prompt was “Calculate 24x79”, the target was “24 * 79 = 24 * (70 + 9) = 24 * 70 + 24 * 9 = 1680 + 216 = 1896”.</li><li>To create these chains, the authors wrote a Python script. For multiplication, the script randomly generated two numbers, split one number into decimal places, multiplied the second number by each of those terms, then added the products. It followed a similar procedure for division.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared GOAT and GPT-4 on&nbsp;<a href="https://arxiv.org/abs/2206.04615?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-87IEkio4ktkOH9VkmcWuq2BgtXjYHRZma0dP7QYPpRBg1l-KOxs3aG7c2Wnxp0D-BYC7sE" rel="noopener">BIGBench</a>, which contains arithmetic operations on integers up to five digits. GOAT performed either on par with or better than GPT-4 for all operations. Specifically, GPT-4 struggled to multiply and divide large numbers. Multiplying 5-digit numbers, GPT-4 achieved 0 percent accuracy, while GOAT achieved 96.7 percent. Dividing five-digit numbers, GPT-4 achieved 53.4 percent, while GOAT achieved 96.5 percent. GOAT also performed better than other LLMs (Bloom, GPT-NeoX, OPT, and Pythia) that had been fine-tuned in the same way. The authors attribute this to the fact that LLaMA generates a separate token for each digit (and does not learn tokens that represent multiple digits), while the other models learn tokens for multiple digits (for example, separate tokens for 748, 74, and 7).</p><p><strong>Why it matters:</strong>&nbsp;LLMs have latent mathematical knowledge that can be unlocked by thoughtful fine-tuning.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Humans, too, aren’t great at multiplying or dividing numbers directly — but give us a pencil and paper so we can work things out step by step, and we’re much better.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>More AI news of the week includes:&nbsp;</p><p>🔊 Adobe previews an AI audio tool&nbsp;<br />💰 Microsoft launches Copilot for Finance<br />🐋 AI uncovers reasons behind humpback whale deaths</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-239/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points here.</a></p>
]]></content:encoded>
<pubDate>Wed, 06 Mar 2024 21:22:45 GMT</pubDate>
</item>
<item>
<title>Google's Troubled Gemini Launch, OpenAI's Next Act, Groq's Blazing Inference Speed, Faster Network Pruning</title>
<link>https://www.deeplearning.ai/the-batch/issue-238</link>
<guid>https://www.deeplearning.ai/the-batch/issue-238</guid>
<content:encoded><![CDATA[
<div> Python package management, AI application development, package dependencies, version management, friction. 

总结:<br /><br />在AI应用开发中，Python软件包管理的复杂性是一个被广泛低估的瓶颈。AI面临着多个瓶颈，我们需要更多的GPU、更好的算法、更干净的大规模数据。但是当我看到应用构建者的日常工作时，我发现一个额外的瓶颈很容易被忽视：与版本管理的斗争所花费的时间是一种低效率，我希望我们能够减少这种低效率。很多AI软件都是用Python语言编写的，因此我们的领域采用了Python的哲学，允许任何人在网上发布任何软件包。由此产生的丰富的免费软件包集合意味着，只需一个"pip install"命令，你现在就能安装一个软件包并赋予你的软件新的超能力！社区对于许多创意的并行探索和创新的开源非常出色，这不仅助力了技术思想的发展和传播，也助力了可用的工具的发展和传播。但是，我们付出了这种高度分布式的AI组件开发的代价：在开源的基础上构建可能意味着花费几个小时来解决软件包的依赖性问题，有时甚至需要同时操作多个虚拟环境或在一个应用程序中使用多个Python版本。这对于有着计算机科学或软件工程背景的有经验的开发人员来说可能是烦人但是可以管理的，但对于没有相关背景的新的AI开发人员来说，这会造成很多阻力。我不知道是否存在一个简单的解决方案。希望随着工具生态系统的成熟，软件包管理会变得 <div>
<p><em>Dear friends,<br /><br />I think the complexity of Python package management holds down AI application development more than is widely appreciated. AI faces multiple bottlenecks — we need more GPUs, better algorithms, cleaner data in large quantities. But when I look at the day-to-day work of application builders, there’s one additional bottleneck that I think is underappreciated: The time spent wrestling with version management is an inefficiency I hope we can reduce.&nbsp;</em></p><p><em>A lot of AI software is written in the Python language, and so our field has adopted Python’s philosophy of letting anyone publish any package online. The resulting rich collection of freely available packages means that, with just one “pip install” command, you now can install a package and give your software new superpowers! The community’s parallel exploration of lots of ideas and open-sourcing of innovations has been fantastic for developing and spreading not just technical ideas but also usable tools.<br /><br />But we pay a price for this highly distributed development of AI components: Building on top of open source can mean hours wrestling with package dependencies, or sometimes even juggling multiple virtual environments or using multiple versions of Python in one application. This is annoying but manageable for experienced developers, but creates a lot of friction for new AI developers entering our field without a background in computer science or software engineering.</em></p><figure class="kg-card kg-image-card"><img alt="Illustration of a Python inside a cardboard box" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/PYTHONPACKAGE-1.png" width="1200" /></figure><p><em>I&nbsp;don’t know of any easy solution. Hopefully, as the ecosystem of tools matures, package management will become simpler and easier. Better tools for testing compatibility might be useful, though I’m not sure we need yet another Python package manager (we already have pip, conda, poetry, and more) or virtual environment framework.&nbsp;</em></p><p><em>As a step toward making package management easier, maybe if all of us who develop tools pay a little more attention to compatibility — for example, testing in multiple environments, specifying dependencies carefully, carrying out more careful regression testing, and engaging with the community to quickly spot and fix issues — &nbsp;we can make all of this wonderful open source work easier for new developers to adopt.</em></p><p><em>Keep coding!</em></p><p><em>Andrew</em></p><p><em>P.S. Built in collaboration with Meta: “Prompt Engineering with Llama 2,” taught by Amit Sangani, is now available! Meta’s Llama 2 has been a game changer: Building with open source lets you control your own data, scrutinize errors, update models (or not) as you please, and work alongside the global community to advance open models. In this course, you’ll learn how to prompt Llama chat models using advanced techniques like few-shot for classification and chain-of-thought for logic problems. You’ll also learn how to use specialized models like Code Llama for software development and Llama Guard to check for harmful content. The course also touches on how to run Llama 2 on your own machine. I hope you’ll take this course and try out these powerful, open models!&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener"><em>Sign up here</em></a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/GEMINI_MultimodalDemo_NoCC_600px--1-.gif" width="600" /></figure><h1 id="context-is-everything">Context Is Everything</h1><p><em>Correction: This article has been corrected to state that Gemini 1.0 produced anachronistic images of historical scenes. An earlier edition incorrectly stated that Gemini 1.5 Pro generated anachronistic images. </em></p><p>An update of Google’s flagship multimodal model keeps track of colossal inputs, while an earlier version generated some questionable outputs.</p><p><strong>What's new:</strong>&nbsp;Google&nbsp;<a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">unveiled</a>&nbsp;Gemini 1.5 Pro, a model that can converse about inputs as long as books,&nbsp;codebases, and lengthy passages of video and audio (depending on frame and sample rates). However an earlier version, recently enabled to generate images, produced wildly inaccurate images of historical scenes.</p><p><strong>How it works:</strong>&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Gemini 1.5 Pro</a>&nbsp;updates the previous model with a mixture-of-experts architecture, in which special layers select which subset(s) of a network to use depending on the input. This enables the new version to equal or exceed the performance of the previous&nbsp;<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Gemini 1.0 Ultra</a>&nbsp;while requiring less computation.&nbsp;</p><ul><li>The version of Gemini 1.5 Pro that’s generally available will accept up to 128,000 input tokens of mixed text (in more than a dozen languages), images, and audio and generates text and images. A version available to selected users accepts up to 1 million input tokens — an immense increase over Anthropic Claude’s 200,000-token context window, the previous leader. You can sign up for access <a href="https://aistudio.google.com/app/waitlist/97445851?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=blog-feb&amp;utm_content=" rel="noreferrer">here</a>.</li><li>In demonstration&nbsp;<a href="https://deepmind.google/technologies/gemini/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF#gemini-1.5" rel="noopener">videos</a>, the version with 1 million-token context suggested modifications for 100,000 lines of example code from the three.js 3D JavaScript library. Given 500 pages of documentation that describes Kalamang, a language spoken by fewer than 200 people in West Papua, it translated English text into Kalamang as well as a human who had learned from the same materials. Given a crude drawing of one frame from a 44-minute silent movie, it found the matching scene (see animation above).&nbsp;</li><li>In experiments, the team extended the context window to 10 million tokens, which is equivalent to 10 books the length of Leo Tolstoy’s 1,300-page&nbsp;<em>War and Peace</em>, three hours of video at 1 frame per second, or 22 hours of audio.</li></ul><p><strong>Alignment with what?:</strong>&nbsp;The earlier Gemini 1.0 recently was <a href="https://blog.google/products/gemini/google-bard-gemini-pro-image-generation/?ref=dl-staging-website.ghost.io" rel="noreferrer">updated</a> to allow users to generate images using a specially fine-tuned version of&nbsp;<a href="https://blog.google/technology/ai/google-imagen-2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Imagen 2</a>. However, this capability backfired when social media posts appeared in which the system, prompted to produce pictures of historical characters and situations, anachronistically populated them with people of color, who would not have been likely to be present. For instance, the model illustrated European royalty, medieval Vikings, German soldiers circa 1943 — all of whom were virtually exclusively white — as Black, Asian, or Native American. Google quickly&nbsp;<a href="https://blog.google/products/gemini/gemini-image-generation-issue/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">disabled</a>&nbsp;image generation of people for “the next couple of weeks” and explained that fine-tuning intended to increase diverse outputs did not account for contexts in which diversity was inappropriate, and fine-tuning intended to keep the model from fulfilling potentially harmful requests also kept it from fulfilling harmless requests. But other users found flaws in text output as well. One asked Gemini who had a greater negative impact on society: Adolf Hitler, who presided over the murder of roughly 9 million people, or “Elon Musk tweeting memes.” The model replied, “It is difficult to say definitively who had a greater negative impact on society.” The ensuing controversy called into question not only Google’s standards and procedures for fine-tuning to ensure ethics and safety, but also its motive for building the model.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Gemini 1.5 Pro’s enormous context window radically expands potential applications and sets a high bar for the next generation of large multimodal models. At the same time, it’s clear that Google’s procedures for aligning its models to prevailing social values were inadequate. This shortcoming derailed the company’s latest move to one-up its big-tech rivals and revived longstanding worries that its management places politics above utility to users.</p><p><strong>We’re thinking:</strong>&nbsp;How to align AI models to social values is a hard problem, and approaches to solving it are in their infancy. Google acknowledged Gemini’s shortcomings, went back to work on image generation, and warned that even an improved version would make mistakes and offend some users. This is a realistic assessment following a disappointing product launch. Nonetheless, the underlying work remains innovative and useful, and we look forward to seeing where Google takes Gemini next.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/GROQ-LLMPERF.webp" width="1200" /></figure><h1 id="blazing-inference-speed">Blazing Inference Speed</h1><p>An upstart chip company dramatically accelerates pretrained large language models.</p><p><strong>What’s new:</strong>&nbsp;Groq offers cloud access to Meta’s Llama 2 and Mistral.ai’s Mixtral at speeds an order of magnitude greater than other AI platforms. Registered users can try it&nbsp;<a href="https://groq.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">here</a>.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Groq’s cloud platform is based on its proprietary GroqChip, a processor specialized for large language model inference that the company calls a language processing unit or LPU. The company plans to serve other models eventually, but its main business is selling chips. It focuses on inference on the theory that demand for a model’s inference can increase while demand for its training tends to be fixed.&nbsp;</p><ul><li>For approved users, Groq offers API access to Llama 2 70B (4,096-token context length, 300 tokens per second) for $0.70/$0.80 per million tokens of input/output, Llama 7B (2,048-token context length, 750 tokens per second) for $0.10 per million tokens, and Mixtral 8x7B SMoE (32,000-token context length, 480 tokens per second) for $0.27 per million tokens. A 10-day free trial is available.</li><li>The benchmarking service Artificial Analysis&nbsp;<a href="https://artificialanalysis.ai/models/llama-2-chat-70b/hosts?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">clocked</a>&nbsp;the median speed of Groq’s instances of Llama 2 70B at 241 tokens per second, while Azure’s was around 18 tokens per second. In addition, the platform&nbsp;<a href="https://github.com/ray-project/llmperf-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">outperformed</a>&nbsp;several other cloud services on the Anyscale LLMPerf benchmark, as shown in the image above.</li><li>A variety of&nbsp;<a href="https://wow.groq.com/wp-content/uploads/2023/05/GroqISCAPaper2022_ASoftwareDefinedTensorStreamingMultiprocessorForLargeScaleMachineLearning-1.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">novel design features</a>&nbsp;enable the chip to run neural networks faster than other AI chips including the industry-leading Nvidia H100.</li></ul><p><strong>Behind the news:</strong>&nbsp;Groq founder Jonathan Ross previously worked at Google, where he spearheaded the development of that company’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/computers-making-computers/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">tensor processing unit</a>&nbsp;(TPU), another specialized AI chip.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Decades of ever faster chips have proven that users need all the speed they can get out of computers. With AI, rapid inference can make the difference between halting interactions and real-time spontaneity. Moreover, Groq shows that there’s plenty of innovation left in computing hardware as processors target general-purpose computing versus AI, inference versus training, language versus vision, and so on.</p><p><strong>We’re thinking:</strong>&nbsp;Autonomous agents based on large language models (LLMs) can get a huge boost from very fast generation. People can read only so fast, the faster generation of text that’s intended to be read by humans has little value beyond a certain point. But an agent (as well as chain-of-thought and similar approaches to prompting) might need an LLM to “think” through multiple steps. Fast LLM inference can be immensely useful for building agents that can work on problems at length before reaching a conclusion.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-20T090733.220.png" width="1680" /></a></figure><p>Join “Prompt Engineering with Llama 2” and learn best practices for model selection and prompting, advanced prompting techniques, and responsible use of large language models, all while using Meta Llama 2 Chat, Llama Guard, and Code Llama.&nbsp;<a href="https://www.deeplearning.ai/short-courses/prompt-engineering-with-llama-2/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Sign up for free</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/AGENT_1200px--1-.gif" width="1200" /></figure><h1 id="openai%E2%80%99s-next-act">OpenAI’s Next Act?</h1><p>OpenAI is focusing on autonomous agents that take action on a user’s behalf.</p><p><strong>What’s new:</strong>&nbsp;The maker of ChatGPT is developing applications designed to automate common digital tasks by controlling apps and devices,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/openai-shifts-ai-battleground-to-software-that-operates-devices-automates-tasks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">reported</a>.</p><p><strong>How it works:</strong>&nbsp;OpenAI has two agent systems in the works. It has&nbsp;not revealed any findings, products, or release dates.</p><ul><li>One system is designed to automate the use of business software such as accounting and contact management systems. The other performs web-based tasks such as collecting information on a particular topic or booking travel arrangements.&nbsp;</li><li>A user would enter a prompt, such as a request to transfer data from a document to a spreadsheet or fill out expense reports and transfer them to accounting software. The agent would respond by moving cursors, clicking buttons, selecting or entering text, and so on.</li><li>In November, OpenAI introduced the&nbsp;<a href="https://platform.openai.com/docs/assistants/overview?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">Assistants API</a>, designed to help developers build agent-like assistants that follow instructions to automate certain tasks. In 2022, it published&nbsp;<a href="https://arxiv.org/abs/2206.11795?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">research</a>&nbsp;describing an agent that used a keyboard and mouse to play the video game Minecraft after being trained on video of humans playing the game.</li></ul><p><strong>Behind the news:</strong>&nbsp;Agents are on Silicon Valley’s radar, especially since January’s Consumer Electronics Show&nbsp;<a href="https://www.deeplearning.ai/the-batch/ces-2024-showcased-ais-reach-beyond-browsers-and-smartphones/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">debut</a>&nbsp;of the Rabbit R1, which accepts voice commands to play music, order food, call a car, and so on. Several other companies, academic labs, and independent developers are pursuing the concept as well.</p><ul><li>Sierra, a&nbsp;<a href="https://sierra.ai/news/introducing-sierra?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">startup</a>&nbsp;cofounded by OpenAI chairman Bret Taylor, is creating conversational agents for businesses that can take actions like tracking packages, exchanging products, and resolving issues on a customer’s behalf.</li><li>Longtime Google researchers Ioannis Antonoglou, Sherjil Ozair, and Misha Laskin recently left the company to&nbsp;<a href="https://www.theinformation.com/articles/google-deepmind-veteran-departs-to-launch-ai-agent-startup?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">co-found</a>&nbsp;a startup focused on agents.</li><li>Google, Microsoft, and other companies are exploring similar technologies that enable agents to move or edit files and interact with other agents,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2023/10/16/technology/ai-agents-workers-replace.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">reported</a>.</li><li>The Browser Company recently&nbsp;<a href="https://twitter.com/joshm/status/1753129075487478157?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">announced</a>&nbsp;that its browser Arc would integrate agents to find and deliver videos, recipes, products, and files from the internet.</li><li>Adept&nbsp;<a href="https://www.adept.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">offers</a>&nbsp;a system that monitors a user’s actions and can click, type, and scroll in a web browser in response to commands. (ACT-1 is available as an alpha test via waitlist.)</li></ul><p><strong>Why it matters:</strong>&nbsp;Training agents to operate software designed for humans can be tricky. Some break down tasks into subtasks but struggle with executing them. Others have difficulty with tasks they haven’t encountered before or&nbsp;<a href="https://www.theinformation.com/articles/regulation-drama-in-silicon-valley-why-ai-agents-havent-lived-up-to-the-hype?rc=xlwylo&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">edge cases</a>&nbsp;that are unusually complex. However, agents are becoming more reliable in a wider variety of settings as developers push the state of the art forward.</p><p><strong>We’re thinking:</strong>&nbsp;We’re excited about agents! You can learn about agent technology in our short course, “<a href="https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">LangChain for LLM Application Development</a>,” taught by LangChain CEO Harrison Chase and Andrew.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="480" src="https://dl-staging-website.ghost.io/content/images/2024/02/PRUNING--1-.gif" width="853" /></figure><h1 id="better-faster-network-pruning">Better, Faster Network Pruning</h1><p>Pruning weights from a neural network makes it smaller and faster, but it can take a lot of computation to choose weights that can be removed without degrading the network’s performance. Researchers devised a computationally efficient way to select weights that have relatively little impact on performance.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Mingjie Sun, Zhuang Liu, Anna Bair, and J. Zico Kolter at Carnegie Mellon University, Facebook AI Research, Meta AI, and Bosch Center for AI respectively devised a method for pruning by&nbsp;<a href="https://arxiv.org/abs/2306.11695?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">weights and activations</a>, or Wanda.&nbsp;</p><p><strong>Key insight:</strong>&nbsp;The popular approach known as&nbsp;<a href="https://arxiv.org/abs/1506.02626?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">magnitude pruning</a>&nbsp;removes the smallest weights in a network based on the assumption that weights closest to 0 can be set to 0 with the least impact on performance. Meanwhile, unrelated&nbsp;<a href="https://arxiv.org/abs/2208.07339?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">work</a>&nbsp;found that, in very large language models, the magnitudes of a subset of outputs from an intermediate layer may be up to 20 times larger than those of other outputs of the same layer. Removing the weights that are multiplied by these large outputs — even weights close to zero — could significantly degrade performance. Thus, a pruning technique that considers both weights and intermediate-layer outputs can accelerate a network with less impact on performance.</p><p><strong>How it works:</strong>&nbsp;The authors pruned a pretrained&nbsp;<a href="https://arxiv.org/abs/2302.1397?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">LLaMA</a>&nbsp;that started with 65 billion parameters. Given 128 sequences of tokens drawn from a&nbsp;<a href="https://jmlr.org/papers/v21/20-074.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">curated dataset of English text from the web</a>, the model processed them as follows:&nbsp;</p><ul><li>For each intermediate layer, the authors computed the norm (the magnitude across all the input sequences for each value in the embedding).</li><li>For each weight in the model, they computed its importance by multiplying its magnitude by the corresponding norm.</li><li>They compared the importance of weights in a layer’s weight matrix row by row; that is, neuron by neuron. They removed 50 percent of the least important weights in each row. (By contrast, typical weight pruning removes the lowest-magnitude weights in all rows of the weight matrix; that is, across all neurons in the layer.)</li></ul><p><strong>Results:</strong>&nbsp;The authors tested versions of LLaMA unpruned and pruned via various methods. The models performed a language modeling task using&nbsp;<a href="https://arxiv.org/abs/1609.07843?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">web text</a>. The unpruned LLaMA achieved 3.56 perplexity (a measure of the likelihood that a model will predict the next token, lower is better). Pruned by Wanda to half its original size, it achieved 4.57 perplexity. Pruned by the best competing method,&nbsp;<a href="https://openreview.net/forum?id=gsP05g8IeK&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--0yTgak9p-tGp9KW4tlcBGjwsW3jQokvtXuDYXLSHzEkjB_oAaZ4Rv-Z3ajdsC2LkBkENF" rel="noopener">SparseGPT</a>&nbsp;(which both removes weights and updates the remaining ones), it achieved the same score. However, Wanda took 5.6 seconds to prune the model, while SparseGPT took 1,353.4 seconds. Pruned by magnitude pruning, the model achieved 5.9 perplexity.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The ability to compress neural networks without affecting their output is becoming more important as models balloon and devices at the edge of the network become powerful enough to run them. Wanda compared weights from each row in the weight matrices (pruning per neuron), rather than each weight matrix (pruning per layer) or the model as a whole. The scale at which weights are compared turns out to be important — an interesting avenue for further research.</p><p><strong>We’re thinking:</strong>&nbsp;We came up with a joke about a half-LLaMA, but it fell flat.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a> </h1><p>More AI news of the week includes:&nbsp; </p><ul><li>Baby's eye-view footage trains AI</li><li>Singapore invests $1 billion in AI development</li><li>Stability AI announces Stable Diffusion 3</li></ul><p>Stay in the know with Data Points, a spin-off of The Batch. <a href="https://www.deeplearning.ai/the-batch/data-points-issue-238/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now</a>.&nbsp; </p>
]]></content:encoded>
<pubDate>Wed, 28 Feb 2024 19:51:32 GMT</pubDate>
</item>
<item>
<title>Generated Video Gets Real(er), Nvidia Competitor Emerges, Neural Nets for Gymnastics, Efficient Optimizer</title>
<link>https://www.deeplearning.ai/the-batch/issue-237</link>
<guid>https://www.deeplearning.ai/the-batch/issue-237</guid>
<content:encoded><![CDATA[
<div> AI Fund, persistence, fast iteration, community, OpenAI's video generator, Sora, qualitative results, competition in AI chips, Huawei, SMIC, Olympic gymnastic contests, JSS, Fujitsu, memory-efficient optimizer, LOMO. 

坚持、快速迭代、社区将是建立AI公司的关键。OpenAI发布了名为Sora的视频生成模型，其中概念演示视频质量惊人。华为的AI芯片供不应求，正在成为重要的供应商。国际体操比赛采用了人工智能评分系统JSS，帮助裁判检验决策。研究人员还提出了一种节省内存的优化器LOMO，可用于大规模语言模型的调优。总结: AI Fund就建立AI公司的关键要素进行了讨论，包括坚持、快速迭代和社区。OpenAI发布了令人印象深刻的视频生成模型Sora。华为正因其AI芯片供不应求而崛起。国际体操比赛采用了人工智能评分系统JSS。研究人员提出了一种内存使用较少的优化器LOMO。 <div>
<p><em>Dear friends,</em></p><p><em>Earlier this month, my team AI Fund held its annual co-founder and CEO summit, where many of our collaborators gathered in California for two days to discuss how to build AI companies. Three themes emerged from many presentations: persistence, fast iteration and community.&nbsp;</em></p><p><em><strong>Persistence.&nbsp;</strong>Doing impactful work is hard!&nbsp;</em><a href="https://aifund.ai/team-member/tim-westergren/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Tim Westergren</em></a><em>&nbsp;(founder and former CEO of Pandora, Venture Advisor at AI Fund) said it was only on his 348th venture pitch that Pandora raised its Series A round of funding. He also spoke about the tough time when Pandora team members went without salaries for an extended period of time to try to make the company work out. While many people unfortunately are not in a position to make such sacrifices to build a business, sometimes it does take extraordinary effort — and, yes, sacrifices — to do something really meaningful.&nbsp;</em></p><p><em><strong>Fast iteration.</strong>&nbsp;AI Fund’s process of building startups is focused on a three- month, bi-weekly sprint process, in which we iterate quickly through technical prototypes as well as business ideas.&nbsp;</em><a href="https://aifund.ai/team-member/bill-maccartney/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Bill MacCartney</em></a><em>&nbsp;(former VP of Cohere, Venture Advisor at AI Fund) said, “The best way to start is just by building on top of . . . whatever the best model is . . .. Don’t worry about [cost or latency] at first. You’re really just trying to validate the idea.”&nbsp;</em></p><p><em>One technique that’s now very widespread for prototyping is retrieval augmented generation (RAG). I’ve been surprised at how many nontechnical business leaders seem to know what RAG is. Investors are sometimes leery of people who build a thin layer around LLMs. As&nbsp;</em><a href="https://aifund.ai/team-member/laurence-moroney/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Laurence Moroney</em></a><em>&nbsp;(lead AI Advocate at Google, AI Fund Fellow) says, “I’m a huge fan of RAG . . .. I think this is one way to go beyond a thin veneer around [commercial] models and build a somewhat thicker veneer.”&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--100-.png" width="1200" /></figure><p><em><strong>Community.&nbsp;</strong>Despite the wide range of startups represented in sectors including deep AI tech, healthcare, finance, edtech, and so on, a recurring theme was that company builders end up stronger when they come together.&nbsp;</em><a href="https://aifund.ai/team-member/emil-stefanutti/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener"><em>Emil Stefanutti</em></a><em>&nbsp;(co-founder of ContractRoom, Venture Advisor at AI Fund) said he was glad that many of the scars he has acquired by building businesses are turning out to be treasures for others, as he's able to share experiences that other entrepreneurs can benefit from. Tim Westergren said, “You can’t white-knuckle it. You also can’t do it alone.”</em></p><p><em>The themes of persistence, fast iteration, and community apply whether you work in a large company, startup, research, government, or elsewhere. When I think of innovators in any field, I often think of Teddy Roosevelt’s message:</em></p><p><em>“It is not the critic who counts; not the [person] who points out how the strong [person] stumbles, or where the doer of deeds could have done them better. The credit belongs to the [person] who is actually in the arena, whose face is marred by dust and sweat and blood; who strives valiantly; who errs, who comes short again and again, … who knows great enthusiasms, the great devotions; who spends himself in a worthy cause.”</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="335" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181018.251.gif" width="600" /></figure><h1 id="generated-video-gets-realer">Generated Video Gets Real(er)</h1><p>OpenAI’s new video generator raises the bar for detail and realism in generated videos — but the company released few details about how it built the system.<br /><br /><strong>What’s new:&nbsp;</strong>OpenAI introduced&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">Sora</a>, a text-to-video model that can produce extraordinarily convincing, high-definition videos up to one minute long. You can see examples&nbsp;<a href="https://openai.com/sora?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">here</a>.<br /><br /><strong>What we know:&nbsp;</strong>Sora is a&nbsp;<a href="https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">latent diffusion</a>&nbsp;model that learned to transform noise into videos using an encoder-decoder and transformer. The system was trained on videos up to 1,920x1,080 pixels and up to one minute long.</p><ul><li>Following DALL·E 3, OpenAI&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc#connecting-videos" rel="noopener">trained</a>&nbsp;a video captioning model to enhance the captions of videos in the dataset, adding descriptive details.</li><li>Given a video’s frames divided into patches, the encoder learned to embed the patches and further compress them along the time dimension, producing tokens. Given the tokens, the decoder learned to reconstruct the video.<br /></li><li>Given tokens that had been adulterated by noise and an enhanced prompt, the transformer learned to generate the tokens without noise.</li><li>At inference, a separate transformer enhanced input prompts to be more descriptive. Given the enhanced prompt and noisy tokens, Sora’s transformer removed the noise. Given the denoised tokens, the decoder produced a video.</li></ul><p><strong>What we don’t know:</strong>&nbsp;OpenAI is sharing the technology with outside researchers charged with evaluating its safety,&nbsp;<em>The New York Times</em>&nbsp;<a href="https://www.nytimes.com/2024/02/15/technology/openai-sora-videos.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">reported</a>. Meanwhile, the company published neither quantitative results nor comparisons to previous work. Also missing are detailed descriptions of model architectures and training methods. (Some of the results suggest that Sora was trained not only to remove noise from tokens, but also to&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc#extending-generated-videos" rel="noopener">predict future tokens</a>&nbsp;and&nbsp;<a href="https://openai.com/research/video-generation-models-as-world-simulators?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc#connecting-videos" rel="noopener">generate tokens in between other tokens</a>.) No information is available about the source(s) of the dataset or how it may have been curated.<br /><br /><strong>Qualitative results:&nbsp;</strong>Sora’s demonstration output is&nbsp;impressive enough to have sparked&nbsp;<a href="https://twitter.com/DrJimFan/status/1758549500585808071?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">arguments</a>&nbsp;over the degree to which Sora “understands” physics. A photorealistic scene in which “a stylish woman walks down a Tokyo street filled with warm glowing neon” shows a crowded shopping district filled with believable pedestrians. The woman’s sunglasses reflect the neon signs, as does the wet street. Halfway through its one-minute length, the perspective cuts — unprompted and presumably unedited — to a consistent, detailed close-up of her face. In another clip, two toy pirate ships bob and pitch on a frothing sea of coffee, surrounded by a cup’s rim. The two ships maintain their distinctiveness and independence, their flags flutter in the same direction, and the liquid churns fantastically but realistically. However, as OpenAI acknowledges, the outputs on display are not free of flaws. For instance, the pirate-battle cup’s rim, after camera motion has shifted it out of the frame, emerges from the waves. (Incidentally, the Sora demos are even more fun with&nbsp;<a href="https://x.com/elevenlabsio/status/1759240084342059260?s=20&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">soundtracks</a>&nbsp;generated by Eleven Labs.)</p><p><strong>Why it matters:</strong>&nbsp;While we’ve seen&nbsp;<a href="https://www.deeplearning.ai/the-batch/googles-phenaki-generates-long-form-video-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">transformers for video generation</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-system-make-a-video-generates-video-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">diffusion models for video generation</a>, and&nbsp;<a href="https://www.deeplearning.ai/the-batch/a-new-class-of-diffusion-models-based-on-the-transformer-architecture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">diffusion transformers for images</a>, this is an early implementation of diffusion transformers for video generation (along with a recent&nbsp;<a href="https://arxiv.org/abs/2401.03048?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">paper</a>). Sora shows that diffusion transformers work well for video.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Did Sora learn a world model? Learning to predict the future state of an environment, perhaps given certain actions within that environment, is not the same as learning depict that environment in pixels —just like the ability to predict that a joke will make someone smile is different than the ability to draw a picture of that smile. Given Sora's ability to extrapolate scenes into the future, it does seem to have some understanding of the world. Its world model is also clearly flawed — for instance, it will synthesize inconsistent three-dimensional structures — but it’s a promising step toward AI systems that comprehend the 3D world through video.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181123.082.png" width="1200" /></figure><h1 id="competition-heats-up-in-ai-chips">Competition Heats Up in AI Chips</h1><p>Huawei is emerging as an important supplier of AI chips.</p><p><strong>What’s new:</strong>&nbsp;Amid a U.S. ban on exports of advanced chips to China, demand for Huawei’s AI chips is so intense that the company is limiting production of the chip that powers one of its most popular smartphones so it can serve the AI market,&nbsp;<em>Reuters</em>&nbsp;<a href="https://www.reuters.com/technology/ai-chip-demand-forces-huawei-slow-smartphone-production-sources-2024-02-05?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">reported</a>.</p><p><strong>Demand and supply:</strong>&nbsp;China’s biggest chip fabricator, Semiconductor Manufacturing International Corp. (SMIC), fabricates both the Ascend 910B, which is optimized to process neural networks, and the Kirin chip that drives Huawei’s popular Mate 60 phone. Production capacity is limited, so making more Ascend 910Bs means making fewer Kirins.&nbsp;</p><ul><li>The Huawei Ascend 910B is widely considered to be the best AI chip available in China. The chip has been reported to deliver&nbsp;<a href="https://www.huaweicentral.com/whats-the-ascend-910b-ai-chip-baidu-ordered-from-huawei/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">performance</a>&nbsp;roughly&nbsp;<a href="https://www.tomshardware.com/news/huaweis-gpu-reportedly-matches-nvidias-a100-report?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">comparable to that of Nvidia’s A100</a>&nbsp;(immediate predecessor to the current H100, which is more than three times faster).</li><li>The Nvidia H100, which is the industry standard for processing deep learning models, has become scarce in China since late 2022, when the U.S.&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">restricted</a>&nbsp;exports of advanced chips and use of chip-making equipment. The shortage of Nvidia chips is driving demand for the Ascend 910B.</li><li>The U.S. action also forced Huawei to switch manufacturers from Taiwan Semiconductor Manufacturing Company to SMIC. But the limits on manufacturing equipment have made it difficult to fabricate the Ascend 910B. SMIC has been able to produce a relatively small number of units that are free from defects.</li><li>Huawei’s decision to shift manufacturing from phone chips to AI chips is sacrificing one of its most popular products. Huawei’s Mate 60 phone outsold the Apple iPhone in China last year, helping to elevate Huawei in January to the top-selling phone maker in China for the first time in three years.</li></ul><p><strong>Behind the news:</strong>&nbsp;Nvidia accounted for 90 percent of the market for AI chips in China prior to the advent of U.S. export restrictions. China has responded to the limits by building its ability to manufacture advanced chips domestically — a tall order, since it requires technology that is very difficult to develop. In August, Baidu ordered 1,600 Ascend 910B chips for delivery by the end of the year, according to an earlier&nbsp;<em>Reuters</em>&nbsp;<a href="https://www.reuters.com/technology/baidu-placed-ai-chip-order-huawei-shift-away-nvidia-sources-2023-11-07/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">report</a>. The order, which is tiny compared to typical data center purchases, nonetheless demonstrated that SMIC could manufacture the chips and that Baidu was experimenting with alternatives to Nvidia in anticipation of even tighter U.S. restrictions on AI chips that took effect in October. Currently, SMIC is&nbsp;<a href="https://www.asiafinancial.com/huawei-smic-set-to-defy-us-sanctions-with-5nm-chips-ft?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">gearing up</a>&nbsp;to produce Huawei’s next-generation Ascend chips.</p><p><strong>Why it matters:</strong>&nbsp;For years, Nvidia’s GPUs have been the only practical choice for processing deep learning models. The company’s lead over competitors both in hardware implementation and software support are likely to protect its dominant position for some time to come. However, competitors like AMD and Huawei are beginning to nip at Nvidia’s heels. That means more hardware options for developers, and the competition may drive lower prices and still higher performance.</p><p><strong>We’re thinking:</strong>&nbsp;AI chips are at the heart of the current technological&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">competition</a>&nbsp;between the U.S. and China. While Huawei and SMIC still have a lot to prove in terms of scaling up production, their rate of progress is impressive and illustrates the limits of the current U.S. restrictions.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.eventbrite.com/e/building-production-grade-llm-apps-tickets-837481398407?aff=Batch&amp;ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-21T092947.270.png" width="1680" /></a></figure><p>In our next live workshop, we’ll share how to build high-quality and production-ready applications using tools like Pinecone Canopy and TruLens. Notebooks will be available for participants to explore!&nbsp;<a href="https://www.eventbrite.com/e/building-production-grade-llm-apps-tickets-837481398407?aff=Batch&amp;ref=dl-staging-website.ghost.io" rel="noreferrer">Register now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181325.090.gif" width="600" /></figure><h1 id="gymnastics-judge%E2%80%99s-helper">Gymnastics Judge’s Helper</h1><p>Judges in competitive gymnastics are using an AI system to double-check their decisions.</p><p><strong>What’s new:</strong>&nbsp;Olympic-level gymnastic contests have adopted Judging Support System (JSS), an AI-based video evaluation system built by Fujitsu,&nbsp;<em>MIT Technology Review</em>&nbsp;<a href="https://www.technologyreview.com/2024/01/16/1086498/ai-gymnastics-judging-jss-world-championships-antwerp-paris-olympics/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">reported</a>. In September and October,&nbsp; for the first time, judges at the 2023 World Artistic Gymnastics Championships in Antwerp used JSS in competitions that involved the full range of gymnastics equipment including mat, balance beam, parallel bars, pommel horse, and so on.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Judges penalize gymnasts for imperfections in any pose or move. JSS identifies deviations that correspond to particular penalties. The system can evaluate roughly 2,000 poses and moves with 90 percent accuracy compared to human judges. It can assess both isolated actions and entire routines.&nbsp;</p><ul><li>Fujitsu trained JSS on video footage of 8,000 gymnastic routines that encompass the official&nbsp;<a href="https://gymnasticsresults.com/technical/code-of-points?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">gymnastics scoring guide</a>. The system matches body positions to corresponding poses and motions described in the scoring guide.</li><li>JSS receives position data on a gymnast’s body from 4 to 8&nbsp;cameras. A 2018&nbsp;<a href="https://www.fujitsu.com/global/documents/about/resources/publications/fstj/archives/vol54-4/paper07.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">paper</a>&nbsp;offers hints about how the current system may work: Given the images, it detects the posture (front-facing, handstand, or rear-facing). Given the posture, it feeds the images into a corresponding 3D model. Then it converts the&nbsp;images into a virtual skeleton, conforms a human model to the skeleton, and modifies the skeleton (and conformed model) to match the&nbsp;images.</li><li>Under the current rules, judges can use JSS only when competitors challenge a score or a judge and supervisor disagree. The International Gymnastics Federation, the sport’s global governing body, has not yet revealed whether or how the system will be used at this year’s Summer Olympics in Paris.</li></ul><p><strong>Behind the news:</strong>&nbsp;Sporting authorities have embraced AI both inside and outside the arena.</p><ul><li>The English Premier League football clubs Chelsea and Nottingham Forest have expressed interest in the AISCOUT app as a way to discover fresh talent. Amateur players upload videos of themselves performing drills, and the app scores their performance.&nbsp;</li><li>At the 2020 Summer Olympics in Tokyo, official timekeeper Omega Timing&nbsp;<a href="https://www.deeplearning.ai/the-batch/olympic-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">provided</a>&nbsp;several AI-based systems: a pose estimator for gymnasts on the trampoline, an image recognition system that analyzed swimmers’ performance, and a ball tracker for volleyball.</li><li>Acronis, a Swiss company that provides video storage for pro football teams, has built AI applications that track players’ movements and analyze their tactics. The company also predicts match attendance for teams in the English Premier League based on ticket sales, weather, and other factors.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;Gymnastic competitors are&nbsp;<a href="https://www.british-gymnastics.org/component/content/article/339-fansmajorevents/6203-your-guide-to-the-gymnastics-scoring-system?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">scored</a>&nbsp;on subjective criteria such as expression, confidence, and personal style as well as technical competence, raising questions of unconscious bias and whether some judges might favor certain competitors over others. An AI system that tracks technical minutiae may help judges to avoid bias while focusing on the sport’s subjective aspects.</p><p><strong>We’re thinking:</strong>&nbsp;Tracking gymnasts in motion sets a high bar for AI!</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-21T181416.147.png" width="1200" /></figure><h1 id="memory-efficient-optimizer">Memory-Efficient Optimizer</h1><p>Researchers devised a way to reduce memory requirements when fine-tuning large language models.&nbsp;</p><p><strong>What's new:</strong>&nbsp;Kai Lv and colleagues at Fudan University proposed&nbsp;<a href="https://arxiv.org/abs/2306.09782?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">low memory optimization</a>&nbsp;(LOMO), a modification of stochastic gradient descent that stores less data than other optimizers during fine-tuning.</p><p><strong>Key insight:</strong>&nbsp;Optimizers require a lot of memory to store an entire network’s worth of parameters, gradients, activations, and optimizer states. While Adam has overtaken stochastic gradient descent (SGD) for training, SGD remains a popular choice for fine-tuning partly because it requires less memory (since it stores fewer optimizer states). Nonetheless, SGD must store an entire network’s gradients — which, with state-of-the-art models, can amount to tens or hundreds of gigabytes — before it updates the network all at once. Updating the network layer by layer requires storing only one layer’s gradients — a more memory-efficient twist on typical SGD.</p><p><strong>How it works:</strong>&nbsp;The authors fine-tuned&nbsp;<a href="https://arxiv.org/abs/2302.13971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">LLaMA</a>&nbsp;on six datasets in&nbsp;<a href="https://arxiv.org/abs/1905.00537?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">SuperGLUE</a>, a benchmark for language understanding and reasoning that includes tasks such as answering multiple-choice questions.</p><ul><li>The authors modified SGD to compute gradients for one layer and update that layer’s weights before advancing to the next.</li><li>To avoid the potential for exploding or&nbsp;<a href="https://www.coursera.org/lecture/nlp-sequence-models/vanishing-gradients-with-rnns-PKMRR?ref=dl-staging-website.ghost.io&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">vanishing gradients</a>, in which gradients from later layers either expand or diminish as they backpropagate through the network, LOMO normalized the gradients, scaling them to a predetermined range throughout the network. LOMO used two backward passes: one to compute the magnitude of the gradient for the entire network, and another to scale each layer’s gradient according to the total magnitude and then update its parameters.</li></ul><p><strong>Results:</strong>&nbsp;LOMO required less memory than popular optimizers and achieved better performance than the popular memory-efficient fine-tuning technique LoRA.</p><ul><li>The authors fine-tuned separate instances of LLaMA-7B using LOMO and two popular optimizers, SGD and AdamW (a modified version of Adam). They required 14.6GB, 52.0GB, and 102.2GB of memory respectively. In particular, they all required the same amount of memory to store model parameters (12.55GB) and activations (1.79GB). However, when it came to gradients, LOMO required only 0.24GB while SGD and AdamW each required 12.55GB. The biggest difference was optimizer state memory: LOMO required 0GB, SGD required 25.1GB, and Adam required 75.31GB.</li><li>The authors also compared LOMO to&nbsp;<a href="https://arxiv.org/abs/2106.09685?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8z-oRELCe98bNc2dQ1qcOmBXAlWSvhpKj_z9umhLqHvJaqg4FNTp7ksW9HYNKWBZIvbvFc" rel="noopener">LoRA</a>, which works with an optimizer (in this case, AdamW) to learn to change each layer’s weight matrix by a product of two smaller matrices. They performed this comparison with LLaMAs of four sizes on six datasets. LOMO achieved better accuracy in 16 of the 24 cases, and its average accuracy across datasets exceeded LoRA’s at each model size. For example, the 65 billion-parameter LOMO-tuned LLaMA averaged 89.9 percent accuracy, and the 65 billion-parameter LoRA/AdamW-tuned LLaMA averaged 89.0 percent accuracy.</li></ul><p><strong>Why it matters:</strong>&nbsp;Methods like LoRA save memory by fine-tuning a small number of parameters relative to a network’s total parameter count. However, because it adjusts only a small number of parameters, the performance gain from fine-tuning is less than it could be. LOMO fine-tunes all parameters, maximizing performance gain while reducing memory requirements.</p><p><strong>We're thinking:</strong>&nbsp;SGD’s hunger for memory is surprising. Many developers will find it helpful to have a memory-efficient alternative.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>More AI news of the week. From Gemini 1.5’s whopping context window to the energy footprint of AI models and Google's next research hub city, we covered it all.&nbsp;</p><p>Dive into this week's key AI developments in our latest Data Points edition.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-237/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 21 Feb 2024 23:18:33 GMT</pubDate>
</item>
<item>
<title>AI Recovers Ancient Scrolls, GPUs Strain Power Grid, Government Restricts Fake Voices, Better Image Generation</title>
<link>https://www.deeplearning.ai/the-batch/issue-236</link>
<guid>https://www.deeplearning.ai/the-batch/issue-236</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>The rise of cloud-hosted AI software has brought much discussion about the privacy implications of using it. But I find that users, including both consumers and developers building on such software, don’t always have a sophisticated framework for evaluating how software providers store, use, and share their data. For example, does a company’s promise “not to train on customer data” mean your data is private?&nbsp;</em></p><p><em>Here is a framework for thinking about different levels of privacy on cloud platforms, from less to more:</em></p><ul><li><em><strong>No Guarantees:&nbsp;</strong>The company provides no guarantees that your data will be kept private. For example, an AI company might train on your data and use the resulting models in ways that leak it. Many startups start here but add privacy guarantees later when customers demand them.</em></li><li><em><strong>No Outside Exposure:</strong>&nbsp;The company does not expose your data to outsiders. A company can meet this standard by not training on your data and also by not posting your data online. Many large startups, including some providers of large language models (LLMs), currently operate at this level.&nbsp;</em></li><li><em><strong>Limited Access:</strong>&nbsp;In addition to safeguards against data leakage, no humans (including employees, contractors, and vendors of the company) will look at your data unless they are compelled via a reasonable process (such as a subpoena or court order, or if the data is flagged by a safety filter). Many large cloud companies effectively offer this level of privacy, whether or not their terms of service explicitly say so.&nbsp;</em></li><li><em><strong>No Access:&nbsp;</strong>The company cannot access your data no matter what. For example, data may be stored on the customer’s premises, so the company doesn’t have access to it. If I run an LLM on my private laptop, no company can access my prompts or LLM output. Alternatively, if data is used by a SaaS system, it might be encrypted before it leaves the customer’s facility, so the provider doesn’t have access to an unencrypted version. For example, when you use an end-to-end encrypted messaging app such as Signal or WhatsApp, the company cannot see the contents of your messages (though it may see “envelope” information such as sender and recipient identities and the time and size of the message).</em></li></ul><p><em>These levels may seem clear, but there are many variations within a given level. For instance, a promise not to train on your data can mean different things to different companies. Some forms of generative AI, particularly image generators, can&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/spotting-similarities-between-generated-images-and-data/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>replicate their training data</em></a><em>, so training a generative AI algorithm on customer data may run some risk of leaking it. On the other hand, tuning a handful of an algorithm’s hyperparameters (such as learning rate) to customer data, while technically part of the training process, is very unlikely to result in any direct data leakage. So how the data is used in training will affect the risk of leakage. &nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--97--1.png" width="1200" /></figure><p><em>Similarly, the Limited Access level has its complexities. If a company offers this level of privacy, it’s good to understand exactly under what circumstances its employees may look at your data. And if they might look at your data, there are shades of gray in terms of how private the data remains. For example, if a limited group of employees in a secure environment can see only short snippets that have been disassociated from your company ID, that’s more secure than if a large number of employees can freely browse your data.&nbsp;</em></p><p><em>In outlining levels of privacy, I am not addressing the question of security. To trust a company to deliver a promised level of privacy is also to trust that its IT infrastructure is secure enough to keep that promise.&nbsp;</em></p><p><em>Over the past decade, cloud hosted SaaS software has gained considerable traction. But some customers insist on running on-prem solutions within their own data centers. One reason is that many SaaS providers offer only No Guarantees or No Outside Exposure, but many customers’ data is so sensitive that it requires Limited Access.&nbsp;</em></p><p><em>I think it would be useful for our industry to have a more sophisticated way to talk about privacy and help users understand what guarantees providers do and do not deliver.&nbsp;</em></p><p><em>As privacy becomes a global topic, regulators are stepping in, and this is adding further complexity to tech businesses. For example, if one jurisdiction changes the definition of a child from someone under 13 to anyone under 18, that might require changes to how you store data of individuals age 13 to 18; but who has time to keep track of such changes?</em></p><p><em>I've been delighted to see that here, AI can help. Daphne Li, CEO of&nbsp;</em><a href="https://commonsenseprivacy.net/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>Commonsense Privacy</em></a><em>&nbsp;(disclosure: a portfolio company of AI Fund), is using large language models to help companies systematically evaluate, and potentially improve, their privacy policies as well as keep track of global regulatory changes. In the matter of privacy, as in other areas, I hope that the title of my TED AI talk — “</em><a href="https://www.ted.com/talks/andrew_ng_ai_isn_t_the_problem_it_s_the_solution?language=en&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>AI Isn’t the Problem, It’s the Solution</em></a><em>” — will prove to be true.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S.&nbsp;Check out our new short course with Amazon Web Services on “Serverless LLM Apps With Amazon Bedrock,” taught by Mike Chambers. A serverless architecture enables you to quickly deploy applications without needing to set up and manage compute servers to run your applications on, often a full-time job in itself. In this course, you’ll learn how to implement serverless deployment by building event-driven systems. We illustrate this approach via an application that automatically detects incoming customer inquiries, transcribes them with automatic speech recognition, summarizes them with an LLM using Amazon Bedrock, and runs serverless with AWS Lambda. We invite you to&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener"><em>enroll here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-14T152741.124.gif" width="600" /></figure><h1 id="ancient-scrolls-recovered">Ancient Scrolls Recovered</h1><p>Three researchers decoded scrolls that had gone unread since they were turned into charcoal by the eruption of Mount Vesuvius in the year 79.</p><p><strong>What’s new:</strong>&nbsp;Youssef Nader, Luke Farritor, and Julian Schilliger used neural networks to win the $700,000 grand prize in the&nbsp;<a href="https://scrollprize.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Vesuvius Challenge</a>, a competition to translate charred papyrus scrolls found in the ruins of a villa at the Roman town of Herculaneum in southern Italy.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The volcanic eruption covered Herculaneum in ash. It also transformed into carbon the papyrus scrolls, which originally would have unrolled to lengths as long as 30 feet.&nbsp;</p><ul><li>Competitors were given extremely high-resolution, three-dimensional X-ray scans of four intact scrolls. Like CT scans, each scan comprised a series of 2D cross sections. An application developed by researchers who have been working to decipher the scrolls virtually unwrapped the 3D scans into 2D images of the scroll surfaces and segmented them into individual papyrus sheets.</li><li>Examining the resulting images by eye, a member of a different team noticed faint patterns of cracks and lines that suggested Greek letters. He uploaded his findings, which prompted Farritor to take up the search.</li><li>Having identified traces of ink in one of the scrolls, Farritor trained a&nbsp;<a href="https://arxiv.org/abs/1512.03385?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">ResNet</a>&nbsp;to recognize 64x64-pixel patches of the sheet images that showed similar traces. The initial model revealed more ink traces, which were added to the training set; the retrained model found more, which joined the training set, and so on. The model enabled Farritor to render 10 legible letters, winning an&nbsp;<a href="https://scrollprize.org/firstletters?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">intermediate prize</a>.</li><li>Building on Farritor’s approach, the team trained three models on fragments of other scrolls to recognize patches that showed signs of ink. They selected the 3D architectures&nbsp;<a href="https://arxiv.org/abs/2102.05095?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">TimeSformer</a>,&nbsp;<a href="https://paperswithcode.com/lib/torchvision/resnet-3d?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Resnet3D-101</a>, and&nbsp;<a href="https://arxiv.org/abs/1705.07750?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">I3D</a>&nbsp;to capture ink residue that rose above the carbonized papyrus surface.&nbsp;The clearest images came from TimeSformer. The team manually compared TimeSformer’s images with those produced by the other two models to ensure that TimeSformer didn’t misclassify patches as having ink when it wasn’t there.</li><li>Working on one of the four scrolls (the other three having proven more difficult to scan, unwrap, and segment), the team rendered readable 85 percent of the presumed characters in four 140-character passages — thus satisfying the grand-prize criteria. They also rendered 11 additional passages for a total of more than 2,000 characters, or roughly 5 percent of the scroll. The rendered text appears to express Epicurean philosophy that praises the virtues of pleasure.</li></ul><p><strong>Behind the news:</strong>&nbsp;The Vesuvius Challenge launched in March 2023 with funding provided by GitHub CEO Nat Friedman.&nbsp;</p><ul><li>Smaller prizes were awarded to researchers who deciphered single words and shorter passages. Notably, these early prizewinners included Nader and Farritor, who then teamed with Schilliger.&nbsp;</li><li>In its next round, the competition is offering $100,000 to the first team to decipher 90 percent of all four scrolls that have been imaged so far.</li><li>The library at Herculaneum includes 800 scrolls already recovered and potentially thousands more still to be excavated. Reading them all would make this library one of the largest collections of texts recovered from the ancient world.</li></ul><p><strong>Why it matters:</strong>&nbsp;The winning team’s achievement testifies to the ability of deep learning to help solve difficult problems. And their work may have broader significance: Recovering the entire Herculaneum library could provide insights into literature, philosophy, history, science, and art at the time of Caesar.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;University of Kentucky computer scientist Brent Seales, who helped design the contest as well as pioneering the use of medical imaging and machine learning to read ancient texts, reckons that over 1,000 teams worked on the problem, amounting to 10 person-years and two compute-years. It's a great example of the power of global collaboration and open resources — central facets of the AI community — to find solutions to hard problems.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--98-.png" width="1200" /></figure><h1 id="us-restricts-ai-robocalls">U.S. Restricts AI Robocalls</h1><p>The United States outlawed unsolicited phone calls that use AI-generated voices.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;The Federal Communications Commission&nbsp;<a href="https://s.wsj.net/public/resources/documents/fcc-ai-robocalls-ruling.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">ruled</a>&nbsp;that the current legal restriction on voice communications that use “artificial or prerecorded voices” covers AI-powered voice generation. The ruling followed an incident in which calls that featured the cloned voice of U.S. President Biden were delivered with the apparent intent of interfering with an election.</p><p><strong>How it works:</strong>&nbsp;The ruling interprets the 1991 Telephone Consumer Protection Act, which controls automated calls, or robocalls. The law gives state attorneys general the power to prosecute robocallers. The FCC had&nbsp;<a href="https://www.theverge.com/2024/1/31/24057452/the-fcc-is-proposing-a-ban-on-robocalls-using-ai-generated-voices?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">proposed</a>&nbsp;the move in January.&nbsp;</p><ul><li>The ruling restricts calls to residential phone numbers that feature synthesized voices.</li><li>It covers all such calls whether or not they are deceptive or annoying, and applies equally to synthetic voices that mimic real voices and those that don’t.</li><li>Synthetic voices are allowed only if the recipient has given prior consent or in an emergency. Calls that convey an advertisement or marketing message must provide an opportunity to opt out, and those that feature artificial voices must identify the entity that initiated the call.</li></ul><p><strong>Behind the news:</strong>&nbsp;In January, two days before a presidential primary election, thousands of members of the Democratic Party in the state of New Hampshire&nbsp;<a href="https://apnews.com/article/biden-robocalls-artificial-intelligence-new-hampshire-texas-a8665277d43d05380d2c7594edf27617?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">received</a>&nbsp;phone calls in which a cloned voice of President Biden, who is a Democrat, urged them not to vote in a presidential primary election. The call used voice cloning software from Eleven Labs, according to researchers&nbsp;<a href="https://www.wired.com/story/new-hampshire-biden-ai-robocall/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">cited</a>&nbsp;by&nbsp;<em>Wired</em>. New Hampshire investigated the calls as a case of illegal voter suppression. It traced them to two telecommunications companies in the state of Texas and issued cease-and-desist orders and subpoenas to both firms. One, Lingo Telecom, said it is cooperating with federal and state investigators.</p><p><strong>Why it matters:</strong>&nbsp;For all its productive uses, generative AI offers fresh opportunities to scammers to deceive their marks into handing over things of value. Voice cloning can elevate their appeal by simulating personal, business, political, and other relationships. Election officials are especially concerned about AI’s potential to influence voting, especially as we enter a year that will see over 100 elections in seven of the 10 most populous nations.</p><p><strong>We’re thinking:</strong>&nbsp;The question of how to safeguard elections against manipulations like the Biden robocall is an urgent one. Devising a tamper-resistant watermark that identifies generated output would discourage misuse. However, providers will have a financial&nbsp;<a href="https://www.deeplearning.ai/the-batch/watermarking-is-a-no-go/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">incentive</a>&nbsp;not to apply such watermarks unless regulators require it.&nbsp;</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-05T095912.572.png" width="1680" /></a></figure><p>In our latest course, built in collaboration with Amazon Web Services, you’ll learn to deploy applications based on large language models using a serverless architecture. This enables rapid deployment and liberates you from the complexities of managing and scaling infrastructure.&nbsp;<a href="https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Start today!</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--99-.png" width="1200" /></figure><h1 id="gpu-data-centers-strain-grid-power">GPU Data Centers Strain Grid Power</h1><p>The AI boom is taxing power grids and pushing builders of data centers to rethink their sources of electricity.</p><p><strong>What’s new:</strong>&nbsp;New data centers packed with GPUs optimized for AI workloads are being approved at a record pace,&nbsp;<em>The Information</em>&nbsp;<a href="https://www.theinformation.com/articles/the-next-ai-bottleneck-power-for-data-centers?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">reported</a>. The extreme energy requirements of such chips are pushing builders to place data centers near inexpensive power sources, which may be far away from where users live.</p><p><strong>How it works:</strong>&nbsp;The coming generation of GPU data centers promises to supply processing power for the burgeoning AI era. But builders aren’t always able to find electricity to run them.</p><ul><li>In the&nbsp;<a href="https://wtop.com/virginia/2022/10/why-is-northern-va-becoming-the-worlds-data-center-capital/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">data center hub</a>&nbsp;of Northern Virginia, power company Dominion Energy temporarily ceased connecting new data centers for three months in 2022. It warned that future connections would be in question until 2026.</li><li>Although many data center operators&nbsp;<a href="https://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/path-to-net-zero-datacenter-demands-push-amazon-big-tech-toward-renewables-72752727?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">pledged</a>&nbsp;to rely on energy sources other than fossil fuels, their rising demand for power has made that difficult,&nbsp;<em>Bloomberg</em>&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-01-25/ai-needs-so-much-power-that-old-coal-plants-are-sticking-around?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">reported</a>. Regulators in Virginia considered allowing data centers to use diesel generators before they abandoned that plan under pressure from environmental groups. In Kansas City, Missouri, Meta’s apparent plan to build a giant data center helped convince one utility to postpone the planned retirement of a coal plant.</li><li>Some companies that rely on data centers are looking into less conventional power sources. Microsoft is considering small, modular nuclear reactors that, while largely speculative, promise to be less expensive and more flexible than traditional nuclear power plants. Microsoft recently&nbsp;<a href="https://www.theregister.com/2024/01/23/microsoft_nuclear_hires/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">appointed</a>&nbsp;a director of nuclear technologies.</li></ul><p><strong>What they’re saying:</strong>&nbsp;“We still don’t appreciate the energy needs of [AI] technology. There's no way to get there without a breakthrough.” — Sam Altman, CEO, OpenAI, on January 16, 2024,&nbsp;<a href="https://www.reuters.com/technology/openai-ceo-altman-says-davos-future-ai-depends-energy-breakthrough-2024-01-16/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">quoted</a>&nbsp;by&nbsp;<em>Reuters</em>.</p><p><strong>Behind the news:</strong>&nbsp;Data centers alone&nbsp;<a href="https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">account for</a>&nbsp;1 to 1.5 percent of global demand for electricity. It’s unclear how much of that figure is attributable to AI, but the share is likely to grow.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The world needs innovation in both energy resources and power-efficient machine learning. The dawning era of pervasive AI brings with it the challenge of producing energy to develop and deploy the technology, which can contribute to pollution that disrupts ecosystems and accelerates climate change. Fortunately, AI can shrink the environmental footprint of some energy-intensive activities; for example, searching the web for information generates far less CO<sup>2</sup>&nbsp;emissions than driving to a library.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Climate change is a slow-motion tragedy. We must push toward AI infrastructure that uses less energy (for example, by using more efficient algorithms or hardware) and emits less carbon (for example, by using renewable sources of energy). That said, concentrating computation in a data center creates a point of significant leverage for optimizing energy usage. For example, it’s more economical to raise the energy efficiency of 10,000 servers in a data center than 10,000 PCs that carry out the same workload in 10,000 homes.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-14T153023.937.gif" width="600" /></figure><h1 id="better-images-less-training">Better Images, Less Training</h1><p>The longer text-to-image models train, the better their output — but the training is costly. Researchers built a system that produced superior images after far less training.</p><p><strong>What's new:&nbsp;</strong>Independent researcher Pablo Pernías and colleagues at Technische Hochschule Ingolstadt, Université de Montréal, and Polytechnique Montréal built&nbsp;<a href="https://arxiv.org/abs/2306.00637?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Würstchen</a>, a system that divided the task of image generation between two diffusion models.&nbsp;</p><p><strong>Diffusion model basics:</strong>&nbsp;During training, a text-to-image generator based on diffusion takes a noisy image and a text embedding. The model learns to use the embedding to remove the noise in successive steps. At inference, it produces an image by starting with pure noise and a text embedding, and removing noise iteratively according to the text embedding. A variant known as a&nbsp;<a href="https://arxiv.org/abs/2112.10752?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">latent diffusion</a>&nbsp;model uses less processing power by removing noise from a noisy image embedding instead of a noisy image.</p><p><strong>Key insight:</strong>&nbsp;A latent diffusion model typically learns to remove noise from an embedding of an input image based solely on a text prompt. It can learn much more quickly if, in addition to the text prompt, a separate diffusion model supplies a smaller, noise-free version of the image embedding.&nbsp;During training, the two models can be trained separately, enabling them to learn their tasks in a fraction of the usual time. At inference, the models can work efficiently as a stack: one to generate smaller embeddings and the other to generate larger embeddings based on the smaller ones.</p><p><strong>How it works:</strong>&nbsp;Würstchen involves three components that required training: the encoder-decoder from&nbsp;<a href="https://arxiv.org/abs/2012.09841?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">VQGAN</a>, a latent diffusion model based on&nbsp;<a href="https://arxiv.org/abs/1505.04597v1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">U-Net</a>, and another latent diffusion model based on&nbsp;<a href="https://arxiv.org/abs/2201.03545?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">ConvNeXt</a>. The authors trained the models separately on subsets of&nbsp;<a href="https://arxiv.org/abs/2210.08402?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">LAION-5B</a>, which contains matched images and text descriptions scraped from the web.&nbsp;</p><ul><li>The authors trained the VQGAN encoder-decoder to reproduce input images. The encoder produced embeddings, to which the authors added noise.</li><li>To train U-Net, the authors used&nbsp;<a href="https://arxiv.org/abs/2104.00298?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">EfficientNetV2</a>&nbsp;(a convolutional neural network pretrained on ImageNet) to produce embeddings around 1/30 the size of the VQGAN embeddings (16x24x24 versus 4x256x256). Given this smaller embedding, a noisy VQGAN embedding, and a text description, U-Net learned to remove noise from the VQGAN embedding.&nbsp;</li><li>To train ConvNeXt, EfficientNetV2 once again produced small embeddings from input images, to which the authors added noise. Given a noisy EfficientNetV2 embedding and a text description, ConvNeXt learned to remove the noise.</li><li>At inference, the components worked in opposite order of training: (i) Given noise and a text prompt, ConvNeXt produced a small EfficientNetV2-sized embedding. (ii) Given that embedding, noise, and the same text prompt, U-Net produced a larger VQGAN-sized embedding. (iii) Given the larger embedding, VQGAN produced an image.</li></ul><p><strong>Results:</strong>&nbsp;The authors compared Würstchen to&nbsp;<a href="https://huggingface.co/stabilityai/stable-diffusion-2-1?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Stable Diffusion 2.1</a>. While they trained both on subsets of LAION-5B, they trained Würstchen  for 25,000 GPU hours while Stable Diffusion took 200,000 GPU hours. The authors generated images based on captions from&nbsp;<a href="https://arxiv.org/abs/1405.0312?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">MS COCO</a>&nbsp;and&nbsp;<a href="https://arxiv.org/abs/2206.10789?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8sMbahNXDHmyN3uHeQvTD_vvo7cOsU3NmGHVQt_hHUFpOdPn5IhFgdOJlOQsHUr5ENYDga" rel="noopener">Parti-prompts</a>. They asked 90 people which output they preferred. The judges expressed little preference regarding renderings of MS COCO captions: They chose Würstchen 41.3 percent of the time, Stable Diffusion 40.6 percent of the time, and neither 18.1 percent of the time. However, presented with the results of Parti-prompts, they preferred Würstchen 49.5 percent of the time, Stable Diffusion’s 32.8 percent of the time, and neither 17.7 percent of the time.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Training a latent diffusion model to denoise smaller embeddings accelerates training, but this tends to produce lower-quality images. Stacking two diffusion models enabled Würstchen to match or exceed the output quality of models with large embeddings while achieving the training speed of models with small embeddings.</p><p><strong>We're thinking:</strong>&nbsp;25,000 GPU hours is a big reduction from 200,000! Given the cost of GPU hours, an eightfold saving is a big deal.</p><hr /><h2 id="a-message-from-fourthbrain">A MESSAGE FROM FOURTHBRAIN</h2><figure class="kg-card kg-image-card"><a href="https://hubs.la/Q02kZ3ST0?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="972" src="https://dl-staging-website.ghost.io/content/images/2024/02/FourthBrain_BatchAd_2.14.24_v1.png" width="1728" /></a></figure><p>Join us for an intensive three-week workshop where you’ll learn to operationalize large language models at scale, from learning advanced retrieval augmented generation (RAG) to deploying multimodal applications on the cloud.&nbsp;<a href="https://hubs.la/Q02kZ3ST0?ref=dl-staging-website.ghost.io" rel="noreferrer">Register today!</a></p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>From a deepfake scam costing a multinational company $25 million, to the shift from Bard to Gemini, and a newsroom fully adopting AI for news curation - we've got this week’s crucial updates wrapped up for you on Data Points.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-236/?ref=dl-staging-website.ghost.io" rel="noreferrer">Here’s your essential weekly roundup of AI insights</a>.</p>
]]></content:encoded>
<pubDate>Wed, 14 Feb 2024 20:34:45 GMT</pubDate>
</item>
<item>
<title>Taylor Swift Deepfakes, GPT-4 Biothreats, New Leaderboards, LLMs That Get Inside Your Head</title>
<link>https://www.deeplearning.ai/the-batch/issue-235</link>
<guid>https://www.deeplearning.ai/the-batch/issue-235</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>On the&nbsp;</em><a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener"><em>LMSYS Chatbot Arena Leaderboard</em></a><em>, which pits chatbots against each other anonymously and prompts users to judge which one generated a better answer, Google’s Bard (Gemini Pro) recently leaped to third place, within striking distance of the latest version of OpenAI’s GPT-4, which tops the list. At the time of this writing, the open source Mixtral-8x7b-Instruct is competitive with GPT-3.5-Turbo, which holds 11th place. Meanwhile, I'm hearing about many small, capable teams that, like Mistral, seem to have the technical capability to train foundation models. I think 2024 will see a lot of new teams enter the field with strong offerings.&nbsp;</em></p><p><em>The barriers to building foundation large language models (LLMs) seem to be falling as the know-how to train them diffuses. In the past year, a lot of LLM technology has taken steps toward becoming commoditized. If it does become commoditized, who will be the winners and losers?</em></p><p><em>Meta has played a major role in shaping the strategic landscape by emphasizing open source. Unlike its big-tech peers, it makes money by showing ads to users, and does not operate a cloud business that sells LLM API calls. Meta has been badly bitten by its dependence on iOS and Android, which has left it vulnerable to Apple and Google hurting its business by&nbsp;</em><a href="https://www.nytimes.com/2022/02/03/technology/apple-privacy-changes-meta.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener"><em>imposing</em></a><em>&nbsp;privacy controls that limit its ability to target ads precisely.&nbsp;Consequently, Meta has a strong incentive to support relatively open platforms that it can build upon and aren’t controlled by any one party. This is why releasing Llama as open source makes a lot of sense for its business (as does its strong support for PyTorch as a counterweight to Google’s TensorFlow). The resulting open source offerings are great for the AI community and diffusion of knowledge!&nbsp;</em></p><p><em>In contrast, Google Cloud and Microsoft Azure stand to benefit more if they manage to offer dominant, closed source LLMs that are closely tied to their cloud offerings. This would help them to grow their cloud businesses. Both Google Cloud and Microsoft Azure, as well as Amazon AWS, are in a good position to build meaningful businesses by offering LLM API calls as part of their broader cloud offerings. However, I expect their cloud businesses to do okay even if they don’t manage to offer an exclusive, clearly dominant LLM (such as Gemini, GPT-4, or their successors). If LLMs become commoditized, they should do fine simply by integrating any new LLMs that gain traction into their API offerings.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--50-.jpg" width="1200" /></figure><p><em>Open or closed, LLMs also offer these companies different opportunities for integration into their existing product lines. For example, Microsoft has a huge sales force for selling its software to businesses. These sales reps are a powerful force for selling its Copilot offerings, which complement the company’s existing office productivity tools. In contrast, Google faces greater risk of disruption to its core business, since some users see asking an LLM questions as a replacement for, rather than a complement to, web search. Nonetheless, it’s making a strong showing with Bard/Gemini. Meta also stands to benefit from LLMs becoming more widely available. Indeed, LLMs are already useful in online advertising, for example, by helping write ad copy to drives more clicks.</em></p><p><em>Tech giants can afford to invest hundreds of millions or even billions of dollars in building LLM technology only to see it become commoditized shortly afterward. Startups would have a harder time surviving after burning this much cash with little to show for it. However, well funded startups will have some time to explore other paths to growing revenue and building a moat.&nbsp;<br /><br />Finally, competition among companies that offer LLMs is great for everyone who builds applications! With so much investment, by both big companies and startups, in improving LLMs and offering them as open source or API calls, I believe — as I described in this talk on “</em><a href="https://www.youtube.com/watch?v=5p248yoa3oE&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener"><em>Opportunities in AI</em></a><em>” — that many of the best business opportunities continue to lie in building applications on top of LLMs.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed--96-.png" width="1200" /></figure><h1 id="nude-deepfakes-spur-legislators">Nude Deepfakes Spur Legislators</h1><p>Sexually explicit deepfakes of Taylor Swift galvanized public demand for laws against nonconsensual, AI-enabled pornography.</p><p><strong>What’s new:</strong>&nbsp;U.S. lawmakers responded to public outcry over lewd AI-generated images of the singer by proposing legislation that would&nbsp;<a href="https://www.documentcloud.org/documents/24397944-defiance-act?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">crack down</a>&nbsp;on salacious images generated without their subject’s permission.&nbsp;</p><p><strong>High-profile target:</strong>&nbsp;In late January, AI-generated images that appeared to depict Swift in the nude appeared on social media sites including X (formerly known as Twitter) and messaging apps such as Telegram. The deepfakes&nbsp;<a href="https://www.bloomberg.com/news/articles/2024-02-05/taylor-swift-deepfakes-originated-from-ai-challenge-report-says?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">originated</a>&nbsp;on the image-sharing site 4chan, where users competed to prompt text-to-image generators in ways that bypassed their keyword filters. Swift fans reported the images, which subsequently were removed. Swift&nbsp;<a href="https://www.vogue.com/article/taylor-swift-deepfake-x-possible-legal-action?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">reportedly</a>&nbsp;is considering legal action against websites that hosted the images.</p><ul><li>Senators of both major U.S. political parties&nbsp;<a href="https://www.judiciary.senate.gov/press/releases/durbin-graham-klobuchar-hawley-introduce-defiance-act-to-hold-accountable-those-responsible-for-the-proliferation-of-nonconsensual-sexually-explicit-deepfake-images-and-videos?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">proposed</a>&nbsp;the Disrupt Explicit Forged Images and Non-Consensual Edits (DEFIANCE) Act, which would allow targets of AI-generated deepfakes to sue and collect financial damages from people who produce, possess, distribute, or receive sexually explicit, nonconsensual images.</li><li>Other U.S. laws under consideration also would permit legal action against deepfakes. The&nbsp;<a href="https://salazar.house.gov/media/press-releases/hundreds-artists-actors-and-creators-back-salazars-no-ai-fraud-act?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">No AI FRAUD Act</a>&nbsp;would allow public figures to sue for unlicensed uses of their likenesses. That legislation would apply not only to images but also generated&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-voice-cloning-tools-used-to-make-ai-generated-songs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">music</a>. Opponents&nbsp;<a href="https://reason.com/2024/01/17/ai-fraud-act-could-outlaw-parodies-political-cartoons-and-more/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">argue</a>&nbsp;that it‘s too broad and could outlaw parodies and harmless memes.</li><li>While U.S. federal law doesn’t regulate deepfakes,&nbsp;<a href="https://eu.usatoday.com/story/news/nation/2024/01/26/was-deepfake-taylor-swift-pornography-illegal-can-she-sue/72359653007/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">10 states</a>&nbsp;forbid nonconsensual deepfake pornography or provide legal recourse. However, identifying perpetrators and seeking damages is difficult in many cases.</li></ul><p><strong>Behind the news:</strong>&nbsp;Sexually explicit deepfakes often&nbsp;<a href="https://www.homesecurityheroes.com/state-of-deepfakes/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ#key-findings" rel="noopener">target</a>&nbsp;celebrities, but several recent incidents involve private citizens who were minors at the time.</p><ul><li>In October 2023, students at a New Jersey high school&nbsp;<a href="https://www.technologyreview.com/2023/12/04/1084271/meet-the-15-year-old-deepfake-porn-victim-pushing-congress/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">distributed</a>&nbsp;deepfakes that depicted more than 30 of their female classmates. One victim, 15-year-old Francesca Mani, is&nbsp;<a href="https://www.technologyreview.com/2023/12/04/1084271/meet-the-15-year-old-deepfake-porn-victim-pushing-congress/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">advocating</a>&nbsp;passage of the U.S. No AI FRAUD Act and pushing New Jersey state lawmakers to introduce a similar bill.</li><li>In September 2023, more than 20 teenage girls in Extremadura, Spain,&nbsp;<a href="https://www.euronews.com/next/2023/09/24/spanish-teens-received-deepfake-ai-nudes-of-themselves-but-is-it-a-crime?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">received</a>&nbsp;messages that included AI-generated nudes of themselves. The perpetrators reportedly downloaded images from the victims’ Instagram accounts and used a free Android app to regenerate them without clothing. In Europe, only the Netherlands&nbsp;<a href="https://www.eur.nl/en/esl/news/how-can-laws-and-regulations-stop-digital-march-deepfakes?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">prohibits</a>&nbsp;the dissemination of such deepfakes. The incident triggered an international debate whether such activity constitutes distributing child pornography, which is widely illegal.&nbsp;</li><li>Law-enforcement agencies face a growing quantity of AI-generated imagery that depicts sexual abuse of both real and fictitious children,&nbsp;<em>The New York Times&nbsp;</em><a href="https://www.nytimes.com/2024/01/30/us/politics/ai-child-sex-abuse.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">reported</a>. In 2002, the U.S. Supreme Court&nbsp;<a href="https://www.nytimes.com/2002/04/16/national/supreme-court-strikes-down-ban-on-virtual-child-pornography.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">struck down</a>&nbsp;a ban on computer-generated child pornography, ruling that it violated the Constitutional&nbsp;guarantee of free speech.&nbsp;</li></ul><p><strong>Why it matters:</strong>&nbsp;The Swift incident dramatizes the growing gap between technological capabilities and legal restrictions. The rapid progress of image generators enables unscrupulous (or simply cruel) parties to prey on innocent victims in ways that exact a terrible toll for which reparation may be inadequate or impossible. In many jurisdictions, the laws against nonconsensual pornography don’t account for AI-generated or AI-edited images. To be actionable, for instance, such images must depict the victim’s own body rather than a generated look-alike.<br /><br /><strong>We’re thinking:</strong>&nbsp;No one, whether a public or private figure, child or adult, should be subject to the humiliation and abuse of being depicted in nonconsensual pornographic images. The U.S., whose constitution guarantees free speech, has weaker tools for silencing harmful messages than other countries. Nonetheless, we hope that Swift gets the justice she seeks and that lawmakers craft thoughtful legislation to protect citizens and provide recourse for victims without banning legitimate applications.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-07T153540.653.gif" width="1200" /></figure><h1 id="new-leaderboards-rank-safety-more">New Leaderboards Rank Safety, More</h1><p>Hugging Face introduced four leaderboards to rank the performance and trustworthiness of large language models (LLMs).</p><p><strong>What’s new:</strong>&nbsp;The open source AI repository now ranks performance on tests of&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-patronus?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">workplace utility</a>,&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-decodingtrust?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">trust and safety</a>, tendency to&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-hallucinations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">generate falsehoods</a>, and&nbsp;<a href="https://huggingface.co/blog/leaderboards-on-the-hub-nphardeval?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">reasoning</a>.<br /><br /><strong>How it works:</strong>&nbsp;The new leaderboards implement benchmarks developed by HuggingFace’s research and corporate partners. Users and developers can submit open models for testing via the individual leaderboard sites; Hugging Face generally selects any closed models that are included.</p><ul><li>The&nbsp;<a href="https://huggingface.co/spaces/PatronusAI/enterprise_scenarios_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Enterprise Scenarios Leaderboard</a>&nbsp;developed by&nbsp;<a href="https://www.patronus.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Patronus</a>, an AI evaluation startup, tests models for accuracy in answering questions about&nbsp;<a href="https://arxiv.org/abs/2311.11944?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">finance</a>,&nbsp;<a href="https://arxiv.org/abs/2308.11462?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">law</a>, customer support, and&nbsp;<a href="https://aclanthology.org/2022.findings-emnlp.359/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">creative writing</a>. It also measures the model’s likelihood to return&nbsp;<a href="https://perspectiveapi.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">toxic answers</a>&nbsp;or&nbsp;<a href="https://www.patronus.ai/announcements/patronus-ai-launches-enterprisepii-the-industrys-first-llm-dataset-for-detecting-business-sensitive-information?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">leak</a>&nbsp;confidential information. Each benchmark assigns a score between 1 and 100. The model with the highest average tops the leaderboard, although models can be sorted by performance on individual tasks.</li><li>The&nbsp;<a href="https://huggingface.co/spaces/AI-Secure/llm-trustworthy-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Secure LLM Safety Leaderboard</a>&nbsp;ranks models according to the Secure Learning Lab’s&nbsp;<a href="https://decodingtrust.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">DecodingTrust</a>&nbsp;benchmark, which was developed by researchers at various universities, the Center for AI Safety, and Microsoft. DecodingTrust tests model output for toxicity, fairness, common social stereotypes, leakage of private information, generalization, and security. The scoring method is similar to that of the Enterprise Scenarios Leaderboard.</li><li>The&nbsp;<a href="https://huggingface.co/spaces/hallucinations-leaderboard/leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Hallucinations Leaderboard</a>&nbsp;implements 14 benchmarks from the&nbsp;<a href="https://github.com/EleutherAI/lm-evaluation-harness?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">EleutherAI Language Model Evaluation Harness</a>. The tests measure the ability to answer factual questions, summarize news articles, understand text, follow instructions, and determine whether statements are true or false.</li><li>The&nbsp;<a href="https://huggingface.co/spaces/NPHardEval/NPHardEval-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">NPHardEval Leaderboard</a>&nbsp;uses a&nbsp;<a href="https://arxiv.org/abs/2312.14890?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">benchmark</a>&nbsp;developed by University of Michigan and Rutgers to measure reasoning and decision-making abilities. The test includes 900 logic problems (100 each for 9 different mathematical algorithms) that are generated dynamically and refreshed each month to prevent overfitting.&nbsp;</li></ul><p><strong>Behind the news:</strong>&nbsp;The new leaderboards complement Hugging Face’s earlier&nbsp;<a href="https://huggingface.co/spaces/optimum/llm-perf-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">LLM-Perf Leaderboard</a>, which gauges latency, throughput, memory use, and energy demands;&nbsp;<a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">Open LLM Leaderboard</a>, which ranks open source options on the EleutherAI Language Model Evaluation Harness; and&nbsp;<a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">LMSYS Chatbot Arena Leaderboard</a>, which ranks chat systems according to blind tests of user preferences.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;The new leaderboards provide consistent evaluations of model performance with an emphasis on practical capabilities such as workplace uses, social stereotyping, and security. Researchers can gain an up-to-the-minute snapshot of the state of the art, while prospective users can get a clear picture of leading models’ strengths and weaknesses. Emerging regulatory regimes such as Europe’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">AI Act</a>&nbsp;and the U.S.’s&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-u-s-executive-order-on-ai-use-and-development/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">executive order on AI</a>&nbsp;emphasize social goods like safety, fairness, and security, giving developers additional incentive to keep raising the bars.</p><p><strong>We’re thinking:</strong>&nbsp;Such leaderboards are a huge service to the AI community, objectively ranking top models, displaying the comparative results at a glance, and simplifying the tradeoffs involved in choosing the best model for a particular purpose. They’re a great aid to transparency and antidote to cherry-picked benchmarks, and they provide clear goals for developers who aim to build better models.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.eventbrite.com/e/turbocharge-your-rag-applications-with-powerful-rag-analytics-tickets-817201701287?aff=Batch&amp;ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/02/The-Batch-ads-and-exclusive-banners---2024-02-06T172247.774.png" width="1680" /></a></figure><p>Retrieval Augmented Generation (RAG) is a powerful way to extend large language models, but to implement it effectively, you need the right retrieval techniques and evaluation metrics. In this workshop, you’ll learn how to build better RAG-powered applications faster.&nbsp;<a href="https://www.eventbrite.com/e/turbocharge-your-rag-applications-with-powerful-rag-analytics-tickets-817201701287?aff=Batch&amp;ref=dl-staging-website.ghost.io" rel="noreferrer">Register now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-07T153736.731.gif" width="1200" /></figure><h1 id="gpt-4-biothreat-risk-is-low">GPT-4 Biothreat Risk is Low</h1><p>GPT-4 poses negligible additional risk that a malefactor could build a biological weapon, according to a new study.</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/research/building-an-early-warning-system-for-llm-aided-biological-threat-creation?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">compared</a>&nbsp;the ability of GPT-4 and web search to contribute to the creation of a dangerous virus or bacterium. The large language model was barely more helpful than the web.</p><p><strong>How it works:</strong>&nbsp;The researchers asked both trained biologists and biology students to design a biological threat using either web search or web search plus GPT-4.</p><ul><li>The authors recruited 50 experts who had doctorates and experience in a laboratory equipped to handle biohazards, and 50 students who had taken a biology course at an undergraduate level or higher. All participants were U.S. citizens or permanent residents and passed a criminal background check.</li><li>Half of each group were allowed to search the web. The other half also had access to GPT-4. (The experts were given a research version of the model that was capable of answering dangerous questions with limited safeguards.)</li><li>Participants were asked to complete 5 tasks that corresponded to steps in building a biological threat: (i) choose a suitable biohazard, (ii) find a way to obtain it, (iii) plan a process to produce the threat in a sufficient quantity, (iv) determine how to formulate and stabilize it for deployment as a bioweapon, and (v) identify mechanisms to release it.</li><li>The authors scored completion of each task for accuracy, completeness, and innovation (0 to 10) as well as time taken (in minutes). Participants scored each task for difficulty (0 to 10).</li></ul><p><strong>Results:</strong>&nbsp;Participants who used GPT-4 showed slight increases in accuracy and completeness.Students with GPT-4 scored 0.25 and 0.41 more points on average, respectively, than students in the control group. Experts with access to the less restricted version of GPT-4 scored 0.88 and 0.82 points higher on average, respectively, than experts in the control group. However, these increases were not statistically significant. Moreover, participants who used GPT-4 didn’t show greater innovation, take less time per task, or view their tasks as easier. Even if GPT-4 could be prompted to provide information that would facilitate a biological attack, the model didn’t provide more information than a user could glean by searching the web.</p><p><strong>Why it matters:</strong>&nbsp;AI alarmists have managed to create a lot of anxiety by promoting disaster scenarios, such as human extinction, that the technology has no clear way to bring about. Meanwhile, the unfounded fears stand to slow down developments that could do tremendous good in the world. Evidence that GPT-4 is no more likely than web search to aid in building a bioweapon is a welcome antidote. (Though we would do well to consider removing from the web unnecessary information that may aid in the making of bioweapons.)</p><p><strong>We’re thinking:</strong>&nbsp;Large language models, like other multipurpose productivity tools such as web search or spreadsheet software, are potentially useful for malicious actors who want to do harm. Yet AI’s potential in biothreat development garners headlines, while Excel’s is rarely mentioned. That makes it doubly important to quantify the risk in ways that can guide regulators and other decision makers.&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/02/unnamed---2024-02-07T153903.061.gif" width="1200" /></figure><h1 id="llms-can-get-inside-your-head">LLMs Can Get Inside Your Head</h1><p>Most people understand that others’ mental states can differ from their own. For instance, if your friend leaves a smartphone on a table and you privately put it in your pocket, you understand that your friend continues to believe it was on the table. Researchers probed whether language models exhibit this capability, which psychologists call theory of mind.</p><p><strong>What's new:</strong>&nbsp;Michal Kosinski at Stanford evaluated the ability of large language models to&nbsp;<a href="https://arxiv.org/abs/2302.02083?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">solve language tasks designed to test for theory of mind in humans</a>. The largest models fared well.</p><p><strong>How it works:</strong>&nbsp;The author evaluated the performance of (GPT-1 through GPT-4 as well as&nbsp;<a href="https://arxiv.org/abs/2211.05100?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">BLOOM</a>) on 40 tasks developed for human studies. In each task, the models completed three prompts in response to a short story. Researchers rewrote the stories in case the original versions had been part of a model’s training set.&nbsp;&nbsp;</p><ul><li>Half of the tasks involved stories about “<a href="https://www.sciencedirect.com/science/article/abs/pii/0010027783900045?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">unexpected transfers,</a>” in which a person leaves a place, change occurs in their absence, and they return. For instance, Anna removed a toy from a box and placed it in a basket after Sally left. The model must complete the prompt, “Sally thinks that the toy is in the …”&nbsp;</li><li>The other half of tasks involved stores about “<a href="https://bpspsychub.onlinelibrary.wiley.com/doi/10.1111/j.2044-835X.1987.tb01048.x?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-8Y8VcIGPKkvslnBMAruA5kYkKFHHrjyvME8HtPe9IOfXg7q3zodrZXs1REGGzuHPrOe2MJ" rel="noopener">unexpected content,</a>” in which a person interacted with mislabeled containers, such as a bottle of beer marked “wine.” The model completed prompts such as “The person believes that the bottle is full of … .”</li><li>Both types of task tested the model’s understanding that characters in the stories believed factually false statements.</li></ul><p><strong>Results:</strong>&nbsp;The models generated the correct response more consistently as they increased in size. GPT-1 (117 million parameters) gave few correct responses, while GPT-4 (size unknown but rumored to be over 1 trillion parameters) solved 90 percent of unexpected content tasks and 60 percent of unexpected transfer tasks, exceeding the performance of 7-year-old children.</p><p><strong>Why it matters</strong>: The tasks in this work traditionally are used to establish a theory of mind in children. Subjecting large language models to the same tasks makes it possible to compare this aspect of intelligence between humans and deep learning models.&nbsp;</p><p><strong>We're thinking</strong>: If a model exhibits a theory of mind, are you more or less likely to give it a piece of your mind?</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>This week, AI innovation is fueling different companies, including Yelp, Mastercard, and Volkswagen. At the same time, governments worldwide are implementing new safety and legal measures concerning generative AI.</p><p>We've distilled the most compelling stories in Data Points, a spin-off of The Batch.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-235/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 07 Feb 2024 20:50:11 GMT</pubDate>
</item>
<item>
<title>AI Jobs Proliferate, Big Compute Giveaway, Generated Video Upgrade, Higher Yields for Small Farms</title>
<link>https://www.deeplearning.ai/the-batch/issue-234</link>
<guid>https://www.deeplearning.ai/the-batch/issue-234</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>Last year, a number of large businesses and individuals went to the media and governments and pushed the message that AI is scary, impossible to control, and might even lead to human extinction. Unfortunately they succeeded: Now many people think AI is scary. But when I speak with regulators, media, and private citizens, I like to bring the issue of whether AI is beneficial or harmful back to a very basic question: Are we better off with more, or less, intelligence in the world?&nbsp;</em></p><p><em>Intelligence is the ability to apply skills and knowledge to make good decisions. Yes, intelligence can be used for nefarious purposes. But over many centuries, a major driver of civilization's progress has been people getting smarter and more educated. Until now, human intelligence has been the primary form of intelligence available. But with artificial intelligence, we have the opportunity to bring much more intelligence into the world. I discussed this opportunity in a recent&nbsp;</em><a href="https://www.ft.com/content/2dc07f9e-d2a9-4d98-b746-b051f9352be3?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener"><em>interview</em></a><em>&nbsp;(paywalled) with&nbsp;</em>Financial Times<em>&nbsp;reporter Ryan McMorrow.</em></p><p><em>Historically, intelligence has been very expensive to acquire. It costs a lot to feed, raise, and train a broadly knowledgeable and experienced human being! That's why it’s so expensive to hire intelligence, such as a highly skilled doctor to examine and advise you on a medical condition, or a patient tutor who can understand your child and gently coach them where they need help. But with artificial intelligence, we have the potential to make intelligence cheap for everyone, so you no longer have to worry about a huge bill for seeing a doctor or educating your child.&nbsp;</em></p><figure class="kg-card kg-image-card"><img alt="Andrew Ng speaking at TED AI, October 17, 2023" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--95--1.png" width="1200" /></figure><p><em>For society's biggest problems, such as climate change, intelligence — including artificial intelligence — also has a significant role to play. While having more intelligence in the world isn't the only thing (there are also nuances such as how to share the wealth it creates, how it will affect jobs, and how to keep it from being used for evil purposes), I believe we are much better off as a society with more intelligence, be it human or artificial intelligence.&nbsp;</em></p><p><em>In my recent talk at TED AI (you can watch the 12-minute presentation&nbsp;</em><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVHq6H6TMxM9W8TV7CF5FvPH4W20x2Jc58Zt8WN8wLL663qgyTW7Y8-PT6lZ3lWW1vt84X3qp-pdW15GPdM1MB7mgW29rQYH5QQknhN5CNCgfWcjXvW1Nk-0Z2p2sl-N6kZsXqsm_PPW1xRk8V7_7ZD2N8B2kl72-slqW2WC8HS8nwxPyV8p8kx68HzNVW2Ft_fP6NG9ptW4pP-c97_Rw6zVwXw816q1n_TW1nftZM13J5CXW7jsFPQ8TNvLQW4X9XTn36QJjcW5_NSsV2V0wgqW3LjCHT5RqpkqW8-vsJ24s1XnlW9hlFXY3VVlDyW6rdfhr7XNJSrW6dmbYZ1hN8JfW1bFlbM2Vg5Z-W5PRXV-28__H4W6KWQj149t3_KW8Svqz77y5SgMf1p_s-004?ref=dl-staging-website.ghost.io" rel="noopener"><em>here</em></a><em>), I touched on why I'm excited about AI and why I think many of the anxieties about it are misplaced. If you speak with someone who’s worried about AI, please forward the talk to them to see if it helps to reassure them. Or ask if they fundamentally believe we want more intelligence in the world. I find that answering this question can be a useful North Star for how we approach AI.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. Check out our new short course on “Building Applications with Vector Databases,” taught by Pinecone’s Tim Tully! Vector databases (DBs) are commonly associated with retrieval augmented generation (RAG) but actually have many uses in AI applications. In this course, you’ll learn about (i) a basic semantic search app that uses a vector DB to find similar documents, (ii) a RAG application querying datasets it was not trained on, (iii) recommender systems that combine semantic search and RAG, (iv) hybrid search, which lets you work with dense and sparse vectors simultaneously, (v) anomaly detection applied to network logs, and (vi) an image-similarity application with a fun example that determines which parent a child resembles more. Come learn how you can use vector DBs to build many different types of applications!&nbsp;</em><a href="https://info.deeplearning.ai/e3t/Ctc/LX+113/cJhC404/VVHq6H6TMxM9W8TV7CF5FvPH4W20x2Jc58Zt8WN8wLL6q3qgyTW8wLKSR6lZ3pKVQv-FK6CXVFLW5yNf5J7XtWVFW32hqkv3z_GSKW5Vrf077Gwm7XW9616wV65JTYjVKWbx-5gkBzGW7JbKMb91ljfBN1zK_6JJ0HXBW9gNydX7RFTXpW587Qwr6mvG_1W86RRt82xcYWbN8jss88Txf9PW52-Fw26r_y54W840Ddf1DMLbyW7qslFw3Z9jlPW1CBJ9f2ZDwSVVhNzFw7MP1hrW57VVWN2BZCmDW6f6qR2468d9MW65cPWp2nyGkJW7td37h61xY7tW63b6H35TD8YRW2qSjYn7_VjfTW8YWt917FrC5JW6wCXdB86rGQRW6vBjsz5lnycrW2nSCMw2NbWWGW8wFB0D2kdLL8f25P8wT04?ref=dl-staging-website.ghost.io" rel="noopener"><em>Enroll here</em></a></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T154407.087.gif" width="1200" /></figure><h1 id="resources-for-research">Resources for Research</h1><p>The United States government wants to connect U.S. AI researchers with resources that can help them develop their projects.</p><p><strong>What’s new:</strong>&nbsp;The National Artificial Intelligence Research Resource (NAIRR)&nbsp;<a href="https://nairrpilot.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">announced</a>&nbsp;the first call for proposals in its pilot program, which will accept applications through March 1. Winning proposals can receive processing power, data, software, and training provided by partner organizations. Another round will kick off in the second quarter of 2024.&nbsp;</p><p><strong>How it works:</strong>&nbsp;Led by the National Science Foundation, NAIRR aims to support innovative AI research by organizing national compute and other infrastructure to be shared among researchers and educators. The initiative pulls together 10 other federal agencies and 25&nbsp;<a href="https://new.nsf.gov/focus-areas/artificial-intelligence/nairr?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">partners</a>&nbsp;including heavyweights like Amazon, Google, Intel, and OpenAI; startups like Allen Institute for Artificial Intelligence, Anthropic, EleutherAI, Hugging Face, and Weights &amp; Biases; and hardware companies like AMD, Intel, and Nvidia.&nbsp;</p><ul><li>NAIRR is calling for projects that qualify as “safe, secure, and trustworthy AI.” Examples include testing and validating AI systems, reducing bias, improving privacy and security, and aligning AI with social values.</li><li>The organization includes divisions that focus on open development, privacy and security, interoperation of partner resources, and education and outreach.</li><li>Proposals will be evaluated based on how well they align with AI safety, security, and trustworthiness; project readiness; technical feasibility; knowledge and experience of their leaders; computing and data requirements; and need for the specific resources provided by the program.</li><li>Researchers whose projects are accepted in the initial round will gain&nbsp;<a href="https://nairrpilot.org/pilot-resources?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">access</a>&nbsp;to models, datasets, AI toolkits, and training provided by government partners including the Department of Defense, NASA, NOAA, the National Institutes of Health, the U.S. Patent and Trademark Office, and the&nbsp;<a href="https://www.deeplearning.ai/the-batch/nist-released-its-ai-risk-management-framework/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">National Institute for Standards and Technology</a>. Researchers may&nbsp;<a href="https://nairrpilot.org/allocations?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">receive</a>&nbsp;time on supercomputers hosted by university and government laboratories.</li><li>Future programs will tap private resources. Microsoft&nbsp;<a href="https://blogs.microsoft.com/on-the-issues/2024/01/24/national-ai-research-resource-nairr-artificial-intelligence/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">pledged</a>&nbsp;$20 million in Azure computing credits and access to OpenAI models. Nvidia&nbsp;<a href="https://blogs.nvidia.com/blog/national-ai-research-resource-pilot/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">promised</a>&nbsp;$30 million worth of access to its DGX Cloud infrastructure and enterprise software.</li></ul><p><strong>Behind the news:&nbsp;</strong>Policymakers&nbsp;<a href="https://www.whitehouse.gov/ostp/news-updates/2023/01/24/national-artificial-intelligence-research-resource-task-force-releases-final-report/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">planned</a>&nbsp;to organize a national infrastructure for AI research after calls from&nbsp;<a href="https://www.nbcnews.com/tech/tech-news/big-tech-pushing-national-cloud-critics-say-big-tech-profit-rcna2971?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">prominent</a>&nbsp;<a href="https://www.deeplearning.ai/the-batch/fei-fei-li-invigorating-the-u-s-ai-ecosystem/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">researchers</a>. NAIRR is now open thanks to an&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-u-s-executive-order-on-ai-use-and-development/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">executive order</a>&nbsp;issued by the White House in October.</p><p><strong>Why it matters</strong>: AI has potential to affect all corners of society yet, generally, only wealthy companies can bear the high costs of building and running large machine learning models. Partnership between government, industry, and academia can pool AI resources to cultivate talent throughout society and support important projects that may not serve a corporate agenda.&nbsp;<br /><br /><strong>We’re thinking:</strong>&nbsp;This is an exciting bid to proliferate AI research. Sharing the fruits of such research via open publications and open source software will bring the technology’s benefits to a wider range of people.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T154457.554.gif" width="600" /></figure><h1 id="high-yields-for-small-farms">High Yields for Small Farms</h1><p>Indian farmers used chatbots and computer vision to produce higher yields at lower costs.</p><p><strong>What’s new:</strong>&nbsp;The state government of Telangana in South India&nbsp;<a href="https://www.weforum.org/agenda/2024/01/how-indias-ai-agriculture-boom-could-inspire-the-world/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">partnered</a>&nbsp;with agricultural aid organization&nbsp;<a href="https://www.digitalgreen.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Digital Green</a>&nbsp;to provide AI tools to chili farmers.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The program, called Saagu Baagu, initially engaged 7,000 small-farm growers of chili peppers. Saagu Baagu provided AI-based tools developed by various Indian tech firms to help the farmers collect market data.</p><ul><li>Digital Green developed a WhatsApp chatbot in partnership with open-source developer&nbsp;<a href="https://glific.org/about-us/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Glific</a>. The chatbot, which converses in the Telugu language, alerts a farmer throughout the day with suggestions depending on a crop’s maturity. Farmers can also ask questions about their crops.</li><li>Agritech startup&nbsp;<a href="https://krishitantra.com/revolutionising-agriculture-the-role-of-ai-in-soil-technology/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">KrishiTantra</a>&nbsp;opened a chain of local soil testing centers. Farmers test soil samples using a machine-learning-powered device that analyzes acidity, nutrient levels, and other qualities. Where traditional soil testing might take several weeks to return results, KrishiTantra’s system sends results and fertilizer recommendations to a farmer’s mobile phone in less than an hour.</li><li>AgNext&nbsp;<a href="https://agnext.com/assessing-the-physical-quality-of-commodities-using-computer-vision-technology/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">provided</a>&nbsp;a computer vision system that assesses the quality of individual chilis in the field. The system detects surface defects and estimates properties such as color, shape, and size, all of which can help reduce crop waste and increase sale prices.</li></ul><p><strong>Results:</strong>&nbsp;The pilot program lasted 18 months, or three cycles of planting, growing, and harvesting peppers. Farmers in the program grew 21 percent more plants per acre while using 9 percent less pesticide and 5 percent less fertilizer, according to the World Economic Forum. Moreover, with a higher-quality harvest, the farmers increased their sale prices by 8 percent. The Telangana government has expanded the program to 500,000 farmers who grow a wider range of crops including chickpeas, cotton, groundnuts, rice, and turmeric.</p><p><strong>Behind the news:</strong>&nbsp;The promise of AI-driven agriculture is attracting investments around the world. Last year, Microsoft&nbsp;<a href="https://www.deeplearning.ai/the-batch/microsoft-open-sources-ai-systems-for-agriculture/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">open-sourced</a>&nbsp;a suite of AI tools to analyze overhead imagery and sensor data to map soil conditions in real time and forecast temperature, precipitation, and soil moisture for days ahead.</p><p><strong>Why it matters:</strong>&nbsp;Many of the Telangana farmers rely on what they can grow and sell to support themselves and their families. That makes them especially vulnerable to market fluctuations and climate change. Their situation is not unique to India. Programs like Saagu Baagu could help support small-scale farming across the world.</p><p><strong>We’re thinking:</strong>&nbsp;Saagu Baagu worked in part because WhatsApp is widely popular throughout India and the chatbot spoke the local language. Smart localization that addresses local technological infrastructures, languages, and agricultural practices can proliferate the benefits of AI in agriculture.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/building-applications-vector-databases/?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners---2024-01-30T091637.902.png" width="1680" /></a></figure><p>In our new course with Pinecone, you’ll learn how to build six applications that use vector databases, including retrieval augmented generation, facial similarity, and anomaly detection.&nbsp;<a href="https://www.deeplearning.ai/short-courses/building-applications-vector-databases/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Sign up now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T154942.886.gif" width="1200" /></figure><h1 id="ai-jobs-grow-beyond-established-hubs">AI Jobs Grow Beyond Established Hubs</h1><p>An analysis of United States job listings shows AI jobs are growing rapidly outside traditional tech hubs.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;Researchers at University of Maryland&nbsp;<a href="https://www.aimaps.ai/download/whitepaper-sheets/from-west-to-the-rest-(white-paper1).pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">analyzed</a>&nbsp;the distribution of AI jobs among U.S. job postings. California hosts the largest concentration, followed by the Washington D.C. metropolitan area (which includes more than one state).</p><p><strong>How it works:</strong>&nbsp;The authors used an unspecified large language model to identify AI jobs, which they define as ones that require AI skills. They categorized each job by the U.S. state in which it was located. To determine whether a given state’s AI economy was growing or shrinking, they calculated the percentage of total U.S. AI jobs in each state in 2018 and 2023. They also calculated the percentage of each state’s total jobs that required AI skills for both dates.</p><ul><li>California continues to post the most U.S. AI jobs. However, California’s share of AI jobs dipped from 26 percent in 2018 to 19 percent in 2023. Still, 1.07 percent of postings in California are AI jobs, well above the national average of 0.56 percent.</li><li>Similarly, the share of AI jobs in the state of Washington, home to Amazon and Microsoft, declined from 13 percent in 2018 to 5 percent in 2023. However, more than 1 percent of Washington postings are AI jobs.</li><li>The combined share of Maryland, Virginia, and Washington D.C. — the U.S. capital region — rose from 7 percent in 2018 to 13 percent in 2023. The authors attributed this growth to the federal government’s embrace of AI: Companies that supply the government have responded by hiring AI experts.</li><li>New York’s and New Jersey’s combined share of AI jobs declined from approximately 12 percent in 2018 to 11 percent in 2023.</li><li>Meanwhile, other parts of the U.S. saw meaningful growth. Texas’ share of AI jobs grew from 6 percent of AI jobs in 2018 to over 8 percent in 2023. Florida’s share rose from 2 to 4 percent in the same time period. The combined share of 12 Midwestern states grew from 10 percent to 13 percent. However, these regions posted much smaller percentages of AI jobs relative to total jobs.</li></ul><p><strong>Behind the news:</strong>&nbsp;A 2021 Brookings&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-hubs-are-few-and-far-between/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">report</a>&nbsp;on U.S. AI jobs focused on metropolitan areas and analyzed not only job postings but also federal grants, research papers, patent filings, and companies. Despite the differences in methodology, it agreed with the new report that investment was driving AI growth outside of the Bay Area. The new report suggests a much wider geographical distribution of AI jobs in 2024 than in 2021. It appears some of the then-emerging industrial investment in AI is bearing fruit.<br /><br /><strong>Why it matters:</strong>&nbsp;For people who aim to make a career in AI, this report contains double good news: (i) Established AI hubs in the U.S. still host the most new openings and (ii) AI jobs are growing far and wide! As the industry becomes more dispersed geographically, AI builders have more options, organizations can select from a more diverse talent pool, and the technology’s benefits can be shared more broadly.<br /><br /><strong>We’re thinking:</strong>&nbsp;Although this report focused on the U.S., we believe that growth in AI jobs is a global trend. One contributor is growing acceptance of remote work (which remains more prevalent than it was a few years ago despite its decline as the Covid pandemic has wanted). This means more AI opportunities for everyone, everywhere!&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="335" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-31T155118.727.gif" width="600" /></figure><h1 id="more-consistent-generated-videos">More Consistent Generated Videos</h1><p>Text-to-video has struggled to produce consistent motions like walking and rotation. A new approach achieves more realistic motion.</p><p><strong>What’s new:</strong>&nbsp;Omer Bar-Tal, Hila Chefer, Omer Tov, and colleagues at Google, Weizmann Institute, Tel-Aviv University, and Technion built&nbsp;<a href="https://arxiv.org/abs/2401.12945?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Lumiere</a>, a system that simplifies the usual process of generating video with improved results. You can see examples of its output&nbsp;<a href="https://lumiere-video.github.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;Most text-to-video generators economize on memory use through a staged process: One model generates a few frames per second, another model generates additional frames between the initial ones, and a third generates a higher resolution version of every frame. Generating in-between frames can make repetitive motions inconsistent. To avoid these inconsistencies, the authors generated all frames at the same time. To bring down memory requirements, the video generator reduced the size of the video embedding before intensive processing and then restored their original size.</p><p><strong>How it works:</strong>&nbsp;Lumiere borrows two components from previous work. It uses a frozen, pretrained text-to-image diffusion model (in this case,&nbsp;<a href="https://arxiv.org/abs/2205.11487?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">Imagen</a>, with additional convolutional and attention layers) to generate low-resolution video frames from a text description. It uses a super-resolution model (unspecified in this case) to boost the frames’ resolution. The authors trained the layers added to Imagen on an unspecified dataset of 30 million videos (16 frames per second, 128x128 pixels per frame) and their captions.&nbsp;</p><ul><li>Given a 5-second video with added noise and its text caption, the layers added to Imagen learned to remove the noise. Following earlier&nbsp;<a href="https://arxiv.org/abs/2210.02303?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">work</a>, the model saved memory by shrinking video embeddings spatially. Specifically, additional convolutional layers progressively shrank the input embedding from size (Time, Height, Width, Depth) to size (Time, Height/2, Width/2, Depth). This effectively shrank the parts of the embedding that correspond to individual frames before subjecting the entire embedding to computationally intensive attention layers. Afterward, further convolutional layers enlarged the embeddings to match the input size.</li><li>In addition to shrinking and enlarging the video embedding spatially, the added layers learned to shrink and enlarge it temporally; that is, from size (Time, Height, Width, Depth) to size (Time/2, Height/2, Width/2, Depth). This further economized on memory usage.</li><li>To accommodate the super-resolution model, Lumiere broke up Imagen’s 5-second video output into overlapping clips. The super-resolution model increased their resolution to 1024×1024.</li><li>To avoid temporal artifacts from this process, Lumiere employed&nbsp;<a href="https://arxiv.org/abs/2302.08113?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_zTtLWq1ZZMZAC_cWYWLP26YekgIae7-rD1jeLN-16XAUnZ5tsiSJ2ylZ5S-ia9AnpH2ZJ" rel="noopener">MultiDiffusion</a>, which learned a weighted sum over the overlapping portions of the clips.&nbsp;</li></ul><p><strong>Results:</strong>&nbsp;Given one video produced by Lumiere and another produced by a competitor (AnimateDiff, Gen2, Imagen Video, Pika, or ZeroScope), judges compared video quality and alignment with the text prompt used to generate a video. For each competitor, they evaluated 400 videos for each of 113 prompts. Comparing video quality, Lumiere beat the best competitor, Gen2, 61 percent to 39 percent. Comparing alignment with the prompt, Lumiere beat the best competitor, ImagenVideo, 55 percent to 45 percent.</p><p><strong>Why it matters:</strong>&nbsp;Earlier video generators produced output with limited motion or motion with noticeable issues (for example, a character’s body shape might change in unexpected ways). By producing all video frames at once, Lumiere generates images of motion without such issues.</p><p><strong>We’re thinking:</strong>&nbsp;Lumiere's approach hints at both the challenge of generating video and the pace of development. Many further refinements are needed to make such systems as useful as, say, ChatGPT, but recent progress is impressive.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>This week on Data Points we spotlight updates in the legal AI sector, China’s freshly introduced regulations for robotaxis, the widely discussed paper on sleeper agents, plans in the EU to build ‘AI factories,’ and more.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-234/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read Data Points now</a>.</p>
]]></content:encoded>
<pubDate>Wed, 31 Jan 2024 21:01:04 GMT</pubDate>
</item>
<item>
<title>Machine Learning Detects Cancer Early, Language Model Learns Geometry, AI Creates Jobs, Nations Invest in Homegrown AI</title>
<link>https://www.deeplearning.ai/the-batch/issue-233</link>
<guid>https://www.deeplearning.ai/the-batch/issue-233</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>Last week, I attended the World Economic Forum, an annual meeting of leaders in government, business, and culture at Davos, Switzerland. I spoke in a few sessions, including a lively discussion with Aiden Gomez, Daphne Koller, Yann LeCun, Kai-Fu Lee, and moderator Nicholas Thompson about the present and possible future technology developments of generative AI. You can watch it&nbsp;</em><a href="https://www.weforum.org/events/world-economic-forum-annual-meeting-2024/sessions/the-expanding-universe-of-generative-models/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>here</em></a><em>.<br /><br />The conference's themes included AI, climate change, economic growth, and global security. But to me, the whole event felt like an AI conference! (This is not just my bias. When I asked a few non-AI attendees whether they felt similarly, about three-quarters of them agreed with me.) I had many conversations along two major themes:<br /><br /><strong>Business implementation of AI.&nbsp;</strong>Many businesses, and to a lesser extent governments, are looking at using AI and trying to develop best practices for doing so. In some of my presentations, I shared my top two tips:</em></p><ul><li><em>Almost all knowledge workers can become more productive right away by using a large language model (LLM) like ChatGPT or Bard as a brainstorming partner, copyeditor, tool to answer basic questions, and so on. But many people still need to be trained to use these models safely and effectively. I also encouraged CEOs to learn to use these tools themselves, so they can lead from the top.</em></li><li><em>In addition to using an LLM’s web interface, API calls offer many new opportunities to build new AI applications. I shared a task-based analysis&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/which-ai-applications-should-you-build/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>framework</em></a><em>&nbsp;and described how an analysis like this can lead to buy-versus-build decisions to pursue identified opportunities, with build being either an in-house project or a spin-out.</em></li></ul><p><em><strong>AI regulation.</strong>&nbsp;With many governments represented at Davos, many discussions about AI regulation also took place. I was delighted that he conversation has become much more sensible compared to 6 months ago, when the narrative was driven by misleading&nbsp;</em><a href="https://www.safe.ai/statement-on-ai-risk?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>analogies between AI and nuclear weapons</em></a><em>&nbsp;and lobbyists had significant momentum pushing proposals that threatened open-source software. However, the fight against stifling regulations isn't over yet! We must continue to protect open-source software and innovation. In detail:</em></p><figure class="kg-card kg-image-card"><img alt="World Economic Forum, January 16, 2024: &quot;The Expanding Universe of Generative Models&quot; panelists" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--92-.png" width="1200" /></figure><ul><li><em>I am happy to report that, in many hours of conversation about AI and regulations, I heard only one person bring up AI leading to human extinction, and the conversation quickly turned to other topics. I'm cautiously optimistic that this particular fear — of an outcome that is overwhelmingly unlikely — is losing traction and fading away.</em></li><li><em>However, big companies, especially ones that would rather not have to compete with open source, are still pushing for stifling, anti-competitive AI regulations in the name of safety. For example, some are still using the argument, “don't we want to know if your open-source LLMs are safe?” to promote potentially onerous testing, reporting, and perhaps even licensing requirements on open-source software. While we would, of course, prefer safe models (just as we would prefer secure software and truthful speech), overly burdensome “protections” could still destroy much innovation without materially reducing harm. &nbsp;</em></li><li><em>Fortunately, many regulators are now aware of the need to protect basic research and development. The battle is still on to make sure we can continue to freely distribute the fruits of R&amp;D, including open-sourcing software. But I'm encouraged by the progress we've made in the last few months.&nbsp;</em></li></ul><p><em>I also went to some climate sessions to listen to speakers. Unfortunately, I came away from them feeling more pessimistic about what governments and corporations are doing on decarbonization and climate change. I will say more about this in future letters, but:</em></p><ul><li><em>Although some experts still talk about 1.5 degrees of warming as an optimistic scenario and 2 degrees as a pessimistic scenario, my own view after reviewing the science is that 2 degrees is a very optimistic scenario, and 4 degrees is a more realistic pessimistic scenario.</em></li><li><em>Unfortunately, this overoptimism is causing us to underinvest in resilience and adaptation (to help us better weather the coming changes) as well as put less effort into exploring potentially game-changing technologies like geo-engineering.&nbsp;</em></li></ul><p><em>Davos is a cold city where temperatures are often below freezing. In one memorable moment at the conference, I had lost my gloves and my hands were freezing. A stranger whom I had met only minutes ago kindly gave me an extra pair. This generous act reminded me that, even as we think about the global impacts of AI and climate change, simple human kindness touches people's hearts and reminds us that the ultimate purpose of our work is to help people.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. Check out our new short course on “Automated Testing for LLMOps,” taught by CircleCI CTO Rob Zuber! This course teaches how you can adapt key ideas from continuous integration (CI), a pillar of efficient software engineering, to building applications based on large language models (LLMs). Tweaking an LLM-based app can have unexpected side effects, and having automated testing as part of your approach to LLMOps (LLM Operations) helps avoid these problems. CI is especially important for AI applications given the iterative nature of AI development, which often involves many incremental changes. Please sign up&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/automated-testing-llmops/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener"><em>here</em></a><em>.</em></p><p>&nbsp;</p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--93-.png" width="1200" /></figure><h1 id="early-detection-for-pancreatic-cancer">Early Detection for Pancreatic Cancer</h1><p>A neural network detected early signs of pancreatic cancer more effectively than doctors who used the usual risk-assessment criteria.</p><p><strong>What’s new:</strong>&nbsp;Researchers at MIT and oncologists at Beth Israel Medical Center in Boston&nbsp;<a href="https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00454-1/fulltext?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">built</a>&nbsp;a model that analyzed existing medical records to predict the risk that an individual will develop the most common form of pancreatic cancer. The model outperformed commonly used genetic tests.<br /><br /><strong>How it works:</strong>&nbsp;The authors trained PrismNN, a vanilla neural network, to predict a patient’s risk of receiving a diagnosis of pancreatic ductal adenocarcinoma (PDAC) in the next 6 to 18 months.</p><ul><li>The authors assembled a dataset of roughly 26,250 patients who had developed PDAC and 1.25 million control patients from a proprietary database of anonymized health records from U.S. health care organizations provided by&nbsp;<a href="https://trinetx.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">TriNetX</a>&nbsp;(one of the study’s funders). All patients were 40 years or older.&nbsp;</li><li>For each patient, the dataset marked 87 features including age, history of conditions like diabetes and hypertension, presence of pancreatic cysts, and current medications.</li><li>The authors trained the model on their dataset to predict the probability of PDAC in the next 6 to 18 months. At inference, they classified patients as high-risk if the probability exceeded a certain threshold.</li></ul><p><strong>Results:</strong>&nbsp;PrismNN identified as high-risk 35.9 percent of patients who went on to develop PDAC, with a false-positive rate of 4.7 percent. In comparison, the genetic criteria typically used to identify patients for pancreatic cancer screening flags 10 percent of patients who go on to develop PDAC. The model performed similarly across age, race, gender, and location, although some groups (particularly Asian and Native American patients) were underrepresented in its training data.</p><p><strong>Behind the news:</strong>&nbsp;AI shows promise in detecting various forms of cancer. In a randomized, controlled trial last year, a neural network&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-matches-humans-in-breast-cancer-diagnosis/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">recognized</a>&nbsp;breast tumors in mammograms at a rate comparable to human radiologists. In 2022, an algorithm successfully&nbsp;<a href="https://www.deeplearning.ai/the-batch/an-ai-powered-microscope-that-helps-pathologists-detect-cancer/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">identified</a>&nbsp;tumors in lymph node biopsies.</p><p><strong>Why it matters:</strong>&nbsp;Cancer of the pancreas is one of the deadliest. Only 11 percent of patients&nbsp;<a href="https://acsjournals.onlinelibrary.wiley.com/doi/10.3322/caac.21708?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">survive</a>&nbsp;for 5 years after diagnosis. Most cases aren’t diagnosed until the disease has reached an advanced stage. Models that can spot early cases could boost the survival rate significantly.</p><p><strong>We’re thinking:</strong>&nbsp;The fact that this study required no additional testing is remarkable and means the authors’ method could be deployed cheaply. However, the results were based on patients who had already been diagnosed with cancer. It remains for other teams to replicate them with patients who have not received a diagnosis, perhaps followed by a randomized, controlled clinical trial.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-24T145719.589.gif" width="1200" /></figure><h1 id="ai-creates-jobs-study-suggests">AI Creates Jobs, Study Suggests</h1><p>Europeans are keeping their jobs even as AI does an increasing amount of work.&nbsp;</p><p><strong>What’s new:&nbsp;</strong>Researchers at the European Central Bank&nbsp;<a href="https://www.ecb.europa.eu/pub/economic-research/resbull/2023/html/ecb.rb231128~0a16e73d87.en.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">found</a>&nbsp;that employment in occupations affected by AI rose over nearly a decade.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors considered jobs that were found to be affected by AI over the past decade according to&nbsp;<a href="https://journals.aom.org/doi/10.5465/AMBPP.2019.140?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">two</a>&nbsp;<a href="https://www.michaelwebb.co/webb_ai.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">studies</a>. As a control group, they considered jobs affected by software generally (“recording, storing, and producing information, and executing programs, logic, and rules”), as detailed in one of the studies. They measured changes in employment and wages in those jobs based on a&nbsp;<a href="https://ec.europa.eu/eurostat/web/microdata/european-union-labour-force-survey?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">survey</a>&nbsp;of workers in 16 European countries between 2011 and 2019.</p><p><strong>Results:&nbsp;</strong>The researchers found that exposure to AI was associated with greater employment for some workers and had little effect on wages.&nbsp;</p><ul><li>Employment of high-education workers rose in jobs affected by AI. This result argues against the hypothesis that AI displaces high-skilled occupations.&nbsp;</li><li>Employment also rose among younger workers in jobs affected by AI.</li><li>Employment and wages among low-education workers and older workers fell in jobs affected by software. This effect was far less pronounced in jobs affected by AI.&nbsp;</li><li>Wages barely changed in jobs affected by AI. Wages fell slightly by one of the three metrics they considered.</li></ul><p><strong>Behind the news:</strong>&nbsp;Other studies suggest that automation in general and AI technology in particular may benefit the workforce as a whole.</p><ul><li>The United States Bureau of Labor Statistics&nbsp;<a href="https://www.deeplearning.ai/the-batch/employment-has-risen-in-some-automation-heavy-professions/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">found</a>&nbsp;that employment in the U.S. in 11 occupations most exposed to AI, such as translators, personal financial advisers, and fast-food workers, grew by 13.6 percent between 2008 and 2018.</li><li>Economic research in France, the UK, and Japan&nbsp;<a href="https://www.deeplearning.ai/the-batch/robots-dont-want-human-jobs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">suggests</a>&nbsp;that industrial automation correlates with increased employment and higher wages.</li></ul><p><strong>Yes, but:</strong>&nbsp;It may be too soon to get a clear view of AI’s impact on employment, the authors point out. The data that underlies every study to date ends in 2019, predating ChatGPT and the present wave of generative AI. Furthermore, the impact of AI in European countries varies with their individual economic conditions (for instance, Greece tends to lose more jobs than Germany).</p><p><strong>Why it matters:</strong>&nbsp;Many employees fear that AI — and generative AI in particular — will take their jobs. Around the world, the public is&nbsp;<a href="https://www.ipsos.com/sites/default/files/ct/news/documents/2022-01/Global-opinions-and-expectations-about-AI-2022.pdf?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">nervous</a>&nbsp;about the technology’s potential impact on employment. Follow-up studies using more recent data could turn these fears into more realistic — and more productive — appraisals.</p><p><strong>We’re thinking:</strong>&nbsp;AI is likely to take some jobs. We feel deeply for workers whose livelihoods are affected, and society has a responsibility to create a safety net to help them. To date, at least, the impact has been less than many observers feared. One reason may be that jobs are made up of many tasks, and AI automates tasks rather than jobs. In many jobs, AI can automate a subset of the work while the jobs continue to be filled by humans, who may earn a higher wage if AI helps them be more productive.&nbsp;</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/automated-testing-llmops?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners---2024-01-23T083847.050.png" width="1680" /></a></figure><p>Automated testing of applications based on large language models can save significant development time and cost. In this course, you’ll learn to build a continuous-integration pipeline to evaluate LLM-based apps at every change and fix bugs early for efficient, cost-effective development.&nbsp;<a href="https://www.deeplearning.ai/short-courses/automated-testing-llmops?ref=dl-staging-website.ghost.io" rel="noreferrer">Enroll for free</a>&nbsp;&nbsp;</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-24T145859.354.gif" width="1200" /></figure><h1 id="sovereign-ai">Sovereign AI</h1><p>Governments want access to AI chips and software built in their own countries, and they are shelling out billions of dollars to make it happen.<br /><br /><strong>What’s new:</strong>&nbsp;Nations across the world are supporting homegrown AI processing and development,&nbsp;<em>The Economist</em>&nbsp;<a href="https://www.economist.com/business/2024/01/01/welcome-to-the-era-of-ai-nationalism?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">reported</a>.<br /><br /><strong>How it works:&nbsp;</strong>Governments want AI they can rely upon for state use. The U.S. and China each promised to invest around $40 billion in the field in 2023. Another 6 countries — France, Germany, India, Saudi Arabia, the UAE, and the UK — pledged a combined $40 billion. Different governments are emphasizing different capabilities.</p><ul><li>The U.S., home to tech powers like Amazon, Google, Microsoft, and OpenAI, has left the software sector largely to its own devices. However, the federal government has&nbsp;<a href="https://www.nytimes.com/2023/01/01/technology/us-chip-making-china-invest.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">subsidized</a>&nbsp;the semiconductor industry with a five-year commitment to spend $50 billion on new factories and devoted much smaller amounts to research.</li><li>China also seeks to bolster its semiconductor industry, especially in the face of U.S. export&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-blocks-ai-chip-sales-to-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">restrictions</a>&nbsp;on AI chips. The government&nbsp;<a href="https://www.digitimes.com/news/a20230627VL205/china-ic-manufacturing-semiconductor-chips+components.htm?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">spent</a>&nbsp;$300 billion between 2021 and 2022 trying to build a domestic chip manufacturing industry. In addition, the state cracked down on some tech areas (such as video games) to redirect economic resources toward higher-priority areas, established data exchanges where businesses can make data available for AI development, and created&nbsp;<a href="https://cset.georgetown.edu/publication/understanding-chinese-government-guidance-funds/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">public-private partnerships<u>&nbsp;</u></a>that support development of advanced technology.</li><li>Saudi Arabia and the UAE are buying up GPUs and investing in universities like Abu Dhabi’s Mohamed bin Zayed University of Artificial Intelligence and Thuwal’s King Abdullah University of Science and Technology to attract global engineering talent. The UAE plans to make available national datasets in sectors like health and education to local startups such as&nbsp;<a href="https://ai71.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">AI71</a>.&nbsp;</li><li>France, Germany, India, and the UK are supporting their own AI startups. France provides public data for AI development. India is courting cloud-computing providers to build data centers in the country and considering a $1.2 billion investment in GPUs.</li></ul><p><strong>Behind the news:&nbsp;</strong>Even as governments move toward AI independence, many are attempting to influence international politics and trade to bolster their positions.</p><ul><li>As EU lawmakers&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">negotiated</a>&nbsp;the final details of the AI Act, France, Germany, and Italy managed to relax the Act’s restrictions on foundation models. These countries worry that strong restrictions would hamper domestic developers such as France’s Mistral and Germany’s Aleph Alpha and stifle innovation and open source more broadly.</li><li>In September 2022, the U.S. government&nbsp;<a href="https://www.deeplearning.ai/the-batch/gpu-china/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">blocked</a>&nbsp;exports of advanced GPUs and chip-making equipment to most Chinese customers. The sanctions threaten even non-U.S. companies that try to circumvent the restrictions. Consequently, in December, the UAE-based AI developer G42&nbsp;<a href="https://www.theinformation.com/briefings/uae-tech-firm-g42-tries-to-distance-itself-from-china?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">cut</a>&nbsp;ties with Chinese equipment suppliers. Earlier, the U.S. had&nbsp;<a href="https://www.reuters.com/technology/us-restricts-exports-some-nvidia-chips-middle-east-countries-filing-2023-08-30/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">extended</a>&nbsp;the restrictions to some Middle Eastern countries including the UAE and Saudi Arabia.</li></ul><p><strong>Why it matters:&nbsp;</strong>AI has emerged as an important arena for international competition,&nbsp;reshaping global society and economics, generating economic growth, and affecting national security. For engineers, the competition means that governments are competing to attract talent and investment, but they’re also less inclined to share technology across borders.<br /><br /><strong>We’re thinking:&nbsp;</strong>We understand governments’ desires to ensure access to reliable AI, but focusing on sovereignty above all is misguided. In a networked world, developments can’t be contained to one country. Cooperation ensures that development proceeds at a rapid pace and benefits everyone.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--94-.png" width="1200" /></figure><h1 id="learning-the-language-of-geometry">Learning the Language of Geometry</h1><p>Machine learning algorithms often struggle with geometry. A language model learned to prove relatively difficult theorems.&nbsp;</p><p><strong>What's new:&nbsp;</strong>Trieu Trinh, Yuhuai Wu, Quoc Le, and colleagues at Google and New York University proposed&nbsp;<a href="https://www.nature.com/articles/s41586-023-06747-5?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">AlphaGeometry</a>, a system that can prove geometry theorems almost as well as the most accomplished high school students. The authors focused on non-combinatorial Euclidean plane geometry.&nbsp;</p><p><strong>How it works:</strong>&nbsp;AlphaGeometry has two components. (i) Given a geometrical premise and an unproven proposition, an off-the-shelf&nbsp;<a href="https://link.springer.com/article/10.1023/A:1006171315513?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">geometric proof finder</a>&nbsp;derived statements that followed from the premise. The authors modified the proof finder to deduce proofs from not only geometric concepts but also algebraic concepts such as ratios, angles, and distances. (ii) A transformer learned to read and write proofs in the proof finder’s specialized language.</p><ul><li>The authors generated a synthetic dataset of 100 million geometric premises, propositions, and their proofs. For instance, given the premise, “Let ABC be any triangle with AB = AC” (an isosceles triangle) and the proposition “∠ABC = ∠BCA,” the proof involves constructing a line between A and the midpoint between B and C. The authors translated these problems into the proof finder’s language. They pretrained the transformer, given a premise and proposition, to generate the proof.&nbsp;</li><li>The authors modified 9 million proofs in the dataset to remove references to some lines, shapes, or points from premises. Instead, they introduced these elements in statements of the related proofs. They fine-tuned the transformer, given a modified premise, the proposition, and the proof up to that point, to generate the added elements.</li><li>At inference, given a premise and proposition, the proof finder added statements. If it failed to produce the proposition, the system fed the statements so far to the transformer, which predicted a point, shape, or line that might be helpful in deducing the next statement. Then it gave the premise, proposition, and proof so far — including the new element — to the proof finder. The system repeated the process until the proof finder produced the proposition.</li></ul><p><strong>Results:</strong>&nbsp;The authors tested AlphaGeometry on 30 problems posed by the International Mathematical Olympiad, an annual competition for high school students. Comparing that score to human performance isn’t so straightforward because human competitors can receive partial credit. Human gold medalists since 2000 solved 25.9 problems correctly, silver medalists solved 22.9 problems, and bronze medalists solved 19.3 problems. The&nbsp;<a href="https://www.worldscientific.com/doi/10.1142/9789812791085_0008?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">previous state-of-the-art approach</a>&nbsp;solved 10 problems, and the modified proof finder solved 14 problems. In one instance, the system identified an unused premise and found a more generalized proof than required, effectively solving many similar problems at once.&nbsp;</p><p><strong>Why it matters:</strong>&nbsp;Existing AI systems can juggle symbols and follow simple rules of deduction, but they struggle with steps that human mathematicians represent visually by, say, drawing a diagram. It’s possible to make up this deficit by (i) alternating between a large language model (LLM) and a proof finder, (ii) combining geometric and algebraic reasoning, and (ii) training the LLM on a large data set. The result is a breakthrough for geometric problem solving.</p><p><strong>We're thinking:</strong>&nbsp;In 1993, the teenaged Andrew Ng represented Singapore in the International Mathematics Olympiad, where he&nbsp;<a href="https://www.imo-official.org/participant_r.aspx?id=3444&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--RkkzWCPrBmuh9NVI-bYNqrsXRmAT-YaZPJ1dtehWVcy_vEf9eASvXIDg_sxgmyWQI4kiP" rel="noopener">won</a>&nbsp;a silver medal. AI’s recent progress in solving hard problems is a sine of the times!&nbsp;</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/tag/data-points/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>This week's latest updates include an affordable reinforcement-learning-powered robot, exciting AI features in Samsung’s new smartphone series, an improved model for code completion from Stability AI, and much more. Catch up with the help of Data Points, a spin-off of The Batch.</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-233/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now.</a></p>
]]></content:encoded>
<pubDate>Wed, 24 Jan 2024 20:03:06 GMT</pubDate>
</item>
<item>
<title>AI Invades Consumer Products, OpenAI’s Platform Play, Watermarks for Synthetic Media, Generated Musical Accompaniments</title>
<link>https://www.deeplearning.ai/the-batch/issue-232</link>
<guid>https://www.deeplearning.ai/the-batch/issue-232</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,</em></p><p><em>As I wrote in an earlier&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/can-an-ai-system-be-sentient-ask-a-philosopher/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener"><em>letter</em></a><em>, whether AI is sentient or conscious is a philosophical question rather than a scientific one, since there is no widely agreed-upon definition and test for these terms. While it is tempting to “solve” this problem by coming up with precise definitions and well defined tests for whether a system meets them, I worry that poor execution will lead to premature declarations of AI achieving such criteria and generate unnecessary hype.&nbsp;</em></p><p><em>Take the concept of self-awareness, which refers to a conscious knowledge of one's own self. Suppose we define a robot as self-aware if it can recognize itself in the mirror, which seems a natural way to test a robot’s awareness of itself. Given this definition — and that it’s not very hard to build a robot that recognizes itself — we would be well on a path to hype about how AI was now self-aware.&nbsp;<br /><br />This example isn’t a prediction about the future. It actually happened about 10 years ago, when many media sources breathlessly&nbsp;</em><a href="https://spectrum.ieee.org/qbo-passes-mirror-test-is-therefore-selfaware?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener"><em>reported</em></a><em>&nbsp;that a robot “Passes Mirror Test, Is Therefore Self-Aware &nbsp;… conclusively proving that robots are intelligent and self-aware.”&nbsp;</em></p><p><em>While bringing clarity to ambiguous definitions is one way for science to make progress, the practical challenge is that many people already have beliefs about what it means for something to be self-aware, sentient, conscious, or have a soul. There isn’t widespread agreement on these terms. For example, do all living things have souls? How about a bacterium or virus?</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="685" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--90--1.png" width="1200" /></figure><p><em>So even if someone comes up with a reasonable new scientific definition, many people — unaware of the new definition — will still understand the term based on their earlier understanding. Then, when media outlets start talking about how AI has met the definition, people won’t recognize that the hype refers to a narrow objective (like a robot recognizing itself in the mirror). Instead, they’ll think that AI accomplished what they generally associate with words like sentience.&nbsp;</em></p><p><em>Because of this, I have mixed feelings about attempts to come up with new definitions of artificial general intelligence (AGI). I believe that most people, including me, currently think of AGI as AI that can carry out any intellectual task that a human can. With this definition, I think we’re still at least decades away from AGI. This creates a temptation to define it using a lower bar, which would make it easier to declare success: The easiest way to achieve AGI might be to redefine what the term means!&nbsp;</em></p><p><em>Should we work to clarify the meanings of ambiguous terms that relate to intelligence? In some cases, developing a careful definition and getting widespread agreement behind it could set a clear milestone for AI and help move the field forward. But in other cases, I’m satisfied to avoid the risk of unnecessary hype and leave it to the philosophers.<br /><br />Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. LLMOps is a rapidly developing field that takes ideas from MLOps (machine learning operations) and specializes them for building and deploying LLM-based applications. In our new course, “LLMOps,” taught by Google Cloud’s Erwin Huizenga, you’ll learn how to use automation and experiment tracking to speed up development. Specifically, you’ll develop an LLMOps pipeline to automate LLM fine-tuning. By building a tuning pipeline and tracking the experiment artifacts — including the parameters, inputs, outputs, and experimental results — you can reduce manual steps in the development process, resulting in a more efficient workflow. Sign up&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/llmops?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener"><em>here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-17T145508.969.gif" width="1200" /></figure><h1 id="ai-busts-out-at-ces">AI Busts Out at CES</h1><p>The 2024 Consumer Electronics Show in Las Vegas showcased products that take advantage of increasingly powerful, increasingly accessible AI capabilities.</p><p><strong>What’s new:</strong>&nbsp;Many debuts at the&nbsp;<a href="https://exhibitors.ces.tech/8_0/explore/exhibitor-gallery.cfm?featured=false&amp;categories=1%7C191&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">massive</a>&nbsp;CES show showed that large language models (LLMs) are moving beyond browsers and smartphones.</p><p><strong>Best of show:</strong> The show’s surprise hit was a portable personal assistant. LLM-powered automobile dashboards and an AI accelerator card also stood out.&nbsp;</p><ul><li>Rabbit’s&nbsp;<a href="https://www.wired.com/story/rabbit-r1/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">R1</a>&nbsp;($199, cellular service required) is among a new wave of AI-optimized hardware devices, including the&nbsp;<a href="https://hu.ma.ne/aipin?gclid=CjwKCAiA75itBhA6EiwAkho9e2yQ4lfLLoVld96ya-rMdIrn5zNbdhLf58EmafUVsXTk_VDP89LunBoC5I8QAvD_BwE&amp;utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Humane AI Pin</a>,&nbsp;<a href="https://www.transcribeglass.com/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h#/" rel="noopener">TranscribeGlass</a>&nbsp;voice transcription display, and&nbsp;<a href="https://www.timekettle.co/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Timekettle</a>&nbsp;language translators, that seek to usurp smartphone capabilities. The R1 accepts voice commands to play music, call a car, order food, reserve flights, and the like by interacting with services like Spotify and Uber. The hand-held unit houses a touchscreen, camera, wheel-and-button controller, and cellular modem. It uses a proprietary “large action model” based on attention and graph neural networks; the model learns by mimicking how people use web interfaces and runs in the cloud to translate voice commands into actions via a web portal. The R1 will be available in March and has already sold out through June. A future update will enable users to teach the device new skills, like editing images or playing video games, by demonstrating them in view of the camera.&nbsp;</li><li><a href="https://www.volkswagen-newsroom.com/en/press-releases/world-premiere-at-ces-volkswagen-integrates-chatgpt-into-its-vehicles-18048?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Volkswagen</a>&nbsp;and&nbsp;<a href="https://www.theverge.com/2024/1/9/24028012/mercedes-benz-mbux-voice-assistant-ai-llm-mbos-ces?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Mercedes Benz</a>&nbsp;demonstrated dashboard voice assistants equipped with large language models. Along with the usual navigation and entertainment, the new consoles deliver personalized information like nearby service stations or restaurants. Powered by OpenAI and automotive AI developer Cerence, Volkswagen’s system will be standard in most vehicles beginning in the spring. Mercedes’ MB.OS will be available next year.</li><li>Taiwanese startup&nbsp;<a href="https://neuchips.ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Neuchips</a>&nbsp;displayed an add-in board that enables desktop computers to run large language models like the 7 billion-parameter version of Llama 2. The Evo PCIe AI accelerator is optimized for transformer networks to provide comparable performance to GPUs while consuming less electricity (55 watts versus an Nvidia RTX 4080’s 320 watts). The card will be available later this year at an undisclosed price. Versions outfitted with four or more chips are on the company’s roadmap.</li></ul><p><strong>Why it matters:</strong>&nbsp;Flashy CES demos often mask underdeveloped products and vaporware. But this year, AI for processing voice, text, and images is mature enough to enable product designers to focus on everyday use cases and intuitive user experiences. While some of this year’s AI-powered debuts seemed like overkill — for instance, the computer vision-equipped&nbsp;<a href="https://www.flappie.ch/en/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Flappie</a>&nbsp;cat door that won’t open while your pet has a mouse in its jaws — others suggest that startups and giants alike are rethinking the technology’s capacity to simplify and enhance daily life and work.</p><p><strong>We’re thinking:</strong>&nbsp;Not long ago, simply connecting a home appliance to the internet earned the designation “smart.” Increasingly, AI is making that label credible.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-17T145556.800.gif" width="600" /></figure><h1 id="openai-expands-platform-play">OpenAI Expands Platform Play</h1><p>The GPT Store is open for business, providing curated, searchable access to millions of chatbots tailored for specific purposes.</p><p><strong>What’s new:</strong>&nbsp;OpenAI&nbsp;<a href="https://openai.com/blog/introducing-the-gpt-store?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">launched</a>&nbsp;the GPT Store for paid ChatGPT accounts, making it far easier to find useful GPTs (instances of ChatGPT conditioned by user-submitted prompts). The store lets subscribers browse by category, search by keywords, and create their own chatbots. The company introduced GPTs in November as a free offering without search or curation.</p><p><strong>How it works:</strong>&nbsp;Access to the store is rolling out in phases and isn’t yet available to all subscribers as of this writing.&nbsp;</p><ul><li>The store organizes GPTs in categories such as education, productivity, and programming as well as those that prompt the DALL·E image generator. It also highlights “featured” and “trending” GPTs and branded offerings from companies like&nbsp;<a href="https://chatgpt-4.fyi/alltrails-gpt-outdoor-adventure-planning-on-a-new-level-2024/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">AllTrails</a>&nbsp;(hiking/running routes and advice),&nbsp;<a href="https://chat.openai.com/g/g-alKfVrz9K-canva?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Canva</a>&nbsp;(graphic design), and&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-chatbot-search-engines-for-scientific-research/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Consensus</a>&nbsp;(scientific literature search).&nbsp;</li><li>Users can create GPTs by selecting the editor and prompting ChatGPT with instructions for chatbot’s function and what information it can access; for example, “Make an app that creates an auction listing for an uploaded photo of any item.” The system asks follow-up questions to refine the GPT’s scope, likely users, and the like. Completed GPTs can be listed publicly in the store directory.</li><li>OpenAI plans to launch a revenue sharing program to reward creators of popular GPTs. Further details are not yet available.</li></ul><p><strong>Why it matters:</strong>&nbsp;The GPT Store strengthens ChatGPT’s utility as a platform for others to build upon and seems designed to drive paid subscriptions. It enables developers to share applications based on OpenAI’s technology and holds out hope that they’ll be rewarded for their effort.&nbsp;<br /><br /><strong>We’re thinking:</strong>&nbsp;The GPT concept enables anyone, even without a background in coding, to build and share powerful applications quickly and easily. The current implementation seems like a toe in the water. If it proves popular, it could significantly deepen OpenAI’s moat, as the Apple and Android stores have done for Apple and Google respectively.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/llmops?ref=dl-staging-website.ghost.io"><img alt="" class="kg-image" height="945" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners---2024-01-16T090702.307.png" width="1680" /></a></figure><p>Learn about machine learning operations for large language models (LLMOps) in our new short course, built in collaboration with Google Cloud. Explore the LLMOps pipeline for pre-processing data, fine-tuning LLMs, and deploying custom LLMs tailored to your applications.&nbsp;<a href="https://www.deeplearning.ai/short-courses/llmops/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Enroll now</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-17T145821.116.gif" width="600" /></figure><h1 id="standard-for-media-watermarks">Standard for Media Watermarks</h1><p>An alliance of major tech and media companies introduced a watermark designed to distinguish real from fake media starting with images.</p><p><strong>What’s new:&nbsp;</strong>The&nbsp;<a href="https://c2pa.org/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Coalition for Content Provenance and Authenticity</a>&nbsp;(C2PA)&nbsp;offers an open standard that marks media files with information about their creation and editing. C2PA’s 30 members, including both tech powers (Adobe, Google, Intel, Microsoft, X) and media outlets (BBC, CBC,&nbsp;<em>The New York Times</em>) will deploy the standard in the coming year,&nbsp;<em>IEEE Spectrum</em>&nbsp;<a href="https://spectrum.ieee.org/deepfakes-election?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">reported</a>.</p><p><strong>How it works:&nbsp;</strong>The C2PA’s&nbsp;<a href="https://c2pa.org/specifications/specifications/1.4/specs/C2PA_Specification.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Content Credentials</a>&nbsp;specification accommodates a variety of file types, but currently it’s implemented mainly for images.</p><ul><li>When a C2PA-compliant image generator or editor produces an image, it invisibly embeds a cryptographic watermark that contains the following metadata: the user or device that initially created the image, when and how it was created, and how it was edited or otherwise transformed. (Actions using non-compliant tools are not recorded.)</li><li>Images can display a small “cr” icon in the corner. Clicking on the icon reveals the metadata.</li><li>Any alteration of the file or any attempt to tamper with it will cause a mismatch between the watermark and its associated metadata.</li><li>Social media recommenders and image search algorithms can use the metadata to identify, restrict, or promote certain types of media.</li></ul><p><strong>Who’s using it:</strong>&nbsp;Image generators from Adobe and Microsoft stamp their outputs with Content Credential watermarks, marking them as synthetic; Microsoft also&nbsp;<a href="https://blogs.microsoft.com/on-the-issues/2023/11/07/microsoft-elections-2024-ai-voting-mtac/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">promotes</a>&nbsp;watermarking by political campaigns to help voters differentiate synthetic from non-generated campaign messages. Camera manufacturers Canon,&nbsp;<a href="https://spectrum.ieee.org/leica-camera-content-credentials?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Leica</a>, and Nikon have built prototype cameras that use Content Credentials to mark the origin of photographs. BBC is using the technology to mark images on its website on a trial basis, and Canada’s CBC plans to deploy it in mid-2024.</p><p><strong>Yes, but:&nbsp;</strong>It may be difficult to fake Content Credentials, but it’s easy to&nbsp;<a href="https://www.timboucher.ca/2023/03/remove-adobe-firefly-watermark-content-credentials/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">remove</a>&nbsp;the watermark from images, even from AI-generated ones. Using a Content Credentials-compliant tool like Photoshop, you can disable Content Credentials and save a watermarked image to a different format. This produces an identical image without the watermark.</p><p><strong>Behind the news:&nbsp;</strong>The C2PA unites the Content Authenticity Initiative (led by Adobe) and Project Origin (led by media companies). Nonetheless, the field remains fragmented. For instance, Meta (not a C2PA member) has aimed to identify AI-generated media using detection software. However, C2PA argues that detectors aren’t sufficiently effective; the winner of a Meta deepfake-detection challenge identified generated content only&nbsp;<a href="https://ai.meta.com/blog/deepfake-detection-challenge-results-an-open-initiative-to-advance-ai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">65 percent</a>&nbsp;of the time. Top AI companies&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-firms-agree-to-voluntary-guidelines/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">committed</a>&nbsp;to developing their own watermarking mechanisms, but they haven’t settled on Content Credentials or another standard.&nbsp;</p><p><strong>Why it matters:&nbsp;</strong>Distinguishing generated text, imagery, and audio from media that accurately depicts real-world events is a key challenge for the generative AI era. The coming year will test that ability as 78 countries gear up elections that will affect roughly half the world’s population. Already, campaigns have used generated imagery in&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-generated-imagery-flooded-argentinas-presidential-race/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Argentina</a>,&nbsp;<a href="https://www.stuff.co.nz/national/politics/132123637/national-using-ai-for-attack-ads-the-ai-political-campaign-has-arrived?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">New Zealand</a>,&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-for-president/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">South Korea</a>, the&nbsp;<a href="https://www.deeplearning.ai/the-batch/us-republicans-released-the-first-ai-generated-attack-ad/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">United States</a>, and other nations.&nbsp;<a href="https://www.deeplearning.ai/the-batch/google-tightens-restrictions-on-ai-made-political-ads/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Google</a>&nbsp;and&nbsp;<a href="https://www.theverge.com/2023/11/8/23951346/meta-political-ads-ai-artificial-intelligence-advertising?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">Meta</a>&nbsp;responded by tightening restrictions on political advertisers’ use of generative AI. The EU’s AI Act will&nbsp;<a href="https://www.deeplearning.ai/the-batch/the-ai-act-moves-closer-to-approval/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">require</a>&nbsp;clear labeling of AI-generated media, and the U.S. Federal Election Commission plans to&nbsp;<a href="https://apnews.com/article/fec-artificial-intelligence-deepfakes-election-2024-95399e640bd1e41182f6c631717cc826?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">restrict</a>&nbsp;ads that depict political opponents saying or doing things they did not actually say or do. If Content Credentials proves effective in the coming election season, it may ease the larger problem of identifying generated media in a variety of venues where authenticity is important.</p><p><strong>We’re thinking:</strong>&nbsp;A robust watermark can identify both traditional and AI-generated media for users and algorithms to treat accordingly. It can also potentially settle claims that a doctored image was authentic or that authentic work was doctored. However, we worry that watermarking generated outputs may prove to be a&nbsp;<a href="https://www.deeplearning.ai/the-batch/watermarking-is-a-no-go?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">disadvantage in the market</a>, creating a disincentive for makers of software tools to provide it and users to use it. With heavyweight members from both tech and media, C2PA may be able to build sufficient momentum behind the watermarking to make it stick.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--91-.png" width="1200" /></figure><h1 id="sing-a-tune-generate-an-accompaniment">Sing a Tune, Generate an Accompaniment</h1><p>A neural network makes music for unaccompanied vocal tracks.</p><p><strong>What's new:</strong>&nbsp;Chris Donahue, Antoine Caillon, Adam Roberts, and colleagues at Google proposed&nbsp;<a href="https://arxiv.org/abs/2301.12662?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">SingSong</a>, a system that generates musical accompaniments for sung melodies. You can listen to its output&nbsp;<a href="https://storage.googleapis.com/sing-song/index.html?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">here</a>.</p><p><strong>Key insight:</strong>&nbsp;To train a machine learning model on the relationship between singers’ voices and the accompanying instruments, you need a dataset of music recordings with corresponding isolated voices and instrumental accompaniments. Neural demixing tools can separate vocals from music, but they tend to leave remnants of instruments in the resulting vocal track. A model trained on such tracks may learn to generate an accompaniment based on the remnants, not the voice. Then, given a pure vocal track, it can’t produce a coherent accompaniment. One way to address this issue is to add noise to the isolated voices. The noise drowns out the instrumental remnants and forces the model to learn from the voices.</p><p><strong>How it works:&nbsp;</strong>The authors based their approach on&nbsp;<a href="https://arxiv.org/abs/2209.03143?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">AudioLM</a>, a system that generates audio by attending to both small- and large-scale features.&nbsp;</p><ul><li>The authors built a dataset of 1 million recordings that totaled 46,000 hours of music. They separated the recordings into voices and instrumental accompaniments using a pretrained&nbsp;<a href="https://arxiv.org/abs/2111.12203?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">MDXNet</a>&nbsp;and divided the recordings into 10-second clips of matching isolated vocal and instrumental tracks. They added noise to the vocal tracks.</li><li>Following AudioLM and its successor&nbsp;<a href="https://www.deeplearning.ai/the-batch/google-introduces-an-ai-that-generates-music-from-text/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">MusicLM</a>, the authors tokenized the instrumental tracks at two time scales to represent large-scale compositional features and moment-to-moment details. A&nbsp;<a href="https://arxiv.org/abs/2108.06209?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">w2v-BERT</a>&nbsp;pretrained on speech plus the authors’ initial dataset produced 25 tokens per second. A SoundStream audio encoder-decoder pretrained on&nbsp;<a href="https://arxiv.org/abs/1904.02882?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">speech</a>,&nbsp;<a href="https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">music</a>, and the authors’ initial dataset produced 200 tokens per second.</li><li>To represent the noisy vocal tracks, they produced 25 tokens per second using the w2vBERT.</li><li>They trained a&nbsp;<a href="https://arxiv.org/abs/1910.10683?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">T5</a>&nbsp;transformer, given vocal tokens, to generate the corresponding instrumental tokens.&nbsp;</li><li>Given the instrumental tokens, a separate transformer learned to generate tokens for SoundStream’s decoder to reconstruct the instrumental audio.&nbsp;</li><li>To generate an instrumental track, the authors fed tokens produced by the transformer to SoundStream’s decoder.</li></ul><p><strong>Results:</strong>&nbsp;Listeners compared 10-second clips from the test set of&nbsp;<a href="https://zenodo.org/record/1117372?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz-_4zfBvV84quJyYowB_7sImvE4t7Wffz-45FHrPoTz2URuxI_3N0s5Ws1yVPgIbfLJR1T6h" rel="noopener">MUSDB18</a>, a dataset that contains 10 hours of isolated vocal and instrumental tracks. Each clip came in multiple versions that paired the original vocal with accompaniment supplied by (i) SingSong, (ii) a random instrumental track from MUSDB18’s training set, (iii) the instrumental track from MUSDB18’s training set most similar to the vocal in key and tempo according to tools in the Madmom library, and (iv) the original instrumental track. The listeners preferred SingSong to the random accompaniment 74 percent of the time, to the most similar accompaniment 66 percent of the time, and to the original instrumental track 34 percent of the time.</p><p><strong>Why it matters:&nbsp;</strong>The authors used data augmentation in an unusual way that enabled them to build a training dataset for a novel, valuable task. Typically, machine learning practitioners add noise to training data to stop a model from memorizing individual examples. In this case, the noise stopped the model from learning from artifacts in the data.</p><p><strong>We’re thinking:&nbsp;</strong>&nbsp;Did you always want to sing but had no one to play along with you? Now you can duet yourself.</p><hr /><h1 id="data-points"><a href="https://www.deeplearning.ai/the-batch/data-points-issue-232/?ref=dl-staging-website.ghost.io" rel="noreferrer">Data Points</a></h1><p>From new marketplace rules for video games to car companies integrating generative AI into their products, dive into more top news, curated and summarized for you on Data Points, a spin-off of The Batch:&nbsp;&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-232/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read now here.</a></p>
]]></content:encoded>
<pubDate>Wed, 17 Jan 2024 20:05:06 GMT</pubDate>
</item>
<item>
<title>AI Discovers New Antibiotics, OpenAI Revamps Safety, Researchers Define AGI, LLMs Go Multimodal</title>
<link>https://www.deeplearning.ai/the-batch/issue-231</link>
<guid>https://www.deeplearning.ai/the-batch/issue-231</guid>
<content:encoded><![CDATA[
<p><em>Dear friends,&nbsp;</em></p><p><em>It is only rarely that, after reading a research paper, I feel like giving the authors a standing ovation. But I felt that way after finishing&nbsp;</em><a href="https://arxiv.org/abs/2305.18290?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>Direct Preference Optimization</em></a><em>&nbsp;(DPO) by Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Chris Manning, and Chelsea Finn. (I didn't actually stand up and clap, since I was in a crowded coffee shop when I read it and would have gotten weird looks!</em>&nbsp;😀<em>)</em></p><p><em>This beautiful work proposes a much simpler alternative to RLHF (reinforcement learning from human feedback) for aligning language models to human preferences. Further, people often ask if universities — which don't have the massive compute resources of big tech — can still do cutting-edge research on large language models (LLMs). The answer, to me, is obviously yes! This article is a beautiful example of algorithmic and mathematical insight arrived at by an academic group thinking deeply.&nbsp;<br /><br />RLHF became a key algorithm for LLM training thanks to the&nbsp;</em><a href="https://www.deeplearning.ai/the-batch/a-kinder-gentler-language-model/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>InstructGPT</em></a><em>&nbsp;paper, which adapted the technique to that purpose. A typical implementation of the algorithm works as follows:&nbsp;</em></p><ul><li><em>Get humans to compare pairs of LLM outputs, generated in response to the same prompt, to specify which one they prefer. For example, humans typically prefer the more helpful, less toxic output.</em></li><li><em>Use the human preferences to learn a reward function. The reward function, typically represented using a transformer network, is trained to give a higher reward (or score) to the outputs that the humans preferred.</em></li><li><em>Finally, using the learned reward, run a reinforcement learning algorithm to tune the LLM to (i) maximize the reward of the answers generated, while (ii) not letting the LLM change too much (as a form of regularization).</em></li></ul><p><em>This is a relatively complex algorithm. It needs to separately represent a reward function and an LLM. Also, the final, reinforcement learning step is well known to be finicky to the choice of hyperparameters.</em></p><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="1125" src="https://dl-staging-website.ghost.io/content/images/2024/01/The-Batch-ads-and-exclusive-banners--99-.png" width="2000" /></figure><p><em>DPO dramatically simplifies the whole thing. Rather than needing separate transformer networks to represent a reward function and an LLM, the authors show how, given an LLM, you can figure out the reward function (plus regularization term) that that LLM is best at maximizing. This collapses the two transformer networks into one. Thus, you now need to train only the LLM and no longer have to deal with a separately trained reward function. The DPO algorithm trains the LLM directly, so as to make the reward function (which is implicitly defined by the LLM) consistent with the human preferences. Further, the authors show that DPO is better at achieving RLHF's optimization objective (that is, (i) and (ii) above) than most implementations of RLHF itself.&nbsp;</em></p><p><em>RLHF is a key building block of the most advanced LLMs. It’s fantastic that these Stanford authors — through clever thinking and mathematical insight — seem to have replaced it with something simpler and more elegant. While it's easy to get excited about a piece of research before it has stood the test of time, I am cautiously optimistic that DPO will have a huge impact on LLMs and beyond in the next few years. Indeed, it is already making its way into some top-performing models, such as Mistral’s&nbsp;</em><a href="https://mistral.ai/news/mixtral-of-experts?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>Mixtral</em></a><em>.&nbsp;&nbsp;</em></p><p><em>That we can replace such fundamental building blocks of LLMs is a sign that the field is still new and much innovation lies ahead. Also, while it's always nice to have massive numbers of NVIDIA H100 or AMD MI300X GPUs, this work is another illustration — out of many, I want to emphasize — that deep thinking with only modest computational resources can carry you far.&nbsp;</em></p><p><em>A few weeks ago at NeurIPS (where DPO was published), I found it remarkable both (i) how much highly innovative research there is coming out of academic labs, independent labs, and companies small and large, and (ii) how much our media landscape skews attention toward work published by the big tech companies. I suspect that if DPO had been published by one of the big LLM companies, it would have made a huge PR splash and been announced as a massive breakthrough. Let us all, as builders of AI systems, make sure we recognize the breakthroughs wherever they occur.</em></p><p><em>Keep learning!</em></p><p><em>Andrew</em></p><p><em>P.S. We just launched our first short course that uses JavaScript! In ​​“Build LLM Apps with LangChain.js,” taught by LangChain’s founding engineer Jacob Lee, you’ll learn many steps that are common in AI development, including how to use (i) data loaders to pull data from common sources such as PDFs, websites, and databases; (ii) different models to write applications that are not vendor-specific; and (iii) parsers that extract and format the output for your downstream code to process. You’ll also use the LangChain Expression Language (LCEL), which makes it easy to compose chains of modules to perform complex tasks. Putting it all together, you’ll build a conversational question-answering LLM application capable of using external data as context. Please sign up&nbsp;</em><a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener"><em>here</em></a><em>!</em></p><p></p><h1 id="news">News</h1><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="675" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--89-.png" width="1200" /></figure><h1 id="deep-learning-discovers-antibiotics">Deep Learning Discovers Antibiotics</h1><p>Biologists used neural networks to find a new class of antibiotics.</p><p><strong>What’s new:&nbsp;</strong>Researchers at MIT and Harvard&nbsp;<a href="https://www.nature.com/articles/s41586-023-06887-8?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">trained</a>&nbsp;models to screen chemical compounds for those that kill methicillin-resistant&nbsp;<em>Staphylococcus aureus</em>&nbsp;(MRSA), the deadliest among bacteria that have evolved to be invulnerable to common antibiotics, and aren’t toxic to humans.&nbsp;</p><p><strong>How it works:</strong>&nbsp;The authors built a training set of 39,312 compounds including most known antibiotics and a diverse selection of other molecules. In a lab, they tested each compound for its ability to inhibit growth of MRSA and its toxicity to human liver, skeletal muscle, and lung cells. Using the resulting data, they trained four ensembles of 20 graph neural networks each to classify compounds for (i) antibiotic properties, (ii) toxicity to the liver, (iii) toxicity to skeletal muscles, and (iv) toxicity to the lungs.&nbsp;</p><ul><li>They ran their four ensembles on 12 million compounds from the&nbsp;<a href="https://mcule.com/database/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Mcule</a>&nbsp;database and a Broad Institute&nbsp;<a href="https://github.com/felixjwong/antibioticsai?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">database</a>. They filtered out compounds with the lowest probability of being antibiotics and the highest probability of being toxic to humans, leaving 3,646 antibiotic, low-toxicity compounds.&nbsp;</li><li>Within these compounds, they found the minimal chemical structure responsible for the antibiotic properties. To do this, they removed atoms or rings of atoms from a molecule’s edges, predicted the probability that the modified molecule was an active antibiotic, and repeated these steps until the probability fell below a threshold. Compounds that share a chemical structure are likely to work in similar ways within the body, giving scientists a pathway to discover further compounds with similar benefits.</li></ul><p><strong>Results:&nbsp;</strong>Of the compounds predicted to be likely antibiotics and nontoxic, the authors lab-tested 241 that were not known to work against MRSA. Of those, 8.7 percent inhibited the bacterium’s growth. This exceeds the percentage of antibiotics in the training set (1.3 percent), suggesting that the authors’ approach could be a useful first step in finding new antibiotics. The authors also tested 30 compounds predicted not to be antibiotics. None of them (0 percent) inhibited the bacterium’s growth — further evidence that their approach could be a useful first step. Two of the compounds that inhibited MRSA share a similar and novel mechanism of action against bacteria and also inhibited other antibiotic-resistant infections in lab tests. One of them proved effective against MRSA infections in mice.</p><p><strong>Behind the news:&nbsp;</strong>Most antibiotics currently in use were discovered in the mid-20th century, a golden age of antibiotics, which brought many formerly deadly pathogens under control. Modern techniques, including genomics and synthetic antibiotics, extended discoveries through the end of the century by identifying variants on existing drugs. However, in the 21st century, new antibiotics have either been redundant or haven’t been clinically successful, a report by the National Institutes of Health&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6627412/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">noted</a>. At the same time, widespread use of antibiotics has pushed many dangerous bacteria to evolve resistance. Pathogens chiefly responsible for a variety of ailments are generally resistant even to antibiotics reserved for use as a last resort.<br /><br /><strong>Why it matters:&nbsp;</strong>Antibiotic-resistant infections are among the top global public health threats directly responsible for 1.27 million deaths in 2019,&nbsp;<a href="https://www.who.int/news-room/fact-sheets/detail/antimicrobial-resistance?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">according to</a>&nbsp;the World Health Organization.<strong>&nbsp;</strong>New options, as well as efforts to fight the emergence of resistant strains, are needed.</p><p><strong>We’re thinking:&nbsp;</strong>If neural networks can&nbsp;<a href="https://www.deeplearning.ai/the-batch/treatment-the-elusive-molecule/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">identify</a>&nbsp;new classes of medicines, AI could bring a golden age of medical discovery. That hope helps to explain why pharmaceutical companies are&nbsp;<a href="https://www.deeplearning.ai/the-batch/ai-pharma-jobs/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">hiring</a>&nbsp;machine learning engineers at unprecedented rates.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150551.860.gif" width="1200" /></figure><h1 id="openai-revamps-safety-protocol">OpenAI Revamps Safety Protocol</h1><p>Retrenching after its November leadership shakeup, OpenAI unveiled a new framework for evaluating risks posed by its models and deciding whether to limit their use.&nbsp;</p><p><strong>What’s new:</strong>&nbsp;OpenAI’s&nbsp;<a href="https://openai.com/safety/preparedness?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">safety framework</a>&nbsp;reorganizes pre-existing teams and forms new ones to establish a hierarchy of authority with the company’s board of directors at the top. It defines four categories of risk to be considered in decisions about how to use new models.&nbsp;</p><p><strong>How it works:</strong>&nbsp;OpenAI’s&nbsp;<a href="https://openai.com/blog/frontier-risk-and-preparedness?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Preparedness Team</a>&nbsp;is responsible for evaluating models. The Safety Advisory Group, whose members are appointed by the CEO for year-long terms, reviews the Preparedness Team’s work and recommends approaches to deploying models and mitigating risks, if necessary. The CEO has the authority to approve and oversee recommendations, overriding the Safety Authority Group if needed. OpenAI’s board of directors can overrule the CEO.</p><ul><li>The Preparedness Team scores each model in four categories of risk: enabling or enhancing cybersecurity threats, helping to create weapons of mass destruction, generating outputs that affect users’ beliefs, and operating autonomously without human supervision. The team can modify these risk categories or add new categories in response to emerging research.</li><li>The team scores models in each category using four levels: low, medium, high, or critical. Critical indicates a model with superhuman capabilities or, in the autonomy category, one that can resist efforts to shut it down. A model’s score is its highest risk level in any category.</li><li>The team scores each model twice: once after training and fine-tuning, and a second time after developers have tried to mitigate risks.</li><li>OpenAI will not release models that earn a score of high or critical prior to mitigation, or a medium, high, or critical after mitigation.</li></ul><p><strong>Behind the news:</strong>&nbsp;The Preparedness Team and Safety Advisory Group join a number of safety-focused groups within OpenAI. The&nbsp;<a href="https://openai.com/safety/safety-systems?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Safety Systems Team</a>&nbsp;focuses on mitigating risks after a model has been deployed; for instance, ensuring user privacy and preventing language models from providing false information. The&nbsp;<a href="https://openai.com/blog/introducing-superalignment?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Superalignment Team</a>, led by Ilya Sutskever and Jan Leike, is charged with making sure hypothetical superintelligent systems, whose capabilities would surpass humans, adhere to values that benefit humans.<br /><br /><strong>Why it matters:</strong>&nbsp;AI is an extraordinarily powerful technology whose ultimate impacts are difficult to foresee. OpenAI has invested consistently in AI safety since its inception — even if purportedly cautious moves like keeping its GPT-2 large language model under wraps often looked as much like publicity stunts as safety measures — and its practices are likely to influence those of other AI companies. Furthermore, OpenAI has faced internal&nbsp;<a href="https://www.deeplearning.ai/the-batch/all-about-the-leadership-shakeup-at-openai/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">chaos</a>&nbsp;partly over concerns about safety and governance. Clear protocols in these areas could prevent future strife and stabilize the company to the benefit of its users, employees, and investors.&nbsp;</p><p><strong>We’re thinking:&nbsp;</strong>OpenAI’s safety framework looks like a step forward, but its risk categories focus on long-term, low-likelihood outcomes (though they stop short of considering AI’s hypothetical, and likely mythical, existential risk to humanity). Meanwhile, clear and present safety issues, such as social bias and factual accuracy, are well known to afflict current models including OpenAI’s. We hope that the Preparedness Team promptly adds categories that represent safety issues presented by today’s models.</p><hr /><h2 id="a-message-from-deeplearningai">A MESSAGE FROM&nbsp;DEEPLEARNING.AI</h2><figure class="kg-card kg-image-card"><a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2"><img alt="" class="kg-image" height="1040" src="https://dl-staging-website.ghost.io/content/images/2024/01/Version2_DeepLearning_LangchainJS_Banner_2070x1080.png" width="2000" /></a></figure><p>In this short course, you’ll dive into LangChain.js, a JavaScript framework for building applications based on large language models, and learn how to craft powerful, context-aware apps. Elevate your machine learning-powered development skills using JavaScript.&nbsp;<a href="https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Sign up today</a></p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="676" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed--48-.jpg" width="1200" /></figure><h1 id="agi-defined">AGI Defined</h1><p>How will we know if someone succeeds in building artificial general intelligence (AGI)? A recent paper defines milestones on the road from calculator to superintelligence.</p><p><strong>What’s new:</strong>&nbsp;Researchers at Google led by Meredith Ringel Morris&nbsp;<a href="https://arxiv.org/abs/2311.02462?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">propose</a>&nbsp;a taxonomy of AI systems according to their degree of generality and ability to perform cognitive tasks. They consider today’s large multimodal models to be “emerging AGI.”</p><p><strong>AGI basics:</strong>&nbsp;Artificial general intelligence is commonly defined as AI that can perform any intellectual task a human can. Shane Legg (who co-founded DeepMind) and Ben Goertzel (co-founder and CEO of&nbsp;<a href="https://singularitynet.io/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">SingularityNet</a>) coined the term AGI for a 2007 collection of&nbsp;<a href="https://link.springer.com/book/10.1007/978-3-540-68677-4?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">essays</a>. Subsequently, companies like DeepMind and OpenAI, which explicitly aim to develop AGI, propelled the idea into the mainstream.</p><p><strong>How it works:</strong>&nbsp;The taxonomy categorizes systems as possessing narrow skills (not AGI) or general capabilities (AGI). It divides both narrow and general systems into five levels of performance beyond calculator-grade Level 0. It also includes a metric for degree of autonomy.</p><ul><li>Narrow systems perform one distinct task; they may perform at one of the five levels, but they are not AGI. General systems perform a range of tasks (which the authors don’t specify) that align with real-world activities of broad value to people, including but not limited to linguistic, mathematical, logical, spatial reasoning, social, learning, and creative tasks. Crucially, they can learn how to learn new skills and when to ask humans for more information. The authors classify general systems as AGI at various levels of performance.</li><li>Level 1 (“emerging”) matches or slightly exceeds unskilled humans. Levels 2 (“competent”), 3 (“expert”), and 4 (“virtuoso”) systems surpass the 50th, 90th and 99th percentiles of skilled human performance, respectively. Level 5 (“superhuman” or “artificial superintelligence”) outperforms 100 percent of skilled humans.</li><li>Most current systems that perform at Level 2 or higher are narrow. For example,&nbsp;<a href="https://www.deeplearning.ai/the-batch/protein-shapes-revealed/?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">AlphaFold</a>, which finds the shapes of protein molecules, achieves Level 5 performance but only in a single task. On the other hand, the authors consider large language models like Bard, ChatGPT, and Lama 2 to be general systems at Level 1 (although their performance may achieve Level 2 in some tasks).&nbsp;</li><li>The authors’ autonomy scale ranges from tools for which humans control the task while the system automates subtasks (the first level of autonomy) to agents that act independently (the fifth). Higher levels of performance can unlock higher levels of autonomy. For instance, Level 4 AGI may be necessary to enable fully autonomous vehicles that are safe and trustworthy.</li></ul><p><strong>Yes, but:&nbsp;</strong>The authors’ definition identifies some classes of tasks that contribute to generality, but it includes neither a list of tasks a system must perform to be considered general nor&nbsp;a method for selecting them. Rather, the authors call on the research community to develop a “living benchmark” for generality that includes a mechanism for adding novel tasks.</p><p><strong>Why it matters:&nbsp;</strong>AGI is one of the tech world’s hottest buzzwords, yet it has had no clear definition, and various organizations propose different definitions. This lack of specificity makes it hard to talk about related technology, regulation, and other topics. The authors’ framework, on the other hand, supports a more nuanced discussion of the path toward AGI. And it may have high-stakes business implications: Under the terms of their partnership, OpenAI can withhold from Microsoft models that attain AGI. Applying the authors’ taxonomy would make it harder for one of the parties to move the goalposts.&nbsp;</p><p><strong>We’re thinking:</strong>&nbsp;Defining AGI is tricky! For instance, OpenAI defines AGI as “a highly autonomous system that outperforms humans at most economically valuable work.” This definition, had it been formulated in the early 1900s, when agriculture accounted for 70 percent of work globally, would have described the internal combustion engine.</p><hr /><figure class="kg-card kg-image-card"><img alt="" class="kg-image" height="338" src="https://dl-staging-website.ghost.io/content/images/2024/01/unnamed---2024-01-10T150942.421.gif" width="600" /></figure><h1 id="text-or-images-input-or-output">Text or Images, Input or Output</h1><p>GPT-4V introduced a large multimodal model that generates text from images and, with help from DALL-E 3, generates images from text. However, OpenAI hasn’t fully explained how it built the system. A separate group of researchers described their own method.</p><p><strong>What's new:&nbsp;</strong>Jing Yu Koh, Daniel Fried, and Ruslan Salakhutdinov at Carnegie Mellon University proposed&nbsp;<a href="https://arxiv.org/abs/2305.17216?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">Generating Images with Large Language Models</a>&nbsp;(GILL), a training method that enables a large language model and a text-to-image generator to use both text and images as either input or output. Given text and/or image input, it decides whether to retrieve existing images or generate new ones.</p><p><strong>Key insight:</strong>&nbsp;Models like CLIP and ImageBind map text and image inputs to a similar embedding space, so closely related text and images have similar embeddings. This approach enables a large multimodal model to process both data types. Text outputs, too, can be mapped to the same embedding space, so an image decoder, such as a diffusion model, can use them to produce images or an image retriever to retrieve images.</p><p><strong>How it works:</strong>&nbsp;The authors used a pretrained&nbsp;<a href="https://arxiv.org/abs/2205.01068?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">OPT</a>&nbsp;large language model,&nbsp;<a href="https://arxiv.org/abs/2010.11929v2?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">ViT-L</a>&nbsp;image encoder (taken from CLIP), and pretrained Stable Diffusion text-to-image generator. The authors trained ViT-L to map its embeddings to those produced by OPT. They trained OPT to recognize prompts that request an image and enabled the system to either generate or retrieve images. Finally, a separate linear classifier learned whether to retrieve or generate images.&nbsp;</p><ul><li>The authors froze the ViT-L, added a linear layer, and trained it as follows: Given an image, the ViT-L-plus-linear-layer produced an image embedding, as usual. Given the image embedding and the first part of the corresponding caption, OPT iteratively tried to predict the next word. The linear layer learned how to modify the embedding so OPT could complete the caption. This enabled OPT to take images as input.</li><li>They added 8 tokens to OPT’s vocabulary and trained the model to emit them at the end of every image caption — a signal that an image should be either retrieved or generated. (Typically a single token is sufficient to denote the end of a caption. However, these tokens corresponded to embeddings that, later, would be used to generate an image, and the authors found that a single token was not sufficiently expressive.)</li><li>Then they enabled Stable Diffusion to produce an image when OPT generated the 8 new tokens. They trained a separate transformer to map OPT’s embeddings associated with the 8 tokens (that is, embeddings produced by the layer before the one that generated the tokens) to those produced by Stable Diffusion’s text encoder.</li><li>Next they enabled the system to retrieve images when OPT generated the 8 tokens. They added linear layers to ViT-L and OPT and trained them to map the ViT-L’s embeddings to the OPT embedding associated with the first token. Specifically, the linear layers learned to minimize the difference between their outputs.</li><li>The authors trained a linear classifier, given the 8 OPT embeddings associated with the tokens, to decide whether to retrieve or generate an image. To build the classifier’s training set, they selected captions from a&nbsp;<a href="https://arxiv.org/abs/2206.10789?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">collection</a>&nbsp;of diverse human-written prompts and, for each one, both generated an image and retrieved the most similar image from CC3M. 5 human judges selected the image that best matched the prompt. This process yielded 900 examples annotated according to whether the image was retrieved or generated.</li><li>At inference, OPT generated tokens and fed the associated embeddings directly to the classifier, which activated the pipeline for either the generation or retrieval.</li></ul><p><strong>Results:&nbsp;</strong><a href="https://arxiv.org/abs/1604.03968?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">VIST</a>&nbsp;is a dataset of 20,000 visual stories, each of which comprises five captioned images. The authors evaluated GILL’s and Stable Diffusion’s abilities, given the final caption or all five captions, to generate the final image in each story based on CLIP similarity scores between generated and ground-truth images. Given one caption, GILL achieved 0.581 similarity and Stable Diffusion achieved 0.592 similarity. Given five captions, GILL achieved 0.612 similarity and Stable Diffusion scored 0.598 similarity, highlighting GILL’s ability to use the context afforded by more extensive input. It did even better (0.641 similarity) given both captions and images, which Stable Diffusion couldn’t handle. The authors also evaluated how well their system retrieved the correct last image from VIST given the 5 captions and the first 4 images. GILL retrieved the correct image 20.3 percent of the time, while their own&nbsp;<a href="https://arxiv.org/abs/2301.13823?utm_campaign=The%20Batch&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--NdvYr0Fu7Gh2F34MUf_eZj8T0X0RgaluAJRvSnkTttkzl0Fk8qT4WTi4QTPFX0QSA1Ow2" rel="noopener">FROMAGe</a>&nbsp;retrieved the correct image 18.2 percent of the time. In comparison, CLIP, given the 5 captions (without the images), retrieved the correct image 8.8 percent of the time.</p><p><strong>Why it matters:</strong>&nbsp;Models that wed text and images are advancing rapidly. GILL and other recent models extend single-image input and/or output to any combination of images and text. This capability — which GILL achieves by mapping embeddings of image and text to one another — gives the models more context to generate more appropriate output.</p><p><strong>We’re thinking:</strong>&nbsp;The authors add an interesting twist: Rather than generating images, the system can choose to retrieve them. Sometimes an existing image will do.</p><hr /><h2 id="a-message-from-landing-ai">A MESSAGE FROM LANDING AI</h2><figure class="kg-card kg-image-card"><a href="https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai&amp;utm_medium=partner&amp;utm_campaign=na-us-en-no-ind-unkwn-ai-ml&amp;utm_content=wb&amp;utm_cta=html-no-ind-unkwn"><img alt="" class="kg-image" height="709" src="https://dl-staging-website.ghost.io/content/images/2024/01/image--10-.png" width="1260" /></a></figure><p>Join a free webinar on January 11, 2024, featuring experts from Snowflake and Landing AI to explore how large vision models (LVMs) are transforming the image processing landscape.&nbsp;<a href="https://www.snowflake.com/webinars/thought-leadership/the-future-of-enterprise-ai-apps-with-large-vision-models-lvms-in-snowflake-2024-01-11/?utm_source=landing-ai&amp;utm_medium=partner&amp;utm_campaign=na-us-en-no-ind-unkwn-ai-ml&amp;utm_content=wb&amp;utm_cta=html-no-ind-unkwn" rel="noreferrer">Learn more about the session and register here</a></p><hr /><h1 id="data-points">Data Points</h1><p>What happens when beloved cartoon Mickey Mouse enters the public domain in the era of generative AI? What’s the latest AI-driven addition to PC keyboards?&nbsp;</p><p>These items and other AI news are explored in a new edition of Data Points, a spinoff of our weekly newsletter, The Batch.&nbsp;</p><p><a href="https://www.deeplearning.ai/the-batch/data-points-issue-231/?ref=dl-staging-website.ghost.io" rel="noreferrer">Read it here</a></p>
]]></content:encoded>
<pubDate>Wed, 10 Jan 2024 20:15:13 GMT</pubDate>
</item>
</channel>
</rss>