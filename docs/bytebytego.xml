<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>ByteByteGo Newsletter</title>
<link>https://blog.bytebytego.com</link>


<item>
<title>A Crash Course in Database Scaling Strategies</title>
<link>https://blog.bytebytego.com/p/a-crash-course-in-database-scaling</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-in-database-scaling</guid>
<content:encoded><![CDATA[
<div> 数据库、应用开发、数据库扩展、性能优化、索引<br />
<br />总结：<br />数据库是现代应用开发的重要组成部分，通过索引等技术来改进数据库的可扩展性和性能。数据库扩展是通过采用各种技术和策略来适应数据增长和维持性能，以确保应用程序的正常运行。选择合适的数据库扩展策略至关重要，否则可能会带来更多问题。 <div>
<p>Databases form the backbone of modern application development. They play a vital role in storing, managing, and retrieving data, enabling applications and services to function effectively.</p><p>As applications gain popularity and attract a growing user base, databases face the challenge of handling ever-increasing data volumes, concurrent users, and complex queries.</p><p>It becomes critical to scale databases effectively to ensure optimal performance and a good user experience.&nbsp;</p><p>Database scaling is the process of adapting and expanding the database infrastructure to accommodate growth and maintain performance under increased load. It involves employing various techniques and strategies to distribute data efficiently, optimize query execution, and utilize hardware resources judiciously.</p><p>Organizations and developers must understand and implement the right database scaling strategy. Choosing the wrong strategies for a particular situation can result in more harm than good.</p><p>In this post, we will cover the most popular database scaling strategies in detail, discussing their benefits and trade-offs.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cff25a5-b061-4fd4-8831-fab148e8926b_1401x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cff25a5-b061-4fd4-8831-fab148e8926b_1401x1600.png" width="1401" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>Indexing</h2><p>Indexing is one of the foundational techniques to enhance the scalability and performance of databases.&nbsp;</p>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 15:31:12 GMT</pubDate>
</item>
<item>
<title>EP118: What are the differences among database locks?</title>
<link>https://blog.bytebytego.com/p/ep118-what-are-the-differences-among</link>
<guid>https://blog.bytebytego.com/p/ep118-what-are-the-differences-among</guid>
<content:encoded><![CDATA[
<div> 数据库锁、API设计中的分页、架构模式（MVC、MVP、MVVM、MVVM-C、VIPER）、浏览器输入URL的过程、扫描二维码支付

总结:<br /><br />
数据库锁是用来保证数据完整性和一致性的机制，常见类型包括Shared Lock、Exclusive Lock等。分页在API设计中是为了高效处理大型数据集，常用技术有Offset-based Pagination、Cursor-based Pagination等。架构模式MVC、MVP、MVVM、MVVM-C、VIPER各有特点，都包含视图、模型和控制器/Presenter/ViewModel。浏览器输入URL时，经过DNS查询、建立TCP连接、发送HTTP请求等步骤。扫描二维码支付过程分为商家生成QR码和消费者扫描支付。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>What are the differences among database locks? </p></li><li><p>How do we Perform Pagination in API Design? </p></li><li><p>What distinguishes MVC, MVP, MVVM, MVVM-C, and VIPER architecture patterns from each other?</p></li><li><p>What happens when you type a URL into your browser?</p></li><li><p>How do you pay from your digital wallet, such as Paypal, Venmo, Paytm, by scanning the QR code? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Paragon_062924">Ship every native SaaS integration your users need (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Paragon_062924" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="756" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d88922-60bc-483c-86ca-b5916742f99a_7747x4021.png" width="1456" /><div></div></div></a></figure></div><p>Is product asking your team to build native product integrations with 3rd party services (ie. Salesforce, Slack, etc.)?</p><p>Save 70% of the engineering effort with Paragon, so you can stay focused on your core competencies.</p><p>Offload the plumbing around integrations with:</p><ul><li><p>Fully managed authentication (OAuth token refresh)</p></li><li><p>Webhook triggers &amp; API abstractions</p></li><li><p>Built-in error and 3rd party rate limit handling</p></li><li><p>100+ pre-built integrations &amp; custom integration builder</p></li><li><p>Enterprise-ready serverless infrastructure</p></li></ul><p>See how 100+ SaaS companies orchestrate ingestion jobs, real-time sync, and event-driven automations with 3rd party SaaS apps in weeks, not months.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Paragon_062924"><span>Learn more</span></a></p><div><hr /></div><h2>What are the differences among database locks? </h2><p>In database management, locks are mechanisms that prevent concurrent access to data to ensure data integrity and consistency. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42c5f5c6-b7d8-46ac-895f-06edd3d7fb7a_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><p>Here are the common types of locks used in databases: </p><ol><li><p>Shared Lock (S Lock) <br />It allows multiple transactions to read a resource simultaneously but not modify it. Other transactions can also acquire a shared lock on the same resource. <br /></p></li><li><p>Exclusive Lock (X Lock) <br />It allows a transaction to both read and modify a resource. No other transaction can acquire any type of lock on the same resource while an exclusive lock is held. <br /></p></li><li><p>Update Lock (U Lock) <br />It is used to prevent a deadlock scenario when a transaction intends to update a resource. <br /></p></li><li><p>Schema Lock <br />It is used to protect the structure of database objects. <br /></p></li><li><p>Bulk Update Lock (BU Lock) <br />It is used during bulk insert operations to improve performance by reducing the number of locks required. <br /></p></li><li><p>Key-Range Lock <br />It is used in indexed data to prevent phantom reads (inserting new rows into a range that a transaction has already read). <br /></p></li><li><p>Row-Level Lock <br />It locks a specific row in a table, allowing other rows to be accessed concurrently. <br /></p></li><li><p>Page-Level Lock <br />It locks a specific page (a fixed-size block of data) in the database. <br /></p></li><li><p>Table-Level Lock <br />It locks an entire table. This is simple to implement but can reduce concurrency significantly.</p></li></ol><div><hr /></div><h2>How do we Perform Pagination in API Design? </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ec91193-f890-4942-bb23-21f706d9524a_1306x1536.gif" title="No alternative text description for this image" /><div></div></div></a></figure></div><p>Pagination is crucial in API design to handle large datasets efficiently and improve performance. Here are six popular pagination techniques: </p><ul><li><p>Offset-based Pagination: <br />This technique uses an offset and a limit parameter to define the starting point and the number of records to return. <br />- Example: GET /orders?offset=0&amp;limit=3 <br />- Pros: Simple to implement and understand. <br />- Cons: Can become inefficient for large offsets, as it requires scanning and skipping rows. <br /></p></li><li><p>Cursor-based Pagination: <br />This technique uses a cursor (a unique identifier) to mark the position in the dataset. Typically, the cursor is an encoded string that points to a specific record. </p><ul><li><p>Example: GET /orders?cursor=xxx <br />- Pros: More efficient for large datasets, as it doesn't require scanning skipped records. <br />- Cons: Slightly more complex to implement and understand. <br /></p></li></ul></li><li><p>Page-based Pagination: <br />This technique specifies the page number and the size of each page. </p><ul><li><p>Example: GET /items?page=2&amp;size=3 <br />- Pros: Easy to implement and use. <br />- Cons: Similar performance issues as offset-based pagination for large page numbers. <br /></p></li></ul></li><li><p>Keyset-based Pagination: <br />This technique uses a key to filter the dataset, often the primary key or another indexed column. </p><ul><li><p>Example: GET /items?after_id=102&amp;limit=3 <br />- Pros: Efficient for large datasets and avoids performance issues with large offsets. <br />- Cons: Requires a unique and indexed key, and can be complex to implement. <br /></p></li></ul></li><li><p>Time-based Pagination: <br />This technique uses a timestamp or date to paginate through records.</p><ul><li><p>Example: GET /items?start_time=xxx&amp;end_time=yyy <br />- Pros: Useful for datasets ordered by time, ensures no records are missed if new ones are added. <br />- Cons: Requires a reliable and consistent timestamp. <br /></p></li></ul></li><li><p>Hybrid Pagination: <br />This technique combines multiple pagination techniques to leverage their strengths. <br />Example: Combining cursor and time-based pagination for efficient scrolling through time-ordered records. </p><ul><li><p>Example: GET /items?cursor=abc&amp;start_time=xxx&amp;end_time=yyy <br />- Pros: Can offer the best performance and flexibility for complex datasets. <br />- Cons: More complex to implement and requires careful design.</p></li></ul></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F571827ac-b3da-44a3-886a-8ca9770bb443_1337x1600.png" width="1337" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">A Crash Course in Database Sharding</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>What distinguishes MVC, MVP, MVVM, MVVM-C, and VIPER architecture patterns from each other?<br /></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1755" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c35aada-289b-4ac5-8c23-8b55065a5d60_1280x1755.jpeg" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>These architecture patterns are among the most commonly used in app development, whether on iOS or Android platforms. Developers have introduced them to overcome the limitations of earlier patterns. So, how do they differ?</p><ul><li><p>MVC, the oldest pattern, dates back almost 50 years</p></li><li><p>Every pattern has a "view" (V) responsible for displaying content and receiving user input</p></li><li><p>Most patterns include a "model" (M) to manage business data</p></li><li><p>"Controller," "presenter," and "view-model" are translators that mediate between the view and the model ("entity" in the VIPER pattern)</p></li><li><p>These translators can be quite complex to write, so various patterns have been proposed to make them more maintainable</p></li></ul><div><hr /></div><h2>What happens when you type a URL into your browser?</h2><p>The diagram below illustrates the steps.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1178" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3cf6a7cb-3aec-4db8-9bdc-fda0dc70c9fe_1898x1536.jpeg" title="No alt text provided for this image" width="1456" /><div></div></div></a></figure></div><ol><li><p>Bob enters a URL into the browser and hits Enter. In this example, the URL is composed of 4 parts:<br />&#128313; scheme - &#119945;&#119957;&#119957;&#119953;://. This tells the browser to send a connection to the server using HTTP.<br />&#128313; domain - &#119942;&#119961;&#119938;&#119950;&#119953;&#119949;&#119942;.&#119940;&#119952;&#119950;. This is the domain name of the site.<br />&#128313; path - &#119953;&#119955;&#119952;&#119941;&#119958;&#119940;&#119957;/&#119942;&#119949;&#119942;&#119940;&#119957;&#119955;&#119946;&#119940;. It is the path on the server to the requested resource: phone.<br />&#128313; resource - &#119953;&#119945;&#119952;&#119951;&#119942;. It is the name of the resource Bob wants to visit.</p><p></p></li><li><p>The browser looks up the IP address for the domain with a domain name system (DNS) lookup. To make the lookup process fast, data is cached at different layers: browser cache, OS cache, local network cache, and ISP cache. <br /><br />2.1 If the IP address cannot be found at any of the caches, the browser goes to DNS servers to do a recursive DNS lookup until the IP address is found (this will be covered in another post). </p><p></p></li><li><p>Now that we have the IP address of the server, the browser establishes a TCP connection with the server.<br /></p></li><li><p>The browser sends an HTTP request to the server. The request looks like this:<br /><br />&#120334;&#120332;&#120347; /&#120369;&#120361;&#120368;&#120367;&#120358; &#120335;&#120347;&#120347;&#120343;/1.1<br />&#120335;&#120368;&#120372;&#120373;: &#120358;&#120377;&#120354;&#120366;&#120369;&#120365;&#120358;.&#120356;&#120368;&#120366;</p><p></p></li><li><p>The server processes the request and sends back the response. For a successful response (the status code is 200). The HTML response might look like this: <br /><br />&#120335;&#120347;&#120347;&#120343;/1.1 200 &#120342;&#120338;<br />&#120331;&#120354;&#120373;&#120358;: &#120346;&#120374;&#120367;, 30 &#120337;&#120354;&#120367; 2022 00:01:01 &#120334;&#120340;&#120347;<br />&#120346;&#120358;&#120371;&#120375;&#120358;&#120371;: &#120328;&#120369;&#120354;&#120356;&#120361;&#120358;<br />&#120330;&#120368;&#120367;&#120373;&#120358;&#120367;&#120373;-&#120347;&#120378;&#120369;&#120358;: &#120373;&#120358;&#120377;&#120373;/&#120361;&#120373;&#120366;&#120365;; &#120356;&#120361;&#120354;&#120371;&#120372;&#120358;&#120373;=&#120374;&#120373;&#120359;-8<br /><br />&lt;!&#120331;&#120342;&#120330;&#120347;&#120352;&#120343;&#120332; &#120361;&#120373;&#120366;&#120365;&gt;<br />&lt;&#120361;&#120373;&#120366;&#120365; &#120365;&#120354;&#120367;&#120360;="&#120358;&#120367;"&gt;<br />&#120335;&#120358;&#120365;&#120365;&#120368; &#120376;&#120368;&#120371;&#120365;&#120357;<br />&lt;/&#120361;&#120373;&#120366;&#120365;&gt;<br /></p></li><li><p>The browser renders the HTML content.</p></li></ol><div><hr /></div><h2>How do you pay from your digital wallet, such as Paypal, Venmo, Paytm, by scanning the QR code? </h2><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31897073-e7f9-422a-9dbf-2f6dc18e6a6d_1280x1780.jpeg" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1780" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31897073-e7f9-422a-9dbf-2f6dc18e6a6d_1280x1780.jpeg" title="diagram" width="1280" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To understand the process involved, we need to divide the &#8220;scan to pay&#8221; process into two sub-processes: </p><ol><li><p>Merchant generates a QR code and displays it on the screen </p></li><li><p>Consumer scans the QR code and pays </p></li></ol><p>Here are the steps for generating the QR code: </p><ol><li><p>When you want to pay for your shopping, the cashier tallies up all the goods and calculates the total amount due, for example, $123.45. The checkout has an order ID of SN129803. The cashier clicks the &#8220;checkout&#8221; button. </p></li><li><p>The cashier&#8217;s computer sends the order ID and the amount to PSP. </p></li><li><p>The PSP saves this information to the database and generates a QR code URL. </p></li><li><p>PSP&#8217;s Payment Gateway service reads the QR code URL. </p></li><li><p>The payment gateway returns the QR code URL to the merchant&#8217;s computer. </p></li><li><p>The merchant&#8217;s computer sends the QR code URL (or image) to the checkout counter. </p></li><li><p>The checkout counter displays the QR code. </p></li></ol><p>These 7 steps complete in less than a second. Now it&#8217;s the consumer&#8217;s turn to pay from their digital wallet by scanning the QR code: </p><ol><li><p>The consumer opens their digital wallet app to scan the QR code. </p></li><li><p>After confirming the amount is correct, the client clicks the &#8220;pay&#8221; button. </p></li><li><p>The digital wallet App notifies the PSP that the consumer has paid the given QR code. </p></li><li><p>The PSP payment gateway marks this QR code as paid and returns a success message to the consumer&#8217;s digital wallet App. </p></li><li><p>The PSP payment gateway notifies the merchant that the consumer has paid the given QR code. </p></li></ol><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 15:30:59 GMT</pubDate>
</item>
<item>
<title>A Crash Course in Database Sharding</title>
<link>https://blog.bytebytego.com/p/a-crash-course-in-database-sharding</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-in-database-sharding</guid>
<content:encoded><![CDATA[
<div> 数据库，横向扩展，性能，挑战，分片
<br />
分片是一种解决数据库横向扩展挑战的技术，将数据库划分为更小、更易管理的单元称为分片。当应用程序接收到更多流量和数据时，数据库可能成为性能瓶颈，影响用户体验。通过分片，可以解决数据库横向扩展的挑战，提高性能，确保应用程序的可伸缩性。不同的公司已经成功实施了分片技术来扩展他们的数据库，有效应对业务增长的需求。
<br /><br />总结: 数据库的横向扩展面临着性能挑战，分片技术能够有效解决这一问题，提升性能，并确保应用程序的可伸缩性。通过对数据库进行分片，可以更好地应对增加的流量和数据量，确保用户体验。 <div>
<p>As an application grows in popularity, it attracts more active users and incorporates additional features. This growth leads to a daily increase in data generation, which is a positive indicator from a business perspective.&nbsp;</p><p>However, it can also pose challenges to the application's architecture, particularly in terms of database scalability.</p><p>The database is a critical component of any application, but it is also one of the most difficult components to scale horizontally. When an application receives increased traffic and data volume, the database can become a performance bottleneck, impacting the user experience.</p><p>Sharding is a technique that addresses the challenges of horizontal database scaling. It involves partitioning the database into smaller, more manageable units called shards.</p><p>In this post, we&#8217;ll cover the fundamentals of database sharding, exploring its various approaches, technical considerations, and real-world case studies showcasing how companies have implemented sharding to scale their databases.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F571827ac-b3da-44a3-886a-8ca9770bb443_1337x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F571827ac-b3da-44a3-886a-8ca9770bb443_1337x1600.png" width="1337" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>What is Sharding?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 15:30:37 GMT</pubDate>
</item>
<item>
<title>How Netflix Manages 238 Million Memberships?</title>
<link>https://blog.bytebytego.com/p/how-netflix-manages-238-million-memberships</link>
<guid>https://blog.bytebytego.com/p/how-netflix-manages-238-million-memberships</guid>
<content:encoded><![CDATA[
<div> 关键词: DevOps, Netflix, membership platform, architecture, technical stack

总结:<br /><br />文章介绍了Netflix的会员平台架构及技术堆栈。该平台负责管理用户的订阅生命周期，经历从简单的库到可处理百万请求的强大架构的演变。采用微服务架构，使用CockroachDB和Cassandra等数据库存储会员数据，通过CDC追踪历史数据变更。开发堆栈中使用Java和Spring Boot，涉及Kafka、Spark和Flink等工具，保证高可用性和数据一致性。运维方面强调可观测性和监控，使用日志、仪表盘、分布式跟踪等工具快速识别和解决问题。总体而言，Netflix的会员平台是其成功的关键组成部分，为亿万用户提供持续流畅的观影体验。 <div>
<h2><a href="https://bit.ly/Datadog_062524">Guide to Accelerating DevOps Transformation (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Datadog_062524" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1356" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25b41cc2-06b7-4572-8996-94c1353483f2_2482x2312.png" width="1456" /><div></div></div></a></figure></div><p>The DevOps model can engender faster development cycles and enhanced agility in responding to market needs. <br /><br />Datadog's DevOps Kit gives you the resources to create and strengthen cultures of observability, collaboration, and data sharing within organizations&#8212;key pillars of the DevOps movement.</p><p><strong>Gain instant access to:</strong></p><ul><li><p><strong>2 eBooks</strong> detailing methods for building and enabling effective development and operations teams</p></li><li><p><strong>A Solutions Brief</strong> describing ways to get full visibility into your DevOps tools</p></li><li><p><strong>A Technical Talk Video</strong> detailing the benefits of adopting a data-driven DevOps mindset</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Datadog_062524"><span>Get the kit</span></a></p></li></ul><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the articles/presentations made by the Netflix engineering team. All credit for the architectural details goes to the Netflix engineering team. The links to the original articles are present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>As a subscription-based streaming service, Netflix's primary revenue source is its membership business. With a staggering 238 million members worldwide, managing memberships efficiently is crucial for the company's success and continued growth.&nbsp;</p><p>The membership platform at Netflix plays a vital role in handling the entire lifecycle of a user's subscription.</p><p>The membership lifecycle consists of various stages and scenarios:</p><ul><li><p><strong>Signup: </strong>A user may begin their Netflix journey by signing up for the service, either directly or through partner channels such as T-Mobile and others.</p></li><li><p><strong>Plan Changes:</strong> Existing members can modify their subscription plans according to their preferences and needs.</p></li><li><p><strong>Renewal: </strong>As a subscription service, Netflix automatically attempts to renew a user&#8217;s plan using the payment method associated with the account.</p></li><li><p><strong>Payment Issues: </strong>In case of problems with the payment gateway or insufficient funds, a user&#8217;s account may be put on hold or granted a grace period to resolve the issue.</p></li><li><p><strong>Membership Pause or Cancellation: </strong>Users have the option to temporarily pause their membership or permanently cancel their subscriptions.</p></li></ul><p>In the following sections, we will explore the architectural decisions made by the Netflix engineering team to support the various capabilities and scalability of its membership platform.</p><div><hr /></div><h2>The High-Level Architecture of Netflix Membership Platform</h2><p>Before diving into the details of Netflix's membership platform, let's take a step back and examine how the company's original pricing architecture was designed.&nbsp;</p><p>In the early days, Netflix's pricing model was relatively straightforward, with only a handful of plans to manage and basic functionality to support.</p><p>To meet these initial requirements, Netflix employed a lightweight, in-memory library. This approach proved to be quite efficient, as the limited scope of the pricing system allowed for a simple and streamlined design.</p><p>The diagram below illustrates this basic architecture:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37775e14-0fb5-4edf-a82a-33c6d77fb195_1600x916.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="834" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37775e14-0fb5-4edf-a82a-33c6d77fb195_1600x916.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As Netflix expanded its global presence and diversified its offerings, the lightweight, in-memory library that initially served the pricing architecture became insufficient.&nbsp;</p><p>The growing complexity and scope of the pricing catalog, coupled with its increasing importance across multiple applications, led to operational challenges. The library's size and dependencies made it difficult to maintain and scale, necessitating a transition to a more robust and scalable architecture.</p><p>The diagram below shows the high-level architecture of Netflix&#8217;s modern membership platform:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38f27d43-db0e-4f28-b763-21b2260f5fa0_1600x1060.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="965" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38f27d43-db0e-4f28-b763-21b2260f5fa0_1600x1060.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The membership platform consists of a dozen microservices and is designed to support four nines (99.99%) availability.&nbsp;</p><p>This high availability requirement originates from the platform's critical role in various user-facing flows. If any of the services experience downtime, it can directly impact the user experience.</p><p>The platform supports several key functionalities:</p><ul><li><p>When a user hits the play button on Netflix, a direct call is made to the membership systems to determine the quality of service associated with their plan. Factors such as the allowed concurrent streams and supported devices for the user are considered. This flow handles the highest traffic volume, as Netflix serves billions of streaming requests every day.</p></li><li><p>The membership flow is triggered when a user accesses their account page. Actions like changing plans, managing extra members, and cancellations directly interact with the membership services.</p></li><li><p>The platform serves as the authoritative source for the total membership count at any given point in time. It emits events and writes to a persistent store, which is consumed by downstream analytics systems within and outside Netflix.</p></li></ul><p>The key points about the architecture diagram are as follows:</p><ul><li><p>The membership platform manages the membership plan and pricing catalog globally, with variations across different regions. The Plan Pricing Catalog Service handles rule management based on location-specific offerings.</p></li><li><p>Two CockroachDB databases are utilized to store plan pricing and code redemption information. The Member Pricing Service supports member actions, such as changing plans or adding extra members.</p></li><li><p>A dedicated microservice handles partner interactions, including bundle activations, signups, and integration with platforms like Apple's App Store.</p></li><li><p>Membership data is stored in Cassandra databases, which support the Subscription Service and History Tracking Service.</p></li><li><p>The platform not only caters to the 238 million active memberships but also focuses on former members and rejoin experiences.</p></li><li><p>The data generated by the platform is shipped to downstream consumers for deriving insights on signups and revenue projections.</p></li></ul><p>Netflix&#8217;s choice of using CockroachDB and Cassandra is interesting.&nbsp;</p><p>While CockroachDB provides strong consistency, making it suitable for critical data such as the plan pricing information, Cassandra is a highly scalable NoSQL database for handling large volumes of membership data.</p><p>Also, the 99.99% availability indicates a strong focus on resilience and fault tolerance. Netflix is anyways famous for its comprehensive chaos engineering practices to proactively test the system&#8217;s resilience.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb22a8b-a5fc-455d-b09b-f8e810d81cd9_1600x890.pnghttps%3A%2F%2Fblog.bytebytego.com%2Fsubscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="810" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb22a8b-a5fc-455d-b09b-f8e810d81cd9_1600x890.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>The Signup Process Flow</h2><p>Once users embark on their Netflix journey, they encounter plan selection options.</p><p>Rendering the plan selection page accurately is of utmost importance due to the geographical variations in currency, pricing, and available plans. Netflix's membership platform ensures that users are presented with the appropriate options based on their location and device type.</p><p>The diagram below shows the detailed steps involved in the Netflix signup process and the services that are triggered during the flow:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F721d4ccf-6623-4484-a0d8-7872e1cbe8e3_1600x1284.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1168" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F721d4ccf-6623-4484-a0d8-7872e1cbe8e3_1600x1284.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s a look at each step in more detail.</p><ol><li><p>The journey begins with users selecting a plan through Netflix's growth engineering apps. The plan details are retrieved from the Membership Plan Catalog service, which is backed by CockroachDB.&nbsp;</p></li><li><p>The Membership Plan Catalog Service loads and reads the plans based on predefined region and device type rules.</p></li><li><p>The retrieved plans are then presented to the user, allowing them to make an informed decision based on their preferences and budget.</p></li><li><p>Once the user chooses a plan, the flow progresses to the payment confirmation screen. Here, users provide their payment details and confirm their subscription.</p></li><li><p>Upon confirmation, the user clicks the "Start Membership" button, triggering the Membership State Service. This service persists the relevant information, such as the selected plan, price tier, and country, into the Cassandra database.</p></li><li><p>The Membership State Service also notifies the Billing Engineering Apps about the payment.&nbsp;</p></li><li><p>The Billing Engineering Apps generate an invoice based on the signup data obtained from the Membership Pricing Service.</p></li><li><p>The membership data is simultaneously written to the Membership History Service, ensuring a comprehensive record of the user's subscription history.</p></li><li><p>Events are published to signal the activation of the membership. These events trigger messaging pipelines responsible for sending welcome emails to the user and informing downstream systems for analytics purposes.</p></li></ol><h2>How Member History Is Tracked?</h2><p>In the early stages of Netflix's membership platform, member history and data were tracked through application-level events.&nbsp;</p><p>While this approach sufficed initially, it became evident that a more granular and persistent data tracking solution was necessary as Netflix expanded and the complexity of member data increased.</p><p>To address this need, Netflix developed a robust solution based on the Change Data Capture (CDC) pattern.&nbsp;</p><p>For reference, CDC is a design pattern that directly captures changes made to a database and propagates those changes to downstream systems for further processing or analysis.</p><p>The diagram below shows how the CDC process works:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19620f0c-746b-4aa7-bd31-d0e6e7329acb_1600x1002.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="445.97802197802196" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19620f0c-746b-4aa7-bd31-d0e6e7329acb_1600x1002.png" width="712" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Adopting a CDC-like approach ensures that all delta changes made to the membership data sources are recorded in an append-only log system, which is backed by a Cassandra database.</p><p>The diagram below shows the flow of historical data in Netflix&#8217;s membership platform:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10297f35-e1ce-4889-906b-3fbd2e84ae6f_1600x1218.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1108" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10297f35-e1ce-4889-906b-3fbd2e84ae6f_1600x1218.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Let&#8217;s walk through the steps in this process:</p><ol><li><p>Suppose there is an update request to modify the billing partner for a member. The request is received by the Membership Subscription Service.</p></li><li><p>The Membership Subscription Service processes the request and updates the relevant information in the Cassandra database.</p></li><li><p>In addition to updating the primary database, the updated data for the user is appended to the Membership History Service. This service is responsible for maintaining a historical record of all changes made to membership data.</p></li><li><p>The Membership History Service takes the appended data and inserts it into the Member History Table. This table serves as a persistent store for the historical data.</p></li><li><p>Finally, an event is emitted to notify downstream systems about the membership update. This allows other services and processes to react to the change and perform any necessary actions.</p></li></ol><p>There are multiple benefits to this design:</p><ul><li><p><strong>Detailed Debugging:</strong> By maintaining a comprehensive history of membership data changes, the system enables detailed debugging and troubleshooting. Developers can trace the sequence of events and understand how the data evolved.</p></li><li><p><strong>Event Replay and Reconciliation:</strong> The append-only nature of the log system allows for the ability to replay events. In case of data corruption or inconsistencies, the system can reconcile the data by replaying the events from a known good state.</p></li><li><p><strong>Customer Service Analysis:</strong> The historical data captured by the Member History Service makes customer service analysis easy.&nbsp;</p></li></ul><h2>Technical Footprint of the Netflix Membership Platform</h2><p>The technical landscape of the Netflix membership platform can be broadly categorized into two main areas: development and operations/monitoring.&nbsp;</p><p>Let's look at each area in detail.</p><h3>Development Stack</h3><p>The development stack of Netflix&#8217;s membership platform can be described by the following key points:</p><ul><li><p>Netflix's architecture is optimized for handling high read requests per second (RPS) to support its massive user base.</p></li><li><p>The membership platform comprises over 12 microservices that communicate using gRPC at the HTTP layer. On a typical day, the platform can handle an impressive 3-4 million requests per second. To support this high volume, Netflix employs techniques like client-side caching at the gRPC level and in-memory caching of entire records to prevent CockroachDB from becoming a single point of failure.</p></li><li><p>The primary programming language used in the membership platform is Java with Spring Boot. However, in certain rewrite scenarios, Netflix is gradually transitioning to Kotlin.</p></li><li><p>Kafka plays a key role in message passing and interfacing with other teams, such as messaging and downstream analytics. This ensures smooth communication and data flow across different systems.</p></li><li><p>Netflix utilizes Spark and Flink for offline reconciliation tasks on their big data. These reconciliation jobs are crucial for maintaining data consistency and alignment between various systems of record within the membership platform, such as subscriptions and member history databases. The accuracy of data also extends to external systems, ensuring a consistent state across the entire ecosystem.</p></li><li><p>To ensure data consistency in online systems, Netflix employs lightweight transactions and uses databases like Cassandra. This approach guarantees the integrity and reliability of data across different services.</p></li></ul><h3>Operations and Monitoring</h3><p>Netflix places a strong emphasis on observability and monitoring to ensure the smooth operation of its membership platform:</p><ul><li><p>Extensive logging, dashboards, and distributed tracing mechanisms enable rapid error detection and resolution. In the complex microservice landscape of Netflix, these tools are essential for identifying and troubleshooting issues.</p></li><li><p>Production alerts are set up to track operational metrics and guarantee optimal service levels.&nbsp;</p></li><li><p>Operational data is leveraged to fuel machine learning models that enhance anomaly detection and enable automated issue resolution processes. All of this is done to try and maintain an uninterrupted streaming experience for the users.</p></li><li><p>Netflix utilizes tools like Kibana and Elasticsearch to create dashboards and analyze log data. In case of a spike in error rates, these dashboards allow the team to quickly identify the specific endpoint causing the issue and take corrective action.</p></li></ul><h2>Conclusion</h2><p>In conclusion, Netflix's membership platform is a critical component of the company's success, enabling it to manage the entire lifecycle of a user's subscription. The platform has evolved from a simple, lightweight library to a robust, scalable architecture that can handle millions of requests per second</p><p>Some key takeaways to remember are as follows:</p><ul><li><p>The membership platform is responsible for managing user signups, plan changes, renewals, and cancellations.</p></li><li><p>It utilizes a microservices architecture and makes use of databases like CockroachDB and Cassandra for storing membership data.</p></li><li><p>The platform captures and stores historical changes to membership data using CDC for debugging, event replay, and analytics.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://youtu.be/fCQKek_J3lQ?si=ibssD2zAHtbW7aG9">Managing 238M memberships at Netflix</a></p></li><li><p><a href="https://www.infoq.com/articles/managing-memberships-netflix/">Netflix&#8217;s Membership Platform</a></p></li><li><p><a href="https://www.infoq.com/presentations/netflix-scalability/">Presentation on Managing 238M memberships at Netflix</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p><br /></p>
]]></content:encoded>
<pubDate>Tue, 25 Jun 2024 15:31:15 GMT</pubDate>
</item>
<item>
<title>EP117: What makes HTTP2 faster than HTTP1?</title>
<link>https://blog.bytebytego.com/p/ep117-what-makes-http2-faster-than</link>
<guid>https://blog.bytebytego.com/p/ep117-what-makes-http2-faster-than</guid>
<content:encoded><![CDATA[
<div> Kafka, RabbitMQ, Messaging Middleware, Pulsar, HTTP2 <br />
总结:<br />
HTTP2相比HTTP1更快的原因在于其具有以下关键特点：二进制帧层使消息编码为二进制格式，实现更高效的处理；多路复用允许客户端和服务器在传输过程中交错发送请求和响应，提高效率；流优先级可定制请求或流的相对权重，确保高优先级请求得到更快响应；服务器推送允许服务器在响应请求时向客户端一并发送附加资源；HPACK头部压缩算法可减小多个请求的头部大小，节省带宽。这些特点使HTTP2实现更快速的传输，但在特定技术场景下也可能存在缓慢情况，因此开发人员需要对其进行测试和优化。Idempotency在各种场景中至关重要，特别是在可能重试或多次执行操作的情况下。Netflix利用缓存技术来保持用户关注度并增强用户体验。包括EVCache的不同用例，如Lookaside Cache、Transient Data Store、Primary Store和High Volume Data。日志解析常用命令包括GREP、CUT、SED、AWK、SORT、UNIQ，结合使用可以快速从日志文件中提取有用信息。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Kafka vs. RabbitMQ vs. Messaging Middleware vs. Pulsar (Youtube video)</p></li><li><p>What makes HTTP2 faster than HTTP1? </p></li><li><p>Top 6 Cases to Apply Idempotency</p></li><li><p>4 Ways Netflix Uses Caching to Hold User Attention</p></li><li><p>Log Parsing Cheat Sheet</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Postman_062224Headline">Collaborating on APIs Is Easier with Postman (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Postman_062224CTA" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ca59bbc-bd0c-4825-a4f5-b896c84aa121_1600x840.png" width="1456" /><div></div></div></a></figure></div><p><a href="https://bit.ly/Postman_062224Headline">API Collaboration</a> improves developer productivity by empowering producers and consumers to share, discover, and reuse high-quality API assets.</p><p>Postman revolutionizes the experience of collaborative API development with Postman <a href="https://bit.ly/Postman_062224Collections">Collections</a> and <a href="https://bit.ly/Postman_062224Workspaces">Workspaces</a>. Used together, they enable API design, testing, and documentation, while providing a shared canvas for collaborating on API assets.&nbsp;</p><p>Learn how companies like <a href="https://bit.ly/Postman_062224Cvent">Cvent</a>, <a href="https://bit.ly/Postman_062224Visma">Visma</a>, <a href="https://bit.ly/Postman_062224BuiltTech">Built Technologies</a>, and <a href="https://bit.ly/Postman_062224Amadeus">Amadeus</a> use Postman to collaborate more easily and deliver better APIs faster.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Postman_062224CTA"><span>Learn More</span></a></p><div><hr /></div><h2><strong>Kafka vs. RabbitMQ vs. Messaging Middleware vs. Pulsar</strong></h2><div class="youtube-wrap" id="youtube2-x4k1XEjNzYQ"><div class="youtube-inner"></div></div><div><hr /></div><h2>What makes HTTP2 faster than HTTP1? </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1727" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69df47d1-db12-4ad8-8dfa-033d391baa0e_1280x1727.gif" title="graphical user interface" width="1280" /><div></div></div></a></figure></div><p>The key features of HTTP2 play a big role in this. Let&#8217;s look at them: </p><ol><li><p>Binary Framing Layer <br />HTTP2 encodes the messages into binary format. <br /> <br />This allows the messages into smaller units called frames, which are then sent over the TCP connection, resulting in more efficient processing. <br /></p></li><li><p>Multiplexing <br />The Binary Framing allows full request and response multiplexing. <br /> <br />Clients and servers can interleave frames during transmissions and reassemble them on the other side. <br /></p></li><li><p>Stream Prioritization <br />With stream prioritization, developers can customize the relative weight of requests or streams to make the server send more frames for higher-priority requests. <br /></p></li><li><p>Server Push <br />Since HTTP2 allows multiple concurrent responses to a client&#8217;s request, a server can send additional resources along with the requested page to the client. <br /></p></li><li><p>HPACK Header Compression <br />HTTP2 uses a special compression algorithm called HPACK to make the headers smaller for multiple requests, thereby saving bandwidth. </p></li></ol><p>Of course, despite these features, HTTP2 can also be slow depending on the exact technical scenario. Therefore, developers need to test and optimize things to maximize the benefits of HTTP2. <br /> <br />Over to you: Have you used HTTP2 in your application?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribehttps://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1652" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5db07039-ccc9-4fb2-afc3-d9a3b1093d6a_3438x3900.jpeg" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Top 6 Cases to Apply Idempotency</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1568" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7da1d252-88b8-4d74-b026-1626cbbb8d59_1280x1568.gif" title="graphical user interface" width="1280" /><div></div></div></a></figure></div><p>Idempotency is essential in various scenarios, particularly where operations might be retried or executed multiple times. Here are the top 6 use cases where idempotency is crucial: </p><ol><li><p>RESTful API Requests <br />We need to ensure that retrying an API request does not lead to multiple executions of the same operation. Implement idempotent methods (like PUT and DELETE) to maintain consistent resource states. <br /></p></li><li><p>Payment Processing <br />We need to ensure that customers are not charged multiple times due to retries or network issues. Payment gateways often need to retry transactions; idempotency ensures only one charge is made. <br /></p></li><li><p>Order Management Systems <br />We need to ensure that submitting an order multiple times results in only one order being placed. We design a safe mechanism to prevent duplicate inventory deductions or updates. <br /></p></li><li><p>Database Operations <br />We need to ensure that reapplying a transaction does not change the database state beyond the initial application. <br /></p></li><li><p>User Account Management <br />We need to ensure that retrying a registration request does not create multiple user accounts. Also, we need to ensure that multiple password reset requests result in a single reset action. <br /></p></li><li><p>Distributed Systems and Messaging <br />We need to ensure that reprocessing messages from a queue does not result in duplicate processing. We Implement handlers that can process the same message multiple times without side effects.</p></li></ol><div><hr /></div><h2>4 Ways Netflix Uses Caching to Hold User Attention</h2><p>The goal of Netflix is to keep you streaming for as long as possible. But a user&#8217;s typical attention span is just 90 seconds.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94417c7a-9711-4103-8677-9fc64c645490_1344x1536.gif" title="No alt text provided for this image" width="1344" /><div></div></div></a></figure></div><p>They use EVCache (a distributed key-value store) to reduce latency so that the users don&#8217;t lose interest.<br /><br />However, EVCache has multiple use cases at Netflix.</p><ol><li><p>Lookaside Cache<br />When the application needs some data, it first tries the EVCache client and if the data is not in the cache, it goes to the backend service and the Cassandra database to fetch the data.<br /><br />The service also keeps the cache updated for future requests.<br /></p></li><li><p>Transient Data Store<br />Netflix uses EVCache to keep track of transient data such as playback session information. <br /><br />One application service might start the session while the other may update the session followed by a session closure at the very end.<br /></p></li><li><p>Primary Store<br />Netflix runs large-scale pre-compute systems every night to compute a brand-new home page for every profile of every user based on watch history and recommendations. <br /><br />All of that data is written into the EVCache cluster from where the online services read the data and build the homepage.<br /></p></li><li><p>High Volume Data<br />Netflix has data that has a high volume of access and also needs to be highly available. For example, UI strings and translations that are shown on the Netflix home page. <br /><br />A separate process asynchronously computes and publishes the UI string to EVCache from where the application can read it with low latency and high availability.</p></li></ol><p>Reference: <a href="https://www.youtube.com/watch?v=Rzdxgx3RC0Q">"Caching at Netflix: The Hidden Microservice" by Scott Mansfield</a></p><div><hr /></div><h2>Log Parsing Cheat Sheet</h2><p>The diagram below lists the top 6 log parsing commands. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1683" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc28f0cbc-a40f-4bdb-88be-f2a0ab900bbc_1280x1683.jpeg" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ol><li><p>GREP <br />GREP searches any given input files, selecting lines that match one or more patterns. <br /></p></li><li><p>CUT <br />CUT cuts out selected portions of each line from each file and writes them to the standard output. <br /></p></li><li><p>SED <br />SED reads the specified files, modifying the input as specified by a list of commands. <br /></p></li><li><p>AWK <br />AWK scans each input file for lines that match any of a set of patterns. <br /></p></li><li><p>SORT <br />SORT sorts text and binary files by lines. <br /></p></li><li><p>UNIQ <br />UNIQ reads the specified input file comparing adjacent lines and writes a copy of each unique input line to the output file. </p></li></ol><p>These commands are often used in combination to quickly find useful information from the log files. For example, the below commands list the timestamps (column 2) when there is an exception happening for xxService. <br /> <br />grep &#8220;xxService&#8221; service.log | grep &#8220;Exception&#8221; | cut -d&#8221; &#8220; -f 2 <br /> <br />Over to you: What other commands do you use when you parse logs?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 22 Jun 2024 15:31:01 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Microservice Communication Patterns</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication</guid>
<content:encoded><![CDATA[
<div> 网络挑战,进程通信,通信模式,性能可扩展性,优劣点

总结:<br /><br />微服务架构带来了独立服务开发的优势，但服务间仍需相互通信以构建一个协调的系统。然而，微服务间通信存在网络挑战和进程通信等困难。开发者在选择通信模式时需要考虑问题的特殊需求，否则会导致性能和可扩展性不佳。本文探讨了微服务的各种通信模式，包括其优势、劣势和最佳使用情况。Microservices architecture promotes the development of independent services. However, these services still need to communicate with each other to function as a cohesive system. Getting the communication right between microservices is often a challenge. There are two primary reasons for this: When microservices communicate over a network, they face inherent challenges associated with inter-process communication. Developers often choose a communication pattern without carefully considering the specific needs of the problem. This can lead to suboptimal performance and scalability. In this post, we explore various communication patterns for microservices and discuss their strengths, weaknesses, and ideal use cases. But first, let’s look at the key challenges associated with microservice communication. <div>
<p>Microservices architecture promotes the development of independent services. However, these services still need to communicate with each other to function as a cohesive system.&nbsp;</p><p>Getting the communication right between microservices is often a challenge. There are two primary reasons for this:</p><ul><li><p>When microservices communicate over a network, they face inherent challenges associated with inter-process communication.</p></li></ul><ul><li><p>Developers often choose a communication pattern without carefully considering the specific needs of the problem. This can lead to suboptimal performance and scalability.</p></li></ul><p>In this post, we explore various communication patterns for microservices and discuss their strengths, weaknesses, and ideal use cases.</p><p>But first, let&#8217;s look at the key challenges associated with microservice communication.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1652" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5db07039-ccc9-4fb2-afc3-d9a3b1093d6a_3438x3900.jpeg" width="1456" /><div></div></div></a></figure></div><h2>Why is Microservice Communication Challenging?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 20 Jun 2024 15:30:51 GMT</pubDate>
</item>
<item>
<title>Scaling to 1.2 Billion Daily API Requests with Caching at RevenueCat</title>
<link>https://blog.bytebytego.com/p/scaling-to-12-billion-daily-api-requests</link>
<guid>https://blog.bytebytego.com/p/scaling-to-12-billion-daily-api-requests</guid>
<content:encoded><![CDATA[
<div> BoldSign, Syncfusion, 缓存, RevenueCat, 数据一致性
总结: BoldSign是Syncfusion提供的电子签名服务，易于开发人员集成。RevenueCat是一个管理应用内订阅和购买的平台，处理大量API请求。RevenueCat通过多种策略保持缓存服务器热。缓存一致性是一个重要挑战，RevenueCat使用写入失败跟踪和一致的CRUD操作来维护数据一致性。缓存服务器迁移时，他们通过逐步切换读取流量来保持数据一致性。 <div>
<h2><a href="https://bit.ly/BoldSign_061824Image">Effortlessly Integrate E-Signatures into Your App with BoldSign (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/BoldSign_061824Image" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="762" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef0928fd-63b8-4e6f-b510-0eb50b2958fe_2400x1256.png" width="1456" /><div></div></div></a></figure></div><p>BoldSign by Syncfusion makes it easy for developers to integrate e-signatures into applications.</p><p>Our powerful <a href="https://bit.ly/BoldSign_061824Image">e-signature API</a> allows you to embed signature requests, create templates, add custom branding, and more.&#8239;&nbsp;</p><p>It&#8217;s so easy to get started that 60% of our customers integrated BoldSign into their apps within one day.&#8239;&nbsp;</p><p>Why BoldSign stands out:&nbsp;</p><ul><li><p>99.999% uptime.&nbsp;</p></li><li><p>Trusted by Ryanair, Cost Plus Drugs, and more.&nbsp;</p></li><li><p>Complies with eIDAS, ESIGN, GDPR, SOC 2, and HIPAA standards.&nbsp;</p></li><li><p>No hidden charges.&nbsp;</p></li><li><p>Free migration support.&#8239;&nbsp;</p></li><li><p>Rated 4.7/5 on G2.&nbsp;</p></li><li><p>Get 20% off the first year with code BYTEBYTEGO20. Valid until Sept. 31, 2024.</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/BoldSign_061824Image"><span>Get started</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the article originally published on the RevenueCat Engineering Blog. All credit for the details about RevenueCat&#8217;s architecture goes to their engineering team. The link to the original article is present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>RevenueCat is a platform that makes it easy for mobile app developers to implement and manage in-app subscriptions and purchases.&nbsp;</p><p>The staggering part is that they handle over 1.2 billion API requests per day from the apps.&nbsp;</p><p>At this massive scale, a fast and reliable performance becomes critical. Some of it is achieved by distributing the workload uniformly across multiple servers.</p><p>However, an efficient caching solution also becomes the need of the hour.</p><p>Caching allows frequently accessed data to be quickly retrieved from fast memory rather than slower backend databases and systems. This can dramatically speed up response times.&nbsp;</p><p>But caching also adds complexity since the cached data must be kept consistent with the source of truth in the databases. Stale or incorrect data in the cache can lead to serious issues.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36d24246-df04-441c-992b-8fad8774a5a5_1600x989.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36d24246-df04-441c-992b-8fad8774a5a5_1600x989.png" /><div></div></div></a></figure></div><p>For an application operating at the scale of RevenueCat, even small inefficiencies or inconsistencies in the caching layer can have a huge impact.&nbsp;</p><p>In this post, we will look at how RevenueCat overcame multiple challenges to build a truly reliable and scalable caching solution using Memcached.</p><div><hr /></div><h2>The Three Key Goals of Caching</h2><p>RevenueCat has three key goals for its caching infrastructure:</p><ul><li><p><strong>Low latency</strong>: The cache needs to be fast because even small delays in the caching layer can have significant consequences at this request volume. Retrying requests and opening new connections are detrimental to the overall performance.&nbsp;</p></li><li><p><strong>Keeping cache servers up and warm</strong>: Cache servers need to stay available and full of frequently accessed data to offload the backend systems.&nbsp;</p></li><li><p><strong>Maintaining data consistency</strong>: Data in the cache needs to be consistent. Inconsistency can lead to serious application issues.&nbsp;</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd66e961c-d13b-4b35-95e9-92354e2aea7e_1600x1102.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd66e961c-d13b-4b35-95e9-92354e2aea7e_1600x1102.png" /><div></div></div></a></figure></div><p>While these main goals are highly relevant to applications operating at scale, a robust caching solution also needs supporting features such as monitoring and observability, optimization, and some sort of automated scaling.</p><p>Let&#8217;s look at each of these goals in more detail and how RevenueCat&#8217;s engineering team achieved them.</p><h2>Low Latency</h2><p>There&#8217;s no doubt that latency has a huge impact on user experience.&nbsp;</p><p>As per a statistic by Amazon, every 100ms of latency costs them 1% in sales. While it&#8217;s hard to confirm whether this is 100% true, there&#8217;s no denying the fact that latency impacts user experience.</p><p>Even small delays of a few hundred milliseconds can make an application feel sluggish and unresponsive. As latency increases, user engagement and satisfaction plummet.</p><p>RevenueCat achieves low latency in its caching layer through two key techniques.</p><h3>1 - Pre-established connections</h3><p>Their cache client maintains a pool of open connections to the cache servers.&nbsp;</p><p>When the application needs to make a cache request, it borrows a connection from the pool instead of establishing a new TCP one. This is because a TCP handshake could nearly double the cache response times. Borrowing the connection avoids the overhead of the TCP handshake on each request.&nbsp;</p><p>But no decision comes without some tradeoff.</p><p>Keeping connections open consumes memory and other resources on both the client and server. Therefore, it&#8217;s important to carefully tune the number of connections to balance resource usage with the ability to handle traffic spikes.</p><h3>2 - Fail-fast approach</h3><p>If a cache server becomes unresponsive, the client immediately marks it as down for a few seconds and fails the request, treating it as a cache miss.&nbsp;</p><p>In other words, the client will not retry the request or attempt to establish new connections to the problematic server during this period.</p><p>The key insight here is that even brief retry delays of 100ms can cause cascading failures under heavy load. Requests pile up, servers get overloaded, and the "retry storm" can bring the whole system down. Though it might sound counterintuitive, failing fast is crucial for a stable system.</p><p>But what&#8217;s the tradeoff here?</p><p>There may be a slight increase in cache misses when servers have temporary issues. But this is far better than risking a system-wide outage. A 99.99% cache hit rate is meaningless if 0.01% of requests trigger cascading failures. Prioritizing stability over perfect efficiency is the right call.</p><p>One potential enhancement over here could be circuit breaking where requests to misbehaving servers can be disabled based on error rates and latency measurements. This is something that Uber uses in their integrated cache solution called CacheFront.</p><p>However, the aggressive timeouts and managing connection pools likely achieve similar results with far less complexity.</p><h2>Keeping Cache Servers Warm</h2><p>The next goal RevenueCat had was keeping the cache servers warm.</p><p>They employed several strategies to achieve this.</p><h3>1 - Planning for Failure with Mirrored and Gutter pool</h3><p>RevenueCat uses fallback cache pools to handle failures.&nbsp;</p><p>Their strategy is designed to handle cache server failures and maintain high availability. The two approaches they use are as follows:</p><ul><li><p><strong>Mirrored pool:</strong> A fully synchronized secondary cache pool that receives all writes and can immediately take over reads if the primary pool fails.</p></li><li><p><strong>Gutter pool:</strong> A small, empty cache pool that temporarily caches values with a short TTL when the primary pool fails, reducing the load on the backend until the primary recovers. For reference, the gutter pool technique was also used by Facebook when they built their caching architecture with Memcached.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50aeb09f-579f-4df0-bb95-31c37134dafb_1600x925.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50aeb09f-579f-4df0-bb95-31c37134dafb_1600x925.png" /><div></div></div></a></figure></div><p>Here also, there are trade-offs to consider concerning server size:</p><p>For example, having smaller servers provides benefits such as:</p><ul><li><p><strong>Granular failure impact:</strong> With many small cache servers, the failure of a single server affects a smaller portion of the cached data. This can make the fallback pool more effective, as it needs to handle a smaller subset of the total traffic.</p></li><li><p><strong>Faster warmup:</strong> When a small server fails and the gutter pool takes over, it can warm up the cache for that server&#8217;s key space more quickly due to the smaller data volume.</p></li></ul><p>However, small servers also have drawbacks:</p><ul><li><p>Increased operational complexity of managing a larger number of servers adds operational complexity.&nbsp;</p></li><li><p>A higher connection overhead where each application server has to maintain connections to all cache servers.&nbsp;</p></li></ul><p>The diagram below from RevenueCat&#8217;s article shows this comparison:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20cacb99-819b-4a42-925c-7eed2bbc2626_1534x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1519" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20cacb99-819b-4a42-925c-7eed2bbc2626_1534x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><ul><li><p><strong>Simplified management:</strong> Fewer large servers are easier to manage and maintain compared to many small instances. There are fewer moving parts and less complexity in the overall system.</p></li><li><p><strong>Improved resource utilization:</strong> Larger servers can more effectively utilize the available CPU, memory, and network resources, leading to better cost efficiency.</p></li><li><p><strong>Fewer connections:</strong> With fewer cache servers, the total number of connections from the application servers is reduced, minimizing connection overhead.</p></li></ul><p>Bigger servers also have some trade-offs:</p><ul><li><p>When a large server fails, a larger portion of the cached data becomes unavailable. The fallback pool needs to handle a larger volume of traffic, potentially increasing the load on the backend.</p></li><li><p>In the case of a failure, warming up the cache for a larger key space may take longer due to the increased data volume.</p></li></ul><p>This is where the strategy of using a mirrored pool for fast failover and a gutter pool for temporary caching strikes a balance between availability and cost.&nbsp;</p><p>The mirrored pool ensures immediate availability. The gutter pool, on the other hand, provides a cost-effective way to handle failures temporarily.</p><p>Generally speaking, it&#8217;s better to design the cache tier based on a solid understanding of the backend capacity. Also, when using sharding, the cache, and the backend sharding should be orthogonal so that a cache server going down translates into a moderate increase on backend servers.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="883" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84724fef-c993-411d-9ad9-07aabc1d7542_1600x970.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>2 - Dedicated Pools</h3><p>Another technique they employ to keep cache servers warm is to use dedicated cache pools for certain use cases.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48b6bfd0-9267-4a51-bf23-dc1f0cae76c7_1600x1191.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1084" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48b6bfd0-9267-4a51-bf23-dc1f0cae76c7_1600x1191.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s how the strategy works:</p><ul><li><p><strong>Identifying high-value data</strong>: The first step is to analyze the application's data access patterns and identify datasets that are crucial for performance, accuracy, or user experience. This could include frequently accessed configuration settings, important user-specific data, or computationally expensive results.</p></li><li><p><strong>Creating dedicated pools: </strong>Instead of relying on a single shared cache pool, create separate pools for each identified high-value dataset. These dedicated pools have their own allocated memory and operate independently from the main cache pool.</p></li><li><p><strong>Reserving memory:</strong> By allocating dedicated memory to each pool, they ensure that the high-value data has a guaranteed space in the cache. This prevents other less critical data from evicting the important information, even under high memory pressure.</p></li><li><p><strong>Tailored eviction policies:</strong> Each dedicated pool can have its eviction policy tailored to the specific characteristics of the dataset. For example, a pool holding expensive-to-recompute data might have a longer TTL or a different eviction algorithm compared to a pool with frequently updated data.</p></li></ul><p>The dedicated pools strategy has several advantages:</p><ul><li><p>Improved cache hit ratio for critical data</p></li><li><p>Increased data accuracy</p></li><li><p>Flexibility in cache management</p></li></ul><h3>3 - Handling Hot Keys</h3><p>Hot keys are a common challenge in caching systems.&nbsp;</p><p>They refer to keys that are accessed more frequently than others, leading to a high concentration of requests on a single cache server. This can cause performance issues and overload the server, potentially impacting the overall system.</p><p>There are two main strategies for handling hot keys:</p><h4>Key Splitting</h4><p>The below points explain how key splitting works:</p><ul><li><p>Key splitting involves distributing the load of a hot key across multiple servers.</p></li><li><p>Instead of having a single key, the key is split into multiple versions, such as keyX/1, keyX/2, keyX/3, etc.</p></li><li><p>Each version of the key is placed on a different server, effectively spreading the load.</p></li><li><p>Clients read from one version of the key (usually determined by their client ID) but write to all versions to maintain consistency.</p></li><li><p>The challenge with key splitting is detecting hot keys in real time and coordinating the splitting process across all clients.</p></li><li><p>It requires a pipeline to identify hot keys, determine the splitting factor, and ensure that all clients perform the splitting simultaneously to avoid inconsistencies.</p></li><li><p>The list of hot keys is dynamic and can change based on real-life events or trends, so the detection and splitting process needs to be responsive.</p></li></ul><h4>Local Caching</h4><p>Local caching is simpler when compared to key splitting.</p><p>Here are some points to explain how it works:</p><ul><li><p>Local caching involves caching hot keys directly on the client-side, rather than relying solely on the distributed cache.</p></li><li><p>A key is cached locally on the client with a short TTL (Time-To-Live) when a key is identified as hot.</p></li><li><p>Subsequent requests for that key are served from the local cache, reducing the load on the distributed cache servers.</p></li><li><p>Local caching doesn't require coordination among clients.</p></li><li><p>However, local caching provides weaker consistency guarantees since the locally cached data may become stale if updates occur frequently.</p></li><li><p>To mitigate this, it&#8217;s important to use short TTLs for locally cached keys and only apply local caching to data that changes rarely.</p></li></ul><h3>Avoiding Thundering Herds</h3><p>When a popular key expires, all clients may request it from the backend simultaneously, causing a spike. This is known as the &#8220;thundering herd situation&#8221;.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6d6a925-6fea-4c79-b9c1-7256764f94c0_1532x992.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6d6a925-6fea-4c79-b9c1-7256764f94c0_1532x992.png" /><div></div></div></a></figure></div><p>RevenueCat avoids this situation since it tries to maintain cache consistency by updating it during the writes. However, when using low TTLs and invalidations from DB changes, the thundering herd can cause a lot of problems.</p><p>Some other potential solutions to avoid thundering herds are as follows:</p><ul><li><p><strong>Recache policy: </strong>The GET requests can include a recache policy. When the remaining TTL is less than the given value, one of the clients will get a miss and re-populate the value in the cache while other clients continue to use the existing value.</p></li><li><p><strong>Stale policy: </strong>In the delete command, the key is marked as stale. A single client gets a miss while others keep using the old value.</p></li><li><p><strong>Lease policy:</strong> In this policy, only one client wins the right to repopulate the value while the losers just have to wait for the winner to re-populate. For reference, Facebook uses leasing in its Memcache setup.</p></li></ul><h3>Cache Server Migrations</h3><p>Sometimes cache servers have to be replaced while minimizing impact on hit rates and user experience.</p><p>RevenueCat has built a coordinated cache server migration system that consists of the following steps:</p><ol><li><p>Warming up the new cluster:</p><ul><li><p>Before switching traffic, the team starts warming up the new cache cluster.</p></li><li><p>They populate the new cluster by mirroring all the writes from the existing cluster.</p></li><li><p>This ensures that the new cluster has the most up-to-date data before serving any requests.</p></li></ul></li><li><p>Switching a percentage of reads:</p><ul><li><p>After the new cluster is sufficiently warm, the team gradually switches a percentage of read traffic to it.</p></li><li><p>This allows them to test the new cluster&#8217;s performance and stability under real-world load.</p></li></ul></li><li><p>Flipping all traffic:</p><ul><li><p>Once the new cluster has proven its stability and performance, the traffic is flipped over to it.</p></li><li><p>At this point, the new cluster becomes the primary cache cluster, serving all read and write requests.</p></li><li><p>The old cluster is kept running for a while, with writes still being mirrored to it. This allows quick fallback in case of any issues.</p></li></ul></li><li><p>Decommissioning the old cluster:</p><ul><li><p>After a period of stable operation with the new cluster as the primary, the old cluster is decommissioned.</p></li><li><p>This frees up resources and completes the migration process.</p></li></ul></li></ol><p>The diagram below shows the entire migration process.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4d8294c-1c80-4b9a-aa1c-14e3f8e819d9_1575x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1479" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4d8294c-1c80-4b9a-aa1c-14e3f8e819d9_1575x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Maintaining data consistency is one of the biggest challenges when using caching in distributed systems.&nbsp;</p><p>The fundamental issue is that data is stored in multiple places - the primary data store (like a database) and the cache. Keeping the data in sync across these locations in the face of concurrent reads and writes is a non-trivial problem.</p><p>See the example below that shows how a simple race condition can result in a consistency problem between the database and the cache.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede53f17-11f8-400e-9067-a70b78ca3238_1600x948.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede53f17-11f8-400e-9067-a70b78ca3238_1600x948.png" /><div></div></div></a><figcaption class="image-caption">Source: <a href="https://www.revenuecat.com/blog/engineering/data-caching-revenuecat/">RevenueCat Engineering Blog</a></figcaption></figure></div><p>What&#8217;s going on over here?</p><ul><li><p>Web Server 1 gets a cache miss and fetches data from the database.</p></li><li><p>A second request results in Web Server 2 performing a DB Write for the same data. It also updates the cache with the new data</p></li><li><p>Web Server 2 refills the cache with the stale data that it had fetched in step 1.</p></li></ul><p>RevenueCat uses two main strategies to maintain cache consistency.</p><h3>1 - Write Failure Tracking</h3><p>In RevenueCat's system, a cache write failure is a strong signal that there may be an inconsistency between the cache and the primary store.&nbsp;</p><p>However, there are better options than simply retrying the write because that can lead to cascading failures and overload as discussed earlier.</p><p>Instead, RevenueCat's caching client records all write failures. After recording, it deduplicates them and ensures that the affected keys are invalidated in the cache at least once (retrying as needed until successful). This guarantees that the next read for those keys will fetch fresh data from the primary store, resynchronizing the cache.</p><p>This write failure tracking allows them to treat cache writes as if they should always succeed, significantly simplifying their consistency model. They can assume the write succeeded, and if it didn't, the tracker will ensure eventual consistency.</p><h3>2 - Consistent CRUD Operations</h3><p>For each type of data operation (Create, Read, Update, Delete), they have developed a strategy to keep the cache and primary store in sync.</p><p>For reads, they use the standard cache-aside pattern: read from the cache, and on a miss, read from the primary store and populate the cache. They always use an "add" operation to populate, which only succeeds if the key doesn't already exist, to avoid overwriting newer values.</p><p>For updates, they use a clever strategy as follows:</p><ul><li><p>Before the update, they reduce the cache entry's TTL to a low value like 30 seconds</p></li><li><p>They update the primary data store</p></li><li><p>After the update, they update the cache with the new value and reset the TTL</p></li></ul><p>If a failure occurs between steps 1 and 2, the cache remains consistent as the update never reaches the primary store. If a failure occurs between 2 and 3, the cache will be stale, but only for a short time until the reduced TTL expires. Also, any complete failures are caught by the write failure tracker that we talked about earlier.</p><p>For deletes, they use a similar TTL reduction strategy before the primary store delete.&nbsp;</p><p>However, for creation, they rely on the primary store to provide unique IDs to avoid conflicts.</p><h2>Conclusion</h2><p>RevenueCat&#8217;s approach illustrates the complexities of running caches at a massive scale. While some details may be specific to their Memcached setup, the high-level lessons are widely relevant.</p><p>Here are some key takeaways to consider from this case study:</p><ul><li><p>Use low timeouts and fail fast on cache misses. Retries can cause cascading failures under load.</p></li><li><p>Plan cache capacity for failure scenarios. Ensure the system can handle multiple cache servers going down without overloading backends.</p></li><li><p>Use fallback and dedicated cache pools. Mirrored fallback pools and dedicated pools for critical data help keep caches warm and handle failures.</p></li><li><p>Handle hot keys through splitting or local caching. Distribute load from extremely popular keys across servers or cache them locally with low TTLs.</p></li><li><p>Avoid "thundering herds" with techniques like stale-while-revalidate and leasing.</p></li><li><p>Track and handle cache write failures. Assume writes always succeed but invalidate on failure to maintain consistency.</p></li><li><p>Implement well-tested strategies for cache updates during CRUD operations. Techniques like TTL reduction before writes help maintain consistency across cache and database.</p></li></ul><p>References:</p><ul><li><p><a href="https://www.revenuecat.com/blog/engineering/data-caching-revenuecat/">Scaling Smoothly: RevenueCat&#8217;s data-caching techniques for 1.2 billion daily API requests</a></p></li><li><p><a href="https://www.infoq.com/news/2024/01/revenuecat-cache-management/">How RevenueCat Manages Caching for Handling over 1.2 Billion API Requests</a></p></li><li><p><a href="https://research.facebook.com/publications/scaling-memcache-at-facebook/">Scaling Memcache at Facebook</a></p></li><li><p><a href="https://www.uber.com/en-IN/blog/how-uber-serves-over-40-million-reads-per-second-using-an-integrated-cache/">How Uber Serves Over 40 Million Reads Per Second from Online Storage Using Integrated Cache</a></p></li><li><p><a href="https://www.gigaspaces.com/blog/amazon-found-every-100ms-of-latency-cost-them-1-in-sales">Amazon Found Every 100ms of Latency Cost Them 1% in Sales</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></p><p></p>
]]></content:encoded>
<pubDate>Tue, 18 Jun 2024 15:30:55 GMT</pubDate>
</item>
<item>
<title>EP116: 11 steps to go from Junior to Senior Developer</title>
<link>https://blog.bytebytego.com/p/ep116-11-steps-to-go-from-junior</link>
<guid>https://blog.bytebytego.com/p/ep116-11-steps-to-go-from-junior</guid>
<content:encoded><![CDATA[
<div> Data Pipeline, Senior Developer, Docker concepts, Microservice architecture, Open-Source Databases
<br />
Data Pipeline是什么？为什么这么受欢迎？数据管道是数据处理流程的自动化，十分流行。成为高级开发人员的11个步骤包括使用合作工具、精通编程语言、API开发、Web服务器与托管、身份验证与测试、数据库、CI/CD、数据结构与算法、系统设计、设计模式、AI工具等。Docker有8个重要概念，如Dockerfile、Docker镜像、容器、注册表、卷、Compose、网络、CLI等。典型微服务架构包括负载均衡器、CDN、API网关、身份验证提供者、服务注册与发现、管理及微服务等组件。最受欢迎的开源数据库包括MySQL、PostgreSQL、MariaDB、Apache Cassandra、Neo4j、SQLite、CockroachDB、Redis、MongoDB、Couchbase等。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>What is Data Pipeline? | Why Is It So Popular? (Youtube video)</p></li><li><p>11 steps to go from Junior to Senior Developer</p></li><li><p>Top 8 must-know Docker concepts </p></li><li><p>What does a typical microservice architecture look like? </p></li><li><p>Top 10 Most Popular Open-Source Databases </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/NewRelic_061524">New Relic Digital Monitoring Experience (DEM) (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/NewRelic_061524" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="680" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2750532-75bd-4c68-ba57-78c3a39bfb9e_1296x680.png" width="1296" /><div></div></div></a></figure></div><p>New Relic DEM solutions are designed to provide comprehensive insights into digital operations, allowing teams to optimize user experiences in real time.</p><p>Download the datasheet&nbsp;for an overview of New Relic DEM capabilities:</p><ul><li><p><strong>Real user monitoring (RUM):</strong> Browser monitoring and mobile monitoring&nbsp;&nbsp;</p></li><li><p><strong>Pixel-perfect replays:</strong> Session replay</p></li><li><p><strong>Proactive issue detection:&nbsp;</strong>Synthetic monitoring, mobile user journeys (crash analysis), and error tracking (errors inbox)</p></li><li><p><strong>Integration and collaboration:</strong> In-app collaboration capabilities&nbsp;</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/NewRelic_061524"><span>Download the data sheet</span></a></p><div><hr /></div><h2>What is Data Pipeline? | Why Is It So Popular?</h2><div class="youtube-wrap" id="youtube2-kGT4PcTEPP8"><div class="youtube-inner"></div></div><div><hr /></div><h2>11 steps to go from Junior to Senior Developer</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1562" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507dbf27-df25-4d96-b09a-0a89e4b27ea4_1280x1562.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><ol><li><p>Collaboration Tools <br />Software development is a social activity. Learn to use collaboration tools like Jira, Confluence, Slack, MS Teams, Zoom, etc. <br /></p></li><li><p>Programming Languages <br />Pick and master one or two programming languages. Choose from options like Java, Python, JavaScript, C#, Go, etc. <br /></p></li><li><p>API Development <br />Learn the ins and outs of API Development approaches such as REST, GraphQL, and gRPC. <br /></p></li><li><p>Web Servers and Hosting <br />Know about web servers as well as cloud platforms like AWS, Azure, GCP, and Kubernetes <br /></p></li><li><p>Authentication and Testing <br />Learn how to secure your applications with authentication techniques such as JWTs, OAuth2, etc. Also, master testing techniques like TDD, E2E Testing, and Performance Testing <br /></p></li><li><p>Databases <br />Learn to work with relational (Postgres, MySQL, and SQLite) and non-relational databases (MongoDB, Cassandra, and Redis). <br /></p></li><li><p>CI/CD <br />Pick tools like GitHub Actions, Jenkins, or CircleCI to learn about continuous integration and continuous delivery. <br /></p></li><li><p>Data Structures and Algorithms <br />Master the basics of DSA with topics like Big O Notation, Sorting, Trees, and Graphs. <br /></p></li><li><p>System Design <br />Learn System Design concepts such as Networking, Caching, CDNs, Microservices, Messaging, Load Balancing, Replication, Distributed Systems, etc. <br /></p></li><li><p>Design patterns <br />Master the application of design patterns such as dependency injection, factory, proxy, observers, and facade. <br /></p></li><li><p>AI Tools <br />To future-proof your career, learn to leverage AI tools like GitHub Copilot, ChatGPT, Langchain, and Prompt Engineering. </p></li></ol><p>Over to you: What else would you add to the roadmap?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="938" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2490fa0-671a-4248-81d9-7106dd8411eb_1600x1031.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Top 8 must-know Docker concepts </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F033ac539-080f-4ad6-87e5-643b18ec3956_1498x1536.gif" title="graphical user interface, application" /><div></div></div></a></figure></div><ol><li><p>Dockerfile: It contains the instructions to build a Docker image by specifying the base image, dependencies, and run command. <br /> </p></li><li><p>Docker Image: A lightweight, standalone package that includes everything (code, libraries, and dependencies) needed to run your application. Images are built from a Dockerfile and can be versioned. <br /></p></li><li><p>Docker Container: A running instance of a Docker image. Containers are isolated from each other and the host system, providing a secure and reproducible environment for running your apps. <br /></p></li><li><p>Docker Registry: A centralized repository for storing and distributing Docker images. For example, Docker Hub is the default public registry but you can also set up private registries. <br /></p></li><li><p>Docker Volumes: A way to persist data generated by containers. Volumes are outside the container&#8217;s file system and can be shared between multiple containers. <br /></p></li><li><p>Docker Compose: A tool for defining and running multi-container Docker applications, making it easy to manage the entire stack. <br /></p></li><li><p>Docker Networks: Used to enable communication between containers and the host system. Custom networks can isolate containers or enable selective communication. <br /></p></li><li><p>Docker CLI: The primary way to interact with Docker, providing commands for building images, running containers, managing volumes, and performing other operations. </p></li></ol><p>Over to you: What other concept should one know about Docker?</p><div><hr /></div><h2>What does a typical microservice architecture look like? &#128071;</h2><p>The diagram below shows a typical microservice architecture.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1779" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c8d4eab-24cb-49c6-92fa-6e914603b21b_1280x1779.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ul><li><p>Load Balancer: This distributes incoming traffic across multiple backend services.</p></li><li><p>CDN (Content Delivery Network): CDN is a group of geographically distributed servers that hold static content for faster delivery. The clients look for content in CDN first, then progress to backend services.</p></li><li><p>API Gateway: This handles incoming requests and routes them to the relevant services. It talks to the identity provider and service discovery.</p></li><li><p>Identity Provider: This handles authentication and authorization for users.</p></li><li><p>Service Registry &amp; Discovery: Microservice registration and discovery happen in this component, and the API gateway looks for relevant services in this component to talk to.</p></li><li><p>Management: This component is responsible for monitoring the services.</p></li><li><p>Microservices: Microservices are designed and deployed in different domains. Each domain has its database.</p></li></ul><p>Over to you: </p><ol><li><p>What are the drawbacks of the microservice architecture?</p></li><li><p>Have you seen a monolithic system be transformed into microservice architecture? How long does it take?</p></li></ol><div><hr /></div><h2>Top 10 Most Popular Open-Source Databases </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1622" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea57069-5a32-4f02-b015-2bdb883dd135_1280x1622.gif" title="diagram" width="1280" /><div></div></div></a></figure></div><p>This list is based on factors like adoption, industry impact, and the general awareness of the database among the developer community. </p><ol><li><p>MySQL </p></li><li><p>PostgreSQL </p></li><li><p>MariaDB </p></li><li><p>Apache Cassandra </p></li><li><p>Neo4j </p></li><li><p>SQLite </p></li><li><p>CockroachDB </p></li><li><p>Redis </p></li><li><p>MongoDB </p></li><li><p>Couchbase </p></li></ol><p>Over to you: Which other database would you add to this list?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 15:31:04 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Cell-based Architecture</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture</guid>
<content:encoded><![CDATA[
<div> bulkheads, cell-based architecture, independent, failure isolation, workload
<br />
cell-based architecture是一种软件开发架构，类似于船只内部的防水隔舱，将工作负载分割成多个独立的cell，每个cell独立运行，不共享状态，处理部分流量请求。这种架构减小了故障影响范围，一旦一个cell发生故障，仅影响部分工作负载，不会引起整体系统崩溃。通过实现故障隔离，cell-based architecture提高了系统的稳定性和可靠性。 <div>
<p>No one wants to sail in a ship that can sink because of a single hull breach.</p><p>This led to the development of bulkheads, which are vertical partition walls that divide a ship&#8217;s interior into watertight compartments.</p><p>Cell-based architecture attempts to follow the same concept in software development.</p><p>In cell-based architecture, there are multiple isolated instances of a workload, where each instance is known as a cell. There are three properties of a cell:</p><ul><li><p>Each cell is independent.</p></li><li><p>A cell does not share the state with other cells.</p></li><li><p>Each cell handles a subset of the overall traffic.</p></li></ul><p>For example, imagine a web application that handles user requests. In a cell-based architecture, multiple cells of the same web application would be deployed, each serving a subset of the user requests. These cells are copies of the same application working together to distribute the workload.</p><p>This approach reduces the blast radius of impact. If a workload uses 5 cells to service 50 requests, a failure in only one cell means that 80% of the requests are unaffected by the failure.</p><p>In other words, failure isolation is the biggest benefit of a cell-based architecture.</p><p>In this post, we will learn about the various aspects of cell-based architecture and its various components in more detail.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2490fa0-671a-4248-81d9-7106dd8411eb_1600x1031.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="938" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2490fa0-671a-4248-81d9-7106dd8411eb_1600x1031.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>What is a Workload?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 15:30:19 GMT</pubDate>
</item>
<item>
<title>How PayPal Scaled Kafka to 1.3 Trillion Daily Messages</title>
<link>https://blog.bytebytego.com/p/how-paypal-scaled-kafka-to-13-trillion</link>
<guid>https://blog.bytebytego.com/p/how-paypal-scaled-kafka-to-13-trillion</guid>
<content:encoded><![CDATA[
<div> Kafka, PayPal, Cluster Management, Monitoring, ACLs
<br />
Kafka是PayPal的关键组件，他们在Cluster Management和Monitoring方面进行了重要的改进。他们引入了ACLs来控制Kafka集群的访问权限。此外，他们建立了专门的QA环境，用于测试和验证变更。总结: PayPal在Kafka平台上的操作经验为大规模运营提供了重要的启示。他们强调工具化操作和持续监控，通过引入ACLs提高安全性，建立QA环境提高开发效率。 <div>
<h2><a href="https://bit.ly/ScyllaDB_061124">Database Performance at Scale: A Practical Guide [FREE BOOK] (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/ScyllaDB_061124" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Face0df4f-42a2-4e55-aab7-1a4841ad3a4e_1600x840.png" width="1456" /><div></div></div></a></figure></div><p>Discover new ways to optimize database performance &#8211; and avoid common pitfalls &#8211; in this free 270-page book.</p><p>This book shares best practices for achieving predictable low latency at high throughput. It&#8217;s based on learnings from thousands of real-world database use cases &#8211; including Discord, Disney, Strava, Expedia, Epic Games &amp; more.</p><ul><li><p>Explore often-overlooked factors that impact database performance at scale</p></li><li><p>Recognize the performance challenges teams face with different types of workloads</p></li><li><p>Select database infrastructure and topology that&#8217;s suited to your needs</p></li><li><p>Optimize how you benchmark and monitor performance</p></li><li><p>Avoid common mistakes that impact latency and throughput</p></li><li><p>Get practical advice for navigating performance tradeoffs</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/ScyllaDB_061124"><span>Download for free</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the article originally published on the PayPal Tech Blog. All credit for the details about PayPal&#8217;s architecture goes to their engineering team. The link to the original article is present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>In the 2022 Retail Friday, PayPal&#8217;s Kafka setup witnessed a traffic volume of 21 million messages per second.</p><p>This was about 1.3 trillion messages in a single day.&nbsp;</p><p>Similarly, Cyber Monday resulted in 19 million messages per second coming to around 1.23 trillion messages in a single day.</p><p>How did PayPal scale Kafka to achieve these incredible numbers?</p><p>In this post, we will go through the complete details of PayPal&#8217;s high-performance Kafka setup that made it possible.</p><div><hr /></div><h2>Kafka at PayPal</h2><p>Apache Kafka is an open-source distributed event streaming platform.</p><p>PayPal adopted Kafka in 2015 and they use it for building data streaming pipelines, integration, and ingestion.</p><p>At present, PayPal&#8217;s Kafka fleet consists of over 1500 brokers hosting 20,000 topics. The 85+ clusters are expected to maintain a 99.99% availability.</p><p>Over the years, PayPal has seen tremendous growth in streaming data and they wanted to ensure high availability, fault tolerance, and optimal performance.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f4ab7cc-f445-44f3-8f13-a1b70a41b13b_1600x1512.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1376" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f4ab7cc-f445-44f3-8f13-a1b70a41b13b_1600x1512.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Some of the specific use cases where PayPal uses Kafka are as follows:&nbsp;</p><ul><li><p><strong>First-party Tracking: </strong>Tracking user interactions and clickstream data on PayPal&#8217;s website and mobile app for real-time analytics and personalization.</p></li><li><p><strong>Application Health Metrics: </strong>Collecting and aggregating performance metrics from various PayPal services to monitor system health and detect anomalies.</p></li><li><p><strong>Database Synchronization: </strong>Synchronizing data between PayPal&#8217;s primary database and secondary databases for disaster recovery and high availability.</p></li><li><p><strong>Application Log Aggregation: </strong>Collecting and centralizing log data from different PayPal applications and services for troubleshooting, monitoring, and analysis.</p></li><li><p><strong>Batch Processing: </strong>Processing large batches of payment transaction data using Kafka as a buffer for decoupling the data ingestion and processing stages.</p></li><li><p><strong>Risk Detection and Management: </strong>Streaming real-time payment data through Kafka for feeding the fraud detection and risk assessment models.</p></li><li><p><strong>Analytics and Compliance: </strong>Capturing and analyzing financial transaction data in real-time for regulatory reporting and audit purposes.</p></li></ul><h2>How PayPal Operates Kafka?</h2><p>PayPal&#8217;s infrastructure is spread across multiple geographically distributed data centers and security zones. Kafka clusters are deployed across these zones.</p><p>There are some key differences between data centers and security zones:</p><ul><li><p>A data center is a physical facility that houses computing infrastructure. A security zone is a logical partition with a data center or across data centers, created through network segmentation.</p></li><li><p>While data centers help with isolation and availability, security zones provide an additional level of security isolation beyond the physical boundaries.</p></li><li><p>Security zones are often defined based on data classification levels, such as highly sensitive, confidential, or public data.</p></li></ul><p>In the context of PayPal, Kafka clusters handling sensitive payment data may be placed in a high-security zone with restricted access. Clusters processing less sensitive data may reside in a different security zone.</p><p>One thing, however, is common.</p><p>Whether it is data centers or security zones, MirrorMaker is used to mirror the data across the data centers, which helps with disaster recovery and communication across security zones.&nbsp;</p><p>For reference, Kafka MirrorMaker is a tool for mirroring data between Apache Kafka clusters. It leverages the Kafka Connect framework to replicate data, which improves resiliency.&nbsp;</p><p>See the diagram below to get an idea about PayPal&#8217;s Kafka setup across data centers and security zones:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf13b1a8-70b3-42b5-8a07-dd61adc91818_1388x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf13b1a8-70b3-42b5-8a07-dd61adc91818_1388x1600.png" width="1388" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Operating Kafka at the scale of PayPal is a challenging task. To manage the ever-growing fleet of Kafka clusters, PayPal has focused on some key areas such as:</p><ul><li><p>Cluster Management</p></li><li><p>Monitoring and Alerting</p></li><li><p>Configuration Management</p></li><li><p>Enhancements and Automation</p></li></ul><p>The diagram below shows a high-level view of PayPal&#8217;s Kafka Landscape:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc267306b-64d1-45e2-bc0a-e61e340dbc04_1600x1015.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="924" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc267306b-64d1-45e2-bc0a-e61e340dbc04_1600x1015.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In the subsequent sections, we will look at each area in greater detail.</p><h2>Cluster Management</h2><p>Cluster management deals with controlling Kafka clusters and reducing operational overhead. Some of the key improvements were done in areas like:</p><ul><li><p>Kafka Config Service</p></li><li><p>ACLs</p></li><li><p>Kafka Libraries for PayPal</p></li><li><p>QA environment</p></li></ul><p>Let&#8217;s look at each improvement in more detail.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1005" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2785489-6c63-40cf-bb4a-1b8656a81d01_1600x1104.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>Kafka Config Service</h3><p>PayPal built a special Kafka config service to make it easy for clients to connect to the Kafka clusters.</p><p>Before the config service, clients had to hardcode the broker IPs in the connection configuration.&nbsp;</p><p>This created a maintenance nightmare due to a couple of reasons:</p><ul><li><p>Firstly, replacing a broker for upgrades, patching, or disk failures required updates to the client. Missing to update one broker IP somewhere would often lead to multiple incidents.</p></li><li><p>Second, Kafka is configuration-heavy, making it tough for developers to figure out a suitable set of configurations. Often, the Kafka clients would override certain properties without knowing the implications, resulting in support issues due to unexpected behavior.</p></li></ul><p>The Kafka config service solved these issues. The service makes it easy for the Kafka clients to follow a standard configuration. Ultimately, it reduces operational and support overhead across teams.</p><p>The diagram below shows the Kafka client retrieving bootstrap servers and configuration from the config service using the topic information.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaa0d294-4b44-4c17-b7a8-26b7f8dc2513_1600x1021.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="929" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaa0d294-4b44-4c17-b7a8-26b7f8dc2513_1600x1021.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Kafka ACLs</h3><p>Initially, any PayPal application could connect to any of the existing Kafka topics. This was an operational risk for the platform considering that it streams business-critical data.</p><p>To ensure controlled access to Kafka clusters, ACLs were introduced.</p><p>For reference, ACLs are used to define which users, groups, or processes have access to specific objects such as files, directories, applications, or network resources. It&#8217;s like a table or list specifying a particular object's permissions.</p><p>With the introduction of ACLs, applications had to authenticate and authorize access to Kafka clusters and topics.&nbsp;</p><p>Apart from making the platform secure, ACLs also provided a record of every application accessing a particular topic or cluster.</p><h3>PayPal Kafka Libraries&nbsp;</h3><p>It was important to ensure that Kafka clusters and the clients connecting to them operate securely. Also, there was a need to ensure easy integration to multiple frameworks and programming languages. They didn&#8217;t want each engineering team to reinvent the wheel.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac03b947-fed2-455d-a3df-9a538691c336_946x624.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="624" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac03b947-fed2-455d-a3df-9a538691c336_946x624.png" width="946" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Supported tech stack for Kafka Libraries. Source: <a href="https://medium.com/paypal-tech/scaling-kafka-to-support-paypals-data-growth-a0b4da420fab">PayPal Tech Blog</a></figcaption></figure></div><p>To facilitate these needs, PayPal built a few important libraries:</p><ul><li><p><strong>Resilient Client Library: </strong>When a client tries to establish a connection to the cluster, this library gets the Kafka broker details and the required configuration for the producer or consumer application.</p></li><li><p><strong>Monitoring Library: </strong>This library publishes critical metrics for client applications, allowing applications to set alerts and get notifications in case of any issues.</p></li><li><p><strong>Kafka Security Library: </strong>The Kafka platform supports more than 800 applications. This library takes care of the required certificates and tokens to enable SSL authentication for applications connecting to the Kafka clusters. It avoids a lot of overhead around key management, certificate updates, and key rotations.</p></li></ul><h3>QA Platform</h3><p>One of the great things PayPal did was to set up a production-like QA platform for Kafka for developers to test changes confidently.</p><p>This is a common problem in many organizations where the testing performed by developers is hardly indicative of the production environment, resulting in issues after launch.&nbsp;</p><p>A dedicated QA platform solves this by providing a direct mapping between production and QA clusters.&nbsp;</p><p>The same security standards are followed. The same topics are hosted on the clusters with the brokers spread across multiple zones within the Google Cloud Platform.</p><h3>Monitoring and Alerting</h3><p>Monitoring and alerting are extremely important aspects for systems operating at a high scale. Teams want to know about issues and incidents quickly so that cascading failures can be avoided.</p><p>At PayPal, the Kafka platform is integrated with the monitoring and alerting systems.</p><p>Apache Kafka provides multiple metrics. However, they have taken out a subset of metrics that help them identify issues faster.&nbsp;</p><p>The Kafka Metrics library filters out the metrics and sends them to the SignalFX backend via SignalFX agents running on all brokers, Zookeepers, MirrorMakers, and Kafka clients. Individual alerts associated with these metrics are triggered whenever abnormal thresholds are breached.&nbsp;</p><h2>Configuration Management</h2><p>Operating a critical system requires one to guard against data loss. This is not only applicable to the application data but also to the infrastructure information.</p><p>What if the infrastructure gets wiped out and we&#8217;ve to rebuild it from scratch?</p><p>At PayPal, configuration management helps them store the complete infrastructure details. This is the single source of truth that allows PayPal to rebuild the clusters in a couple of hours if needed.</p><p>They store the Kafka metadata such as topic details, clusters, and applications in an internal configuration management system. The metadata is also backed up to ensure that they have the most recent data in case it&#8217;s required to re-create clusters and topics in case of a recovery.</p><h2>Enhancements and Automation</h2><p>Large-scale systems require special tools to carry out operational tasks as quickly as possible.</p><p>PayPal built multiple such tools for operating their Kafka cluster. Let&#8217;s look at a few important ones:</p><h3>Patching Security Vulnerabilities</h3><p>PayPal uses BareMetal for deploying the Kafka brokers and virtual machines for Zookeeper and MirrorMakers.</p><p>As we can expect, all of these hosts need to be patched at frequent intervals to fix any security vulnerabilities.&nbsp;</p><p>Patching requires BM restart which can cause partitions to lag. This can also lead to data loss in the case of Kafka topics that are configured with a replica set of three.&nbsp;</p><p>They built a plugin to query whether a partition was lagging before patching the host, thereby ensuring only a single broker is patched at a time with no chances of data loss.</p><h3>Topic Onboarding</h3><p>Application teams require topics for their application functionality. To make this process standardized, PayPal built an Onboarding Dashboard to submit a new topic request.</p><p>The diagram below shows the onboarding workflow for a topic.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5171a6df-fad2-4dad-9709-de223718bb5f_1600x1002.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="912" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5171a6df-fad2-4dad-9709-de223718bb5f_1600x1002.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>A special review team checks the capacity requirements for the new topic and onboards it to one of the available clusters. They use a capacity analysis tool integrated into the onboarding workflow to make the decision.</p><p>For each new application being onboarded to the Kafka system, a unique token is generated. This token is used to authenticate the client&#8217;s access to the Kafka topic. As discussed earlier, an ACL is created for the specific application and topic based on their role.</p><h3>MirrorMaker Onboarding</h3><p>As mentioned earlier, PayPal uses MirrorMaker for mirroring the data from one cluster to another.</p><p>For this setup, developers also use the Kafka Onboarding UI to register their requirements. After due checks by the Kafka team, the MirrorMaker instances are provisioned.</p><p>The diagram below shows the process flow for the same:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdd0e9ef-6fbb-4c47-b748-9d04bdd0617a_1600x851.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="774" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdd0e9ef-6fbb-4c47-b748-9d04bdd0617a_1600x851.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Conclusion</h2><p>The Kafka platform at PayPal is a key ingredient for enabling seamless integration between multiple applications and supporting the scale of their operation.</p><p>Some important learnings to take away from this study are as follows:</p><ul><li><p>Tooling is a must when operating Kafka on a large scale. This involves operations such as cluster installation, topic management, patching VMs, etc.</p></li><li><p>Availability is as good as the ability of alerting and monitoring systems to provide timely inputs to the infrastructure team.</p></li><li><p>ACLs are a great way to have a better understanding of how the various applications are connected with Kafka.</p></li><li><p>A dedicated QA environment is critical for developers to ship changes with confidence and speed.</p></li></ul><p><strong>References</strong></p><ul><li><p><a href="https://medium.com/paypal-tech/scaling-kafka-to-support-paypals-data-growth-a0b4da420fab">Scaling Kafka to Support PayPal&#8217;s Data Growth</a></p></li><li><p><a href="https://www.confluent.io/resources/kafka-summit-2020/marching-toward-a-trillion-kafka-messages-per-day-running-kafka-at-scale-at-paypal/">Marching towards a Trillion Kafka Messages Per Day</a></p></li><li><p><a href="https://developers.redhat.com/articles/2023/11/13/demystifying-kafka-mirrormaker-2-use-cases-and-architecture">Demystifying Kafka MirrorMaker2</a></p></li><li><p><a href="https://kafka.apache.org/uses">Kafka Use Cases</a></p></li></ul><div><hr /></div><h2>SPONSOR US</h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p><br /></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 15:30:53 GMT</pubDate>
</item>
<item>
<title>EP115: Life is Short, Use Dev Tools</title>
<link>https://blog.bytebytego.com/p/ep115-life-is-short-use-dev-tools</link>
<guid>https://blog.bytebytego.com/p/ep115-life-is-short-use-dev-tools</guid>
<content:encoded><![CDATA[
<div> KISS, SOLID, CAP, BASE, Dev Tools, Production Web Application, Frontend Performance, Developer Standards, Sponsorship<br /><br />总结: 本文介绍了系统设计中的重要术语和开发工具，以及如何构建高性能的生产级Web应用程序。通过讨论8个前端性能提升技巧和开发人员需要了解的8个标准，全面展示了技术行业的最新趋势。此外，还提供了赞助机会，让产品和服务能够直接接触到50万以上的技术专业人士。通过这些内容，读者可以了解如何提升自己在开发领域的水平，以及如何将产品推广给相关目标群体。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>KISS, SOLID, CAP, BASE: Important Terms You Might Not Know! (Youtube video)</p></li><li><p>Life is Short, Use Dev Tools </p></li><li><p>10 Essential Components of a Production Web Application</p></li><li><p>How to load your websites at lightning speed</p></li><li><p>Top 8 Standards Every Developer Should Know</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/LinearB_060824">What You Need to Know About Software Engineering Intelligence [Workshop]&nbsp;(Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/LinearB_060824" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="359.010989010989" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22df6e02-75ef-476b-9cca-3926e28b8dd9_1600x798.png" width="720" /><div></div></div></a></figure></div><p>How can you get holistic visibility across your SDLC, insights about your engineering performance, and implement automations that unblock your bottlenecks? </p><p>Software Engineering Intelligence (SEI) Platforms are solving visibility and operations challenges for engineering teams. Join LinearB&#8217;s workshop on June 20th or 27th to learn about how SEI tools are rapidly accelerating developer productivity in enterprises.</p><p>We&#8217;ll demonstrate how you can use SEI to take on:</p><ul><li><p>Developer Productivity - accelerating output</p></li><li><p>Profitable Engineering - the data behind resourcing and costs</p></li><li><p>Developer Experience - protecting team health and reducing toil</p></li><li><p>GenAI (Copilot) Impact - the effects it&#8217;s having on your software pipelines</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/LinearB_060824"><span>Register now</span></a></p><div><hr /></div><h2>KISS, SOLID, CAP, BASE: Important Terms You Might Not Know!</h2><div class="youtube-wrap" id="youtube2-cTyZ_hbmbDw"><div class="youtube-inner"></div></div><div><hr /></div><h2>Life is Short, Use Dev Tools </h2><p>The right dev tool can save you precious time, energy, and perhaps the weekend as well. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1565" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e5b9d5-3426-42ab-b690-2413ab249270_1280x1565.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><p>Here are our favorite dev tools: </p><ol><li><p>Development Environment <br />A good local dev environment is a force multiplier. Powerful IDEs like VSCode, IntelliJ IDEA, Notepad++, Vim, PyCharm &amp; Jupyter Notebook can make your life easy. <br /></p></li><li><p>Diagramming <br />Showcase your ideas visually with diagramming tools like DrawIO, Excalidraw, mindmap, Mermaid, PlantUML, Microsoft Visio, and Miro <br /></p></li><li><p>AI Tools <br />AI can boost your productivity. Don&#8217;t ignore tools like ChatGPT, GitHub Copilot, Tabnine, Claude, Ollama, Midjourney, and Stable Diffusion. <br /></p></li><li><p>Hosting and Deployment <br />For hosting your applications, explore solutions like AWS, Cloudflare, GitHub, Fly, Heroku, and Digital Ocean. <br /></p></li><li><p>Code Quality <br />Quality code is a great differentiator. Leverage tools like Jest, ESLint, Selenium, SonarQube, FindBugs, and Checkstyle to ensure top-notch quality. <br /></p></li><li><p>Security <br />Don&#8217;t ignore the security aspects and use solutions like 1Password, LastPass, OWASP, Snyk, and Nmap. <br /></p></li><li><p>Note-taking <br />Your notes are a reflection of your knowledge. Streamline your note-taking with Notion, Markdown, Obsidian, Roam, Logseq, and Tiddly Wiki. <br /></p></li><li><p>Design <br />Elevate your visual game with design tools like Figma, Sketch, Adobe Illustrator, Canva, and Adobe Photoshop. <br /></p></li></ol><p>Over to you: Which dev tools do you use? </p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1198" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F203c1745-28f1-405c-80c1-b456e391c708_1600x1317.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>10 Essential Components of a Production Web Application</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1568" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cae662e-b5f0-4015-b4b7-7d9eac154903_1280x1568.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ol><li><p>It all starts with CI/CD pipelines that deploy code to the server instances. Tools like Jenkins and GitHub help over here.</p></li><li><p>The user requests originate from the web browser. After DNS resolution, the requests reach the app servers.</p></li><li><p>Load balancers and reverse proxies (such as Nginx &amp; HAProxy) distribute user requests evenly across the web application servers.</p></li><li><p>The requests can also be served by a Content Delivery Network (CDN).</p></li><li><p>The web app communicates with backend services via APIs.</p></li><li><p>The backend services interact with database servers or distributed caches to provide the data.</p></li><li><p>Resource-intensive and long-running tasks are sent to job workers using a job queue.</p></li><li><p>The full-text search service supports the search functionality. Tools like Elasticsearch and Apache Solr can help here.</p></li><li><p>Monitoring tools (such as Sentry, Grafana, and Prometheus) store logs and help analyze data to ensure everything works fine. </p></li><li><p>In case of issues, alerting services notify developers through platforms like Slack for quick resolution. </p></li></ol><p>Over to you: What other components would you add to the architecture of a production web app?</p><div><hr /></div><h2>How to load your websites at lightning speed?</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1585" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0167296-81d2-46ad-bea6-183cac627c4d_1280x1585.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>Check out these 8 tips to boost frontend performance:</p><ol><li><p>Compression<br />Compress files and minimize data size before transmission to reduce network load.</p><p></p></li><li><p>Selective Rendering/Windowing<br />Display only visible elements to optimize rendering performance. For example, in a dynamic list, only render visible items.<br /></p></li><li><p>Modular Architecture with Code Splitting<br />Split a bigger application bundle into multiple smaller bundles for efficient loading.<br /></p></li><li><p>Priority-Based Loading<br />Prioritize essential resources and visible (or above-the-fold) content for a better user experience.<br /></p></li><li><p>Pre-loading<br />Fetch resources in advance before they are requested to improve loading speed.<br /></p></li><li><p>Tree Shaking or Dead Code Removal<br />Optimize the final JS bundle by removing dead code that will never be used.<br /></p></li><li><p>Pre-fetching<br />Proactively fetch or cache resources that are likely to be needed soon.<br /></p></li><li><p>Dynamic Imports<br />Load code modules dynamically based on user actions to optimize the initial loading times.</p></li></ol><p>Over to you: What other frontend performance tips would you add to this cheat sheet?</p><div><hr /></div><h2>Top 8 Standards Every Developer Should Know</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef0ca4ec-4ab6-4bd3-a0f2-bf49da47748b_1536x1536.gif" title="No alternative text description for this image" /><div></div></div></a></figure></div><ul><li><p>TCP/IP <br />Developed by the IETF organization, the TCP/IP protocol is the foundation of the Internet and one of the best-known networking standards. <br /> </p></li><li><p>HTTP <br />The IETF has also developed the HTTP protocol, which is essential for all web developers. <br /> </p></li><li><p>SQL <br />Structured Query Language (SQL) is a domain-specific language used to manage data. <br /> </p></li><li><p>OAuth <br />OAuth (Open Authorization) is an open standard for access delegation commonly used to grant websites or applications limited access to user information without exposing their passwords. <br /> </p></li><li><p>HTML/CSS <br />With HTML, web pages are rendered uniformly across browsers, which reduces development effort spent on compatibility issues.HTML tags. <br /> <br />CSS standards are often used in conjunction with HTML. <br /> </p></li><li><p>ECMAScript <br />ECMAScript is a standardized scripting language specification that serves as the foundation for several programming languages, the most well-known being JavaScript. <br /> </p></li><li><p>ISO Date <br />It is common for developers to have problems with inconsistent time formats on a daily basis. ISO 8601 is a date and time format standard developed by the ISO (International Organization for Standardization) to provide a common format for exchanging date and time data across borders, cultures, and industries. <br /> </p></li><li><p>OpenAPI <br />OpenAPI, also known as the OpenAPI Specification (OAS), is a standardized format for describing and documenting RESTful APIs.</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 15:30:59 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Content-Delivery Networks (CDN)</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-content-delivery</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-content-delivery</guid>
<content:encoded><![CDATA[
<div> Latency, Conversion Rate, E-commerce, Content-Delivery Network, Market Size
<br />
凭借内容交付网络（CDN）可以减少延迟，提高网站性能。根据Portent的研究，页面加载速度快，转化率会更高，电子商务转化率随着加载时间增加而下降。优化的加载时间是少于2秒。CDN是一个地理分布的服务器网络，通过将用户请求重定向到最近的CDN服务器，提供快速可靠的内容传递。CDN市场预计到2028年将达到近380亿美元，Akamai、Cloudflare和亚马逊CloudFront等公司正在大力投资改进CDN解决方案。总结: CDN的使用可以降低延迟，提高网站性能，有效解决了现代网络时代组织面临的性能问题。 <div>
<p>In the era of the modern web, latency can directly impact an organization&#8217;s bottom line.</p><p>Here are some stats from a study by Portent:</p><ul><li><p>A page that loads in 1 second has a 3x higher conversion rate than a page that takes 5 seconds to load.</p></li><li><p>E-commerce conversion rates decrease by 0.3% for every second of load time.</p></li><li><p>The optimal loading time to maximize sales is less than 2 seconds.</p></li></ul><p>One of the most effective strategies to reduce latency is using a Content-Delivery Network or a CDN.</p><p>A CDN is a geographically distributed network of servers that work together to deliver fast and reliable content delivery across the globe.</p><p>When a user requests content from a website or application that uses a CDN, the request is redirected to the nearest CDN server, which serves the content to the user. This reduces the distance data travels and improves overall performance.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98c2b44b-f305-4e3c-90d1-24e6c181bd93_1600x896.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="815" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98c2b44b-f305-4e3c-90d1-24e6c181bd93_1600x896.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Think of a CDN like an ATM. If money were available only from one bank branch in town, everyone would have to make a time-consuming trip to that branch. With ATMs in every locality, everyone has fast and easy access to money.&nbsp;</p><p>The market size for CDN-related solutions is expected to reach nearly $38 billion by 2028, with companies like Akamai, Cloudflare, and Amazon CloudFront investing heavily in improving their CDN offerings.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95404fea-d1ef-45ec-96e2-17796bf260d5_1999x1755.jpeg" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1278" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95404fea-d1ef-45ec-96e2-17796bf260d5_1999x1755.jpeg" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Why the Need for a CDN?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 06 Jun 2024 15:30:28 GMT</pubDate>
</item>
<item>
<title>AWS Lambda Under the Hood</title>
<link>https://blog.bytebytego.com/p/aws-lambda-under-the-hood</link>
<guid>https://blog.bytebytego.com/p/aws-lambda-under-the-hood</guid>
<content:encoded><![CDATA[
<div> AWS Lambda, Assignment Service, Firecracker, Chunking, SnapStart  
总结:<br /><br />本文介绍了AWS Lambda的架构和内部机制。AWS Lambda是一个无服务器计算服务，支持同步和异步调用模式。介绍了同步调用和异步调用的工作流程，以及Assignment Service的引入解决了Worker Manager的挑战。Firecracker是用于运行AWS Lambda和AWS Fargate等无服务器工作负载的轻量级虚拟机管理器。讨论了Firecracker的重要技术细节，以及SnapStart功能如何减少冷启动延迟。最后，介绍了AWS Lambda作为存储服务的功能，包括代码和数据的有效存储、共享常用数据和使用SnapStart加速初始化等。AWS Lambda通过这些先进技术实现了高效的无服务器计算服务。 <div>
<h2><a href="https://bit.ly/WorkOS_060424">WorkOS: enterprise-grade auth for modern SaaS apps (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/WorkOS_060424" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="763" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79e9b43-75d7-4a65-a598-c9fe68df9033_1600x838.png" width="1456" /><div></div></div></a></figure></div><p>WorkOS helps companies become Enterprise Ready ridiculously fast.</p><p>&#8594; It supports a complete User Management solution along with SSO, SCIM, RBAC, &amp; FGA.</p><p>&#8594; Unlike other auth providers that rely on user-centric models, WorkOS is designed for B2B SaaS with an org modeling approach.</p><p>&#8594; The APIs are flexible, easy-to-use, and modular. Pick and choose what you need and integrate in minutes.</p><p>&#8594; Best of all, User Management is free up to 1 million MAUs&nbsp;and includes bot protection, impersonation, MFA, &amp; more.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/WorkOS_060424"><span>Future-proof your auth stack with WorkOS</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from multiple AWS reInvent talks and articles by the Amazon engineering team. All credit for information about AWS Lambda&#8217;s internals goes to the presenters and authors. The link to these videos and articles is present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>AWS Lambda is a serverless compute service that allows developers to run code without provisioning or managing servers.</p><p>Lambda functions can be triggered by various AWS services, HTTP endpoints, or custom events generated by applications. This makes it highly versatile for building event-driven architectures.</p><p>There are some interesting stats about AWS Lambda:</p><ul><li><p>Processes over 10 trillion invocations per month.</p></li><li><p>More than a million customers have built applications using AWS Lambda.</p></li><li><p>The customer base includes individuals, startups, enterprises, and large organizations.</p></li><li><p>Supports various applications, such as IT automation, data processing pipelines, microservices-based applications, web applications, and machine learning workloads.</p></li></ul><p>The timeline below shows the evolution of AWS Lambda over the years.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd69d56b0-4731-4bde-9b42-59925476826c_1600x852.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="775" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd69d56b0-4731-4bde-9b42-59925476826c_1600x852.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In this post, we will look at the architecture and internals of AWS Lambda.</p><h2>How is a Lambda Function Invoked?</h2><p>There are two types of invocation models supported by Lambda.</p><h3>1 - Synchronous Invocation</h3><p>In synchronous invocation, the caller directly calls the Lambda function. This can be done using the AWS CLI, SDK, or other services like the API Gateway.</p><p>The diagram below shows the entire process:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d363a4c-7e04-4244-81c1-247d2a4a038e_1600x986.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="897" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d363a4c-7e04-4244-81c1-247d2a4a038e_1600x986.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The process involves the following components:</p><ul><li><p><strong>Front-End Service: </strong>The front-end service performs authentication and authorization of the request. It also loads and caches metadata to optimize performance.</p></li><li><p><strong>Counting Service: </strong>This service checks quota limits based on account, burst, or reserved concurrency. It ensures high throughput and low latency while operating across multiple availability zones (AZs).</p></li><li><p><strong>Assignment Service: </strong>The assignment service routes invocation requests to available worker hosts. It coordinates the creation of secure execution environments, setting up limits such as memory and CPU allocation. We will talk more about it in a later section.</p></li><li><p><strong>Placement Service: </strong>The assignment service communicates with the placement service to determine the best worker host to handle the new execution environment. The placement service uses machine learning models to make informed decisions about where to place new execution environments. These models take into account variables such as packing density and fleet utilization to make the decisions.</p></li><li><p><strong>Worker Hosts: </strong>They are responsible for downloading, mounting, and running the function code within a microVM. They manage multiple runtimes (such as Node.js, Java, and Python) and Lambda agents for monitoring and operation.</p></li></ul><p>When an invocation occurs, it can have a warm or cold start.</p><p>If a warm (already running) execution environment is available, the payload is sent directly to it, and the function runs immediately.</p><p>If no warm environment is available, a new execution environment is created. The process involves initializing the runtime, downloading function code, and preparing the environment for execution.</p><p>The assignment service keeps track of execution environments. If there are errors during initialization, the environment is marked unavailable. When environments are near the end of their lease, they are gracefully shut down to ensure stability and resource efficiency.</p><h3>2 - Asynchronous Invocation</h3><p>In asynchronous invocation, the caller doesn&#8217;t wait for the function&#8217;s response. Instead, the event is placed in an internal queue and processed separately.</p><p>The process involves:</p><ul><li><p><strong>Event Invoke Frontend Service: </strong>This service handles asynchronous requests. It authenticates and authorizes the request, then places the event in an internal SQS queue.</p></li><li><p><strong>Polling Instances: </strong>A fleet of pollers reads messages from the SQS queues and sends them to the synchronous front-end service for processing.</p></li><li><p><strong>Synchronous Processing:</strong> Despite being an async request, the actual function execution uses the same synchronous processing pathway as described earlier.</p></li><li><p><strong>Event Destinations: </strong>These can be configured to handle callbacks after processing, providing notifications of success or failure.</p></li></ul><p>The diagram below shows the asynchronous invocation process:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87e33617-1c2e-43cd-8e40-a7e24105b189_1600x833.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="758" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87e33617-1c2e-43cd-8e40-a7e24105b189_1600x833.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Lambda manages multiple internal queues, scaling them dynamically based on load. The queue manager oversees the creation, deletion, and monitoring of these queues to ensure efficient processing.</p><p>As far as polling is concerned, Lambda can poll from various event sources like Kinesis, DynamoDB, SQS, Kafka, and Amazon MQ. The pollers perform the following functions:</p><ul><li><p><strong>Read and Filter: </strong>Poll messages from the sources, optionally filtering them to reduce traffic and simplify function code.</p></li><li><p><strong>Batch Processing: </strong>Batch records together before sending them to the function, optimizing performance and reducing costs.</p></li><li><p><strong>Synchronous Invocation: </strong>Use the same synchronous pathway to execute the function, ensuring consistency.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d97f56a-30a5-4e3d-b069-4bc8f3262ea1_1600x913.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="831" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d97f56a-30a5-4e3d-b069-4bc8f3262ea1_1600x913.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Control plane services (such as State Manager and Stream Tracker) manage the pollers, ensuring they are assigned correctly, scaling them up or down, and handling failures gracefully.</p><p>In case a function fails, the message is returned to the queue with a visibility timeout, allowing for retries.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="735" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d1d63b-f864-41e2-8bec-80a41cc800ac_1600x808.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>State Management in Lambda</h2><p>In the earlier architecture of AWS Lambda, the Worker Manager service was responsible for coordinating the execution environments between the frontend invoke service and the worker hosts.</p><p>The worker manager performed a couple of important tasks:</p><ul><li><p><strong>State Management: </strong>The Worker Manager kept track of which execution environments were available and on which hosts they were running.</p></li><li><p><strong>Execution Lifecycle: </strong>It managed the lifecycle of these environments, ensuring that they were ready to process invocations and handling termination when no longer needed.</p></li></ul><p>There were some challenges with the worker manager:</p><ul><li><p><strong>Single Point of Failure: </strong>Each Worker Manager instance stored the state of execution environments in memory. If a Worker manager failed, the execution environments it managed could become orphaned.</p></li><li><p><strong>Orphaned Environments:</strong> Orphaned environments could continue processing current invocations but could not be used for new invocations, leading to cold starts and inefficient resource utilization.</p></li><li><p><strong>Zonal Failures:</strong> In case of a failure in an Availability Zone (AZ), Worker Managers in that AZ would become unavailable. This will also make the environments managed by them unavailable, resulting in capacity loss and increased cold start latencies.</p></li></ul><h3>Introduction of the Assignment Service</h3><p>To address the challenges with Worker Manager, AWS Lambda introduced the Assignment Service which offers a more robust and resilient way to manage execution environments.</p><p>The Assignment Service is written in Rust, which is chosen for its performance, memory safety, and low latency characteristics.&nbsp;</p><p>The diagram below shows the high-level design of the Assignment Service</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2fd3b32-d588-4aa9-a248-992db2be9894_1600x974.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="886" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2fd3b32-d588-4aa9-a248-992db2be9894_1600x974.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The architecture of the Assignment Service has some key properties:</p><h4>1 - Partitioned Design</h4><p>The Assignment Service is divided into multiple partitions. Each partition consists of one leader and two followers, spread across different Availability Zones (AZs). This ensures high availability and fault tolerance.</p><p>Multiple partitions run simultaneously, with each Assignment Service host managing several partitions. This helps with load distribution and provides redundancy.</p><h4>2 - External Journal Log Service</h4><p>The leader in each partition writes the state of execution environments to an external journal log service. The followers read from this log to keep their state in sync with the leader.</p><p>In case the leader fails, one of the followers can quickly take over as the new leader using the state information from the journal log.</p><h4>3 - Frontend Interaction</h4><p>The frontend invoke service interacts with the leader of the relevant partition to manage invocations.&nbsp;</p><p>The leader coordinates with the placement service to create new execution environments and writes this information to the log for followers to update their state.</p><h4>4 - Failure Handling</h4><p>If an AZ experiences an outage, the leader and followers in other AZs continue to operate. This means that execution environments in the unaffected AZs remain available and aren&#8217;t orphaned.</p><p>If a leader fails, a follower can take over quickly using the replicated state, ensuring that there are no interruptions in service and reducing the chances of cold starts.</p><h2>The Role of Firecracker MicroVM</h2><p>Firecracker is a lightweight virtual machine manager (VMM) designed specifically for running serverless workloads such as AWS Lambda and AWS Fargate. It uses Linux&#8217;s Kernel-based Virtual Machine to create and manage microVMs.</p><p>The primary goal of Firecracker is to provide secure and fast-booting microVMs.</p><p>Initially, AWS Lambda used EC2 instances to run functions, dedicating a T2 instance to each tenant. This was secure but inefficient, leading to high overhead due to the need for provisioning entire EC2 instances for each function.</p><p>In 2018, Lambda transitioned to using Firecracker for managing execution environments. This allowed for much smaller, lightweight microVMs, significantly reducing resource overhead and improving the fleet&#8217;s efficiency.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffac8de07-6586-4bf7-9d48-f6db8322b148_1600x1295.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1178" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffac8de07-6586-4bf7-9d48-f6db8322b148_1600x1295.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here are some key technical details of the Firecracker implementation.</p><h3>1 - MicroVMs and Isolation</h3><p>Firecracker enables the creation of microVMs, which are smaller and more efficient than traditional VMs. Each microVM runs its isolated execution environment, including the runtime, function code, and any extensions.</p><p>Firecracker ensures a strong solution between microVMs, which is crucial for multi-tenant environments where different customer functions run on the same physical host.</p><h3>2 - Startup Times</h3><p>Firecracker microVMs are designed to boot in milliseconds, significantly reducing the cold start latency for Lambda functions.&nbsp;</p><p>For further optimization, Lambda uses a feature called SnapStart (initially available for the Corretto Java 11 runtime). SnapStart pre-initializes execution environments and takes snapshots, which are restored on demand when needed. We will talk more about it in the next section.</p><h3>3 - Resource Utilization</h3><p>By running multiple microVMs on a single physical host, Firecracker improves CPU utilization, memory, and storage resources. This allows Lambda to handle more functions with fewer resources.</p><p>Also, Firecracker supports the dynamic scaling of resources for quick adjustment to changing workloads.</p><h3>4 - Storage and Networking</h3><p>Lambda uses a virtual file system driver to present an EXT4 file system to the microVMs. This driver handles file system calls and maps them to the underlying storage.</p><p>Firecracker optimizes network performance by providing high-speed virtual network interfaces, ensuring fast and reliable communication.</p><h2>Lambda as a Storage Service</h2><p>AWS Lambda is primarily known as a serverless compute service. However, it also incorporates significant storage service functionalities.</p><p>Think of Lambda not just as a compute service but also as a storage service because it deals with storing and managing a lot of data behind the scenes.</p><p>But why is storage important for Lambda?</p><p>It&#8217;s because when you run a function on Lambda, it needs three main things:</p><ul><li><p><strong>Input Data:</strong> The information or data your function will process</p></li><li><p><strong>Function Code:</strong> The code you wrote that tells Lambda what to do&nbsp;</p></li><li><p><strong>Execution Environment:</strong> The virtual machine (VM) where your code runs.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d4de897-b4c0-4f07-84bb-58b1eccf1732_1600x1242.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1130" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d4de897-b4c0-4f07-84bb-58b1eccf1732_1600x1242.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To make all of this work smoothly, Lambda needs to manage and store these components efficiently.</p><h3>1 - Storing Code and Data Efficiently</h3><p>Instead of storing your entire code or data as one big piece, Lambda breaks it down into smaller pieces called chunks.</p><p>This process is known as chunking and it allows Lambda to handle large and complex functions more effectively.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f76a65b-82ed-47c3-80a4-33b2d2e6e477_1600x880.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="801" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f76a65b-82ed-47c3-80a4-33b2d2e6e477_1600x880.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s how it works:</p><ul><li><p><strong>Breaking down container images: </strong>When you upload a container image (which can be up to 10 GB) to AWS Lambda, it doesn&#8217;t store the entire image as one big file. Instead, Lambda breaks this image down into smaller pieces or chunks. For example, the base OS layer is broken down into smaller pieces, the runtime layer into another set of pieces, and so on.</p></li><li><p><strong>Storage and Access: These chunks are then stored separately, making it easier to manage and retrieve them as needed. When your function runs, Lambda only loads the chunks it needs at that moment, rather than the entire image. This is much faster and more efficient.</strong></p></li><li><p><strong>Retrieving Chunks: When your function is invoked, Lambda checks which parts of the container image it needs to execute the function. It then retrieves only those specific chunks from storage.</strong></p></li><li><p><strong>Optimizing Performance: Since only the required chunks are loaded, this reduces the amount of data that needs to be transferred and processed, leading to faster startup times and better performance. Frequently accessed chunks can be cached to avoid fetching them from the main storage repeatedly.</strong></p></li></ul><h3>2 - Sharing Common Data</h3><p>Lambda often runs many functions that use similar code or data such as base operating system layer or common runtime libraries.&nbsp;</p><p>Instead of storing multiple copies of the same thing, it stores one copy and reuses it.</p><p>To make sure the shared data is secure, Lambda uses a technique called convergent encryption.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88eb699a-bd99-4d18-aea8-c9a3b96b554e_1600x881.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="802" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88eb699a-bd99-4d18-aea8-c9a3b96b554e_1600x881.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>But how does convergent encryption work?</p><ul><li><p><strong>Plaintext Chunk Creation: </strong>Lambda starts with a plaintext chunk, which is a segment of the flattened file system of a container image. Each chunk represents a specific range of the block device that makes up the file system.</p></li><li><p><strong>Appending Extra Data:</strong> To ensure security and integrity, additional data is appended to the chunk. This extra data is generated by the Lambda service and can include metadata or unique identifiers. The purpose of this extra data is to add a layer of uniqueness to the chunk.</p></li><li><p><strong>Hash Computation: </strong>A cryptographic hash function is used to compute a hash of the combined plaintext chunk and extra data. This hash serves as the encryption key for that specific chunk, ensuring that identical chunks produce the same hash and thus the same encryption key.</p></li><li><p><strong>Encryption: </strong>The plaintext chunk, along with the extra data, is then encrypted using the computed hash as the encryption key.</p></li><li><p><strong>Manifest Creation: </strong>Lambda creates a manifest file that contains the keys (hashes) and pointers to the encrypted chunks in the storage subsystem. The manifest itself is encrypted with a customer-specific AWS Key Management Service, ensuring that only authorized entities can access it.</p></li></ul><h3>3 - Making Initialization Faster with SnapStart</h3><p>When a Lambda function is invoked and there isn&#8217;t an already running execution environment, Lambda has to create a new one. This involves several steps:</p><ul><li><p><strong>Provisioning</strong>: Setting up a new virtual machine</p></li><li><p><strong>Downloading: </strong>Retrieving the function code from storage</p></li><li><p><strong>Initializing: </strong>Starting the runtime and initializing the function code.</p></li></ul><p>These steps can take time, especially for complex functions or runtimes like Java, which have longer startup times. This delay is known as cold start latency.</p><p>SnapStart is a feature designed to significantly reduce cold start latency by pre-initializing the execution environment and then using snapshots.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbda5bb9f-e59e-4248-b7f6-aaf55e6e1431_1600x875.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="796" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbda5bb9f-e59e-4248-b7f6-aaf55e6e1431_1600x875.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s how it works:</p><ul><li><p>When you update your function code or deploy a new version, Lambda performs an initial setup and creates a new execution environment.</p></li><li><p>Once the execution environment is fully set up and ready to handle invocations, Lambda takes a snapshot of this environment. The snapshot captures the entire state of the VM, including the memory state, runtime state, and initialized data. The snapshot is then broken down into smaller pieces and encrypted to ensure security.</p></li><li><p>These encrypted chunks are stored securely.</p></li><li><p>When a new invocation request arrives, Lambda first checks if there&#8217;s an already running execution environment (a warm start). If not, it proceeds to use the snapshot. The necessary chunks are loaded and decrypted and the environment is brought back to the state it was in when the snapshot was taken.</p></li></ul><h2>Conclusion</h2><p>AWS Lambda revolutionized the way developers build and deploy applications by providing a serverless environment that abstracts away the complexities of infrastructure management.</p><p>Here are the main takeaways from the internals of AWS Lambda:</p><ul><li><p>To achieve the impressive statistics associated with Lambda, AWS leverages multiple advanced techniques such as chunking and convergent encryption to manage and share common data.&nbsp;</p></li><li><p>The introduction of SnapStart addressed the critical challenge of cold start latency, particularly for runtimes like Java.</p></li><li><p>The transition from the Worker Manager to the Assignment Service marked a significant improvement in state management.</p></li><li><p>With Firecracker microVMs, Lambda achieves lightweight and secure virtualization.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://youtu.be/0_jfH6qijVY?si=z_mHoo_lDT3OLrYG">A closer look at AWS Lambda</a></p></li><li><p><a href="https://www.infoq.com/presentations/aws-lambda-arch/">AWS Lambda Under the Hood</a></p></li><li><p><a href="https://youtu.be/AECR8WMHjv0?si=yB6O9FcnmCPyhnUq">AWS Lambda Under the Hood - YouTube</a></p></li><li><p><a href="https://youtu.be/QdzV04T_kec?si=X79wEB5zzmJQLogj">A Serverless Journey: AWS Lambda</a></p></li><li><p><a href="https://www.amazon.science/blog/how-awss-firecracker-virtual-machines-work">How do AWS Firecracker virtual machines work?</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></p>
]]></content:encoded>
<pubDate>Tue, 04 Jun 2024 15:31:00 GMT</pubDate>
</item>
<item>
<title>EP114: 7 Must-know Strategies to Scale Your Database</title>
<link>https://blog.bytebytego.com/p/ep114-7-must-know-strategies-to-scale</link>
<guid>https://blog.bytebytego.com/p/ep114-7-must-know-strategies-to-scale</guid>
<content:encoded><![CDATA[
<div> Scaling databases, Retry strategies, Reddit's architecture, Cross-Site Scripting, Sponsorship
<br />
数据库扩展，重试策略，Reddit架构，跨站脚本攻击，赞助
<br /><br />总结:
<br />
本文讨论了数据库扩展的7个策略，重试失败的方法，Reddit的核心架构，跨站脚本攻击以及赞助广告。数据库扩展策略包括索引、物化视图、去标准化、垂直扩展、缓存、复制和分片。重试策略涵盖了线性、指数和随机的不同方式。Reddit架构采用CDN、微服务以及多种存储和数据处理技术。跨站脚本攻击是常见漏洞，要加强用户意识和防范措施。赞助广告提供推广机会，影响大批技术专业人士。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>7 must-know strategies to scale your database</p></li><li><p>How do we retry on failures?</p></li><li><p>Reddit&#8217;s Core Architecture</p></li><li><p>Everything You Need to Know About Cross-Site Scripting (XSS)</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Nylas_060124CTA">Your ultimate guide to integrating email, calendars &amp; contacts (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Nylas_060124CTA" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1200" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37925e71-6a06-4d9f-811a-90b0336d8733_1200x1200.png" width="1200" /><div></div></div></a></figure></div><p>Launch native email, calendar, and contacts capabilities with the greatest possible ROI. This latest guide from Nylas walks you through the most common options to launch these integrations for all major email and calendar service providers (Gmail, Outlook, IMAP, etc.) including APIs vs. building yourself. <a href="https://bit.ly/Nylas_060124CTA">Read on to discover best practices and</a>:<br /></p><ul><li><p>How complex it is to build the email, calendar and contacts integration from scratch</p></li><li><p>The true cost of building your own email, calendar, contacts integration</p></li><li><p>6 Questions for CTOs and product managers to future-proof their business</p></li></ul><p>If you're interested in trying out an API that integrates these email and calendar service providers for you, <strong><a href="https://bit.ly/Nylas_060124dashboard">check out Nylas</a></strong>.&nbsp;</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Nylas_060124CTA"><span>Read More</span></a></p><div><hr /></div><h2>7 must-know strategies to scale your database</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f560185-6b26-4359-ae8a-123b44d8884a_1345x1536.gif" title="No alternative text description for this image" width="1345" /><div></div></div></a></figure></div><ol><li><p>Indexing: <br />Check the query patterns of your application and create the right indexes. <br /></p></li><li><p>Materialized Views: <br />Pre-compute complex query results and store them for faster access. <br /></p></li><li><p>Denormalization: <br />Reduce complex joins to improve query performance. <br /></p></li><li><p>Vertical Scaling <br />Boost your database server by adding more CPU, RAM, or storage. <br /></p></li><li><p>Caching <br />Store frequently accessed data in a faster storage layer to reduce database load. <br /></p></li><li><p>Replication <br />Create replicas of your primary database on different servers for scaling the reads. <br /></p></li><li><p>Sharding <br />Split your database tables into smaller pieces and spread them across servers. Used for scaling the writes as well as the reads. </p></li></ol><p>Over to you: What other strategies do you use for scaling your databases?</p><div><hr /></div><h2>How do we retry on failures?</h2><p>In distributed systems and networked applications, retry strategies are crucial for handling transient errors and network instability effectively. The diagram shows 4 common retry strategies.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24495c00-fa48-45c0-90f4-6dbfb6cb1c95_1291x1536.gif" title="No alt text provided for this image" width="1291" /><div></div></div></a></figure></div><ul><li><p>Linear Backoff<br />Linear backoff involves waiting for a progressively increasing fixed interval between retry attempts. <br /><br />Advantages: Simple to implement and understand. <br /><br />Disadvantages: May not be ideal under high load or in high-concurrency environments as it could lead to resource contention or "retry storms".<br /></p></li><li><p>Linear Jitter Backoff<br />Linear jitter backoff modifies the linear backoff strategy by introducing randomness to the retry intervals. This strategy still increases the delay linearly but adds a random "jitter" to each interval. <br /><br />Advantages: The randomness helps spread out the retry attempts over time, reducing the chance of synchronized retries across instances.<br /><br />Disadvantages: Although better than simple linear backoff, this strategy might still lead to potential issues with synchronized retries as the base interval increases only linearly.<br /></p></li><li><p>Exponential Backoff<br />Exponential backoff involves increasing the delay between retries exponentially. The interval might start at 1 second, then increase to 2 seconds, 4 seconds, 8 seconds, and so on, typically up to a maximum delay. This approach is more aggressive in spacing out retries than linear backoff.<br /><br />Advantages: Significantly reduces the load on the system and the likelihood of collision or overlap in retry attempts, making it suitable for high-load environments.<br /><br />Disadvantages: In situations where a quick retry might resolve the issue, this approach can unnecessarily delay the resolution.<br /></p></li><li><p>Exponential Jitter Backoff<br />Exponential jitter backoff combines exponential backoff with randomness. After each retry, the backoff interval is exponentially increased, and then a random jitter is applied. The jitter can be either additive (adding a random amount to the exponential delay) or multiplicative (multiplying the exponential delay by a random factor). <br /><br />Advantages: Offers all the benefits of exponential backoff, with the added advantage of reducing retry collisions even further due to the introduction of jitter.<br /><br />Disadvantages: The randomness can sometimes result in longer than necessary delays, especially if the jitter is significant.</p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1158" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd70ae0a-7b12-4bf7-a15d-ed5a3f4a9117_1600x1272.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Reddit&#8217;s Core Architecture</h2><p>A quick look at Reddit&#8217;s Core Architecture that helps it serve over 1 billion users every month. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application, Teams" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c184477-46df-4f37-b224-262c64a6ec58_1280x1611.gif" title="graphical user interface, application, Teams" /><div></div></div></a></figure></div><p>This information is based on research from many Reddit engineering blogs. But since architecture is ever-evolving, things might have changed in some aspects. <br /> <br />The main points of Reddit&#8217;s architecture are as follows: </p><ol><li><p>Reddit uses a Content Delivery Network (CDN) from Fastly as a front for the application <br /></p></li><li><p>Reddit started using jQuery in early 2009. Later on, they started using Typescript and have now moved to modern Node.js frameworks. Over the years, Reddit has also built mobile apps for Android and iOS. <br /></p></li><li><p>Within the application stack, the load balancer sits in front and routes incoming requests to the appropriate services. <br /></p></li><li><p>Reddit started as a Python-based monolithic application but has since started moving to microservices built using Go. <br /></p></li><li><p>Reddit heavily uses GraphQL for its API layer. In early 2021, they started moving to GraphQL Federation, which is a way to combine multiple smaller GraphQL APIs known as Domain Graph Services (DGS). In 2022, the GraphQL team at Reddit added several new Go subgraphs for core Reddit entities thereby splitting the GraphQL monolith. <br /></p></li><li><p>From a data storage point of view, Reddit relies on Postgres for its core data model. To reduce the load on the database, they use memcached in front of Postgres. Also, they use Cassandra quite heavily for new features mainly because of its resiliency and availability properties. <br /></p></li><li><p>To support data replication and maintain cache consistency, Reddit uses Debezium to run a Change Data Capture process. <br /></p></li><li><p>Expensive operations such as a user voting or submitting a link are deferred to an async job queue via RabbitMQ and processed by job workers. For content safety checks and moderation, they use Kafka to transfer data in real-time to run rules over them. <br /></p></li><li><p>Reddit uses AWS and Kubernetes as the hosting platform for its various apps and internal services. <br /></p></li><li><p>For deployment and infrastructure, they use Spinnaker, Drone CI, and Terraform. </p></li></ol><p>Over to you: what other aspects do you know about Reddit&#8217;s architecture?</p><div><hr /></div><h2>Everything You Need to Know About Cross-Site Scripting (XSS)</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1668" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2debd75-6209-41a3-a13f-f2364c281444_1280x1668.jpeg" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>XSS, a prevalent vulnerability, occurs when malicious scripts are injected into web pages, often through input fields. Check out the diagram below for a deeper dive into how this vulnerability emerges when user input is improperly handled and subsequently returned to the client, leaving systems vulnerable to exploitation.<br /><br />Understanding the distinction between Reflective and Stored XSS is crucial. Reflective XSS involves immediate execution of the injected script, while Stored XSS persists over time, posing long-term threats. Dive into the diagrams for a comprehensive comparison of these attack vectors.<br /><br />Imagine this scenario: A cunning hacker exploits XSS to clandestinely harvest user credentials, such as cookies, from their browser, potentially leading to unauthorized access and data breaches. It's a chilling reality.<br /><br />But fret not! Our flyer also delves into effective mitigation strategies, empowering you to fortify your systems against XSS attacks. From input validation and output encoding to implementing strict Content Security Policies (CSP), we've got you covered.<br /><br />Over to you: How can we amplify user awareness to proactively prevent falling victim to XSS attacks? Share your insights and strategies below! Let's collaboratively bolster our web defenses and foster a safer digital environment.</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Sat, 01 Jun 2024 15:30:57 GMT</pubDate>
</item>
<item>
<title>A Crash Course on REST APIs</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-rest-apis</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-rest-apis</guid>
<content:encoded><![CDATA[
<div> APIs、软件、接口、通信、REST API<br />
REST API是软件之间通信的重要方式，通过定义一组规则、协议和方法，在不同的应用程序之间建立联系。从60年代的子程序和库到80年代的远程过程调用（RPC），再到2000年代的Web服务和最近的RESTful APIs，API的形式不断演变。如今，REST API已成为开发者的首选，其简单性和可扩展性备受推崇。API-first的软件开发方法也逐渐流行，强调构建解耦服务。通过探索REST API的基本和高级概念，我们能更深入了解这一领域。 <br /><br />总结: <br />APIs是软件之间的重要通信方式，REST API通过定义规则和方法促进了不同应用程序之间的联系，使得软件开发更加灵活和可扩展。 <div>
<p>Application Programming Interfaces (APIs) are the backbone of software communication.</p><p>In the acronym API, the word &#8220;Application&#8221; refers to software that performs a distinct function. An &#8220;Interface&#8221; is a contract between two applications that defines a set of rules, protocols, and methods for communication. &#8220;Programming&#8221; makes all of this possible.</p><p>APIs have been around for a long time in one form or the other:</p><ul><li><p>In the 60s and 70s, we had subroutines and libraries to share code and functionality between programs.&nbsp;</p></li><li><p>In the 1980s, Remote Procedure Calls (RPC) emerged, allowing programs running on different computers to execute procedures on each other.</p></li><li><p>With the widespread adoption of the Internet in the 2000s, web services such as SOAP became widely adopted.</p></li><li><p>The late 2000s and early 2010s marked the rise of RESTful APIs, which have since become the dominant approach due to their simplicity and scalability.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd70ae0a-7b12-4bf7-a15d-ed5a3f4a9117_1600x1272.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1158" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd70ae0a-7b12-4bf7-a15d-ed5a3f4a9117_1600x1272.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In recent years, the API-first approach to software development has gained significant traction, driven by the emphasis on building loosely coupled services. REST APIs, in particular, have emerged as the go-to choice for developers worldwide.</p><p>In this post, we will explore the world of REST APIs and cover basic to advanced concepts.</p><div><hr /></div><h2>Introduction to REST APIs</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 30 May 2024 15:30:25 GMT</pubDate>
</item>
<item>
<title>The Scaling Journey of LinkedIn</title>
<link>https://blog.bytebytego.com/p/the-scaling-journey-of-linkedin</link>
<guid>https://blog.bytebytego.com/p/the-scaling-journey-of-linkedin</guid>
<content:encoded><![CDATA[
<div> containerized environments, scaling, service-oriented architecture, caching, real-time analytics

总结：<br /><br />这篇文章主要介绍了LinkedIn在发展过程中的扩展之路。从最初的单一的单体系统到服务面向架构的转变，LinkedIn采取了多种技术手段来应对不断增长的需求。文章中详细介绍了LinkedIn如何通过构建新的服务来解决不同需求，包括成员连接管理、搜索功能、数据库复制等。LinkedIn还采用缓存技术和实时分析技术来支持其日益增长的数据需求。最后，LinkedIn还提出了解决授权管理问题的方案，以保护用户数据安全。LinkedIn的经验对于其他开发者团队来说是宝贵的参考，尤其是在面对快速扩展需求时。 <div>
<h2><a href="https://bit.ly/Datadog_052824Headline">10 Insights On Real-World Container Usage (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Datadog_052824Headline" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1080" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35436006-94db-4232-878b-cbbeae4ea59e_1080x1080.png" width="1080" /><div></div></div></a></figure></div><p>As organizations have scaled their containerized environments, many are now exploring the next technology frontier of containers by building next-gen applications, enhancing developer productivity, and optimizing costs.</p><p>Datadog analyzed telemetry data from over 2.4 billion containers to understand the present container landscape, with key insights into:</p><ul><li><p>Trends in adoption for technologies such as serverless containers and GPU-based compute on containers</p></li><li><p>How organizations are managing container costs and resources through ARM-based compute and horizontal pod autoscaling</p></li><li><p>Popular workload categories and languages for containers</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Datadog_052824Headline"><span>Read the report</span></a></p><div><hr /></div><p>LinkedIn is one of the biggest social networks in the world with almost a billion members.</p><p>But the platform had humble beginnings.</p><p>The idea of LinkedIn was conceived in Reid Hoffman&#8217;s living room in 2002 and it was officially launched in May 2003. There were 11 other co-founders from Paypal and Socialnet who collaborated closely with Reid Hoffman on this project.</p><p>The initial start was slow and after the first month of operation, LinkedIn had just around 4300 members. Most of them came through personal invitations by the founding members.&nbsp;</p><p>However, LinkedIn&#8217;s user base grew exponentially over time and so did the content hosted on the platform. In a few years, LinkedIn was serving tens of thousands of web pages every second of every day to users all over the world.</p><p>This unprecedented growth had one major implication.</p><p>LinkedIn had to take on some extraordinary challenges to scale its application to meet the growing demand. While it would&#8217;ve been tough for the developers involved in the multiple projects, it&#8217;s a gold mine of lessons for any developer.</p><p>In this article, we will look at the various tools and techniques LinkedIn adopted to scale the platform.</p><div><hr /></div><h2>Humble Beginning with Leo</h2><p>Like many startups, LinkedIn also began life with a <strong>monolithic architecture</strong>.</p><p>There was one big application that took care of all the functionality needed for the website. It hosted web servlets for the various pages, handled business logic, and also connected to the database layer.&nbsp;</p><p>This monolithic application was internally known as Leo. Yes, it was as magnificent as MGM&#8217;s Leo the Lion.</p><p>The below diagram represents the concept of Leo on a high level.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcf884de-6fbe-4259-a6a5-fd174c2bbd34_1600x1344.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1223" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcf884de-6fbe-4259-a6a5-fd174c2bbd34_1600x1344.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>However, as the platform grew in terms of functionality and complexity, the monolith wasn&#8217;t enough.</p><h2>The First Need of Scaling</h2><p>The first pinch point came in the form of two important requirements:</p><ul><li><p>Managing member-to-member connections</p></li><li><p>Search capabilities</p></li></ul><p>Let&#8217;s look at both.</p><h3>Member Graph Service</h3><p>A social network depends on connections between people.&nbsp;</p><p>Therefore, it was critical for LinkedIn to effectively manage member to member connections. For example, LinkedIn shows the graph distance and common connections whenever we view a user profile on the site.</p><p>To display this small piece of data, they needed to perform low-latency graph computations, creating the need for a system that can query connection data using <strong>in-memory graph traversals</strong>. The in-memory requirement is key to realizing the performance goals of the system.&nbsp;</p><p>Such a system had a completely different usage profile and scaling need as compared to Leo.</p><p>Therefore, the engineers at LinkedIn built a <strong>distributed and partitioned graph system</strong> that can store millions of members and their connections. It could also handle hundreds of thousands of queries per second (QPS).</p><p>The system was called Cloud and it happened to be the first service at LinkedIn. It consisted of three major subcomponents:</p><ol><li><p><strong>GraphDB</strong> - a partitioned graph database that was also replicated for high availability and durability</p></li><li><p><strong>Network Cache Service</strong> - a distributed cache that stores a member&#8217;s network and serves queries requiring second-degree knowledge</p></li><li><p><strong>API Layer</strong> - the access point for the front end to query the data.</p></li></ol><p>The below diagram shows the high-level architecture of the member graph service.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F141d467c-35c1-4946-8f0e-a9b295e06fcd_1600x1041.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="947" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F141d467c-35c1-4946-8f0e-a9b295e06fcd_1600x1041.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To keep it separate from Leo, LinkedIn utilized Java RPC for communication between the monolith and the graph service.</p><h3>Search Service</h3><p>Around the same time, LinkedIn needed to support another critical functionality - <strong>the capability to search people and topics</strong>.&nbsp;</p><p>It is a core feature for LinkedIn where members can use the platform to search for people, jobs, companies, and other professional resources. Also, this search feature should aim to provide deeply personalized search results based on a member&#8217;s identity and relationships.</p><p>To support this requirement, a new search service was built using <strong>Lucene</strong>.&nbsp;</p><p>Lucene is an open-source library that provides three functionalities:</p><ul><li><p>Building a search index</p></li><li><p>Searching the index for matching entities</p></li><li><p>Determining the importance of these entities through relevant scores</p></li></ul><p>Once the search service was built, both the monolith and the new member graph service started feeding data into this service.</p><p>While the building of these services solved key requirements, the continued growth in traffic on the main website meant that Leo also had to scale.</p><p>Let&#8217;s look at how that was achieved.</p><h2>Scaling Leo</h2><p>As LinkedIn grew in popularity, the website grew and Leo&#8217;s roles and responsibilities also increased. Naturally, the once-simple web application became more complex.</p><p><strong>So - how was Leo scaled?</strong></p><p>One straightforward method was to spin up multiple instances of Leo and run them behind a Load Balancer that routes traffic to these instances.</p><p>It was a nice solution but it only involved the application layer of Leo and not the database. However, the increased workload was negatively impacting the performance of LinkedIn&#8217;s most critical system - its <strong>member profile database</strong> that stored the personal information of every registered user. Needless to say, this was the heart of LinkedIn.</p><p>A quick and easy fix for this was going for classic vertical scaling by throwing additional compute capacity and memory for running the database. It&#8217;s a good approach to buy some time and get some breathing space for the team to think about a long-term solution to scaling the database.</p><p>The member profile database had one major issue. It handled both read and write traffic, resulting in a heavy load.&nbsp;</p><p>To scale it out, the team turned to <strong>database replication</strong>.</p><p>New replica databases were created. These replicas were a copy of the primary database and stayed in sync with the primary using Databus. While writes were still handled by the primary database, the trick was to send the majority of read requests to the replica databases.</p><p>However, data replication always results in some amount of replication lag. If a request reads from the primary database and the replica database at the same time, it can get different results because the replication may not have completed. A classic example is a user updating her profile information and not able to see the updated data on accessing the profile just after the update.</p><p>To deal with issues like this, special logic was built to decide when it was safe or consistent to read from the replica database versus the primary database.</p><p>The below diagram tries to represent the architecture of LinkedIn along with database replication</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ae6342-e436-4fb9-87e8-319992fd6e71_1600x1035.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="942" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ae6342-e436-4fb9-87e8-319992fd6e71_1600x1035.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>While replication solved a major scaling challenge for LinkedIn, the website began to see more and more traffic. Also, from a product point of view, LinkedIn was evolving rapidly.</p><p>It created two major challenges:</p><ul><li><p>Leo was often going down in production and it was becoming more difficult to recover from failures</p></li><li><p>Releasing new features became tough due to the complexity of the monolithic application</p></li></ul><p>High availability is a critical requirement for LinkedIn. A social network being down can create serious ripple effects for user adoption. It soon became obvious that they had to kill Leo and break apart the monolithic application into more manageable pieces.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="840" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bb39625-0f08-43c8-89fb-b9a0b90406f6_2496x1440.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Killing Leo with Service-Oriented Architecture</h2><p>While it sounds easy to break apart the monolithic application, it&#8217;s not easy to achieve in practice.</p><p>You want to perform the migration in a seamless manner without impacting the existing functionality. Think of it as changing a car&#8217;s tires while it is moving on the highway at 60 miles per hour.</p><p>The engineers at LinkedIn started to extract functionalities from the monolith in their own separate services. Each service contained APIs and business logic specific to a particular functionality.</p><p>Next, services to handle the <strong>presentation layer </strong>were built<strong> </strong>such as public profiles or recruiter products. For any new product, brand-new services were created completely outside of Leo.&nbsp;</p><p>Over time, the effort towards SOA led to the emergence of vertical slices where each slice handled a specific functional area.</p><ul><li><p>The frontend servers fetched data from different domains and handled the presentation logic to build the HTML via JSPs.</p></li><li><p>The mid-tier services provided API access to data models.</p></li><li><p>The backend data services provided consistent access to the database.</p></li></ul><p>By 2010, LinkedIn had already built over 150 separate services and by 2015, they had over 750 services.</p><p>The below diagram represents a glimpse of the SOA-based design at LinkedIn:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da33485-b160-4f78-ac18-37c6e613d63b_1377x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da33485-b160-4f78-ac18-37c6e613d63b_1377x1600.png" width="1377" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At this point, you may wonder what was the benefit of this massive change.</p><ul><li><p>First, these services were built in a <strong>stateless manner</strong>. Scaling can be achieved by spinning up new instances of a service and putting them behind a load balancer. Such an approach is known as horizontal scaling and it was more cost-effective compared to scaling the monolithic application.</p></li><li><p>Second, each service was expected to define how much load it could take and the engineering team was able to build out early provisioning and performance monitoring capabilities to support any deviations.</p></li></ul><h2>Managing Hypergrowth with Caching</h2><p>It&#8217;s always a good thing for a business owner to achieve an exponential amount of growth.</p><p>Of course, it does create a bunch of problems. Happy problems but still problems that must be solved.</p><p>Despite moving to service-oriented architecture and going for replicated databases, LinkedIn had to scale even further.</p><p>This led to the adoption of caching.</p><p>Many applications started to introduce mid-tier caching layers like memcached or couchbase. These caches were storing derived data from multiple domains. Also, they added caches to the data layers by using Voldemort to store precomputed results when appropriate.</p><p>However, if you&#8217;ve worked with caching, you would know that caching brings along with it a bunch of new challenges in terms of invalidations, managing consistency, and performance.</p><p>Over time, the LinkedIn team got rid of many of the mid-tier caches.&nbsp;</p><p>Caches were kept close to the data store in order to reduce the latency and support horizontal scalability without the cognitive load of maintaining multiple caching layers.</p><h2>Data Collection with Kafka</h2><p>As LinkedIn&#8217;s footprint grew, it also found itself managing a huge amount of data.</p><p>Naturally, when any company acquires a lot of data, it wants to put that data to good use for growing the business and offering more valuable services to the users. However, to make meaningful conclusions from the data, they have to collect the data and bring it in one place such as a data warehouse.</p><p>LinkedIn started developing many custom data pipelines for streaming and queuing data from one system to another.</p><p>Some of the applications were as follows:</p><ul><li><p>Aggregating logs from every service</p></li><li><p>Collecting data regarding tracking events such as pageviews</p></li><li><p>Queuing of emails for LinkedIn&#8217;s inMail messaging system</p></li><li><p>Keeping the search system up to date whenever someone updates their profile</p></li></ul><p>As LinkedIn grew, it needed more of these custom pipelines and each individual pipeline also had to scale to keep up with the load.</p><p>Something had to be done to support this requirement.</p><p>This led to the development of Kafka, a distributed pub-sub messaging platform. It was built around the concept of a commit log and its main goal was to enable speed and scalability.</p><p>Kafka became a universal data pipeline at LinkedIn and enabled near real-time access to any data source. It empowered the various Hadoop jobs and allowed LinkedIn to build real-time analytics, and improve site monitoring and alerting.</p><p>See the below diagram that shows the role of Kafka at LinkedIn.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac326132-2101-4bdc-895b-0138e1ed9e28_1600x1438.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1309" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac326132-2101-4bdc-895b-0138e1ed9e28_1600x1438.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Over time, Kafka became an integral part of LinkedIn&#8217;s architecture. Some latest facts about Kafka adoption at LinkedIn are as follows:</p><ul><li><p>Over 100 Kafka clusters with more than 4000 brokers</p></li><li><p>100K topics and 7 million partitions</p></li><li><p>7 trillion messages handled per day</p></li></ul><h2>Scaling the Organization with Inversion</h2><p>While scaling is often thought of as a software concern, LinkedIn realized very soon that this is not true.</p><p>At some time, you also need to scale up at an organizational level.&nbsp;</p><p>At LinkedIn, the organizational scaling was carried out via an internal initiative called <strong>Inversion</strong>.</p><p>Inversion put a pause on feature development and allowed the entire engineering organization to focus on improving the tooling and deployment, infrastructure and developer productivity. In other words, they decided to focus on improving the developer experience.</p><p>The goal of Inversion was to increase the engineering capability of the development teams so that new scalable products for the future could be built efficiently and in a cost-effective way.&nbsp;</p><p>Let&#8217;s look at a few significant tools that were built as part of this initiative:</p><h3>Rest.li</h3><p>During the transformation from Leo to a service-oriented architecture, the extracted APIs were based on Java-based RPC.&nbsp;</p><p>Java-based RPC made sense in the early days but it was no longer sufficient as LinkedIn&#8217;s systems evolved into a polyglot ecosystem with services being written in Java, Node.js, Python, Ruby and so on. For example, it was becoming hard for mobile services written in Node.js to communicate with Java object-based RPC services.</p><p>Also, the earlier APIs were tightly coupled with the presentation layer, making it difficult to make changes.</p><p>To deal with this, the LinkedIn engineers created a new API model called <strong>Rest.li</strong>.</p><p><strong>What made Rest.li so special?</strong></p><p>Rest.li was a framework for developing RESTful APIs at scale. It used simple JSON over HTTP, making it easy for non-Java-based clients to communicate with Java-based APIs.</p><p>Also, Rest.li was a step towards a data-model-based architecture that brought a consistent API model across the organization.&nbsp;</p><p>To make things even more easy for developers, they started using Dynamic Discovery (D2) with Rest.li services. With D2, there was no need to configure URLs for each service that you need to talk to. It provides multiple features such as client-based load balancing, service discovery and scalability.</p><p>The below diagram shows the use of Rest.li along with Dynamic Discovery.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faba00d83-f7b0-48c2-a0c3-6bcbaf05df3d_1508x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1545" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faba00d83-f7b0-48c2-a0c3-6bcbaf05df3d_1508x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Super Blocks</h3><p>A service-oriented architecture is great for decoupling domains and scale out services independently.</p><p>However, there are also downsides.</p><p>Many of the applications at LinkedIn depend on data from multiple sources. For example, any request for a user&#8217;s profile page not only fetches the profile data but includes other details such as photos, connections, groups, subscription information, following info, long-form blog posts and so on.</p><p>In a service-oriented architecture, it means making hundreds of calls to fetch all the needed data.&nbsp;</p><p>This is typically known as the &#8220;call graph&#8221; and you can see that this call graph can become difficult to manage as more and more services are created.</p><p>To mitigate this issue, LinkedIn introduced the concept of a <strong>super block</strong>.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F051be3c2-80fe-4b60-ba6f-e47027cfcd84_1600x1177.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1071" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F051be3c2-80fe-4b60-ba6f-e47027cfcd84_1600x1177.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>A super block is a grouping of related backend services with a single access API.&nbsp;</p><p>This allows teams to create optimized interfaces for a bunch of services and keep the call graph in check. You can think of the super block as the implementation of the facade pattern.</p><h3>Multi-Data Center</h3><p>In a few years after launch, LinkedIn became a global company with users joining from all over the world.</p><p>They had to scale beyond serving traffic from just one data center. Multiple data centers are incredibly important to maintain high availability and avoid any single point of failure. Moreover, this wasn&#8217;t needed just for a single service but the entire website.</p><p>The first move was to start serving public profiles out of two data centers (Los Angeles and Chicago).&nbsp;</p><p>Once it was proven that things work, they enhanced all other services to support the below features:</p><ul><li><p>Data replication</p></li><li><p>Callbacks from different origins</p></li><li><p>One-way data replication events</p></li><li><p>Pinning users to geographically-close data centers</p></li></ul><p>As LinkedIn has continued to grow, they have migrated the edge infrastructure to Azure Front Door (AFD). For those who don&#8217;t know, AFD is Microsoft&#8217;s global application and content delivery network and migrating to it provided some great benefits in terms of latency and resilience.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82dd657c-0cf0-495c-8e32-62c2445402ce_700x365.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="365" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82dd657c-0cf0-495c-8e32-62c2445402ce_700x365.png" width="700" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Image Source: <a href="https://www.linkedin.com/blog/engineering/scalability/linkedin-scales-edge-with-azure-front-door">Scaling LinkedIn&#8217;s Edge with Azure Front Door</a> </figcaption></figure></div><p>This move scaled them up to 165+ Points of Presence (PoPs) and helped improve median page load times by up to 25 percent.</p><p>The edge infrastructure is basically how our devices connect to LinkedIn today. Data from our device traverses the internet to the closest PoP that houses HTTP proxies that forward those requests to an application server in one of the LinkedIn data centers.</p><h2>Advanced Developments Around Scalability</h2><p>Running an application as complex and evolving as LinkedIn requires the engineering team to keep investing into building scalable solutions.</p><p>In this section, we will look at some of the more recent developments LinkedIn has undergone.</p><h3>Real Time Analytics with Pinot</h3><p>A few years ago, the LinkedIn engineering team hit a wall with regards to analytics</p><p>The scale of data at LinkedIn was growing far beyond what they could analyze. The analytics functionality was built using generic storage systems like Oracle and Voldemort. However, these systems were not specialized for OLAP needs and the data volume at LinkedIn was growing in both breadth and depth.</p><p>At this point, you might be wondering about the need for real-time analytics at LinkedIn.&nbsp;</p><p>Here are three very important use-cases:</p><ol><li><p>The <strong>Who&#8217;s Viewed Your Profile</strong> is LinkedIn&#8217;s flagship analytics product that allows members to see who has viewed their profile in real-time. To provide this data, the product needs to run complex queries on large volumes of profile view data to identify interesting insights.</p></li><li><p><strong>Company Page Analytics</strong> is another premium product offered by LinkedIn. The data provided by this product enables company admins to understand the demographic of the people following their page.</p></li><li><p>LinkedIn also heavily uses analytics internally to support critical requirements such as A/B testing.</p></li></ol><p>To support these key analytics products and many others at scale, the engineering team created Pinot.</p><p><strong>Pinot is a web-scale real-time analytics engine designed and built at LinkedIn</strong>.&nbsp;</p><p>It allows them to slice, dice and scan through massive quantities of data coming from a wide variety of products in real-time.</p><p><strong>But how does Pinot solve the problem?</strong></p><p>The below diagram shows a comparison between the pre-Pinot and post-Pinot setup.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23532699-4d61-491f-9476-05d57b3844b4_1274x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23532699-4d61-491f-9476-05d57b3844b4_1274x1600.png" width="1274" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As you can see, Pinot supports real-time data indexing from Kafka and Hadoop, thereby simplifying the entire process.</p><p>Some of the other benefits of Pinot are as follows:</p><ul><li><p>Pinot supports low latency and high QPS OLAP queries. For example, it&#8217;s capable of serving thousands of <strong>Who&#8217;s Viewed My Profile</strong> requests while maintaining SLA in the order of 10s of milliseconds</p></li><li><p>Pinot also simplifies operational aspects like cluster rebalancing, adding or removing nodes, and re-bootstrapping</p></li><li><p>Lastly, Pinot has been future-proofed to handle new data dimensions without worrying about scale</p></li></ul><h3>Authorization at LinkedIn Scale</h3><p>Users entrust LinkedIn with their personal data and it was extremely important for them to maintain that trust.</p><p>After the SOA transformation, LinkedIn runs a microservice architecture where each microservice retrieves data from other sources and serves it to the clients. Their philosophy is that a microservice can only access data with a valid business use case. It prevents the unnecessary spreading of data and minimizes the damage if an internal service gets compromised.</p><p>A common industry solution to manage the authorization is to define Access Control Lists (ACLs). An ACL contains a list of entities that are either allowed or denied access to a particular resource.</p><p>For example, let&#8217;s say there is a Rest.li resource to manage <strong>greetings</strong>. The ACL for this resource can look something like this.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F950bb2f6-8976-49e6-b7df-94003dc4782a_1600x1045.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="951" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F950bb2f6-8976-49e6-b7df-94003dc4782a_1600x1045.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In this case, the <strong>client-service</strong> can read but not write whereas the <strong>admin-service</strong> can both read and write to greetings.</p><p>While the concept of an ACL-based authorization is quite simple, it&#8217;s a challenge to maintain at scale. LinkedIn has over 700 services that communicate at an average rate of tens of millions of calls per second. Moreover, this figure is only growing.</p><p>Therefore, the team had to devise a solution to handle ACLs at scale. Mainly, there were three critical requirements:</p><ul><li><p>Check authorization quickly</p></li><li><p>Deliver ACL changes quickly</p></li><li><p>Track and manage a large number of ACLs</p></li></ul><p>The below diagram shows a high-level view of how LinkedIn manages authorization between services.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98ce60b8-b354-48cc-8f0f-6834403bedbb_1999x1207.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="879" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98ce60b8-b354-48cc-8f0f-6834403bedbb_1999x1207.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Some key points to consider over here are as follows:</p><ul><li><p>To make authorization checks quick, they built an authorization client module that runs on every service at LinkedIn. This module decides whether an action should be allowed or denied. New services pick up this client by default as part of the basic service architecture.</p></li><li><p>Latency is a critical factor during an authorization check and making a network call every time is not acceptable. Therefore, all relevant ACL data is kept in memory by the service.</p></li><li><p>To keep the ACL data fresh, every client reaches out to the server at fixed intervals and updates its in-memory copy. This is done at a fast enough cadence for any ACL changes to be realized quickly.</p></li><li><p>All ACLs are stored in LinkedIn&#8217;s Espresso database. It&#8217;s a fault-tolerant distributed NoSQL database that provides a simple interface.</p></li><li><p>To manage latency and scalability, they also keep a Couchbase cache in front of Espresso. This means even on the server side, the data is served from memory. To deal with stale data in the Couchbase, they use a Change Data Capture system based on LinkedIn&#8217;s Brooklin to notify the service when an ACL has changed so that the cache can be cleared.</p></li><li><p>Every authorization check is logged in the background. This is necessary for debugging and traffic analysis. LinkedIn uses Kafka for asynchronous, high-scale logging. Engineers can check the data in a separate monitoring system known as <strong>inGraphs</strong>.</p></li></ul><h2>Conclusion</h2><p>In this post, we&#8217;ve taken a brief look at the scaling journey of LinkedIn.</p><p>From its simple beginnings as a standalone monolithic system serving a few thousand users, LinkedIn has come a long way. It is one of the largest social networks in the world for professionals and companies, allowing seamless connection between individuals across the globe.</p><p>To support the growing demands, LinkedIn had to undertake bold transformations at multiple steps.&nbsp;</p><p>In the process, they&#8217;ve provided a lot of learnings for the wider developer community that can help you in your own projects.</p><p><strong>References</strong>:</p><ul><li><p><a href="https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin">A Brief History of Scaling LinkedIn</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/scalability/linkedin-scales-edge-with-azure-front-door">Scaling LinkedIn&#8217;s Edge with Azure Front Door</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/open-source/apache-kafka-trillion-messages">How LinkedIn customizes Apache Kafka for 7 trillion messages per day</a></p></li><li><p><a href="https://engineering.linkedin.com/real-time-distributed-graph/using-set-cover-algorithm-optimize-query-latency-large-scale-distributed">Using Set Cover Algorithm to optimize query latency for a large-scale distributed graph</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/scalability/authorization-at-linkedins-scale">Authorization at LinkedIn&#8217;s Scale</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/architecture/restli-restful-service-architecture-scale">Rest.li: RESTful Service Architecture at Scale</a></p></li><li><p><a href="https://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot">Real-time analytics at a massive scale with Pinot</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p><br /><br /><br /><br /><br /><br /><br /><br /></p>
]]></content:encoded>
<pubDate>Tue, 28 May 2024 15:31:05 GMT</pubDate>
</item>
<item>
<title>EP113: AWS Services Cheat Sheet</title>
<link>https://blog.bytebytego.com/p/ep113-aws-services-cheat-sheet</link>
<guid>https://blog.bytebytego.com/p/ep113-aws-services-cheat-sheet</guid>
<content:encoded><![CDATA[
<div> AWS Services, API designs, Postman, Azure Services, computer programs run

<br />
API设计和发布对于应用程序的成功至关重要。Postman为团队合作提供了有效的工具，使API设计、测试和文档编写更加简单和高效。AWS和Azure作为主要云服务平台，提供了丰富的服务和功能，满足了不同用户的需求。运行计算机程序涉及多个步骤，包括用户交互、程序预加载、依赖解析和加载、内存分配以及程序终止。这些技术和工具的发展不断推动着软件开发和云计算技术的进步。总结:API设计和发布对于应用程序至关重要，Postman为团队合作提供了有效工具，AWS和Azure作为云服务平台提供丰富服务，计算机程序的运行包括多个步骤，推动软件开发和云计算技术的发展。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Do You Know How Mobile Apps Are Released? (Youtube video)</p></li><li><p>AWS Services Cheat Sheet </p></li><li><p>A cheat sheet for API designs</p></li><li><p>Azure Services Cheat Sheet </p></li><li><p>How do computer programs run? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Postman_052425Headline">Collaborating on APIs is Easier With Postman (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Postman_052425Headline" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="819" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e4e769d-06a0-4464-b727-b9b39c6f2133_1660x934.png" width="1456" /><div></div></div></a></figure></div><p>Whether you&#8217;re a team of four or 40,000, development teams need to collaborate on APIs. <a href="https://bit.ly/Postman_052425Headline">API Collaboration</a>&nbsp;improves developer productivity by empowering both API producers and consumers to share, discover, and reuse high-quality API assets.</p><p>Postman revolutionizes the experience of collaborative API development with <a href="https://bit.ly/Postman_052524Collections">Collections</a> and <a href="https://bit.ly/Postman_052425Workspaces">Workspaces</a>. Used together, they enable API design, testing, and documentation, providing a shared canvas for collaborating on API assets.</p><p>Learn how Postman is giving teams of all sizes and functions the ability to rapidly iterate on API development, elevate the quality of their APIs, and extend their API workflows for large-scale initiatives.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Postman_052425Headline"><span>Learn More</span></a></p><div><hr /></div><h2>Do You Know How Mobile Apps Are Released?</h2><div class="youtube-wrap" id="youtube2-RIX4ufelA58"><div class="youtube-inner"></div></div><div><hr /></div><h2>AWS Services Cheat Sheet </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F915d1659-0779-460e-b71f-a7dd9d812556_1415x1536.gif" title="No alternative text description for this image" width="1415" /><div></div></div></a></figure></div><p>AWS grew from an in-house project to the market leader in cloud services, offering so many different services that even experts can find it a lot to take in. <br /> <br />The platform not only caters to foundational cloud needs but also stays at the forefront of emerging technologies such as machine learning and IoT, establishing itself as a bedrock for cutting-edge innovation. AWS continuously refines its array of services, ensuring advanced capabilities for security, scalability, and operational efficiency are available. <br /> <br />For those navigating the complex array of options, this AWS Services Guide is a helpful visual aid. <br /> <br />It simplifies the exploration of AWS's expansive landscape, making it accessible for users to identify and leverage the right tools for their cloud-based endeavors. <br /> <br />Over to you: What improvements would you like to see in AWS services based on your usage?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1893" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66e9dc1a-3ca4-40a6-9578-ee59e9ae0ef8_3000x3900.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>A cheat sheet for API designs</h2><p>APIs expose business logic and data to external systems, so designing them securely and efficiently is important.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae83c804-21ac-4baa-ab4a-56ca0ba0f4d2_1452x1536.gif" title="No alt text provided for this image" width="1452" /><div></div></div></a></figure></div><ul><li><p>API key generation<br />We normally generate one unique app ID for each client and generate different pairs of public key (access key) and private key (secret key) to cater to different authorizations. For example, we can generate one pair of keys for read-only access and another pair for read-write access. <br /></p></li><li><p>Signature generation<br />Signatures are used to verify the authenticity and integrity of API requests. They are generated using the secret key and typically involve the following steps:<br /><br />- Collect parameters<br />- Create a string to sign<br />- Hash the string: Use a cryptographic hash function, like HMAC (Hash-based Message Authentication Code) in combination with SHA-256, to hash the string using the secret key. <br /></p></li><li><p>Send the requests<br />When designing an API, deciding what should be included in HTTP request parameters is crucial. Include the following in the request parameters:<br /><br />- Authentication Credentials<br />- Timestamp: To prevent replay attacks.<br />- Request-specific Data: Necessary to process the request, such as user IDs, transaction details, or search queries.<br />- Nonces: Randomly generated strings included in each request to ensure that each request is unique and to prevent replay attacks.<br /></p></li><li><p>Security guidelines<br />To safeguard APIs against common vulnerabilities and threats, adhere to these security guidelines.</p></li></ul><div><hr /></div><h2>Azure Services Cheat Sheet </h2><p>Launching in 2010, Microsoft Azure has quickly grown to hold the No. 2 position in market share by evolving from basic offerings to a comprehensive, flexible cloud ecosystem.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc905b80e-685f-4145-a12c-02d704f70efd_1414x1536.gif" title="No alt text provided for this image" width="1414" /><div></div></div></a></figure></div><p>Today, Azure not only supports traditional cloud applications but also caters to emerging technologies such as AI, IoT, and blockchain, making it a crucial platform for innovation and development.<br /><br />As it evolves, Azure continues to enhance its capabilities to provide advanced solutions for security, scalability, and efficiency, meeting the demands of modern enterprises and startups alike. This expansion allows organizations to adapt and thrive in a rapidly changing digital landscape.<br /><br />The attached illustration can serve as both an introduction and a quick reference for anyone aiming to understand Azure.<br /><br />Over to you: How does your experience with Azure compare to that with AWS?<br /><br />Over to you: Does the card network charge the same interchange fee for big merchants as for small merchants?</p><div><hr /></div><h2>How do computer programs run? </h2><p>The diagram shows the steps. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F416ff1bc-c6c4-475a-b45f-7842fbfcd726_1435x1536.gif" title="No alternative text description for this image" width="1435" /><div></div></div></a></figure></div><ul><li><p>User interaction and command initiation <br />By double-clicking a program, a user is instructing the operating system to launch an application via the graphical user interface. <br /></p></li><li><p>Program Preloading <br />Once the execution request has been initiated, the operating system first retrieves the program's executable file. <br /> <br />The operating system locates this file through the file system and loads it into memory in preparation for execution. <br /></p></li><li><p>Dependency resolution and loading <br />Most modern applications rely on a number of shared libraries, such as dynamic link libraries (DLLs). </p><p></p></li><li><p>Allocating memory space <br />The operating system is responsible for allocating space in memory. <br /> </p></li><li><p>Initializing the Runtime Environment <br />After allocating memory, the operating system and execution environment (e.g., Java's JVM or the .NET Framework) will initialize various resources needed to run the program. <br /></p></li><li><p>System Calls and Resource Management <br />The entry point of a program (usually a function named `main`) is called to begin execution of the code written by the programmer. <br /></p></li><li><p>Von Neumann Architecture <br />In the Von Neumann architecture, the CPU executes instructions stored in memory. <br /></p></li><li><p>Program termination <br />Eventually, when the program has completed its task, or the user actively terminates the application, the program will begin a cleanup phase. This includes closing open file descriptors, freeing up network resources, and returning memory to the system. </p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Sat, 25 May 2024 15:30:49 GMT</pubDate>
</item>
<item>
<title>API Security Best Practices</title>
<link>https://blog.bytebytego.com/p/api-security-best-practices</link>
<guid>https://blog.bytebytego.com/p/api-security-best-practices</guid>
<content:encoded><![CDATA[
<div> APIs, security vulnerabilities, threats, authentication, best practices

<br />
API安全性是现代应用程序的支柱。API暴露了很大的攻击面，增加了安全漏洞的风险。常见的威胁包括SQL注入、跨站脚本攻击和分布式拒绝服务（DDoS）攻击。因此，实施强大的安全措施来保护API和其处理的敏感数据至关重要。认证确保只有经授权的用户或应用程序可以访问受保护的资源或API端点。在实现认证之前，选择适当的认证机制非常重要，根据我们的用例、安全要求和与客户端应用程序的兼容性。以下是保护API的一些流行认证机制。

<br /><br />总结:API安全性至关重要，需要应对潜在的安全漏洞和威胁。认证是确保只有授权用户访问受保护资源或API端点的关键。选择适当的认证机制，并实施安全措施如身份验证、授权、安全通信和速率限制，是设计安全API的核心策略。 <div>
<p>APIs are the backbone of modern applications. They expose a very large surface area for attacks, increasing the risk of security vulnerabilities. Common threats include SQL injection, cross-site scripting, and distributed denial of service (DDoS) attacks.&nbsp;</p><p>That's why it's crucial to implement robust security measures to protect APIs and the sensitive data they handle. However, many companies struggle to achieve comprehensive API security coverage. They often rely solely on dynamic application security scanning or external pen testing. While these methods are valuable, they may not fully cover the API layer and its increasing attack surface.&nbsp;</p><p>In this week&#8217;s issue, we'll explore API security best practices. From authentication and authorization to secure communication and rate limiting, we&#8217;ll cover essential strategies for designing secure APIs.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66e9dc1a-3ca4-40a6-9578-ee59e9ae0ef8_3000x3900.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1893" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66e9dc1a-3ca4-40a6-9578-ee59e9ae0ef8_3000x3900.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>Authentication</h2><p>Authentication ensures that only authorized users or applications can access protected resources or API endpoints. Before implementing authentication, choosing the appropriate authentication mechanism is crucial based on our use case, security requirements, and compatibility with client applications.&nbsp;</p><p>Below are some popular authentication mechanisms for securing APIs:</p>
      <p>
          <a href="https://blog.bytebytego.com/p/api-security-best-practices">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 23 May 2024 15:30:58 GMT</pubDate>
</item>
<item>
<title>How Slack Built a Distributed Cron Execution System for Scale</title>
<link>https://blog.bytebytego.com/p/how-slack-built-a-distributed-cron</link>
<guid>https://blog.bytebytego.com/p/how-slack-built-a-distributed-cron</guid>
<content:encoded><![CDATA[
<div> Slack, cron execution system, scalability, reliability, Job Queue

总结:<br /><br />
Slack在处理大规模系统中的cron执行工作时遇到了挑战，决定重新构建分布式cron执行系统。他们采用了Scheduled Job Conductor、Job Queue和Vitess Database Table等组件来解决问题。Scheduled Job Conductor使用Go和Kubernetes实现，采用了Leader-Follower架构和灵活的横向扩展。Job Queue则处理资源密集的任务，通过Kafka和Redis实现高效的作业处理。最后，Vitess表用于数据重复处理和作业跟踪，提高了系统的可靠性和监控。Slack的经验表明，通过简单的解决方案构建大规模系统是可行的。 <div>
<h2><a href="https://bit.ly/QAWolf_052124">&#128075;Goodbye low test coverage and slow QA cycles (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_052124" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="750" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2e17972-3779-4bb2-beb3-1fadf11f4c85_1000x750.png" width="1000" /><div></div></div></a></figure></div><p>Bugs sneak out when less than 80% of user flows are tested before shipping. But getting that kind of coverage &#8212; and staying there &#8212; is hard and pricey for any sized team.</p><p><a href="https://bit.ly/QAWolf_052124">QA Wolf</a> takes testing off your plate:</p><p>&#8594; Get to 80% test coverage in just 4 months.</p><p>&#8594; Stay bug-free with <a href="https://bit.ly/QAWolf_052124">24-hour maintenance</a> and on-demand test creation.</p><p>&#8594; Get <a href="https://bit.ly/QAWolf_052124">unlimited parallel test runs</a></p><p>&#8594; Zero Flakes guaranteed</p><p>QA Wolf has generated <a href="https://bit.ly/QAWolf_052124">amazing results</a> for companies like Salesloft, AutoTrader, Mailchimp, and Bubble.</p><p>&#127775; Rated 4.5/5 on G2</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_052124"><span>Learn more about their 90-day pilot</span></a></p><div><hr /></div><p>Have you ever stretched a simple tool to its absolute limits before you upgraded?</p><p>We do it all the time. And so do the big companies that operate on a massive scale. This is because simple things can sometimes take you much further than you initially think. Of course, you may have to pay with some toil and tears.</p><p>This is exactly what Slack, a $28 billion company with 35+ million users, did for its cron execution workflow that handles critical functionalities. Instead of moving to some other new-age solutions, they rebuilt their cron execution system from the ground up to run jobs reliably at their scale.&nbsp;</p><p>In today&#8217;s post, we&#8217;ll look at how Slack architected a distributed cron execution system and the choices made in the overall design.</p><div><hr /></div><h2>The Role of Cron Jobs at Slack</h2><p>As you already know, Slack is one of the most popular platforms for team collaboration.&nbsp;</p><p>Due to its primary utility as a communication tool, Slack is super dependent on the right notification reaching the right person at the right time.&nbsp;</p><p>However, as the platform witnessed user and feature growth, Slack faced challenges in maintaining the reliability of its notification system, which largely depended on cron jobs.&nbsp;</p><p>For reference, cron jobs are used to automate repetitive tasks. You can configure a cron job to ensure that specific scripts or commands run at predefined intervals without manual intervention.</p><p>Cron jobs play a crucial role in Slack's notification system by making sure that messages and reminders reach users on time. A lot of the critical functionality at Slack relies on these cron scripts. For example,&nbsp;</p><ul><li><p>Sending timely reminders to users.</p></li><li><p>Delivering email notifications to keep the users informed about important updates in the team.</p></li><li><p>Pushing message notifications to users so that they don&#8217;t miss critical conversations.</p></li><li><p>Performing regular database clean-ups to maintain system performance.</p></li></ul><p>As Slack grew, there has been a massive growth in the number of cron scripts and the amount of data processed by these scripts. Ultimately, this caused a dip in the overall reliability of the execution environment.</p><h2>The Issues with Cron Jobs</h2><p>Some of the challenges and issues Slack faced with their original cron execution approach were as follows:</p><ul><li><p><strong>Maintainability Issues:</strong> Managing many cron scripts on a single node became cumbersome and error-prone as Slack&#8217;s functionalities expanded. Tasks like updating, troubleshooting, and monitoring the scripts required a lot of effort from the engineering team.</p></li><li><p><strong>Cost-ineffective Vertical Scaling: </strong>As the number of cron scripts increased, Slack tried to vertically scale the node by adding more CPU and RAM. However, this approach quickly became cost-ineffective, as the hardware requirements grew disproportionately to the number of scripts.</p></li><li><p><strong>Single Point of Failure: </strong>Relying on a single node to execute all cron jobs introduced a significant risk to Slack&#8217;s critical functionality. Any misconfigurations, hardware failures, or software issues on the node could bring down the entire notification system.</p></li></ul><p>To solve these issues, Slack decided to build a brand new cron execution service that was more reliable and scalable than the original approach.</p><h2>The High-Level Cron Execution Architecture</h2><p>The below diagram shows the high-level cron execution architecture.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F494650c6-0993-4b60-b69f-f1cd05c464c6_1600x995.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="905" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F494650c6-0993-4b60-b69f-f1cd05c464c6_1600x995.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>There are 3 main components in this design. Let&#8217;s look at each of them in more detail.</p><h3>Scheduled Job Conductor</h3><p>Slack developed a new execution service. It was written in Go and deployed on Bedrock.</p><p>Bedrock is Slack&#8217;s in-house platform that wraps around Kubernetes, providing an additional abstraction layer and functionality for Slack&#8217;s specific needs. It builds upon Kubernetes and adds some key features such as:</p><ul><li><p>Simplified deployment</p></li><li><p>Custom resource definitions specific to Slack&#8217;s infrastructure</p></li><li><p>Enhanced monitoring and logging</p></li><li><p>Integration with Slack&#8217;s infrastructure</p></li></ul><p>The new service mimics the behavior of cron by utilizing a Go-based cron library while benefiting from the scalability and reliability provided by Kubernetes.&nbsp;</p><p>The below diagram shows how the Scheduled Job Conductor works in practice.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3c56544-a9d4-40e6-88b9-68fee6d3cefc_1600x998.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="908" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3c56544-a9d4-40e6-88b9-68fee6d3cefc_1600x998.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>It had some key properties that we should consider.</p><h4>1 - Scalability through Kubernetes Deployment</h4><p>By deploying the cron execution service on Bedrock, Slack gains the ability to easily scale up multiple pods as needed.&nbsp;</p><p>As you might be aware, Kubernetes provides a flexible infrastructure for containerized applications. You can dynamically adjust the number of pods based on the workload.</p><h4>2 - Leader Follower Architecture</h4><p>Interestingly, Slack's cron execution service does not process requests on multiple pods simultaneously.&nbsp;</p><p>Instead, they adopt a leader-follower architecture, where only one pod (the leader) is responsible for scheduling jobs, while the other pods remain in standby mode.&nbsp;</p><p>This design decision may seem counterintuitive, as it appears to introduce a single point of failure. However, the Slack team determined that synchronizing the nodes would be a more significant challenge than the potential risk of having a single leader.</p><p>A couple of advantages of the leader-follower architecture are as follows:</p><ul><li><p><strong>Rapid Failover: </strong>If the leader pod goes down, Kubernetes can quickly promote one of the standby pods to take over the work. This minimizes downtime and makes the cron execution service highly available.</p></li><li><p><strong>Simplified Synchronization: </strong>By having a single leader, Slacks avoids the complexity of dealing with conflicts.</p></li></ul><h4>3 - Offloading Resource-Intensive Tasks</h4><p>The job conductor service is only responsible for job scheduling. The actual execution is handled by worker nodes.</p><p>This separation of concerns allows the cron execution service to focus on job scheduling while the job queue handles resource-intensive tasks.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" title="" width="1109" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>The Job Queue</h3><p>Slack's cron execution service relies on a powerful asynchronous compute platform called the Job Queue to handle the resource-intensive task of running scripts.&nbsp;</p><p>The Job Queue is a critical component of Slack's infrastructure, processing a whopping 9 billion jobs per day.</p><p>The Job Queue consists of a series of so-called theoretical &#8220;queues&#8221; through which various types of jobs flow. Each script triggered by a cron job is treated as a single job within the Job Queue.</p><p>See the below diagram for reference:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9144169-fc4e-474b-b6e5-d900ae76ff66_1600x996.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="906" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9144169-fc4e-474b-b6e5-d900ae76ff66_1600x996.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The key components of the job queue architecture are as follows:</p><ul><li><p><strong>Kafka: </strong>Jobs are initially stored in Kafka since it provides durable storage. Kafka ensures that jobs are persisted and can be recovered in case of system failures or backups.</p></li><li><p><strong>Redis: </strong>From Kafka, jobs are moved into Redis (an in-memory data store) for short-term storage. Redis allows additional metadata, such as the identity of the worker executing the job, to be stored alongside the job itself. This metadata is important for tracking and managing job execution.</p></li><li><p><strong>Job Workers:</strong> Jobs are dispatched from Redis to job workers, which are nodes that execute the script. Each job worker is capable of running the scripts associated with the jobs it receives.</p></li></ul><p>Slack achieves several important benefits by using the Job Queue:</p><ul><li><p><strong>Offloading compute and memory concerns: </strong>The Job Queue is designed to handle a massive amount of work, with a capacity far exceeding the requirements of the cron execution service. Offloading the compute and memory demands of the running scripts helps keep the cron execution service lightweight.</p></li><li><p><strong>Isolation and performance: </strong>The Job Queue lets them keep the jobs isolated on their specific &#8220;queues&#8221; so that the jobs triggered by the cron execution service are processed smoothly. There is no impact on them due to other jobs in the system.</p></li><li><p><strong>Reliability and fault tolerance: </strong>The Job Queue&#8217;s architecture ensures that jobs are stored durably and recoverable in case of failures.</p></li><li><p><strong>Reduce development and maintenance efforts: </strong>This was probably the most important factor since leveraging an existing, battle-tested system like the Job Queue helped Slack reduce the development time required to build the cron execution service.</p></li></ul><h3>Vitess Database Table for Job Tracking</h3><p>To boost the reliability of their cron execution service, Slack also employed a Vitess table for deduplication and job tracking.</p><p>Vitess is a database clustering system for horizontal scaling of MySQL. It provides a scalable and highly available solution for managing large-scale data.</p><p>A couple of important requirements handled by Vitess are as described as follows:</p><h4>1 - Deduplication</h4><p>Within Slack&#8217;s original cron system, they used <strong>flocks</strong>, a Linux utility for managing locking in scripts so that only one copy of a script runs at a time.&nbsp;</p><p>While this approach worked fine, there were cases where a script&#8217;s execution time exceeded its recurrence intervals, leading to the possibility of two copies running concurrently.</p><p>To handle this issue, Slack introduced a Vitess table to handle deduplication.</p><p>Here&#8217;s how it works:</p><ul><li><p>When a new job is triggered, Slack records its execution as a new row in the Vitess table.</p></li><li><p>The job&#8217;s status is updated as it progresses through the system, with possible states including &#8220;enqueued&#8221;, &#8220;in progress&#8221;, and &#8220;done&#8221;.</p></li><li><p>Before kicking off a new run of a job, Slack queries the table to check if there are any active instances of the same job already running. This query is made efficient by using an index on the script names.</p></li></ul><p>The below diagram shows some sample data stored in Vitess.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbe4dc22-6be8-4a6d-b0b3-14029d47718b_1600x941.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="856" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbe4dc22-6be8-4a6d-b0b3-14029d47718b_1600x941.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h4>2 - Job Tracking and Monitoring</h4><p>The Vitess table also helps with job tracking and monitoring since it contains information about the state of each job.</p><p>The job tracking functionality is exposed through a simple web page that displays the execution details. Developers can easily look up the state of their script runs and any errors encountered during execution.</p><h2>Conclusion</h2><p>One can debate whether using cron was the right decision for Slack when it came to job scheduling.</p><p>But it can also be said that organizations that choose the simplest solution for critical functionalities are more likely to grow into organizations of Slack&#8217;s size. On the other hand, companies that deploy solutions that try to solve all the problems when they have 0 customers never become that big. The difference is an unrelenting focus on solving the business problem rather than building fancy solutions from the beginning.</p><p>Slack&#8217;s journey from a single cron box to a sophisticated, distributed cron execution service shows how simple solutions can be used to build large-scale systems.</p><p><strong>References:</strong></p><ul><li><p><a href="https://slack.engineering/executing-cron-scripts-reliably-at-scale/">Executing Cron Scripts Reliably at Scale</a></p></li><li><p><a href="https://slack.engineering/scaling-slacks-job-queue/">Scaling Slack&#8217;s Job Queue</a></p></li><li><p><a href="https://slack.engineering/applying-product-thinking-to-slacks-internal-compute-platform/">Applying Product Thinking to Slack&#8217;s Internal Compute Platform</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p></p>
]]></content:encoded>
<pubDate>Tue, 21 May 2024 15:31:08 GMT</pubDate>
</item>
<item>
<title>Cloudflare’s Trillion-Message Kafka Infrastructure: A Deep Dive</title>
<link>https://blog.bytebytego.com/p/cloudflares-trillion-message-kafka</link>
<guid>https://blog.bytebytego.com/p/cloudflares-trillion-message-kafka</guid>
<content:encoded><![CDATA[
<div> 云服务、Kafka、挑战、解决方案、扩展规模
<br />
总结:云服务公司Cloudflare通过Kafka处理了1万亿条消息。早期使用PHP的单块架构导致挑战，因此采用Kafka解决服务耦合和重试问题。后来使用Protocol Buffers标准化消息，提高传输效率。引入连接器框架简化数据同步流程。面临的扩展挑战包括可见性不足、过于频繁的告警以及无法跟上生产速率。通过改进健康检查，批量消费等技术，成功解决这些挑战。 <div>
<p><em>Disclaimer: The content (text and diagrams) in this post has been derived and compiled from the fantastic articles originally published on the Cloudflare Tech Blog by Matt Boyle, Andrea Medda, and Chris Shepherd. All credit for the details covered here goes to them. The links to the exact articles are in the references section at the end of the post. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><div><hr /></div><p>How much is 1 trillion?</p><p>If you were to start counting one number per second, it would take you over 31000 years to reach 1 trillion.</p><p>Now, imagine processing 1 trillion messages. This is the incredible milestone Cloudflare&#8217;s Kafka infrastructure achieved recently.</p><p>Cloudflare&#8217;s vision is to build a better Internet by providing a global network. They enable customers to secure and accelerate their websites, APIs, and applications.</p><p>However, as Cloudflare&#8217;s customer base grew rapidly, they needed to handle massive volumes of data and traffic while maintaining high availability and performance. Both scale and resilience were significant for their Kafka infrastructure.</p><p>Cloudflare has been using Kafka in production since 2014. They currently run 14 distinct Kafka clusters with roughly 330 nodes spread over multiple data centers.&nbsp;</p><p>In this article, we will explore the challenges solved and lessons learned by Cloudflare&#8217;s engineering team in their journey of scaling Kafka.</p><div><hr /></div><h2>The Early Days</h2><p>In the early days of Cloudflare, their architecture was built around a monolithic PHP application.&nbsp;</p><p>While this approach worked well initially, it created challenges as their product offerings grew. With numerous teams contributing to the same codebase, the monolithic architecture started to impact Cloudflare's ability to deliver features and updates safely and efficiently.</p><p>A couple of major issues were as follows:</p><ul><li><p>There was a tight coupling between services. Any change had a significant impact radius and required a lot of coordination between teams.&nbsp;</p></li><li><p>It was difficult to implement retry mechanisms to handle scenarios when something went wrong.</p></li></ul><p>To address these challenges, Cloudflare turned to Apache Kafka as a solution for decoupling services and enabling retry mechanisms.&nbsp;</p><p>See the diagram below that demonstrates this scenario.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9289fec1-bb42-4a98-9079-b5111f4df6cd_1600x927.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="844" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9289fec1-bb42-4a98-9079-b5111f4df6cd_1600x927.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>As you can notice, if multiple teams needed to emit messages that the audit log system was interested in, they could simply produce messages for the appropriate topics.&nbsp;</p><p>The audit log system could then consume from those topics without any direct coupling to the producing services. Adding a new service that needed to emit audit logs was as simple as producing for the right topics, without requiring any changes to the consuming side.</p><p>Kafka, a distributed streaming platform, had already proven its ability to handle massive volumes of data within Cloudflare's infrastructure.&nbsp;</p><p>As a first step, they created a message bus cluster on top of Kafka. It became the most general-purpose cluster available to all application teams at Cloudflare.&nbsp;</p><p>Onboarding to the cluster was made simple through a pull request process, which automatically set up topics with the desired replication strategy, retention period, and access control lists (ACLs).</p><p>The impact of the message bus cluster on loose coupling was evident.&nbsp;</p><ul><li><p>Teams could now emit messages to topics without being aware of the specific services consuming those messages.</p></li><li><p>Consuming services could listen to relevant topics without needing to know the details of the producing services.</p></li></ul><p>There was greater flexibility and independence among teams.&nbsp;</p><h2>Standardizing Communication</h2><p>As Cloudflare&#8217;s architecture evolved towards a decoupled and event-driven system, a new challenge emerged: unstructured communication between services.&nbsp;</p><p>There was no well-defined contract for message formats, leading to issues.</p><p>A common pitfall was the lack of agreement on message structure. For example, a producer might send a JSON blob with certain expected keys, but if the consumer wasn&#8217;t aware of this expectation, it could lead to unprocessable messages and tight coupling between services.</p><p>To address this challenge, Cloudflare turned to Protocol Buffers (Protobuf) as a solution for enforcing message contracts.</p><p>Protobuf, developed by Google, is a language-agnostic data serialization format that allows for defining strict message types and schemas.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff812fa60-0040-4dc0-b07e-2438cb6fe131_1600x946.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="861" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff812fa60-0040-4dc0-b07e-2438cb6fe131_1600x946.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption"><strong>Source: <a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Cloudflare Tech Blog</a></strong></figcaption></figure></div><p>It provided several benefits such as:</p><ul><li><p>Producers and consumers could have a shared understanding of message structures using a schema registry.</p></li><li><p>Since Protobuf supports versioning and schema evolution, it was possible to make changes to message formats without breaking existing consumers. This enabled both forward and backward compatibility.</p></li><li><p>Protobuf&#8217;s compact binary format results in smaller message sizes compared to JSON, improving efficiency.</p></li></ul><p>To streamline Kafka usage and enforce best practices, Cloudflare developed an internal message bus client library in Go. This library handled the complexities of configuring Kafka producers and consumers. All the best practices and opinionated defaults were baked into this library.</p><p>There was one controversial decision at this point.</p><p>The message bus client library enforced a one-to-one mapping between Protobuf message types and Kafka topics. This meant that each topic could only contain messages of a single Protobuf type. The idea was to avoid the confusion and complexity of handling multiple message formats within a single topic.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b9c584c-a7de-43af-9f7f-f9f9176786c0_1600x949.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="864" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b9c584c-a7de-43af-9f7f-f9f9176786c0_1600x949.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>There was a major trade-off to consider.&nbsp;</p><p>The strict one-to-one mapping between message types and topics resulted in a larger number of topics, partitions, and replicas while impacting resource utilization. On the other side, it also improved the developer experience, reduced coupling, and increased reliability.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="775" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F118d82e9-3c58-4214-b418-c6b270c6f968_1600x852.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Abstracting Common Patterns</h2><p>As Cloudflare&#8217;s adoption of Kafka grew and more teams started leveraging the message bus client library, a new pattern emerged.</p><p>Teams were using Kafka for similar styles of jobs. For example, many teams were building services that read data from one system of record and pushed it to another system, such as Kafka or Cloudflare edge database called Quicksilver. These services often involved similar configurations and boilerplate code.</p><p>There were a couple of problems such as:</p><ul><li><p>Duplicated efforts across teams.</p></li><li><p>Following best practices was harder.</p></li></ul><p>To address this, the application services team developed the connector framework.</p><p>Inspired by Kafka connectors, the framework allows engineers to quickly spin up services that can read from one system and push data to another with minimal configuration. The framework abstracts away the common patterns and makes it easy to build data synchronization pipelines.</p><p>The diagram below shows a high-level view of the connector approach.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4111e4-a323-41da-851a-3aa30be08adb_1600x945.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="860" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4111e4-a323-41da-851a-3aa30be08adb_1600x945.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Cloudflare Tech Blog</a></figcaption></figure></div><p>Using the connector framework is straightforward.</p><ul><li><p>The developers use a CLI tool to generate a ready-to-go service by providing just a few parameters.</p></li><li><p>The generated service includes all the necessary components, such as a reader, a writer, and optional transformations.</p></li><li><p>To configure the connector, you just need to tweak the environment variables, eliminating the need for code changes in most cases. For example, developers can specify the reader (let&#8217;s say, Kafka), the writer (let&#8217;s say Quicksilver), and any transformations using environment variables. The framework takes care of the rest.</p></li></ul><p>Here&#8217;s a more concrete example of how the connector framework is used in Cloudflare&#8217;s communication preferences service.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdaa21e79-97c5-46d3-9e11-57c6cc0880d1_1595x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1461" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdaa21e79-97c5-46d3-9e11-57c6cc0880d1_1595x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Cloudflare Tech Blog</a></figcaption></figure></div><p>The communication preferences service allows customers to opt out of marketing information through the Cloudflare dashboard. When a customer updates their communication preferences, the service stores the change in its database and emits a message to Kafka.</p><p>To keep other systems in sync with the communication preferences, the team leverages the connector framework. They have set up three different connectors that read the communication preference changes from Kafka and synchronize them to three separate systems such as:</p><ul><li><p>Transactional email service</p></li><li><p>Customer management system</p></li><li><p>Marketing email system</p></li></ul><h2>Scaling Challenges and Solutions</h2><p>Cloudflare faced multiple scaling challenges with its Kafka adoption. Let&#8217;s look at a few of the major ones and how the team solved those challenges.</p><h3>1 - Visibility</h3><p>When Cloudflare experienced a surge in internet usage and customer growth during the pandemic, the audit logs system faced a lot of challenges in keeping up with the increased traffic.</p><p>Audit logs are a crucial feature for customers to track changes to their resources, such as the deletion of a website or modifications to security settings. As more customers relied on Cloudflare&#8217;s services, the audit logs systems struggled to process the growing volume of events on time.</p><p>As a first fix, the team invested in a pipeline that pushes audit log events directly into customer data buckets, such as R2 or S3.&nbsp;</p><p>See the diagram below:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32e096a0-91c8-42db-a652-520c04b2903c_1600x934.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="850" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32e096a0-91c8-42db-a652-520c04b2903c_1600x934.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>However, when the pipeline was deployed to production, they encountered multiple issues.</p><ul><li><p>The system was accruing logs and failing to clear them fast enough.</p></li><li><p>Breaches in service level objectives (SLOs).</p></li><li><p>Unacceptable delays in delivering audit log data to customers.</p></li></ul><p>Initially, the team lacked the necessary tooling in their SDK to understand the root cause of the performance issues. They couldn&#8217;t determine whether the bottleneck was in reading from Kafka, performing transformations, or saving data to the database.</p><p>To gain visibility, they enhanced their SDK with Prometheus metrics, specifically using histograms to measure the duration of each step in the message processing flow. They also explored OpenTelemetry, a collection of SDKs and APIs that made it easy to collect metrics across services written in different programming languages.</p><p>With better visibility provided by Prometheus and OpenTelemetry, the team could identify the longest-running parts of the pipeline. Both reading from Kafka and pushing data to the bucket were slow.</p><p>By making targeted improvements, they were able to reduce the lag and ensure that audit logs were delivered to customers on time, even at high throughput rates of 250 to 500 messages per second.</p><h3>2 - Noisy On-call</h3><p>One thing leads to another.</p><p>Adding metrics to the Kafka SDK provided valuable insights into the health of the cluster and the services using it. However, it also led to a new challenge: a noisy on-call experience.</p><p>The teams started receiving frequent alerts related to unhealthy applications unable to reach the Kafka brokers. There were also alerts about lag issues and general Kafka cluster health problems.</p><p>The existing alerting pipeline was fairly basic. Prometheus collected the metrics and AlertManager continuously monitored them to page the team via PagerDuty.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe01a0ae3-a74c-40de-a1d4-5985cba79f5c_1600x934.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="850" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe01a0ae3-a74c-40de-a1d4-5985cba79f5c_1600x934.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>Most problems faced by services concerning Kafka were due to deteriorating network conditions. The common solution was to restart the service manually. However, this often required on-call engineers to wake up during the night to perform manual restarts or scale services up and down, which was far from ideal.</p><p>To address this challenge, the team decided to leverage Kubernetes and their existing knowledge to improve the situation. They introduced health checks.</p><p>Health checks allow applications to report their readiness to operate, enabling the orchestrator to take appropriate actions when issues arise.</p><p>In Kubernetes, there are three types of health checks:</p><ol><li><p><strong>Liveness Probe: </strong>They indicate whether a service is <em>ready to run</em>.</p></li><li><p><strong>Readiness Probe: </strong>They determine if a service is <em>prepared</em> to receive HTTP traffic.</p></li><li><p><strong>Startup Probes: </strong>They act as an extended liveness check for slow-starting services.</p></li></ol><p>Kubernetes periodically pings the service at a specific endpoint (example: /health), and the service must respond with a successful status code to be considered healthy.</p><p>For Kafka consumers, implementing a readiness probe doesn&#8217;t make much sense, as they typically don&#8217;t expose an HTTP server. Therefore, the team focused on implementing simple liveness checks that worked as follows:</p><ul><li><p>Perform a basic operation with the Kafka broker, such as listing topics.&nbsp;</p></li><li><p>If the operation fails, the health check fails, indicating an issue with the service&#8217;s ability to communicate with the broker.</p></li></ul><p>The diagram below shows the approach:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd1b41db-69ec-4047-8539-e51eb855a57b_1600x1194.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1087" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd1b41db-69ec-4047-8539-e51eb855a57b_1600x1194.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://blog.cloudflare.com/intelligent-automatic-restarts-for-unhealthy-kafka-consumers">Cloudflare Tech Blog</a></figcaption></figure></div><p>There were still cases where the application appeared healthy but was stuck and unable to produce or consume messages. To handle this, the team implemented smarter health checks for Kafka consumers.</p><p>The smart health checks rely on two key concepts:</p><ul><li><p>The current offset represents the last available offset on a partition.</p></li><li><p>The committed offset is the last offset committed by a specific consumer for that partition.</p></li></ul><p>Here&#8217;s what happens during the health check:</p><ul><li><p>The consumer retrieves both offsets.&nbsp;</p></li><li><p>If it fails to retrieve them, the consumer is considered unhealthy.&nbsp;</p></li><li><p>If the offsets are successfully retrieved, the consumer compares the last committed offset with the current offset.&nbsp;</p></li><li><p>If they are the same, no new messages have been appended to the partition, and the consumer is considered healthy.</p></li><li><p>If the last committed offset hasn&#8217;t changed since the previous check, the consumer is likely stuck and needs to be restarted.</p></li></ul><p>Implementing these smart health checks led to improvements in the on-call experience as well as overall customer satisfaction.</p><h3>3 - Inability to Keep Up</h3><p>Another challenge that sprang up as Cloudflare&#8217;s customer base grew was with the email system.&nbsp;</p><p>The email system is responsible for sending transactional emails to customers, such as account verification emails, password reset emails, and billing notifications. These emails were critical for customer engagement and satisfaction, and any delays or failures in delivering them can hurt the user experience.</p><p>During traffic spikes, the email system struggled to process the high volume of messages being produced to Kafka.&nbsp;</p><p>The system was designed to consume messages one at a time, process them, and send the corresponding emails. However, as the production rate increased, the email system fell behind, creating a growing backlog of messages and increased lag.</p><p>One thing was clear to the engineering team at Cloudflare. The existing architecture wasn&#8217;t scalable enough to handle the increasing production rates.</p><p>Therefore, they introduced batch consumption to optimize the email system&#8217;s throughput.</p><p>Batch consumption is a technique where instead of processing messages one at a time, the consumer retrieves a batch of messages from Kafka and processes them together. This approach has several advantages, particularly in scenarios with high production rates.</p><p>The diagram below shows the batching approach.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e3e82df-4d72-438c-8be7-1526950b2413_1600x830.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="755" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e3e82df-4d72-438c-8be7-1526950b2413_1600x830.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>The changes made were as follows:</p><ul><li><p>The Kafka consumer was modified to retrieve a configurable number of messages in each poll.</p></li><li><p>They updated the email-sending logic to process the batch of messages. Techniques like bulk database inserts and parallel email dispatching were used.</p></li></ul><p>Batch consuming with emails was soon put to the test during a major product launch that generated a surge in sign-ups and account activations.&nbsp;</p><p>This resulted in a massive increase in the number of account verification emails that had to be sent. However, the email system was able to handle the increased load efficiently.</p><h2>Conclusion</h2><p>Cloudflare&#8217;s journey of scaling Kafka to handle 1 trillion messages is remarkable.&nbsp;</p><p>From the early days of their monolithic architecture to the development of sophisticated abstractions and tools, we&#8217;ve seen how Cloudflare tackled multiple challenges across coupling, unstructured communication, and common usage patterns.</p><p>Along the way, we&#8217;ve also learned valuable lessons that can be applied to any organization. Here are a few of them:</p><ul><li><p>It&#8217;s important to strike a balance between configuration and simplicity. While flexibility is necessary for diverse use cases, it&#8217;s equally important to standardize and enforce best practices.</p></li><li><p>Visibility is the key in distributed systems. If you can&#8217;t see what&#8217;s happening in a certain part of your application, it becomes hard to remove bottlenecks.</p></li><li><p>Clear and well-defined contracts between producers and consumers are essential for building loosely coupled systems that can evolve independently.</p></li><li><p>Sharing knowledge and best practices across the organization helps streamline the adoption process and creates opportunities for improvement.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Using Apache Kafka to process 1 trillion messages</a></p></li><li><p><a href="https://www.infoq.com/articles/kafka-clusters-cloudflare/">Tales of Kafka at Cloudflare</a></p></li><li><p><a href="https://blog.cloudflare.com/intelligent-automatic-restarts-for-unhealthy-kafka-consumers">Intelligent automatic restarts for unhealthy Kafka consumers</a></p></li><li><p><a href="https://youtu.be/_booBjCB7rU?si=M4UYkZ7ltxSC2GJW">Lessons learned on the way to 1 trillion messages</a></p></li><li><p><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">Configure Liveness, Readiness, and Startup Probes</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Mon, 20 May 2024 15:31:15 GMT</pubDate>
</item>
<item>
<title>EP112: What is a deadlock?</title>
<link>https://blog.bytebytego.com/p/ep112-what-is-a-deadlock</link>
<guid>https://blog.bytebytego.com/p/ep112-what-is-a-deadlock</guid>
<content:encoded><![CDATA[
<div> API Protocols, Deadlock, Authentication, ElasticSearch, CPU Usage
<br /><br />总结: 本周文章介绍了最流行的API协议、死锁、基于会话和JWT的身份验证区别、ElasticSearch的应用以及CPU使用率100%的常见情况。其中详细解释了死锁的概念、预防和恢复方法，以及基于会话和JWT的身份验证方式的比较。此外，还介绍了ElasticSearch在文本搜索、实时分析、机器学习、地理数据应用、日志和事件数据分析、安全信息与事件管理等方面的典型用例，以及导致CPU使用率达到100%的常见原因。整体来看，这篇文章涵盖了系统设计中的重要概念和技术，对读者了解和运用这些知识具有一定的参考价值。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Top 9 Most Popular API Protocols (Youtube video)</p></li><li><p>What is a deadlock? </p></li><li><p>What&#8217;s the difference between Session-based authentication and JWTs? </p></li><li><p>Top 6 ElasticSearch Use Cases</p></li><li><p>Top 9 Cases Behind 100% CPU Usage</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/LinearB_051824">[Complimentary Download] Gartner Market Guide: Software Engineering Intelligence (SEI) Platforms (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/LinearB_051824" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="371.0192307692308" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47201120-d762-43fb-b2de-5ac248a959c1_1600x838.png" width="708" /><div></div></div></a></figure></div><p>Engineering teams are rapidly adopting Software Engineering Intelligence (SEI) Platforms to improve productivity and value delivery. According to Gartner&#8217;s recent Market Guide, use of SEI platforms by engineering organizations will rise to 50% by 2027, compared to 5% in 2024. LinearB was recognized by Gartner as a representative vendor, so we&#8217;re offering ByteByteGo readers a complimentary copy.&nbsp;</p><p>Learn how you can unlock the transformative potential of SEI platforms by leveraging key features like: </p><ul><li><p>Extensive data from DevOps tools for critical metrics and insights.</p></li><li><p>Customizable dashboards that highlight pivotal trends and inform strategic decisions.</p></li><li><p>Insights into KPIs that showcase your team's achievements.</p><p></p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/LinearB_051824"><span>Download your guide now</span></a></p></li></ul><div><hr /></div><h2>Top 9 Most Popular API Protocols</h2><div class="youtube-wrap" id="youtube2-zY2DMpCUfCg"><div class="youtube-inner"></div></div><div><hr /></div><h2>What is a deadlock? </h2><p>A deadlock occurs when two or more transactions are waiting for each other to release locks on resources they need to continue processing. This results in a situation where neither transaction can proceed, and they end up waiting indefinitely. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3702d55e-77eb-4dc6-9a57-2d3272fa5c4f_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><ul><li><p>Coffman Conditions <br />The Coffman conditions, named after Edward G. Coffman, Jr., who first outlined them in 1971, describe four necessary conditions that must be present simultaneously for a deadlock to occur: <br /> <br />- Mutual Exclusion <br />- Hold and Wait <br />- No Preemption <br />- Circular Wait <br /></p></li><li><p>Deadlock Prevention <br />- Resource ordering: impose a total ordering of all resource types, and require that each process requests resources in a strictly increasing order. <br /> <br />- Timeouts: A process that holds resources for too long can be rolled back. <br /> <br />- Banker&#8217;s Algorithm: A deadlock avoidance algorithm that simulates the allocation of resources to processes and helps in deciding whether it is safe to grant a resource request based on the future availability of resources, thus avoiding unsafe states. <br /></p></li><li><p>Deadlock Recovery <br />- Selecting a victim: Most modern Database Management Systems (DBMS) and Operating Systems implement sophisticated algorithms for detecting deadlocks and selecting victims, often allowing customization of the victim selection criteria via configuration settings. The selection can be based on resource utilization, transaction priority, cost of rollback etc. <br /> <br />- Rollback: The database may roll back the entire transaction or just enough of it to break the deadlock. Rolled-back transactions can be restarted automatically by the database management system. </p></li></ul><p>Over to you: have you solved any tricky deadlock issues?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" title="" width="1109" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>What&#8217;s the difference between Session-based authentication and JWTs? </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1560" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02c27d00-914e-4626-b507-51627646af11_1280x1560.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><p>Here&#8217;s a simple breakdown for both approaches: <br /> <br /><strong>Session-Based Authentication</strong> <br /> <br />In this approach, you store the session information in a database or session store and hand over a session ID to the user. <br /> <br />Think of it like a passenger getting just the Ticket ID of their flight while all other details are stored in the airline&#8217;s database. <br /> <br />Here&#8217;s how it works: </p><ol><li><p>The user makes a login request and the frontend app sends the request to the backend server. </p></li><li><p>The backend creates a session using a secret key and stores the data in session storage.</p></li><li><p>The server sends a cookie back to the client with the unique session ID. </p></li><li><p>The user makes a new request and the browser sends the session ID along with the request. </p></li><li><p>The server authenticates the user using the session ID. </p></li></ol><p><strong>JWT-Based Authentication</strong> <br /> <br />In the JWT-based approach, you don&#8217;t store the session information in the session store. <br /> <br />The entire information is available within the token. <br /> <br />Think of it like getting the flight ticket along with all the details available on the ticket but encoded. <br /> <br />Here&#8217;s how it works: </p><ol><li><p>The user makes a login request and it goes to the backend server. </p></li><li><p>The server verifies the credentials and issues a JWT. The JWT is signed using a private key and no session storage is involved. </p></li><li><p>The JWT is passed to the client, either as a cookie or in the response body. Both approaches have their pros and cons but we&#8217;ve gone with the cookie approach. </p></li><li><p>For every subsequent request, the browser sends the cookie with the JWT. </p></li><li><p>The server verifies the JWT using the secret private key and extracts the user info.</p></li></ol><div><hr /></div><h2>Top 6 ElasticSearch Use Cases</h2><p>Elasticsearch is widely used for its powerful and versatile search capabilities. The diagram below shows the top 6 use cases: </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c1dd39f-3e32-4fd7-9360-7e460357e008_1280x1664.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><ul><li><p>Full-Text Search <br />Elasticsearch excels in full-text search scenarios due to its robust, scalable, and fast search capabilities. It allows users to perform complex queries with near real-time responses. <br /></p></li><li><p>Real-Time Analytics <br />Elasticsearch's ability to perform analytics in real-time makes it suitable for dashboards that track live data, such as user activity, transactions, or sensor outputs. <br /></p></li><li><p>Machine Learning <br />With the addition of the machine learning feature in X-Pack, Elasticsearch can automatically detect anomalies, patterns, and trends in the data. <br /></p></li><li><p>Geo-Data Applications <br />Elasticsearch supports geo-data through geospatial indexing and searching capabilities. This is useful for applications that need to manage and visualize geographical information, such as mapping and location-based services. <br /></p></li><li><p>Log and Event Data Analysis <br />Organizations use Elasticsearch to aggregate, monitor, and analyze logs and event data from various sources. It's a key component of the ELK stack (Elasticsearch, Logstash, Kibana), which is popular for managing system and application logs to identify issues and monitor system health. </p><p></p></li><li><p>Security Information and Event Management (SIEM) <br />Elasticsearch can be used as a tool for SIEM, helping organizations to analyze security events in real time. <br /></p></li></ul><p>Over to you: What did we miss?</p><div><hr /></div><h2>Top 9 Cases Behind 100% CPU Usage</h2><p>The diagram below shows common culprits that can lead to 100% CPU usage. Understanding these can help in diagnosing problems and improving system efficiency. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c1af2cb-4c71-424e-a0ef-f1c618a78666_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><ol><li><p>Infinite Loops </p></li><li><p>Background Processes </p></li><li><p>High Traffic Volume </p></li><li><p>Resource-Intensive Applications </p></li><li><p>Insufficient Memory </p></li><li><p>Concurrent Processes </p></li><li><p>Busy Waiting </p></li><li><p>Regular Expression Matching </p></li><li><p>Malware and Viruses </p></li></ol><p>Over to you: Did we miss anything important?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 18 May 2024 15:30:55 GMT</pubDate>
</item>
<item>
<title>A Crash Course in GraphQL</title>
<link>https://blog.bytebytego.com/p/a-crash-course-in-graphql</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-in-graphql</guid>
<content:encoded><![CDATA[
<div> GraphQL, API, maintenance costs, interface, connectivity 
<br />
GraphQL 是一项可改变客户端和服务器交互方式的工具。它可以作为在完全重构应用和什么也不做之间找到的一个折中点。虽然不是解决所有问题的灵丹妙药，但可以通过减少维护成本、简化开发流程来帮助解决应用程序接口日益复杂的问题。相比于REST API和BFFs，GraphQL具有各自的优缺点。在2023年，API协议的格局正在逐渐演变，适应这个变化的一个解决方案就是GraphQL。 <br /><br />总结:GraphQL作为一种新的API工具，可以帮助解决日益增长的维护成本和接口连接问题，是在API协议演变中的一种解决方案，以其灵活性和优势为用户提供了更好的开发体验。 <div>
<p></p><p>The complexity of software applications has grown by leaps and bounds over the years.</p><p>This has led to a rise in the number of interfaces between various systems, resulting in an ever-growing API footprint.</p><p>While APIs have revolutionized the connectivity between systems, the explosion of integrations between clients and servers often leads to maintenance problems. Even minor backend changes take more implementation time since developers must analyze and test more. Despite all the effort, there are still high chances that issues creep into the application.</p><p>Refactoring the application interfaces is one way to address growing maintenance costs. However, this is costly, and there&#8217;s no guarantee that we won&#8217;t encounter similar issues as the system evolves.</p><p>What&#8217;s the solution to this problem?</p><p>GraphQL is a tool that brings a major change in how clients and servers interact. While it&#8217;s not a silver bullet, it can be a sweet spot between a complete application overhaul and doing absolutely nothing</p><p>In this issue, we&#8217;ll explore GraphQL's features and concepts, compare it to REST API and BFFs, and discuss its advantages and disadvantages.</p><div><hr /></div><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1018.5752930568079" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" title="" width="706" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">The Evolving Landscape of API Protocols in 2023</figcaption></figure></div><h2>What is GraphQL?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 16 May 2024 15:30:42 GMT</pubDate>
</item>
<item>
<title>How Facebook served billions of requests per second Using Memcached</title>
<link>https://blog.bytebytego.com/p/how-facebook-served-billions-of-requests</link>
<guid>https://blog.bytebytego.com/p/how-facebook-served-billions-of-requests</guid>
<content:encoded><![CDATA[
<div> Facebook, Memcached, scalability, challenges, optimizations
<br /><br />总结:
Facebook通过优化和实现Memcached，解决了处理海量数据和为数十亿用户提供服务的挑战。他们在架构决策和服务器优化方面取得了重要进展。重要的学习点是：接受最终一致性，设计系统以应对故障，以及可以在多个级别进行优化。 <div>
<h2><a href="https://bit.ly/WorkOS_051424">Creating stronger passwords with AuthKit (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/WorkOS_051424" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38010da7-970d-40ed-96fa-e17bc7a96a77_1600x840.png" width="1456" /><div></div></div></a></figure></div><p>A common cause of data breaches and account hijacking is customers using weak or common passwords.<br /><br />One way to mitigate this risk is to inform new users about the strength of their passwords as they create them.<br /><br />To solve this problem, Dropbox created zxcvbn, an open-source library that calculates password strength based on factors like entropy, dictionary checks, and pattern recognition.<br /><br />If you want an easy way to implement user password security in your app, check out AuthKit, an open-source login box that incorporates zxcvbn and other best practices to provide a much more secure onboarding experience for new users.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/WorkOS_051424"><span>Read the guide</span></a></p><div><hr /></div><p>There are two absolute truths about running a social network at the scale of Facebook:</p><ul><li><p>First, it cannot go down.</p></li><li><p>Second, it cannot run slow.</p></li></ul><p>These two factors determine whether people are going to stay on your social network or not.&nbsp;</p><p>Even a few people leaving impacts the entire user base because the users are interconnected. Most people are online because their friends or relatives are online and there&#8217;s a domino effect at play. If one user drops off due to issues, there are chances that other users will also leave.</p><p>Facebook had to deal with these issues early on because of its popularity. At any point in time, millions of people were accessing Facebook from all over the world.</p><p>In terms of software design, this meant a few important requirements:</p><ul><li><p>Facebook had to support real-time communication.</p></li><li><p>They had to build capabilities for on-the-fly content aggregation.</p></li><li><p>Scale to handle billions of user requests.</p></li><li><p>Store trillions of items across multiple geographic locations.</p></li></ul><p>To achieve these goals, Facebook took up the open-source version of Memcached and enhanced it to build a distributed key-value store.</p><p>This enhanced version was known as Memcache.</p><p>In this post, we will look at how Facebook solved the multiple challenges in scaling memcached to serve billions of requests per second.</p><div><hr /></div><h2>Introduction to Memcached</h2><p>Memcached is an in-memory key-value store that supports a simple set of operations such as set, get, and delete.</p><p>The open-source version provided a single-machine in-memory hash table. The engineers at Facebook took up this version as a basic building block to create a distributed key-value store known as Memcache.</p><p>In other words, &#8220;Memcached&#8221; is the source code or the running binary whereas &#8220;Memcache&#8221; stands for the distributed system behind it.</p><p>Technically, Facebook used Memcache in two main ways:</p><h3>Query Cache</h3><p>The job of the query cache was to reduce the load on the primary source-of-truth databases.</p><p>In this mode, Facebook used Memcache as a demand-filled look-aside cache. You may have also heard about it as the cache-aside pattern.</p><p>The below diagram shows how the look-aside cache pattern works for the read and write path.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10c6a41b-307f-45f2-b2e0-ff6da2454400_1600x959.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="873" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10c6a41b-307f-45f2-b2e0-ff6da2454400_1600x959.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The read path utilizes a cache that is filled on-demand. This means that data is only loaded into the cache when a client specifically requests it.&nbsp;</p><p>Before serving the request, the client first checks the cache. If the desired data is not found in the cache (a cache miss), the client retrieves the data from the database and also updates the cache.</p><p>The write path takes a more interesting approach to updating data.&nbsp;</p><p>After a particular key is updated in the database, the system doesn&#8217;t directly update the corresponding value in the cache. Instead, it removes the data for that key from the cache entirely. This process is known as cache invalidation.</p><p>By invalidating the cache entry, the system ensures that the next time a client requests data for that key, it will experience a cache miss and be forced to retrieve the most up-to-date value directly from the database. This approach helps maintain data consistency between the cache and the database.</p><h3>Generic Cache</h3><p>Facebook also leverages Memcache as a general-purpose key-value store. This allows different teams within the organization to utilize Memcache for storing pre-computed results generated from computationally expensive machine learning algorithms.</p><p>By storing these pre-computed ML results in Memcache, other applications can quickly and easily access them whenever needed.</p><p>This approach offers several benefits such as improved performance and resource optimization.</p><h2>High-Level Architecture of Facebook</h2><p>Facebook&#8217;s architecture is built to handle the massive scale and global reach of its platform.&nbsp;</p><p>At the time of their Memcached adoption, Facebook&#8217;s high-level architecture consisted of three key components:</p><h3>1 - Regions</h3><p>Facebook strategically places its servers in various locations worldwide, known as regions. These regions are classified into two types:</p><ul><li><p><strong>Primary Region: </strong>The primary region is responsible for handling the majority of user traffic and data management.</p></li><li><p><strong>Secondary Region: </strong>Multiple secondary regions are distributed globally to provide redundancy, load balancing, and improved performance for users in different geographical areas.</p></li></ul><p>Each region, whether primary or secondary, contains multiple frontend clusters and a single storage cluster.</p><h3>2 - Frontend Clusters</h3><p>Within each region, Facebook employs frontend clusters to handle user requests and serve content. A frontend cluster consists of two main components:</p><ul><li><p><strong>Web Servers: </strong>These servers are responsible for processing user requests, rendering pages, and delivering content to the users.</p></li><li><p><strong>Memcache Servers: </strong>Memcache servers act as a distributed caching layer, storing frequently accessed data in memory for quick retrieval.</p></li></ul><p>The frontend clusters are designed to scale horizontally based on demand. As user traffic increases, additional web and Memcache servers can be added to the cluster to handle the increased load.</p><h3>3 - Storage Cluster</h3><p>At the core of each region lies the storage cluster. This cluster contains the source-of-truth database, which stores the authoritative copy of every data item within Facebook&#8217;s system.</p><p>The storage cluster takes care of data consistency, durability, and reliability.</p><p>By replicating data across multiple regions and employing a primary-secondary architecture, Facebook achieves high availability and fault tolerance.</p><p>The below diagram shows the high-level view of this architecture:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f8ebeb-fc61-4427-bb0b-dbc7aa8ef619_1600x923.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="840" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f8ebeb-fc61-4427-bb0b-dbc7aa8ef619_1600x923.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>One major philosophy that Facebook adopted was a willingness to expose slightly stale data instead of allowing excessive load on the backend.&nbsp;</p><p>Rather than striving for perfect data consistency at all times, Facebook accepted that users may sometimes see outdated information in their feeds. This approach allowed them to handle high traffic loads without crumbling under excessive strain on the backend infrastructure.</p><p>To make this architecture work at an unprecedented scale of billions of requests every day, Facebook had to solve multiple challenges such as:</p><ul><li><p>Managing latency and failures within a cluster.</p></li><li><p>Managing data replication within a region.</p></li><li><p>Managing data consistency across regions.</p></li></ul><p>In the next few sections, we will look at how Facebook handled each of these challenges.</p><h2>Within Cluster Challenges</h2><p>There were three important goals for the within-cluster operations:</p><ul><li><p>Reducing latency</p></li><li><p>Reducing the load on the database</p></li><li><p>Handling failures</p></li></ul><h3>1 - Reducing Latency</h3><p>As mentioned earlier, every frontend cluster contains hundreds of Memcached servers, and items are distributed across these servers using techniques like Consistent Hashing.</p><p>For reference, Consistent Hashing is a technique that allows the distribution of a set of keys across multiple nodes in a way that minimizes the impact of node failures or additions. When a node goes down or a new node is introduced, Consistent Hashing ensures that only a small subset of keys needs to be redistributed, rather than requiring a complete reshuffling of data.</p><p>The diagram illustrates the concept of Consistent Hashing where keys are mapped to a circular hash space, and nodes are assigned positions on the circle. Each key is assigned to the node that falls closest to it in a clockwise direction.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac03e7f-77db-4b52-9c30-bd2718bd8bfe_1600x1461.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1330" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac03e7f-77db-4b52-9c30-bd2718bd8bfe_1600x1461.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At Facebook's scale, a single web request can trigger hundreds of fetch requests to retrieve data from Memcached servers. Consider a scenario where a user loads a popular page containing numerous posts and comments.&nbsp;</p><p>Even a single request can require the web servers to communicate with multiple Memcached servers in a short timeframe to populate the necessary data.</p><p>This high-volume data fetching occurs not only in cache hit situations but also when there&#8217;s a cache miss. The implication is that a single Memcached server can turn into a bottleneck for many web servers, leading to increased latency and degraded performance for the end user.</p><p>To reduce the possibility of such a scenario, Facebook uses a couple of important tricks visualized in the diagram.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa67ef54c-971d-43fa-bba6-6ed418fdefcc_1600x1123.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1022" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa67ef54c-971d-43fa-bba6-6ed418fdefcc_1600x1123.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h4>Parallel Requests and Batching</h4><p>To understand the concept of parallel requests and batching, consider a simple analogy.&nbsp;</p><p>Imagine going to the supermarket every time you need an item. It would be incredibly time-consuming and inefficient to make multiple trips for individual items. Instead, it&#8217;s much more effective to plan your shopping trip and purchase a bunch of items together in a single visit.</p><p>The same optimization principle applies to data retrieval in Facebook's frontend clusters.&nbsp;</p><p>To maximize the efficiency of data retrieval, Facebook constructs a Directed Acyclic Graph (DAG) that represents the dependencies between different data items.</p><p>The DAG provides a clear understanding of which data items can be fetched concurrently and which items depend on others.</p><p>By analyzing the DAG, the web server can determine the optimal order and grouping of data fetches. It identifies data items that can be retrieved in parallel, without any dependencies, and groups them in a single batch request.</p><h4>Using UDP&nbsp;</h4><p>Facebook employed a clever strategy to optimize network communication between the web servers and the Memcache server.</p><p>For fetch requests, Facebook configured the clients to use UDP instead of TCP.&nbsp;</p><p>As you may know, UDP is a connectionless protocol and much faster than TCP. By using UDP, the clients can send fetch requests to the Memcache servers with less network overhead, resulting in faster request processing and reduced latency.</p><p>However, UDP has a drawback: it doesn&#8217;t guarantee the delivery of packets. If a packet is lost during transmission, UDP doesn&#8217;t have a built-in mechanism to retransmit it.&nbsp;</p><p>To handle such cases, they treated UDP packet loss as a cache miss on the client side. If a response isn&#8217;t received within a specific timeframe, the client assumes that the data is not available in the cache and proceeds to fetch it from the primary data source.</p><p>For update and delete operations, Facebook still used TCP since it provided a reliable communication channel that ensured the delivery of packets in the correct order. It removed the need for adding a specific retry mechanism, which is important when dealing with update and delete operations.</p><p>All these requests go through a special proxy known as <strong>mcrouter</strong> that runs on the same machine as the webserver. Think of the <strong>mcrouter</strong> as a middleman that performs multiple duties such as data serialization, compression, routing, batching, and error handling. We will look at <strong>mcrouter</strong> in a later section.</p><h3>2 - Reducing Load</h3><p>The most important goal for Memcache is to reduce the load on the database by reducing the frequency of data fetching from the database.&nbsp;</p><p>Using Memcache as a look-aside cache solves this problem significantly. But at Facebook&#8217;s scale, two caching-related issues can easily appear.</p><ul><li><p><strong>Stale Set: </strong>This happens when the cache is set with outdated data and there&#8217;s no easy way of invalidating it.</p></li><li><p><strong>Thundering Herd: </strong>This problem occurs in a highly concurrent environment when a cache miss triggers a thundering herd of requests to the database.</p></li></ul><p>The below diagram visualizes both of these issues.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3bd7af6-8955-4c31-a20f-40216163cab3_1396x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3bd7af6-8955-4c31-a20f-40216163cab3_1396x1600.png" title="" width="1396" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To minimize the probability of these two critical issues, Facebook used a technique known as leasing.</p><p>Leasing helped solve both stale sets and thundering herds, helping Facebook reduce peak DB query rates from 17K/second to 1.3K/second.</p><h4>Stale Sets</h4><p>Consider that a client requests memcache for a particular key and it results in a cache miss.</p><p>Now, it&#8217;s the client&#8217;s responsibility to fetch the data from the database and also update memcache so that future requests for the same key don&#8217;t result in a cache miss.</p><p>This works fine most of the time but in a highly concurrent environment, the data being set by the client may get outdated by the time it gets updated in the cache.</p><p>Leasing prevents this from happening.&nbsp;</p><p>With leasing, Memcache hands over a lease (a 64-bit token bound to a specific key) to a particular client to set data into the cache whenever there&#8217;s a cache miss.&nbsp;</p><p>The client has to provide this token when setting the value in the cache and memcache can verify whether the data should be stored by verifying the token. If the item was already invalidated by the time the client tried to update, Memcache will invalidate the lease token and reject the request.</p><p>The below diagram shows the concept of leasing in a much better manner.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fea2405-ad1a-4c6f-b378-268362482977_1573x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1481" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fea2405-ad1a-4c6f-b378-268362482977_1573x1600.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h4>Thundering Herds</h4><p>A slight modification to the leasing technique also helps solve the thundering herd issue.</p><p>In this modification, Memcache regulates the rate of issuing the lease tokens. For example, it may return a token once every 5 seconds per key.</p><p>For any requests for the key within 5 seconds of the lease token being issued, Memcache sends a special response requesting the client to wait and retry so that these requests don&#8217;t hit the database needlessly. This is because there&#8217;s a high probability that the client holding the lease token will soon update the cache and the waiting clients will get a cache hit when they retry.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="927" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e5a5e3-b6f2-4f89-98f5-8c5f59c5d795_1600x1019.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>3 - Handling Failures</h3><p>In a massive-scale system like Facebook, failures are an inevitable reality.</p><p>With millions of users using the platform, any disruption in data retrieval from Memcache can have severe consequences. If clients are unable to fetch data from Memcache, it places an excessive load on the backend servers, potentially leading to cascading failures in downstream services.</p><h3>Two Levels of Failure</h3><p>Facebook faced two primary levels of failures when it comes to Memcache:</p><ul><li><p><strong>Small-Scale Outages:</strong> A small number of hosts may become inaccessible due to network issues or other localized problems. While these outages are limited in scope, they can still impact the overall system performance.</p></li><li><p><strong>Widespread Outages: In more severe cases, an entire cluster may go down, affecting a significant percentage of the Memcache hosts. Such widespread outages create a greater threat to the stability and availability of the system.</strong></p></li></ul><h4>Handling Widespread Outages</h4><p>To mitigate the impact of a cluster going down, Facebook diverts web requests to other functional clusters.</p><p>By redistributing the load, Facebook ensures that the problematic cluster is relieved of its responsibilities until it can be restored to health.</p><h4>Automated Remediation for Small Outages</h4><p>For small-scale outages, Facebook relies on an automated remediation system that automatically detects and responds to host-level issues by bringing up new instances to replace the affected ones.</p><p>However, the remediation process is not instantaneous and can take some time to complete. During this time window, the backend services may experience a surge in requests as clients attempt to fetch data from the unavailable Memcache hosts.&nbsp;</p><p>The common way of handling this is to rehash keys and distribute them among the remaining servers.&nbsp;</p><p>However, Facebook&#8217;s engineering team realized that this approach was still prone to cascading failures. In their system, many keys can account for a significant portion of the requests (almost 20%) to a single server. Moving these high-traffic keys to another server during a failure scenario could result in overload and further instability.&nbsp;</p><p>To mitigate this risk, Facebook went with the approach of using Gutter machines. Within each cluster, they allocate a pool of machines (typically 1% of the Memcache servers) specifically designated as Gutter machines. These machines are designed to take over the responsibilities of the affected Memcache servers during an outage.</p><p>Here&#8217;s how they work:</p><ul><li><p>If a Memcache client receives no response (not even a cache miss), the client assumes that the server has failed and issues a request to the Gutter pool.</p></li><li><p>If the request to the Gutter pool returns a cache miss, the client queries the database and inserts the data into the Gutter pool so that subsequent requests can be served from Memcache.</p></li><li><p>Gutter entries expire quickly to remove the need for invalidations.</p></li></ul><p>The below diagram shows how the Gutter pool works:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1671dbf-d312-46f4-8de9-42c1062cdc5d_1600x916.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="834" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1671dbf-d312-46f4-8de9-42c1062cdc5d_1600x916.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Though there are chances of serving stale data, the backend is protected. Remember that this was an acceptable trade-off for them when compared to availability.</p><h2>Region Level Challenges</h2><p>At the region level, there were multiple frontend clusters to deal with and the main challenge was handling Memcache invalidations across all of them.</p><p>Depending on the load balancer, users can connect to different front-end clusters when requesting data. This results in caching a particular piece of data in multiple clusters.</p><p>In other words, you can have a scenario where a particular key is cached in the Memcached servers of multiple clusters within the region. The below diagram shows this scenario:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc775036-767c-4d47-b834-8ee6b8010f65_1600x926.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="843" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc775036-767c-4d47-b834-8ee6b8010f65_1600x926.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As an example, the keys &#8220;abc&#8221; and &#8220;xyz&#8221; are present in multiple frontend clusters within a region and need to be invalidated in case of an update to their values.</p><h3>Cluster Level Invalidation</h3><p>Invalidating this data at the cluster level is reasonably simpler. Any web server that modifies the data is responsible for invalidating the data in that cluster. This provides read-after-write consistency for the user who made the request. It also reduces the lifetime of the stale data within the cluster.</p><p>For reference, read-after-write consistency is a guarantee that if a user makes some updates, he/she should always see those updates when they reload the page.</p><h3>Region Level Invalidation</h3><p>For region-level invalidation, the invalidation process is a little more complex and the webserver doesn&#8217;t handle it.</p><p>Instead, Facebook created an invalidation pipeline that works like this:</p><ul><li><p>An invalidation daemon known as <strong>mcsqueal</strong> runs on every database server within the storage cluster.</p></li><li><p>This daemon inspects the commit log, extracts any deletes, and broadcasts them to the Memcache deployments in every frontend cluster within the region.</p></li><li><p>For better performance, <strong>mcsqueal</strong> batches these deletes into fewer packets and sends them to dedicated servers running <strong>mcrouter</strong> instances in each cluster.</p></li><li><p>The <strong>mcrouter </strong>instance iterates over the individual deletes within the batch and routes them to the correct Memcache server.</p></li></ul><p>The below diagram explains this process.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3cb6fbf-eb4d-496d-b11e-0235fbc12d95_1600x1070.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="974" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3cb6fbf-eb4d-496d-b11e-0235fbc12d95_1600x1070.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Challenges with Global Regions</h2><p>Operating at the scale of Facebook requires them to run and maintain data centers globally.</p><p>However, expanding to multiple regions also creates multiple challenges. The biggest one is maintaining consistency between the data in Memcache and the persistent storage across the regions.</p><p>In Facebook&#8217;s region setup, one region holds the primary databases while other geographic regions contain read-only replicas. The replicas are kept in sync with the primary using MySQL&#8217;s replication mechanism.</p><p>However, when replication is involved, there is bound to be some replication lag. In other words, the replica databases can fall behind the primary database.</p><p>There are two main cases to consider when it comes to consistency here:</p><h3>Writes from the Primary Region</h3><p>Let&#8217;s say a web server in the primary region (US) receives a request from the user to update their profile picture.</p><p>To maintain consistency, this change needs to be propagated to other regions as well.</p><ul><li><p>The replica databases have to be updated.</p></li><li><p>Also, the Memcache instances in the secondary regions need to be invalidated.</p></li></ul><p>The tricky part is managing the invalidation along with the replication.</p><p>If the invalidation arrives in the secondary region (Europe) before the actual change is replicated to the database in the region, there are chances of a race condition as follows:</p><ul><li><p>Someone in the Europe region tries to view the profile picture.</p></li><li><p>The system fetches the information from the cache but it has been invalidated.</p></li><li><p>Data is fetched from the read-only database in the region, which is still lagging. This means that the fetch request gets the old picture and sets it within the cache.</p></li><li><p>Eventually, the replication is successful but the cache is already set with stale data and future requests will continue fetching this stale data from the cache.</p></li></ul><p>The below diagram shows this scenario:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51b29010-3717-46a9-8fb7-52403f6026db_1600x980.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="892" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51b29010-3717-46a9-8fb7-52403f6026db_1600x980.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To avoid such race conditions, Facebook implemented a solution where the storage cluster having the most up-to-date information is responsible for sending invalidations within a region. It uses the same <strong>mcsqueal</strong> setup we talked about in the previous section.</p><p>This approach ensures that invalidations don&#8217;t get sent prematurely to the replica regions before the change has been fully replicated in the databases.</p><h3>Writes from the Non-Primary Region</h3><p>When dealing with writes originating from non-primary regions, the sequence of events is as follows:</p><ul><li><p>User updates their profile picture from a secondary region. While reads are served from the replica or secondary regions, the writes go to the primary region.</p></li><li><p>After the writes are successful, the changes also need to be replicated in the secondary region as well.</p></li><li><p>However, there&#8217;s a risk that before the replication catches up, a read request on the replica region may fetch and cache stale data in Memcache.</p></li></ul><p>To solve this problem, Facebook used the concept of a remote marker.</p><p>The remote marker is used to indicate whether the data in the local replica is potentially stale and it should be queried from the primary region.</p><p>It works as follows:</p><ul><li><p>When a client web server requests to update the data for key K, it sets a remote marker R for that key in the replica region.</p></li><li><p>Next, it performs the write to the primary region.</p></li><li><p>Also, the key K is deleted from the replica region&#8217;s Memcache servers.</p></li><li><p>A read request comes along for K in the replica region but the webserver would get a cache miss.</p></li><li><p>It checks whether the remote marker R exists and if found, the query is directed to the primary region.</p></li></ul><p>The below diagram shows all the steps in more detail.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e7903d4-f4e3-4d7e-8d10-641e507c8f7e_1600x981.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="893" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e7903d4-f4e3-4d7e-8d10-641e507c8f7e_1600x981.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At this point, you may think that this approach is inefficient because they are first checking the cache, then the remote marker, and then making the query to the primary region.</p><p>In this scenario, Facebook chose to trade off latency for a cache miss in exchange for a reduced probability of reading stale data.</p><h2>Single Server Optimizations</h2><p>As you can see, Facebook implemented some big architectural decisions to scale Memcached for their requirements. However, they also spent a significant time optimizing the performance of individual Memcache servers.</p><p>While the scope of these improvements may seem small in isolation, their cumulative impact at Facebook&#8217;s scale was significant.</p><p>Here are a few important optimizations that they made:</p><h3>Automatic Hash Table Expansion</h3><p>As the number of stored items grows, the time complexity of lookups in a hash table can degrade to O(n) if the table size remains fixed. This reduces the performance.</p><p>Facebook implemented an automatic expansion mechanism for the hash table. When the number of items reaches a certain threshold, the hash table automatically doubles in size, ensuring that the time complexity of the lookups remains constant even as the dataset grows.</p><h3>Multi-Threaded Server Architecture</h3><p>Serving a high volume of requests on a single thread can result in increased latency and reduced throughput.</p><p>To deal with this, they enhanced the Memcache server to support multiple threads and handle requests concurrently.</p><h3>Dedicated UDP Port for Each Thread</h3><p>When multiple threads share the same UDP port, contentions can occur and lead to performance problems.</p><p>They implemented support for each thread to have its own dedicated UDP port so that the threads can operate more efficiently.</p><h3>Adaptive Slab Allocator</h3><p>Inefficient memory allocation and management can lead to fragmentation and suboptimal utilization of system resources.</p><p>Facebook implemented an Adaptive Slab Allocator to optimize memory organization within each Memcache server. The slab allocator divides the available memory into fixed-size chunks called slabs. Each slab is further divided into smaller units of a specific size.&nbsp;</p><p>The allocator dynamically adapts the slab sizes based on the observed request patterns to maximize memory utilization.</p><h2>Conclusion</h2><p>Facebook&#8217;s journey in scaling Memcached serves as a fantastic case study for developers and engineers. It highlights the challenges that come up when building a globally distributed social network that needs to handle massive amounts of data and serve billions of users.</p><p>With their implementation and optimization of Memcache, Facebook demonstrates the importance of tackling scalability challenges at multiple levels. From high-level architectural decisions to low-level server optimizations, every aspect plays an important role in ensuring the performance, reliability, and efficiency of the system.</p><p>Three key learning points to take away from this study are as follows:</p><ul><li><p>Embracing eventual consistency is the key to performance and availability. However, every decision has to be taken based on a good understanding of the trade-offs.</p></li><li><p>Failures are inevitable and it&#8217;s critical to design your system for failures.</p></li><li><p>Optimization can be done at multiple levels.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://research.facebook.com/publications/scaling-memcache-at-facebook/">Scaling Memcache at Facebook</a></p></li><li><p><a href="https://www.youtube.com/watch?v=UH7wkvcf0ys">Facebook and Memcached</a></p></li><li><p><a href="https://pdos.csail.mit.edu/6.824/papers/memcache-faq.txt">Memcache FAQ by MIT</a></p></li><li><p><a href="https://www.ehcache.org/documentation/2.8/recipes/thunderingherd.html">Thundering Herd</a></p></li><li><p><a href="https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside">Cache-Aside Pattern</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Tue, 14 May 2024 15:30:27 GMT</pubDate>
</item>
<item>
<title>EP111: My Favorite 10 Books for Software Developers</title>
<link>https://blog.bytebytego.com/p/ep111-my-favorite-10-books-for-software</link>
<guid>https://blog.bytebytego.com/p/ep111-my-favorite-10-books-for-software</guid>
<content:encoded><![CDATA[
<div> 编程原则、软件开发书籍、重要论文、实时数据、IPv4 vs. IPv6
编程原则的重要性、软件开发人员必读的经典书籍如《The Pragmatic Programmer》、重要的改变计算机世界的25篇论文、实时数据利用的关键Change Data Capture、IPv4与IPv6的区别。
<br /><br />总结: 本文介绍了编程原则、软件开发书籍、重要论文、实时数据和IPv4与IPv6之间的区别。重点强调编程原则的重要性，推荐了经典的软件开发书籍，列举了改变计算机世界的25篇重要论文，介绍了实时数据利用的关键Change Data Capture以及IPv4和IPv6之间的差异。文章内容涵盖了编程知识、软件开发经验、计算机技术的重要变革和网络协议的演变。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>10 Coding Principles Explained in 5 Minutes (Youtube video)</p></li><li><p>My Favorite 10 Books for Software Developers </p></li><li><p>25 Papers That Completely Transformed the Computer World</p></li><li><p>Change Data Capture: Key to Leverage Real-time Data</p></li><li><p>IPv4 vs. IPv6, what are the differences? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65b29d8d-75dd-4d36-b1af-08b6227f6138_1355x1600.png" title="" width="1355" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>10 Coding Principles Explained in 5 Minutes</h2><div class="youtube-wrap" id="youtube2-GmXPwRNIrAU"><div class="youtube-inner"></div></div><div><hr /></div><h2>My Favorite 10 Books for Software Developers </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1040" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12d664a0-da33-43da-9059-48075c1cad7d_800x1040.gif" title="No alternative text description for this image" width="800" /><div></div></div></a></figure></div><p>General Advice </p><ol><li><p>The Pragmatic Programmer by Andrew Hunt and David Thomas </p></li><li><p>Code Complete by Steve McConnell: Often considered a bible for software developers, this comprehensive book covers all aspects of software development, from design and coding to testing and maintenance. </p></li></ol><p>Coding </p><ol><li><p>Clean Code by Robert C. Martin </p></li><li><p>Refactoring by Martin Fowler </p></li></ol><p>Software Architecture </p><ol><li><p>Designing Data-Intensive Applications by Martin Kleppmann </p></li><li><p>System Design Interview (our own book :)) </p></li></ol><p>Design Patterns </p><ol><li><p>Design Patterns by Eric Gamma and Others </p></li><li><p>Domain-Driven Design by Eric Evans </p></li></ol><p>Data Structures and Algorithms </p><ol><li><p>Introduction to Algorithms by Cormen, Leiserson, Rivest, and Stein </p></li><li><p>Cracking the Coding Interview by Gayle Laakmann McDowell </p></li></ol><p>Over to you: What is your favorite book?</p><div><hr /></div><h2>25 Papers That Completely Transformed the Computer World</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="text" class="sizing-normal" height="1644" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F951c4ad6-986d-490c-a2b7-bfe0d0385a1f_1280x1644.jpeg" title="text" width="1280" /><div></div></div></a></figure></div><ol><li><p><a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo - Amazon&#8217;s Highly Available Key Value Store</a></p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf">Google File System</a>: Insights into a highly scalable file system</p></li><li><p><a href="https://research.facebook.com/file/839620310074473/scaling-memcache-at-facebook.pdf">Scaling Memcached at Facebook</a>: A look at the complexities of Caching</p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">BigTable</a>: The design principles behind a distributed storage system</p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43438.pdf">Borg - Large Scale Cluster Management at Google</a></p></li><li><p><a href="https://www.cs.cornell.edu/projects/ladis2009/papers/lakshman-ladis2009.pdf">Cassandra</a>: A look at the design and architecture of a distributed NoSQL database</p></li><li><p><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>: Into a new deep learning architecture known as the transformer</p></li><li><p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/Kafka.pdf">Kafka</a>: Internals of the distributed messaging platform</p></li><li><p><a href="https://www.foundationdb.org/files/fdb-paper.pdf">FoundationDB</a>: A look at how a distributed database</p></li><li><p><a href="https://web.stanford.edu/class/cs245/readings/aurora.pdf">Amazon Aurora</a>: To learn how Amazon provides high-availability and performance</p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf">Spanner</a>: Design and architecture of Google&#8217;s globally distributed databas</p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/16cb30b4b92fd4989b8619a61752a2387c6dd474.pdf">MapReduce</a>: A detailed look at how MapReduce enables parallel processing of massive volumes of data</p></li><li><p><a href="https://dl.acm.org/doi/pdf/10.1145/3477132.3483546">Shard Manager</a>: Understanding the generic shard management framework</p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/papers/dapper-2010-1.pdf">Dapper</a>: Insights into Google&#8217;s distributed systems tracing infrastructure</p></li><li><p><a href="https://www.researchgate.net/publication/308993790_Apache_Flink_Stream_and_Batch_Processing_in_a_Single_Engine">Flink</a>: A detailed look at the uni&#64257;ed architecture of stream and batch processing</p></li><li><p><a href="https://arxiv.org/pdf/2310.11703.pdf">A Comprehensive Survey on Vector Databases</a></p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/10683a8987dbf0c6d4edcafb9b4f05cc9de5974a.pdf">Zanzibar</a>: A look at the design, implementation and deployment of a global system for managing access control lists at Google&nbsp;</p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/d84ab6c93881af998de877d0070a706de7bec6d8.pdf">Monarch</a>: Architecture of Google&#8217;s in-memory time series database&nbsp;</p></li><li><p><a href="https://thrift.apache.org/static/files/thrift-20070401.pdf">Thrift</a>: Explore the design choices behind Facebook&#8217;s code-generation tool</p></li><li><p><a href="https://bitcoin.org/bitcoin.pdf">Bitcoin</a>: The ground-breaking introduction to the peer-to-peer electronic cash system</p></li><li><p><a href="https://web.stanford.edu/~rezab/papers/wtf_overview.pdf">WTF - Who to Follow Service at Twitter</a>: Twitter&#8217;s (now X) user recommendation system</p></li><li><p><a href="https://www.vldb.org/pvldb/vol13/p3217-matsunobu.pdf">MyRocks: LSM-Tree Database Storage Engine</a></p></li><li><p><a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">GoTo Considered Harmful</a></p></li><li><p><a href="https://raft.github.io/raft.pdf">Raft Consensus Algorithm</a>: To learn about the more understandable consensus algorithm</p></li><li><p><a href="https://lamport.azurewebsites.net/pubs/time-clocks.pdf">Time Clocks and Ordering of Events</a>: The extremely important paper that explains the concept of time and event ordering in a distributed system&nbsp;</p></li></ol><p>Over to you: I&#8217;m sure we missed many important papers. Which ones do you think should be included?</p><div><hr /></div><h2>Change Data Capture: Key to Leverage Real-time Data</h2><p>90% of the world&#8217;s data was created in the last two years and this growth will only get faster. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1557" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc324fb65-98cb-44b4-878f-f56d1bd432a1_1280x1557.gif" title="graphical user interface" width="1280" /><div></div></div></a></figure></div><p><br /> <br />However, the biggest challenge is to leverage this data in real-time. Constant data changes make databases, data lakes, and data warehouses out of sync. <br /> <br />CDC or Change Data Capture can help you overcome this challenge. <br /> <br />CDC identifies and captures changes made to the data in a database, allowing you to replicate and sync data across multiple systems. <br /> <br />So, how does Change Data Capture work? Here's a step-by-step breakdown: <br /> <br />1 - Data Modification: A change is made to the data in the source database. It could be an insert, update, or delete operation on a table. <br /> <br />2 - Change Capture: A CDC tool monitors the database transaction logs to capture the modifications. It uses the source connector to connect to the database and read the logs. <br /> <br />3 - Change Processing: The captured changes are processed and transformed into a format suitable for the downstream systems. <br /> <br />4 - Change Propagation: The processed changes are published to a message queue and propagated to the target systems, such as data warehouses, analytics platforms, distributed caches like Redis, and so on. <br /> <br />5 - Real-Time Integration: The CDC tool uses its sink connector to consume the log and update the target systems. The changes are received in real time, allowing for conflict-free data analysis and decision-making. <br /> <br />Users only need to take care of step 1 while all other steps are transparent. <br /> <br />A popular CDC solution uses Debezium with Kafka Connect to stream data changes from the source to target systems using Kafka as the broker. Debezium has connectors for most databases such as MySQL, PostgreSQL, Oracle, etc. <br /> <br />Over to you: have you leveraged CDC in your application before?</p><div><hr /></div><h2>IPv4 vs. IPv6, what are the differences? </h2><p>The transition from Internet Protocol version 4 (IPv4) to Internet Protocol version 6 (IPv6) is primarily driven by the need for more internet addresses, alongside the desire to streamline certain aspects of network management.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7680062-0800-404d-86bf-ef4237788b2a_1536x1536.gif" title="graphical user interface, application" /><div></div></div></a></figure></div><ul><li><p>Format and Length <br />IPv4 uses a 32-bit address format, which is typically displayed as four decimal numbers separated by dots (e.g., 192.168.0. 12). The 32-bit format allows for approximately 4.3 billion unique addresses, a number that is rapidly proving insufficient due to the explosion of internet-connected devices. <br /> <br />In contrast, IPv6 utilizes a 128-bit address format, represented by eight groups of four hexadecimal digits separated by colons (e.g., 50B3:F200:0211:AB00:0123:4321:6571:B000). This expansion allows for approximately much more addresses, ensuring the internet's growth can continue unabated. </p><p></p></li><li><p>Header <br />The IPv4 header is more complex and includes fields such as the header length, service type, total length, identification, flags, fragment offset, time to live (TTL), protocol, header checksum, source and destination IP addresses, and options. <br /> <br />IPv6 headers are designed to be simpler and more efficient. The fixed header size is 40 bytes and includes less frequently used fields in optional extension headers. The main fields include version, traffic class, flow label, payload length, next header, hop limit, and source and destination addresses. This simplification helps improve packet processing speeds. </p><p></p></li><li><p>Translation between IPv4 and IPv6 <br />As the internet transitions from IPv4 to IPv6, mechanisms to allow these protocols to coexist have become essential: <br /> <br />- Dual Stack: This technique involves running IPv4 and IPv6 simultaneously on the same network devices. It allows seamless communication in both protocols, depending on the destination address availability and compatibility. The dual stack is considered one of the best approaches for the smooth transition from IPv4 to IPv6.</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p></p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p></p><p>Space Fills Up Fast - Reserve Today</p><p></p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><div><hr /></div></li></ul>
]]></content:encoded>
<pubDate>Sat, 11 May 2024 15:30:45 GMT</pubDate>
</item>
<item>
<title>HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</title>
<link>https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive</link>
<guid>https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive</guid>
<content:encoded><![CDATA[
<div> HTTP1, HTTP/1.1, Persistent Connections, Pipelining, Caching and Conditional Requests

总结:<br /><br />HTTP/1是互联网世界增长的推动力之一，HTTP/1.1作为其主要版本，在满足需求和解决问题的基础上，引入了持久连接、管线化、分块传输编码以及缓存和条件请求等重要特性。虽然HTTP/1.1在过去的20多年间发挥了巨大作用，但随着网站规模和资源增加，HTTP/1.1的性能问题也逐渐暴露出来。随着网站越来越大，HTTP1.1的性能问题变得越来越突出。Persistent Connections解决了连接频繁开关的问题，Pipelining提高了性能，Chunked Transfer Encoding改善了页面加载速度，而Caching和Conditional Requests优化了缓存和数据传输，但仍然存在一些问题。(HTTP/1.1 introduced several key features that improved performance, but as websites grew in size, limitations of HTTP/1.1's capabilities started to become apparent.) <div>
<p>What has powered the incredible growth of the World Wide Web?</p><p>There are several factors, but HTTP or Hypertext Transfer Protocol has played a fundamental role.</p><p>Once upon a time, the name may have sounded like a perfect choice. After all, the initial goal of HTTP was to transfer hypertext documents. These are documents that contain links to other documents.</p><p>However, developers soon realized that HTTP can also help transfer other content types, such as images and videos. Over the years, HTTP has become critical to the existence and growth of the web.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7880fc22-160a-4d20-9e74-00f9ded06681_1600x938.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="854" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7880fc22-160a-4d20-9e74-00f9ded06681_1600x938.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In today&#8217;s deep dive, we&#8217;ll unravel the evolution of HTTP, from its humble beginnings with HTTP1 to the latest advancements of HTTP2 and HTTP3. We&#8217;ll look at how each version addressed the limitations of its predecessor, improving performance, security, and user experience.</p><p>By the end of this article, you&#8217;ll have a solid understanding of the key differences between HTTP1, HTTP2, and HTTP3, helping you make informed decisions when designing web applications.</p><h2>HTTP1 - The Foundation</h2><p>HTTP/1 was introduced in 1996. Before that, there was HTTP/0.9, a simple protocol that only supported the GET method and had no headers. Only HTML files were included in HTTP responses. There were no HTTP headers and no HTTP status codes.</p><p>HTTP/1.0 added headers, status codes, and additional methods such as POST and HEAD. However, HTTP/1 still had limitations. For example, each request-response pair needed a new TCP connection&nbsp;</p><p>In 1997, HTTP/1.1 was released to address the limitations of HTTP/1. Generally speaking, HTTP/1.1 is the definitive version of HTTP1. This version powered the growth of the World Wide Web and is still used heavily despite being over 25 years old.</p><p>What contributed to its incredible longevity?</p><p>There were a few important features that made it so successful.</p><h3>1 - Persistent Connections&nbsp;</h3><p>As mentioned, HTTP started as a single request-response protocol.&nbsp;</p><p>A client opens a connection to the server, makes a request, and gets the response. The connection is then closed. If there&#8217;s a second request, the cycle repeats. The same cycle repeats for subsequent requests.</p><p>It&#8217;s like a busy restaurant where a single waiter handles all orders. For each customer, the waiter takes the order, goes to the kitchen, prepares the food, and then delivers it to the customer&#8217;s table. Only then does the waiter move on to the next customer.</p><p>As the web became more media-oriented, closing the connection constantly after every response proved wasteful. If a web page contains multiple resources that have to be fetched, you would have to open and close the connection multiple times.</p><p>Since HTTP/1 was built on top of TCP (Transmission Control Protocol), every new connection meant going through the 3-way handshake process.</p><p>HTTP/1.1 got rid of this extra overhead by supporting persistent connections. It assumed that a TCP connection must be kept open unless directly told to close. This meant:</p><ul><li><p>No closing of the connection after every request</p></li><li><p>No multiple TCP handshakes.</p></li></ul><p>The diagram below shows the difference between multiple connections and persistent connections.</p><h3></h3><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22b23944-a2ab-432e-aad0-0ecfb9ae5144_1600x1018.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="926" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22b23944-a2ab-432e-aad0-0ecfb9ae5144_1600x1018.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>2 - Pipelining</h3><p>HTTP/1.1 also introduced the concept of pipelining.&nbsp;</p><p>The idea was to allow clients to send multiple requests over a single TCP connection without waiting for corresponding responses. For example, when the browser sees that it needs two images to render a web page, it can request them one after the other.</p><p>The below diagram explains the concept of pipelining in more detail.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97c703ce-13e1-4afc-8242-de06e90491cb_1600x1018.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="926" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97c703ce-13e1-4afc-8242-de06e90491cb_1600x1018.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Pipelining further improved performance by reducing the latency for each response before sending the next request. However, pipelining had some limitations around head-of-line blocking that we will discuss shortly.</p><h3>3 - Chunked Transfer Encoding</h3><p>HTTP/1.1 introduced chunked transfer encoding that allowed servers to send responses in smaller chunks rather than waiting for the entire response to be generated.&nbsp;</p><p>This enabled faster initial page rendering and improved the user experience, particularly for large or dynamically generated content.</p><h3>4 - Caching and Conditional Requests</h3><p>HTTP/1.1 introduced sophisticated caching mechanisms and conditional requests.</p><p>It added headers like Cache-Control and ETag, which allowed clients and servers to better manage cached content and reduce unnecessary data transfers.&nbsp;</p><p>Conditional requests, using headers like If-Modified-Since and If-None-Match, enabled clients to request resources only if they had been modified since a previous request, saving bandwidth and improving performance.</p><h2>The Problem with HTTP/1.1</h2><p>There&#8217;s no doubt that HTTP/1.1 was game-changing and enabled the amazing growth trajectory of the web over the last 20+ years.</p><p>However, the web has also evolved considerably since the time HTTP/1.1 was launched.</p><p>Websites have grown in size, with more resources to download and more data to be transferred over the network. According to the HTTP Archive, the average website these days requests around 80 to 90 resources and downloads nearly 2 MB of data.</p><p>The next graph shows the steady growth of website size over the last 10+ years.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda88ee-86d9-4798-aa45-40d10b1fa4b2_1600x1032.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="939" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda88ee-86d9-4798-aa45-40d10b1fa4b2_1600x1032.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption"><strong>Source: <a href="https://httparchive.org/reports/state-of-the-web">HTTP Archive State of the Web</a></strong></figcaption></figure></div><p>This growth exposed a fundamental performance problem with HTTP/1.1. </p><p>The diagram below explains the problem visually.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46611727-f8b9-4b47-b1d1-92b6458fd746_1600x1195.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1087" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46611727-f8b9-4b47-b1d1-92b6458fd746_1600x1195.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 09 May 2024 15:30:46 GMT</pubDate>
</item>
<item>
<title>100X Scaling: How Figma Scaled its Databases</title>
<link>https://blog.bytebytego.com/p/100x-scaling-how-figma-scaled-its</link>
<guid>https://blog.bytebytego.com/p/100x-scaling-how-figma-scaled-its</guid>
<content:encoded><![CDATA[
<div> 数据库扩展，垂直分区，水平分片，Figma，DBProxy
<br />
<br />
总结: Figma是一个快速增长的设计平台，面临着数据库规模的迅速增长，通过垂直分区和水平分片的方式来解决数据库扩展的挑战。他们首先进行垂直分区，将高流量的相关表移动到单独的数据库中，然后实施水平分片来将大表跨多个物理数据库分割，通过引入新服务DBProxy来解决路由和查询执行问题。通过这些创新的解决方案，Figma达到了逐步实现数据库横向分片的目标，确保了服务的稳定性和可扩展性。 <div>
<h2><a href="https://bit.ly/QAWolf_050724">&#128536; Kiss bugs goodbye with fully automated end-to-end test coverage (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_050724" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="752" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94f074d9-31a4-450a-9b8b-84ea8556f86d_1200x752.png" width="1200" /><div></div></div></a></figure></div><p>Bugs sneak out when less than 80% of user flows are tested before shipping. But getting that kind of coverage &#8212; and staying there &#8212; is hard and pricey for any sized team.</p><p><a href="https://bit.ly/QAWolf_050724">QA Wolf</a> takes testing off your plate:</p><p>&#8594; Get to 80% test coverage in just 4 months.</p><p>&#8594; Stay bug-free with <a href="https://bit.ly/QAWolf_050724">24-hour maintenance</a> and on-demand test creation.</p><p>&#8594; Get <a href="https://bit.ly/QAWolf_050724">unlimited parallel test runs</a></p><p>&#8594; Zero Flakes guaranteed</p><p>QA Wolf has generated <a href="https://bit.ly/QAWolf_050724">amazing results</a> for companies like Salesloft, AutoTrader, Mailchimp, and Bubble.</p><p>&#127775; Rated 4.5/5 on G2</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_050724"><span>Learn more about their 90-day pilot</span></a></p><div><hr /></div><p>Figma, a collaborative design platform, has been on a wild growth ride for the last few years. Its user base has grown by almost 200% since 2018, attracting around 3 million monthly users.</p><p>As more and more users have hopped on board, the infrastructure team found themselves in a spot. They needed a quick way to scale their databases to keep up with the increasing demand.</p><p>The database stack is like the backbone of Figma. It stores and manages all the important metadata, like permissions, file info, and comments. And it ended up growing a whopping 100x since 2020!&nbsp;</p><p>That's a good problem to have, but it also meant the team had to get creative.</p><p>In this article, we'll dive into Figma's database scaling journey. We'll explore the challenges they faced, the decisions they made, and the innovative solutions they came up with. By the end, you'll better understand what it takes to scale databases for a rapidly growing company like Figma.</p><h2>The Initial State of Figma&#8217;s Database Stack</h2><p>In 2020, Figma still used a single, large Amazon RDS database to persist most of the metadata. While it handled things quite well, one machine had its limits.&nbsp;</p><p>During peak traffic, the CPU utilization was above 65% resulting in unpredictable database latencies.</p><p>While complete saturation was far away, the infrastructure team at Figma wanted to proactively identify and fix any scalability issues. They started with a few tactical fixes such as:</p><ul><li><p>Upgrade the database to the largest instance available (from r5.12xlarge to r5.24xlarge).</p></li><li><p>Create multiple read replicas to scale read traffic.</p></li><li><p>Establish new databases for new use cases to limit the growth of the original database.</p></li><li><p>Add PgBouncer as a connection pooler to limit the impact of a growing number of connections.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa398da3d-1c1e-46b9-9cff-942a7b6ff403_1600x990.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="901" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa398da3d-1c1e-46b9-9cff-942a7b6ff403_1600x990.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>These fixes gave them an additional year of runway but there were still limitations:</p><ul><li><p>Based on the database traffic, they learned that write operations contributed a major portion of the overall utilization.&nbsp;</p></li><li><p>All read operations could not be moved to replicas because certain use cases were sensitive to the impact of replication lag.</p></li></ul><p>It was clear that they needed a longer-term solution.</p><h2>The First Step: Vertical Partitioning</h2><p>When Figma's infrastructure team realized they needed to scale their databases, they couldn't just shut everything down and start from scratch. They needed a solution to keep Figma running smoothly while they worked on the problem.&nbsp;</p><p>That's where vertical partitioning came in.</p><p>Think of vertical partitioning as reorganizing your wardrobe. Instead of having one big pile of mess, you split things into separate sections. In database terms, it means moving certain tables to separate databases.</p><p>For Figma, vertical partitioning was a lifesaver. It allowed them to move high-traffic, related tables like those for &#8220;Figma Files&#8221; and &#8220;Organizations&#8221; into their separate databases. This provided some much-needed breathing room.</p><p>To identify the tables for partitioning, Figma considered two factors:</p><ol><li><p><strong>Impact: Moving the tables should move a significant portion of the workload.</strong></p></li><li><p><strong>Isolation: The tables should not be strongly connected to other tables.</strong></p></li></ol><p>For measuring impact, they looked at average active sessions (AAS) for queries. This stat describes the average number of active threads dedicated to a given query at a certain point in time.</p><p>Measuring isolation was a little more tricky. They used runtime validators that hooked into ActiveRecord, their Ruby ORM. The validators sent production query and transaction information to Snowflake for analysis, helping them identify tables that were ideal for partitioning based on query patterns and table relationships.</p><p>Once the tables were identified, Figma needed to migrate them between databases without downtime. They set the following goals for their migration solution:</p><ul><li><p>Limit potential availability impact to less than 1 minute.</p></li><li><p>Automate the procedure so it is easily repeatable.</p></li><li><p>Have the ability to undo a recent partition.</p></li></ul><p>Since they couldn&#8217;t find a pre-built solution that could meet these requirements, Figma built an in-house solution. At a high level, it worked as follows:</p><ul><li><p>Prepared client applications to query from multiple database partitions.</p></li><li><p>Replicated tables from the original database to a new database until the replication lag was near 0.</p></li><li><p>Paused activity on the original database.</p></li><li><p>Waited for databases to synchronize.</p></li><li><p>Rerouted query traffic to the new database.</p></li><li><p>Resumed activity.</p></li></ul><p>To make the migration to partitioned databases smoother, they created separate PgBouncer services to split the traffic virtually. Security groups were implemented to ensure that only PgBouncers could directly access the database.</p><p>Partitioning the PgBouncer layer first gave some cushion to the clients to route the queries incorrectly since all PgBouncer instances initially had the same target database. During this time, the team could also detect the routing mismatches and make the necessary corrections.</p><p>The below diagram shows this process of migration.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227d8304-f560-4987-95de-5afcc7b02a86_1244x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227d8304-f560-4987-95de-5afcc7b02a86_1244x1600.png" width="1244" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="741" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b106e37-e264-4af2-98ce-26cd979aa36f_801x741.png" title="" width="801" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-cicd">A Crash Course in CI/CD</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Implementing Replication</h2><p>Data replication is a great way to scale the read operations for your database. When it came to replicating data for vertical partitioning, Figma had two options in Postgres: streaming replication or logical replication.</p><p>They chose logical replication for 3 main reasons:</p><ul><li><p>Logical replication allowed them to port over a subset of tables so that they could start with a much smaller storage footprint in the destination database.</p></li><li><p>It enabled them to replicate data into a database running a different Postgres major version.</p></li><li><p>Lastly, it allowed them to set up reverse replication to roll back the operation if needed.</p></li></ul><p>However, logical replication was slow. The initial data copy could take days or even weeks to complete.&nbsp;</p><p>Figma desperately wanted to avoid this lengthy process, not only to minimize the window for replication failure but also to reduce the cost of restarting if something went wrong.</p><p>But what made the process so slow?</p><p>The culprit was how Postgres maintains indexes in the destination database. While the replication process copies rows in bulk, it also updates the indexes one row at a time. By removing indexes in the destination database and rebuilding them after the data copy, Figma reduced the copy time to a matter of hours.</p><h2>Need for Horizontal Scaling</h2><p>As Figma's user base and feature set grew, so did the demands on their databases.&nbsp;</p><p>Despite their best efforts, vertical partitioning had limitations, especially for Figma&#8217;s largest tables. Some tables contained several terabytes of data and billions of rows, making them too large for a single database.</p><p>A couple of problems were especially prominent:</p><ul><li><p><strong>Postgres Vacuum Issue: Vacuuming is an essential background process in Postgres that reclaims storage occupied by deleted or obsolete rows. Without regular vacuuming, the database would eventually run out of transaction IDs and grind to a halt. However, vacuuming large tables can be resource-intensive and cause performance issues and downtime.</strong></p></li><li><p><strong>Max IO Operations Per Second: Figma&#8217;s highest write tables were growing so quickly that they would soon exceed the max IOPS limit of Amazon&#8217;s RDS.</strong></p></li></ul><p>For a better perspective, imagine a library with a rapidly growing collection of books. Initially, the library might cope by adding more shelves (vertical partitioning). But eventually, the building itself will run out of space. No matter how efficiently you arrange the shelves, you can&#8217;t fit an infinite number of books in a single building. That&#8217;s when you need to start thinking about opening branch libraries.</p><p>This is the approach of horizontal sharding.</p><p>For Figma, horizontal sharding was a way to split large tables across multiple physical databases, allowing them to scale beyond the limits of a single machine.&nbsp;</p><p>The below diagram shows this approach:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0570f4-0d65-49bd-9cb6-e581e08f4269_1244x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0570f4-0d65-49bd-9cb6-e581e08f4269_1244x1600.png" width="1244" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>However, horizontal sharding is a complex process that comes with its own set of challenges:</p><ul><li><p>Some SQL queries become inefficient to support.</p></li><li><p>Application code must be updated to route queries efficiently to the correct shard.</p></li><li><p>Schema changes must be coordinated across all shards.&nbsp;</p></li><li><p>Postgres can no longer enforce foreign keys and globally unique indexes.</p></li><li><p>Transactions span multiple shards, which means Postgres cannot be used to enforce transactionality.</p></li></ul><h2>Exploring Alternative Solutions</h2><p>The engineering team at Figma evaluated alternative SQL options such as CockroachDB, TiDB, Spanner, and Vitess as well as NoSQL databases.</p><p>Eventually, however, they decided to build a horizontally sharded solution on top of their existing vertically partitioned RDS Postgres infrastructure.&nbsp;</p><p>There were multiple reasons for taking this decision:</p><ul><li><p>They could leverage their existing expertise with RDS Postgres, which they had been running reliably for years.</p></li><li><p>They could tailor the solution to Figma&#8217;s specific needs, rather than adapting their application to fit a generic sharding solution.</p></li><li><p>In case of any issues, they could easily roll back to their unsharded Postgres databases.</p></li><li><p>They did not need to change their complex relational data model built on top of Postgres architecture to a new approach like NoSQL. This allowed the teams to continue building new features.</p></li></ul><h2>Figma&#8217;s Unique Sharding Implementation</h2><p>Figma&#8217;s approach to horizontal sharding was tailored to their specific needs as well as the existing architecture. They made some unusual design choices that set their implementation apart from other common solutions.</p><p>Let&#8217;s look at the key components of Figma&#8217;s sharding approach:</p><h3>Colos (Colocations) for Grouping Related Tables</h3><p>Figma introduced the concept of &#8220;colos&#8221; or colocations, which are a group of related tables that share the same sharding key and physical sharding layout.&nbsp;</p><p>To create the colos, they selected a handful of sharding keys like UserId, FileId, or OrgID. Almost every table at Figma could be sharded using one of these keys.</p><p>This provides a friendly abstraction for developers to interact with horizontally sharded tables.&nbsp;</p><p>Tables within a colo support cross-table joins and full transactions when restricted to a single sharding key. Most application code already interacted with the database in a similar way, which minimized the work required by applications to make a table ready for horizontal sharding.</p><p>The below diagram shows the concept of colos:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F991f6f8e-c62a-4071-bf54-7bfdac7e9e95_1600x1087.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="989" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F991f6f8e-c62a-4071-bf54-7bfdac7e9e95_1600x1087.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Logical Sharding vs Physical Sharding</h3><p>Figma separated the concept of &#8220;logical sharding&#8221; at the application layer from &#8220;physical sharding&#8221; at the Postgres layer.</p><p>Logical sharding involves creating multiple views per table, each corresponding to a subset of data in a given shard. All reads and writes to the table are sent through these views, making the table appear horizontally sharded even though the data is physically located on a single database host.</p><p>This separation allowed Figma to decouple the two parts of their migration and implement them independently. They could perform a safer and lower-risk logical sharding rollout before executing the riskier distributed physical sharding.&nbsp;</p><p>Rolling back logical sharding was a simple configuration change, whereas rolling back physical shard operations would require more complex coordination to ensure data consistency.</p><h3>DBProxy Query Engine for Routing and Query Execution</h3><p>To support horizontal sharding, the Figma engineering team built a new service named DBProxy that sits between the application and connection pooling layers such as the PGBouncer.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b03c9da-f712-44b7-aaa2-386f433ee45f_1600x1188.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1081" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b03c9da-f712-44b7-aaa2-386f433ee45f_1600x1188.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>DBProxy includes a lightweight query engine capable of parsing and executing horizontally sharded queries. It consists of three main components:</p><ol><li><p>A query parser that reads the SQL sent by the application and transforms it into an Abstract Syntax Tree (AST).</p></li><li><p>A logical planner that parses the AST, extracts the query type (insert, update, etc.), and logical shard IDs from the query plan.</p></li><li><p>A physical planner that maps the query from logical shard IDs to physical databases and rewrites queries to execute on the appropriate physical shard.</p></li></ol><p>The below diagram shows the practical use of these three components within the query processing workflow.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa76c90f1-4149-48bd-9615-faa6fd8d0a16_1600x982.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="894" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa76c90f1-4149-48bd-9615-faa6fd8d0a16_1600x982.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>There are always trade-offs when it comes to queries in a horizontally sharded world. Queries for a single shard key are relatively easy to implement. The query engine just needs to extract the shard key and route the query to the appropriate physical database.</p><p>However, if the query does not contain a sharding key, the query engine has to perform a more complex &#8220;scatter-gather&#8221; operation. This operation is similar to a hide-and-seek game where you send the query to every shard (scatter), and then piece together answers from each shard (gather).&nbsp;</p><p>The below diagram shows how single-shard queries work when compared to scatter-gather queries.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b900cff-db00-4b9b-84c4-1bc3abb2d8fd_1373x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b900cff-db00-4b9b-84c4-1bc3abb2d8fd_1373x1600.png" width="1373" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As you can see, this increases the load on the database, and having too many scatter-gather queries can hurt horizontal scalability.</p><p>To manage things better, DBProxy handles load-shedding, transaction support, database topology management, and improved observability.</p><h3>Shadow Application Readiness Framework</h3><p>Figma added a &#8220;shadow application readiness&#8221; framework capable of predicting how live production traffic would behave under different potential sharding keys.&nbsp;</p><p>This framework helped them keep the DBProxy simple while reducing the work required for the application developers in rewriting unsupported queries.&nbsp;</p><p>All the queries and associated plans are logged to a Snowflake database, where they can run offline analysis. Based on the data collected, they were able to pick a query language that supported the most common 90% of queries while avoiding the worst-case complexity in the query engine.</p><h2>Conclusion</h2><p>Figma&#8217;s infrastructure team shipped their first horizontally sharded table in September 2023, marking a significant milestone in their database scaling journey.</p><p>It was a successful implementation with minimal impact on availability. Also, the team observed no regressions in latency or availability after the sharding operation.</p><p>Figma&#8217;s ultimate goal is to horizontally shard every table in their database and achieve near-infinite scalability. They have identified several challenges that need to be solved such as:</p><ul><li><p>Supporting horizontally sharded schema updates</p></li><li><p>Generating globally unique IDs for horizontally sharded primary keys</p></li><li><p>Implementing atomic cross-shard transactions for business-critical use cases.</p></li><li><p>Enabling distributed globally unique indexes.</p></li><li><p>Developing an ORM model to improve developer velocity</p></li><li><p>Automatic reshard operations to enable shard splits at the click of a button.</p></li></ul><p>Lastly, after achieving a sufficient runway, they also plan to reassess their current approach of using in-house RDS horizontal sharding versus switching to an open-source or managed alternative in the future.</p><p><strong>References:</strong></p><ul><li><p><a href="https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/">How Figma&#8217;s databases team lived to tell the scale</a></p></li><li><p><a href="https://www.figma.com/blog/how-figma-scaled-to-multiple-databases/">The growing pains of database architecture</a></p></li><li><p><a href="https://www.pgbouncer.org/features.html">Features of PgBouncer</a></p></li><li><p><a href="https://zipdo.co/statistics/figma-user/">Figma User Statistics</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a>.</strong></p>
]]></content:encoded>
<pubDate>Tue, 07 May 2024 15:30:45 GMT</pubDate>
</item>
<item>
<title>EP110: Top 5 Strategies to Reduce Latency</title>
<link>https://blog.bytebytego.com/p/ep110-top-5-strategies-to-reduce</link>
<guid>https://blog.bytebytego.com/p/ep110-top-5-strategies-to-reduce</guid>
<content:encoded><![CDATA[
<div> Latency, Load Balancer, Data Sharding Algorithms, C++ Use Cases, Apache Kafka

<br />
Latency对于高规模用户系统来说是一项重要影响收入的因素，而减少延迟的策略包括数据库索引、缓存、负载均衡、内容交付网络、异步处理、数据压缩等。负载均衡的实际用例包括故障处理、实例健康检查、SSL终止、跨区负载均衡和用户粘性，能提升系统可靠性。数据分片算法有基于范围、基于哈希、一致性哈希和虚拟桶分片方法。C++的用途广泛，包括嵌入式系统、游戏开发、操作系统、数据库、网络、科学计算等。Apache Kafka是分布式事件流平台，包含broker、topic、partition、producer、consumer和consumer group等重要组件，并可用作消息传递和日志聚合。 

<br /><br />总结: 
- 减少延迟的策略包括数据库索引、缓存、负载均衡、内容交付网络、异步处理、数据压缩
- 负载均衡的实际用例有故障处理、实例健康检查、SSL终止、跨区负载均衡、用户粘性
- 常用数据分片算法有基于范围、基于哈希、一致性哈希、虚拟桶分片方法
- C++适用于嵌入式系统、游戏开发、操作系统、数据库、网络、科学计算等用例
- Apache Kafka作为分布式事件流平台，包含多个关键组件和用途 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Top 5 Strategies to Reduce Latency</p></li><li><p>Load Balancer Realistic Use Cases You May Not Know</p></li><li><p>Top 4 data sharding algorithms explained</p></li><li><p>Top 8 C++ Use Cases</p></li><li><p>Apache Kafka in 100 Seconds</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/NewRelic_050324">New Relic AI monitoring, the industry&#8217;s first APM for AI, now generally available (Sponsore</a>d)</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/NewRelic_050324" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="630" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6192fcd8-53fc-4461-9e2c-8a73050c1d7c_1200x630.png" width="1200" /><div></div></div></a></figure></div><p>New Relic AI monitoring provides unprecedented visibility and insights to engineers and developers who are modernizing their tech stacks. With New Relic AI monitoring, engineering teams can monitor, alert, debug, and root-cause AI-powered applications.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/NewRelic_050324"><span>Get started</span></a></p><div><hr /></div><h2>Top 5 Strategies to Reduce Latency</h2><p>10 years ago, Amazon found that every 100ms of latency cost them 1% in sales. <br /> <br />That&#8217;s a staggering $5.7 billion in today&#8217;s terms. <br /> <br />For high-scale user-facing systems, high latency is a big loss of revenue. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F801df2c4-056a-400c-91cc-8dc09fced890_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><p>Here are the top strategies to reduce latency: </p><ol><li><p>Database Indexing </p></li><li><p>Caching </p></li><li><p>Load Balancing </p></li><li><p>Content Delivery Network </p></li><li><p>Async Processing </p></li><li><p>Data Compression </p></li></ol><p>Over to you: What other strategies to reduce latency have you seen? </p><div><hr /></div><h2>Load Balancer Realistic Use Cases You May Not Know</h2><p>Load balancers are inherently dynamic and adaptable, designed to efficiently address multiple purposes and use cases in network traffic and server workload management. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d1ff6df-980d-43e9-aba9-7498a2ce3237_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><p>Let's explore some of the use cases: </p><ol><li><p>Failure Handling: <br />Automatically redirects traffic away from malfunctioning elements to maintain continuous service and reduce service interruptions. </p></li><li><p>Instance Health Checks: <br />Continuously evaluates the functionality of instances, directing incoming requests exclusively to those that are fully operational and efficient. </p></li><li><p>Platform Specific Routing: <br />Routes requests from different device types (like mobiles, desktops) to specialized backend systems, providing customized responses based on platform. </p></li><li><p>SSL Termination: <br />Handles the encryption and decryption of SSL traffic, reducing the processing burden on backend infrastructure. </p></li><li><p>Cross Zone Load Balancing: <br />Distributes incoming traffic across various geographic or network zones, increasing the system's resilience and capacity for handling large volumes of requests. </p></li><li><p>User Stickiness: <br />Maintains user session integrity and tailored user interactions by consistently directing requests from specific users to designated backend servers. </p></li></ol><p>Over to you: <br />Which of these use cases would you consider adding to your network to enhance system reliability and why?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="741" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b106e37-e264-4af2-98ce-26cd979aa36f_801x741.png" width="801" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-cicd">A Crash Course in CI/CD</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Top 4 Data Sharding Algorithms Explained</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f404d8a-413b-4874-a9f7-90763e635ed9_1280x1664.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><p>We are dealing with massive amounts of data. Often we need to split data into smaller, more manageable pieces, or &#8220;shards&#8221;. Here are some of the top data sharding algorithms commonly used: </p><ul><li><p>Range-Based Sharding <br />This involves partitioning data based on a range of values. For example, customer data can be sharded based on alphabetical order of last names, or transaction data can be sharded based on date ranges. </p></li><li><p>Hash-Based Sharding <br />In this method, a hash function is applied to a shard key chosen from the data (like a customer ID or transaction ID). <br />This tends to distribute data more evenly across shards compared to range-based sharding. However, we need to choose a proper hash function to avoid hash collision. </p></li><li><p>Consistent Hashing <br />This is an extension of hash-based sharding that reduces the impact of adding or removing shards. It distributes data more evenly and minimizes the amount of data that needs to be relocated when shards are added or removed. </p></li><li><p>Virtual Bucket Sharding <br />Data is mapped into virtual buckets, and these buckets are then mapped to physical shards. This two-level mapping allows for more flexible shard management and rebalancing without significant data movement.</p></li></ul><div><hr /></div><h2>Top 8 C++ Use Cases</h2><p>C++ is a highly versatile programming language that is suitable for a wide range of applications. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9dbf2f6-84ed-4533-a681-1ef110eb4084_1280x1664.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><ul><li><p>Embedded Systems <br />The language's efficiency and fine control over hardware resources make it excellent for embedded systems development. </p></li><li><p>Game Development <br />C++ is a staple in the game development industry due to its performance and efficiency. </p></li><li><p>Operating Systems <br />C++ provides extensive control over system resources and memory, making it ideal for developing operating systems and low-level system utilities. </p></li><li><p>Databases <br />Many high-performance database systems are implemented in C++ to manage memory efficiently and ensure fast execution of queries. </p></li><li><p>Financial Applications </p></li><li><p>Web Browsers <br />C++ is used in the development of web browsers and their components, such as rendering engines. </p></li><li><p>Networking <br />C++ is often used for developing network devices and simulation tools. </p></li><li><p>Scientific Computing <br />C++ finds extensive use in scientific computing and engineering applications that require high performance and precise control over computational resources. </p></li></ul><p>Over to you - What did we miss? </p><div><hr /></div><h2>Apache Kafka in 100 Seconds</h2><p>This post is written by guest author <a href="https://www.linkedin.com/in/sanazzakeri/">Sanaz Zakeri</a>, who is a Senior Software Engineer @Uber.</p><p>Apache Kafka is a distributed event streaming platform used for building real-time data processing pipelines and streaming applications. It is highly scalable, fault-tolerant, reliable, and can handle large volumes of data.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="Image" class="sizing-normal" height="1066" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ade5eb-1223-4cdc-a2ed-dccd1e42dc6e_1202x1066.jpeg" title="Image" width="1202" /><div></div></div></a></figure></div><p>In order to understand Kafka, we need to define two terms:</p><ul><li><p>Events: a log of state of something at a specific point in time</p></li><li><p>Event streams: continuous and unbounded series of events</p></li></ul><p>Kafka can be used as a Messaging in a publish-subscribe model, where producers write event streams, and consumers read the events. This publish-subscribe model enables decoupling of event stream producers and consumers. Also, Kafka can be used as a log aggregation platform, ingesting and storing logs from multiple sources in a durable and fault-tolerant way.</p><ul><li><p><strong>Kafka Components: </strong></p><p>Kafka cluster has multiple key components to provide the distributed infrastructure and reliably capture, store, order and provide event streams to client applications.</p></li><li><p><strong>Brokers: </strong></p><p>At the heart of the Kafka cluster lies the brokers which are physical servers that handle event streams. After events are published by producers, the broker makes the events available to consumers. Brokers bring scalability to Kafka as Kafka clusters can span multiple brokers across a variety of infrastructure setup to handle large volumes of events. They also bring fault tolerance since events can be stored and replicated across multiple brokers.</p></li><li><p><strong>Topics: </strong></p><p>Topic is the subject name of where the events are published by producers. Topics can have zero or more consumers listening to them and processing the events.</p></li><li><p><strong>Partition: </strong></p><p>In a topic, data is organized into partitions which store ordered streams of events. Each event within a partition is assigned a unique sequential identifier called offset that represents its position in the partition. Events are appended&nbsp; continually to the partition. A Topics can have one or more partitions. Having more than one partition in a topic enables parallelism as more consumers can read from the topic.</p><p>Partitions belonging to a topic can be distributed across separate brokers in the cluster, which brings high data availability and scalability. If one broker fails, the partitions on the remaining brokers can continue to serve data, ensuring fault tolerance.</p></li><li><p><strong>Producers: </strong></p><p>Producers are client applications&nbsp; that write events to Kafka topics as a stream of events.</p></li><li><p><strong>Consumers: </strong></p><p>Consumers are the client applications that subscribe to topics and process or store the events coming to the specific topic. Consumers read events in the order they were received within each partition.</p><p>Applications which require real time processing of data will have multiple consumers in a consumer group which can read from partitions on the subscribed topic.</p></li><li><p><strong>Consumer Groups: </strong></p><p>Consumer group is used to organize consumers that are reading a stream of events from one or more topics. Consumer groups enable parallel processing of events and each consumer in the consumer group can read from one partition to enable load balancing on the client application. This functionality not only brings the parallel processing but also brings fault tolerance since if a consumer fails in a consumer group, Partition can be reassigned to another group member.&nbsp;</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a>.</strong></p>
]]></content:encoded>
<pubDate>Sat, 04 May 2024 15:30:41 GMT</pubDate>
</item>
<item>
<title>Unlocking the Power of SQL Queries for Improved Performance</title>
<link>https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries</link>
<guid>https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries</guid>
<content:encoded><![CDATA[
<div> SQL, 数据管理, 数据库, 查询优化, Explain Plan

总结:<br /><br />SQL是现代数据管理的基础，通过优化查询可以提升数据库性能和降低成本。使用Explain Plan工具可以分析查询执行计划，帮助识别潜在问题。在MySQL中，使用EXPLAIN命令可以获取执行查询的详细信息，包括表、操作、索引等。优化查询时，可以根据EXPLAIN的输出结果找到潜在瓶颈，并进行调整。通过实际示例演示了如何使用EXPLAIN命令来分析查询的执行计划。 <div>
<p>SQL, or Structured Query Language, is the backbone of modern data management. It enables efficient retrieval, manipulation, and management of data in a Database Management System (DBMS). Each SQL command taps into a complex sequence within a database, building on concepts like the connection pool, query cache, command parser, optimizer, and executor, which we covered in our last issue.</p><p>Crafting effective queries is essential. The right SQL can enhance database performance; the wrong one can lead to increased costs and slower responses. In this issue, we focus on strategies such as using the Explain Plan, adding proper indexes, and optimizing commands like COUNT(*) and ORDER BY. We also dive into troubleshooting slow queries.</p><p>While MySQL is our primary example, the techniques and strategies discussed are applicable across various database systems. Join us as we refine SQL queries for better performance and cost efficiency.</p><div><hr /></div><h2>Explain Plan</h2><p>In MySQL, the EXPLAIN command, known as EXPLAIN PLAN in systems like Oracle, is a useful tool for analyzing how queries are executed. By adding EXPLAIN before a SELECT statement, MySQL provides information about how it processes the SQL. This output shows the tables involved, operations performed (such as sort, scan, and join), and the indexes used, among other execution details. This tool is particularly useful for optimizing SQL queries, as it helps developers see the query execution plan and identify potential bottlenecks.</p><p>When an EXPLAIN statement is executed in MySQL, the database engine simulates the query execution. This simulation generates a detailed report without running the actual query. This report includes several important columns:</p><ul><li><p>id: Identifier for each step in the query execution.</p></li><li><p>select_type: The type of SELECT operation, like SIMPLE (a basic SELECT without unions or subqueries), SUBQUERY, or UNION.</p></li><li><p>table: The table involved in a particular part of the query.</p></li><li><p>type: The join type shows how MySQL joins the tables. Common types include ALL (full table scan), index (index scan), range (index range scan), eq_ref (unique index scan), const/system (constant value optimization).</p></li><li><p>possible_keys: Potential indexes that might be used.</p></li><li><p>key: The key (index) chosen by MySQL.</p></li><li><p>key_len: The length of the chosen key.</p></li><li><p>ref: Columns or constants used with the key to select rows.</p></li><li><p>rows: Estimated number of rows MySQL expects to examine when executing the query.</p></li><li><p>Extra: Additional details, such as the use of temporary tables or filesorts.</p></li></ul><p>Let's explore a practical application of the EXPLAIN command using a database table named <em>orders</em>. Suppose we want to select orders with user_id equal to 100.</p><pre><code><strong>SELECT</strong> * <strong>FROM</strong> orders <strong>WHERE</strong> user_id = 100;</code></pre><p>To analyze this query with EXPLAIN, we would use:</p><pre><code><strong>EXPLAIN SELECT</strong> * <strong>FROM</strong> orders <strong>WHERE</strong> user_id = 100;</code></pre><p>The output might look like this:&nbsp;</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d33f7e-6fca-47da-9e4a-04a9e053c2b8_1470x210.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="208" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d33f7e-6fca-47da-9e4a-04a9e053c2b8_1470x210.png" width="1456" /><div></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 15:31:02 GMT</pubDate>
</item>
<item>
<title>How to Execute End-to-End Tests at Scale</title>
<link>https://blog.bytebytego.com/p/how-to-execute-end-to-end-tests-at</link>
<guid>https://blog.bytebytego.com/p/how-to-execute-end-to-end-tests-at</guid>
<content:encoded><![CDATA[
<div> GCP, Argo CD, Kubernetes, Playwright, QA Wolf
总结:<br /><br />文章介绍了QA Wolf公司的专门基础设施，能够在短短几分钟内并发运行数千个端到端测试，满足客户的期望。他们的技术栈包括Google Cloud Platform(GCP)、Argo CD、Kubernetes、Playwright等工具。利用GitOps方法构建基础设施，采用Pulumi作为IaC工具，使用Typescript编写测试，通过运行数据文件执行测试。他们的执行流程由Run Director服务调度，运行Shard集群提供高可用性和更快测试，同时报告测试结果。该基础设施建立在全云原生架构上，支持快速迭代，为客户快速交付提供价值。 <div>
<p></p><p>Running E2E tests reliably and efficiently is a critical piece of the puzzle for any software organization.&nbsp;</p><p>There are mainly two expectations software teams have when it comes to testing:</p><ul><li><p>Ship as fast as possible without introducing (or reintroducing) bugs</p></li><li><p>Run tests as cheaply as possible without compromising on quality.</p></li></ul><p>In today&#8217;s issue, we are fortunate to host guest author John Gluck, Principal Testing Advocate at QA Wolf. He&#8217;ll be sharing insights into QA Wolf&#8217;s specialized infrastructure capable of running thousands of concurrent E2E tests in just a few minutes and meeting the expectations of their customers.</p><p><a href="https://www.qawolf.com/">QA Wolf</a> is a full-service solution for mid-to-large product teams who want to speed up their QA cycles and reduce the cost of building, running, and maintaining comprehensive regression test coverage.&nbsp;&nbsp;</p><p>Also, <a href="https://sched.co/1YeP3">Mufav Onus</a> of QA Wolf spoke at Kubecon 2024 in Paris about how they automatically resume pods on spot instances after unexpected shutdowns. <a href="https://www.youtube.com/watch?v=c2MbSM9-7Xs">Take a look</a>.</p><div><hr /></div><h2>The Challenge of Running E2E Tests</h2><p>Running E2E tests efficiently is challenging for any organization. The runners tend to cause resource spikes, which cause tests and applications to behave unpredictably.&nbsp; That&#8217;s why it&#8217;s fairly common for large product teams to strategically schedule their test runs. As the number of tests and the number of runs increases, the challenges become exponentially more difficult to overcome.&nbsp;&nbsp;</p><p>While the largest companies in the world may run 10,000 end-to-end tests each month, and a handful run 100,000, QA Wolf runs more than 2 million. At our scale, to support the number of customers that we do, our infrastructure has to address three major concerns:&nbsp;</p><ul><li><p><strong>Availability -</strong> Customers can execute their tests at any time with no restrictions on the number or frequency of parallel runs. The system must be highly available. We can&#8217;t use scheduling tricks to solve this.&nbsp;</p></li><li><p><strong>Speed - </strong>Tests need to run fast. DORA recommends 30 minutes as the maximum time for test suite execution, and customers want to follow this principle.</p></li><li><p><strong>Reliability - </strong>&nbsp;Node contention issues, instance hijacking, and test system execution outages (the things in-house test architects deal with on a regular basis) are simply not tolerable when people are paying you to execute their tests.</p></li></ul><p>For better or worse, StackOverflow didn&#8217;t have blueprints for the kind of test-running infrastructure we needed to build. Success came from lots of experimentation and constant refinement.&nbsp;</p><p>In this post, we discuss the problems we faced and the decisions we made so that we could solve them through experimentation.</p><h2>The Tech Stack Breakdown</h2><p></p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5150f81a-b38f-46c8-b7d2-cf27a9e5f84a_2410x896.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="541" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5150f81a-b38f-46c8-b7d2-cf27a9e5f84a_2410x896.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">The tech stack</figcaption></figure></div><p>To set the stage, we are completely cloud-native and built our infrastructure on the Google Cloud Platform (GCP).&nbsp;</p><p>We went with GCP for its GKE (Kubernetes) implementation and cluster autoscaling capabilities, which are critical for handling the demand for test execution nodes. There are similar tools out there, but our engineers also had previous experience with GCP, which helped us get started.&nbsp;</p><p>We adopted a GitOps approach so we could run lots of configuration experiments on our infrastructure quickly and safely without disrupting ongoing operations.&nbsp;</p><p>Argo CD was a good choice because of its support for GitOps and Kubernetes. A combination of Helm and Argo Workflows helps make the deployment process consistent and organized. We used Argo CD Application Sets and App of Apps patterns which are considered best practices.</p><p>For IaC, we chose Pulumi because it&#8217;s open source, and unlike Terraform, it doesn&#8217;t force developers to adopt another DSL (Domain-Specific Language)</p><p>Lastly, we used Typescript to write the tests. Our customers look at the test code written for them, and Typescript makes it easy to understand. We chose Playwright as the test executor and test framework for multiple reasons, such as:</p><ol><li><p>Playwright can handle the complex tests that customers may need to automate.</p></li><li><p>Simpler APIs and an easier install prevent customers from being locked into our solution.&nbsp;</p></li><li><p>It&#8217;s backed by Microsoft, and more active development is expanding the list of native capabilities.</p></li></ol><h2>The Ecosystem</h2><p>For the infrastructure ecosystem, we went with one VPC and three main application clusters.&nbsp;</p><p>Each of the three clusters has a specific role:</p><ul><li><p>The application cluster</p></li><li><p>The test instance or runner cluster</p></li><li><p>Operations cluster</p></li></ul><p>The operations cluster is the primary cluster and manages the other two clusters. Argo CD runs within this cluster.</p><p>See the diagram below that shows this arrangement.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a34a0b7-6d02-405c-93cd-3341f60efb8a_980x597.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="441.0489795918367" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a34a0b7-6d02-405c-93cd-3341f60efb8a_980x597.png" width="724" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At the time of startup, the operations cluster creates both the application and runner clusters. It provisions warm nodes on the runner cluster, each containing two pods, and each pod is built on a single container image.&nbsp;</p><p>See the diagram below for reference:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90386158-64cc-4736-a8b0-3569b3ba7e0d_1600x974.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="435.6978021978022" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90386158-64cc-4736-a8b0-3569b3ba7e0d_1600x974.png" width="716" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>This structure is fully expendable. Our developers can tear down the entire system and rebuild it from scratch with the touch of a button, which increases predictability for developers and is also great for supporting disaster recovery.&nbsp;</p><p>GKE&#8217;s cluster autoscaler scales the warm nodes on the runner cluster up and down based on demand.&nbsp;</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="662" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbec68d98-d61b-411c-824c-64205354de37_661x662.png" title="" width="661" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-cicd">A Crash Course in CI/CD</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-ipv4-addressing">A Crash Course in IPv4 Addressing</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>The Customer-Facing Application</h2><p>The customer-facing application is a specialized IDE where our QA engineers can write, run, and maintain Playwright tests. It has views for managing configuration and third-party integrations with visualization dashboards.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1917074-931e-4567-b53d-d4abc6b6dfe9_1600x785.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="351.11538461538464" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1917074-931e-4567-b53d-d4abc6b6dfe9_1600x785.png" width="716" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">QA Wolf&#8217;s Test Editor</figcaption></figure></div><h2>Writing Tests</h2><p>The tests built and maintained by our in-house QA engineers are autonomous, isolated, idempotent, and atomic, so they can run predictably in a fully parallelized context.</p><p>When a QA engineer saves a test, the application persists the code for the test onto GCS with its corresponding helpers and any associated parsed configuration needed to run it in Playwright. This is the Run Data File for the test. In case you don&#8217;t know, GCS is the GCP equivalent of AWS S3.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27e79e48-de79-49d0-924a-48b903a67644_542x701.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="804.4686346863468" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27e79e48-de79-49d0-924a-48b903a67644_542x701.png" width="622" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In the initial implementation, we tried passing the Run Data File as a payload in HTML, but the payload containing the test code for all tests in a run was too large for Kubernetes etcd. To get around this, we took the path of least resistance by writing all the code to a central file and giving the client a reference to the file location to pass back to the application.</p><h2>The Execution Flow</h2><p>As mentioned earlier, we orchestrate runs with Argo Workflows because it can run on a Kubernetes cluster without external dependencies.</p><p>Customers or QA engineers can use a scheduler in the application or an API call to start a test run. When a test run is triggered, the application gathers the locations of all necessary Run Data Files. It also creates a new database record for each test run, including a unique build number that acts as an identifier for the test run request. The application uses the build number later to associate system logs and video locations.</p><p>Lastly, it passes the Run Data file locations list to the Run Director service.</p><p>The below diagram depicts the entire execution flow at a high level.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a79ebdf-390b-4d61-91e5-ad9337c5c23a_1305x1077.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="590.9057471264368" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a79ebdf-390b-4d61-91e5-ad9337c5c23a_1305x1077.png" width="716" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>The Run Director</h2><p>The Run Director is a simple, long-living, horizontally-scalable HTTP service.&nbsp;</p><p>When invoked, the Run Director reports the initial test run status to the application via a webhook and the build number. For each location in the list, the Run Director invokes an Argo Workflows template and hydrates it with the Run Data file at that location. By performing both actions simultaneously, individual test runs can be started faster so that all the tests in the run can finish more quickly.</p><p>The Argo Workflow then provisions a Kubernetes pod for each test run requested from the available warm nodes. It attaches the code for each test to a volume on a corresponding container on the pod. This approach allows us to use the same container build for every test execution. If there aren&#8217;t enough pods for the run on warm nodes, GKE uses cluster autoscaling to meet demand.&nbsp;</p><p>Each test runs in its own pod and container, which isolates the tests and makes it easier for the developers to troubleshoot them. Running tests like this also confines resource consumption issues to the node where the specific tests are having trouble.</p><p>The test code runs from the container entry point. Argo Workflow drives the provisioning process and starts each container with the help of Kubernetes</p><p>The application runs all the tests in headed browsers. This is important because the container is destroyed after the test finishes, and the headed browser makes it possible to capture videos of tests. The videos are an essential debugging tool to know about what happened at the moment, especially in cases where it&#8217;s difficult to recreate a particular failure.&nbsp;</p><p>Due to the high standard for test authorship and the infrastructure reliability, the primary cause of test failure is when the system-under-test (SUT) is not optimized for testing. It makes sense when you think about it. The slower the SUT, the more the test is required to poll, increasing the demand on the processor running the test. Though we can&#8217;t tell the customer how to build their application to improve test performance, we can isolate each test&#8217;s resource consumption to prevent it from impacting other tests.&nbsp;</p><h2>The Flake Detection</h2><p>We maintain a very high standard of test authorship, which allows us to make certain assumptions.</p><p>Since the tests are expected to pass, we can safely assume that a test failure or error is due to an anomaly, such as a temporarily unavailable SUT. The application schedules such failures for automatic retry. It flags any other failure &#8211; such as a suspected infrastructure problem &#8211; for investigation and doesn&#8217;t retry. Argo Workflows will attempt to re-run a failed test three times.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faae5939b-9b9a-468f-8f32-86bc55ddbfc0_1600x1124.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="491.8269230769231" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faae5939b-9b9a-468f-8f32-86bc55ddbfc0_1600x1124.png" width="700" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">QA Wolf Flake Detection Process</figcaption></figure></div><p>If the tests pass on retry, the application resumes as usual and assumes the failure was anomalous. In case all retries fail, the system creates a defect report, and a QA engineer investigates to confirm whether the failure is due to a bug in the application or some other issue.</p><h2>The Run Shard Clusters</h2><p>One of the most significant advantages of the Run Director service is the concept of Run Shard Clusters.</p><p>The sharding strategy allows us to spread the various test runs across clusters located worldwide. We have a GCP global VPC with a bunch of different subnets in different regions. This makes it possible to provision sharding clusters in different regions that can be accessed privately via the Run Director service.</p><p>Shard clusters provide several advantages, such as:</p><ul><li><p><strong>Replicated high availability </strong>- If one region goes down, not everything grinds to a halt.</p></li><li><p><strong>Closer-to-home testing</strong> - The ability to run customer tests close to their home region results in a more accurate performance of their applications and systems.</p></li><li><p><strong>Experimentation </strong>-<strong> </strong>We can experiment with different versions of our Argo Workflows implementation or different run engines without cutting overall traffic to the same version. This also allows us to experiment with cost-saving measures such as spot instances.</p></li></ul><h2>Reporting</h2><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ef5006-498e-41f9-9a2c-d7b3f2000dff_1600x769.jpeg" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="338.46153846153845" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ef5006-498e-41f9-9a2c-d7b3f2000dff_1600x769.jpeg" width="704" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">The QA Wolf Application Dashboard</figcaption></figure></div><p>Of course, our customers also want to see test results, so we needed to create a reliable system that allowed them to do so.</p><p>Once the test finishes running and retrying (if needed), the Argo Workflow template uploads any run artifacts saved by Playwright back to GCS using the build number. Some of this information will be aggregated and appear on our application&#8217;s dashboard.&nbsp; Other pieces of information from these artifacts are displayed at the test level, such as logs and run history.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20875576-d0ff-42a0-9704-65465133489e_317x494.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="687.2365930599369" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20875576-d0ff-42a0-9704-65465133489e_317x494.png" width="441" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Run History for a QA Wolf test</figcaption></figure></div><p>On the infrastructure side, the Argo Workflow triggers Kubernetes to shut down the container and detach the volume, ensuring that the system doesn&#8217;t leave unnecessary resources running. This helps keep down operational costs.</p><h2>Conclusion</h2><p>Our unique approach was developed to meet customer needs for speed, availability, and reliability. We are one of the few companies running e2e tests at this scale, so we needed to discover how to create a system to support that through trial and error; therefore, we designed our system to also support fast iteration.&nbsp; Our cost-efficient, full parallel test execution is the backbone of our application and we see it delivering value for our customers on a daily basis.</p><div><hr /></div><p>If you&#8217;d like to learn more about QA Wolf&#8217;s test run infrastructure or how it can help you ship faster with fewer escapes, visit their website to <a href="http://www.qawolf.com/?utm_source=bytebytego&amp;utm_medium=newsletter&amp;utm_campaign=bbgnewsletter">schedule a demo</a>.&nbsp;</p><p>Related Links</p><ul><li><p><a href="https://www.qawolf.com/blog/flaky-coverage-is-fake-coverage">Flaky coverage is fake coverage</a></p></li><li><p><a href="https://www.qawolf.com/blog/the-challenges-and-rewards-of-full-test-parallelization">Parallel testing: what it is, why it's hard, and why you should do it</a></p></li><li><p><a href="https://www.qawolf.com/blog/principles-for-writing-parallizable-tests">Three ways to improve your parallelized tests</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a>.</strong></p>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 16:24:12 GMT</pubDate>
</item>
</channel>
</rss>