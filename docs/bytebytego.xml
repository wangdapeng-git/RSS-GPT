<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>ByteByteGo Newsletter</title>
<link>https://blog.bytebytego.com</link>


<item>
<title>EP127: 20 Popular Open Source Projects Started or Supported By Big Companies</title>
<link>https://blog.bytebytego.com/p/ep127-20-popular-open-source-projects</link>
<guid>https://blog.bytebytego.com/p/ep127-20-popular-open-source-projects</guid>
<content:encoded><![CDATA[
<div> HTTP, UML, Tools, Status Codes, NoSQL
<br />
HTTP 1、HTTP 2和HTTP 3之间的区别，20个由大公司发起或支持的流行开源项目，UML类图表的基本要素，将代码转化为美丽图表的6个工具，以及一些奇怪的HTTP状态码。NoSQL的重要性和相关课程也被推荐。NVIDIA最新的H200 SXM提供了更好的性能，并邀请大家测试。总结: 文章介绍了HTTP和UML的基本概念、相关工具以及一些奇怪的HTTP状态码，同时推荐了NoSQL相关课程和新产品。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>HTTP 1 Vs HTTP 2 Vs HTTP 3! (Youtube video)</p></li><li><p>20 Popular Open Source Projects Started or Supported By Big Companies </p></li><li><p>A Cheatsheet for UML Class Diagrams </p></li><li><p>Top 6 Tools to Turn Code into Beautiful Diagrams</p></li><li><p>5 HTTP Status Codes That Should Never Have Been Created </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/ScyllaDB_083124Updated">Free NoSQL Training: Live and Instructor Led (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/ScyllaDB_083124Updated" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42d26a69-0e51-4464-9c1e-6c314bc098ee_1600x840.png" width="1456" /><div></div></div></a></figure></div><p>Whether you&#8217;re just curious about NoSQL or looking to optimize your NoSQL performance, this event is a fast way to learn more and get your questions answered by experts.&nbsp;</p><p>You can choose from 6 courses across two tracks:</p><ul><li><p><strong>Essentials:</strong> NoSQL vs SQL architectures, data modeling fundamentals, and building a sample high-performance application with ScyllaDB.</p></li><li><p><strong>Advanced: </strong>Deep dives into application development practices, advanced data modeling, optimizing your database topology, monitoring for performance, and more.</p></li></ul><p>As the name suggests, it&#8217;s truly live (with no on-demand equivalent!) Bring your toughest questions. You can interact with speakers and connect with fellow attendees throughout the event.&nbsp;</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/ScyllaDB_083124Updated"><span>Register for Free</span></a></p><div><hr /></div><h2><strong>HTTP 1 Vs HTTP 2 Vs HTTP 3!</strong></h2><div class="youtube-wrap" id="youtube2-UMwQjFzTQXw"><div class="youtube-inner"></div></div><div><hr /></div><h2>20 Popular Open Source Projects Started or Supported By Big Companies </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1622" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde7879c-18c0-4c7c-8f35-56f661859421_1280x1622.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><ol><li><p>Google <br />- Kubernetes <br />- TensorFlow <br />- Go <br />- Angular </p></li><li><p>Meta <br />- React <br />- PyTorch <br />- GraphQL <br />- Cassandra </p></li><li><p>Microsoft <br />- VSCode <br />- TypeScript <br />- Playwright </p></li><li><p>Netflix <br />- Chaos Monkey <br />- Hystrix <br />- Zuul </p></li><li><p>LinkedIn <br />- Kafka <br />- Samza <br />- Pinot </p></li><li><p>RedHat <br />- Ansible <br />- OpenShift <br />- Ceph Storage </p></li></ol><p>Over to you: Which other project would you add to the list?</p><div><hr /></div><h2><a href="https://bit.ly/Nebius_083024">Are you ready to train your AI model on NVIDIA&#174; H200 GPU cluster with InfiniBand? (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Nebius_083024" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="Image" class="sizing-normal" height="1066" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8a177836-5d21-4b16-947b-d5aa08d32778_1066x1066.jpeg" title="Image" width="1066" /><div></div></div></a></figure></div><p>NVIDIA claims that H200 SXM offer significant enhancements over the H100 SXM, delivering up to 45% better performance in generative AI and HPC tasks. Want to test it this autumn? Contact Nebius AI team. </p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Nebius_083024"><span>Learn more</span></a></p><div><hr /></div><h2>A Cheatsheet for UML Class Diagrams </h2><p>UML is a standard way to visualize the design of your system and class diagrams are used across the industry. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, diagram" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f236404-6ba9-4ba6-a25b-b3c76a7c073a_1281x1536.gif" title="graphical user interface, diagram" width="1281" /><div></div></div></a></figure></div><p>They consist of: </p><ol><li><p>Class <br />Acts as the blueprint that defines the properties and behavior of an object. <br /></p></li><li><p>Attributes <br />Attributes in a UML class diagram represent the data fields of the class. <br /></p></li><li><p>Methods <br />Methods in a UML class diagram represent the behavior that a class can perform. <br /></p></li><li><p>Interfaces <br />Defines a contract for classes that implement it. Includes a set of methods that the implementing classes must provide. <br /></p></li><li><p>Enumeration <br />A special data type that defines a set of named values such as product category or months in a year. <br /></p></li><li><p>Relationships <br />Determines how one class is related to another. Some common relationships are as follows: <br />- Association <br />- Aggregation <br />- Composition <br />- Inheritance <br />- Implementation <br /> </p></li></ol><p>Over to you: What other building blocks have you seen in UML class diagrams?</p><div><hr /></div><h2>Top 6 Tools to Turn Code into Beautiful Diagrams</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7011f6fb-599e-4dac-b783-55240a86f8e7_1280x1664.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ul><li><p>Diagrams</p></li><li><p>Go Diagrams</p></li><li><p>Mermaid</p></li><li><p>PlantUML</p></li><li><p>ASCII diagrams</p></li><li><p>Markmap</p></li></ul><p>Did we miss anything? What's your favorite?</p><div><hr /></div><h2>5 HTTP Status Codes That Should Never Have Been Created </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, text, application, email" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4462d605-d2ae-4643-add4-f8811cdd49ec_1289x1536.jpeg" title="graphical user interface, text, application, email" width="1289" /><div></div></div></a></figure></div><ul><li><p>451 Unavailable for Legal Reasons: Access denied due to legal issues. </p></li><li><p>218 This is Fine: Inspired by the meme, bypasses server error overrides. </p></li><li><p>420 Enhance Your Calm: Twitter&#8217;s old code for exceeding rate limits. Now changed to 429. </p></li><li><p>530 Site Frozen: Used by Pantheon for locked sites, often unpaid bills. </p></li><li><p>418 I'm a Teapot: A classic April Fool's joke indicating a server's limitations.</p></li></ul><p>Over to you: Have you come across any other weird HTTP Status Codes? </p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:sponsorship@bytebytego.com">sponsorship@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Sat, 31 Aug 2024 15:30:54 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Load Balancers for Scaling</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-load-balancers</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-load-balancers</guid>
<content:encoded><![CDATA[
<div> 关键词: load balancers, system architecture, network traffic, multiple servers, horizontal scalability

总结:<br /><br />
load balancers在系统架构中扮演关键角色，像酒店前台接待员一样，分配来自网络的流量到多台服务器上。通过有效地分担工作负荷，load balancers帮助系统在高峰期保持性能稳定。这样系统可以水平扩展，保证了系统的可靠性和性能。 <div>
<p>Over the years, load balancers have become a crucial component of system architecture, acting as the front-line gatekeepers that distribute incoming network traffic across multiple servers.&nbsp;</p><p>Much like a hotel receptionist who greets guests, checks their documents, and directs them to specific rooms, load balancers manage the data flow within a system to ensure that the system is horizontally scalable.</p><p>By effectively distributing the workload across multiple servers, load balancers help maintain system performance, even during peak usage.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53ec7e8b-12a1-403f-aecb-cc370ee7e837_2250x2840.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1838" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53ec7e8b-12a1-403f-aecb-cc370ee7e837_2250x2840.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-load-balancers">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 15:30:30 GMT</pubDate>
</item>
<item>
<title>EP126: The Ultimate Kafka 101 You Cannot Miss</title>
<link>https://blog.bytebytego.com/p/ep126-the-ultimate-kafka-101-you</link>
<guid>https://blog.bytebytego.com/p/ep126-the-ultimate-kafka-101-you</guid>
<content:encoded><![CDATA[
<div> AWS Services, Kafka, API Design, Internet Works, QA Wolf
<br />
AWS是云服务领域的领导者，不断提供新的服务以满足不断发展的需求。Kafka是分布式事件存储和流平台，被广泛应用于大数据流处理。API设计需要遵循领域模型，选择合适的HTTP方法和状态码，实现幂等性，版本控制，语义化路径，批量处理和查询语言设计等。而互联网工作原理简单易懂，QA Wolf提供快速测试服务，可以提高测试效率，减少错误。总结：AWS提供多样化服务，Kafka用于大数据处理，API设计需遵循一定规则，互联网工作原理简单，QA Wolf可提高测试效率。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>How the Internet Works in 9 Minutes (Youtube video)</p></li><li><p>AWS Services Cheat Sheet </p></li><li><p>The Ultimate Kafka 101 You Cannot Miss </p></li><li><p>8 Tips for Efficient API Design</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/QAWolf_082424">&#9986;&#65039;Cut your QA cycles down to minutes with automated testing (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_082424" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="736" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F321732b3-caf3-420e-9e7b-6a330fbf281d_1473x745.png" width="1456" /><div></div></div></a></figure></div><p>Are slow test cycles bottlenecking your dev teams&#8217; release velocity? With QA Wolf, your organization can run entire test suites in minutes for faster feedback and developer confidence to ship.</p><p><a href="https://bit.ly/QAWolf_082424">QA Wolf</a> takes testing off your plate. They can get you:</p><ul><li><p><a href="https://bit.ly/QAWolf_082424">80% automated test coverage in weeks</a>&#8212;not years</p></li><li><p><a href="https://bit.ly/QAWolf_082424">Unlimited parallel test runs</a></p></li><li><p>24-hour maintenance and on-demand test creation</p></li><li><p>Zero flakes, guaranteed</p></li></ul><p>The benefit? No more manual E2E testing. No more slow QA cycles. No more bugs reaching production.</p><p>With QA Wolf, <a href="QAWolf_082424CaseStudy">D</a><a href="https://bit.ly/QAWolf_072024CaseStudy">rata&#8217;s team of 80+ engineers</a> achieved 4x more test cases and 86% faster QA cycles.</p><p>&#127775;Rated 4.8/5 on G2.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_082424"><span>Schedule a demo to learn more</span></a></p><div><hr /></div><h2>How the Internet Works in 9 Minutes</h2><div class="youtube-wrap" id="youtube2-sMHzfigUxz4"><div class="youtube-inner"></div></div><div><hr /></div><h2>AWS Services Cheat Sheet </h2><p>AWS grew from an in-house project to the market leader in cloud services, offering so many different services that even experts can find it a lot to take in. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff416d0da-2f7a-46df-9709-f7859c5e5613_1415x1536.gif" title="No alternative text description for this image" width="1415" /><div></div></div></a></figure></div><p>The platform not only caters to foundational cloud needs but also stays at the forefront of emerging technologies such as machine learning and IoT, establishing itself as a bedrock for cutting-edge innovation. AWS continuously refines its array of services, ensuring advanced capabilities for security, scalability, and operational efficiency are available. <br /> <br />For those navigating the complex array of options, this AWS Services Guide is a helpful visual aid. <br /> <br />It simplifies the exploration of AWS's expansive landscape, making it accessible for users to identify and leverage the right tools for their cloud-based endeavors. <br /> <br />Over to you: What improvements would you like to see in AWS services based on your usage?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e469dc6-af33-408b-acc5-e11f57fd9aca_1437x1600.png" width="1437" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-scaling-the-api">A Crash Course on Scaling the API Layer</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-architectural-scalability">A Crash Course on Architectural Scalability</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservices-design">A Crash Course on Microservices Design Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design">A Crash Course on Domain-Driven Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/tidying-code">"Tidying" Code</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>The Ultimate Kafka 101 You Cannot Miss </h2><p>Kafka is super-popular but can be overwhelming in the beginning. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d00da63-c92c-46c4-8bb7-86f0adf769c6_1354x1536.gif" title="graphical user interface, application" width="1354" /><div></div></div></a></figure></div><p>Here are 8 simple steps that can help you understand the fundamentals of Kafka.</p><ol><li><p>What is Kafka? <br />Kafka is a distributed event store and a streaming platform. It began as an internal project at LinkedIn and now powers some of the largest data pipelines in the world in orgs like Netflix, Uber, etc. <br /></p></li><li><p>Kafka Messages <br />Message is the basic unit of data in Kafka. It&#8217;s like a record in a table consisting of headers, key, and value. <br /></p></li><li><p>Kafka Topics and Partitions <br />Every message goes to a particular Topic. Think of the topic as a folder on your computer. Topics also have multiple partitions. <br /></p></li><li><p>Advantages of Kafka <br />Kafka can handle multiple producers and consumers, while providing disk-based data retention and high scalability. <br /></p></li><li><p>Kafka Producer <br />Producers in Kafka create new messages, batch them, and send them to a Kafka topic. They also take care of balancing messages across different partitions. <br /></p></li><li><p>Kafka Consumer <br />Kafka consumers work together as a consumer group to read messages from the broker. <br /></p></li><li><p>Kafka Cluster <br />A Kafka cluster consists of several brokers where each partition is replicated across multiple brokers to ensure high availability and redundancy. <br /></p></li><li><p>Use Cases of Kafka <br />Kafka can be used for log analysis, data streaming, change data capture, and system monitoring. <br /></p></li></ol><p>Over to you: What else would you add to get a better understanding of Kafka?</p><div><hr /></div><h2>8 Tips for Efficient API Design</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F43fc8687-6891-4cbf-acf6-d5447cd1e592_1350x1536.gif" title="graphical user interface" width="1350" /><div></div></div></a></figure></div><ul><li><p>Domain Model Driven <br /> When designing the path structure of a RESTful API, we can refer to the domain model. <br /></p></li><li><p>Choose Proper HTTP Methods <br />Defining a few basic HTTP Methods can simplify the API design. For example, PATCH can often be a problem for teams. <br /></p></li><li><p>Implement Idempotence Properly <br />Designing for idempotence in advance can improve the robustness of an API. GET method is idempotent, but POST needs to be designed properly to be idempotent. <br /></p></li><li><p>Choose Proper HTTP Status Codes <br />Define a limited number of HTTP status codes to use to simplify application development. <br /></p></li><li><p>Versioning <br />Designing the version number for the API in advance can simplify upgrade work. <br /></p></li><li><p>Semantic Paths <br />Using semantic paths makes APIs easier to understand, so that users can find the correct APIs in the documentation. <br /></p></li><li><p>Batch Processing <br />Use batch/bulk as a keyword and place it at the end of the path. <br /></p></li><li><p>Query Language <br />Designing a set of query rules makes the API more flexible. For example, pagination, sorting, filtering etc.</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:sponsorship@bytebytego.com">sponsorship@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 24 Aug 2024 15:30:51 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Scaling the API Layer</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-scaling-the-api</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-scaling-the-api</guid>
<content:encoded><![CDATA[
<div> API、通信、后端服务、功能和数据、扩展性
<br />
API层是现代互联网应用程序中客户端和后端服务之间通信的基础。它作为客户端访问应用程序提供的功能和数据的主要接口。API层在应用程序架构中起着关键作用，对应用程序的扩展性至关重要。提升API层的扩展性对于处理负载和流量峰值、提供更好的用户体验以及优化成本和资源利用至关重要。需要理解关键概念，使用测试过的扩展策略和最佳实践来实现API层的扩展。<br /><br />总结:API层是应用程序的关键接口，扩展性对于处理负载和提供用户体验至关重要，需要理解关键概念，使用扩展策略和最佳实践来实现API层的扩展。 <div>
<p>The API (Application Programming Interface) layer serves as the backbone for communication between clients and the backend services in modern internet-based applications.</p><p>It acts as the primary interface through which clients, such as web or mobile applications, access the functionality and data provided by the application. The API Layer of any application has several key responsibilities such as:</p><ul><li><p>Process incoming requests from clients based on the defined API contract.</p></li><li><p>Enforce security mechanisms and protocols by authenticating and authorizing clients based on their credentials or access tokens.</p></li><li><p>Orchestrate interactions between various backend services and aggregate the responses received from them.</p></li><li><p>Handle responses by formatting and returning the result to the client.</p></li></ul><p>Due to the central role APIs play in the application architecture, they become critical for the application scalability.</p><p>The scalability of the API layer is crucial due to the following reasons:</p><ul><li><p><strong>Handling Load and Traffic Spikes: </strong>As applications become popular, they encounter increased traffic and sudden spikes in user demand. A scalable API can manage the increased load efficiently.</p></li><li><p><strong>Better User Experience:</strong> The bar for user expectation has gone up. Most users these days expect fast and responsive applications. A scalable API ensures that the application can support a high number of users without compromising performance.</p></li><li><p><strong>Cost and Resource Optimization: </strong>Scalable APIs unlock the path to better resource utilization. Rather than provisioning the infrastructure upfront for the highest demand level, instances are added and removed based on demand, resulting in reduced operational costs.</p></li></ul><p>In this article, we&#8217;ll learn the key concepts a developer must understand for API scalability. We will also look at some tried and tested strategies for scaling the API layer with basic code examples for clarity. Lastly, we will also look at some best practices that can help with scaling the API layer.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e469dc6-af33-408b-acc5-e11f57fd9aca_1437x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9e469dc6-af33-408b-acc5-e11f57fd9aca_1437x1600.png" width="1437" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-scaling-the-api">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 22 Aug 2024 15:30:14 GMT</pubDate>
</item>
<item>
<title>Trillions of Indexes: How Uber’s LedgerStore Supports Such Massive Scale</title>
<link>https://blog.bytebytego.com/p/trillions-of-indexes-how-ubers-ledgerstore</link>
<guid>https://blog.bytebytego.com/p/trillions-of-indexes-how-ubers-ledgerstore</guid>
<content:encoded><![CDATA[
<div> LedgerStore, Indexing Architecture, Trillion Entries Migration, Data Backfill, Validation <br />
LedgerStore是Uber的自定义存储解决方案，用于管理财务交易数据，支持三种主要的索引类型，包括强一致性索引、最终一致性索引和时间范围索引。Uber成功将1.2PB的压缩数据和超过1万亿条记录迁移至LedgerStore，通过进行阴影验证和离线验证，解决了数据回填过程中的挑战。迁移至LedgerStore带来了显著的成本节约和性能改进，是Uber处理大规模数据操作的成功案例。 <br /><br />总结: <br /> LedgerStore是Uber的关键存储解决方案，支持不同类型的索引，迁移1万亿条记录的成功案例展示了数据回填和验证过程中的挑战和解决方案。包括成本节约和性能改进在内，这个迁移案例展示了Uber处理大规模数据操作的能力。 <div>
<h2><a href="https://bit.ly/Astronomer_082024">Try Fully Managed Apache Airflow and get certified for FREE (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://www.astronomer.io/try-astro/?utm_source=bytebytego-newsletter&amp;utm_medium=newsletter&amp;utm_campaign=bytebytego-newsletter-free-cert-rialhttps://bit.ly/Astronomer_082024" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29240e69-a578-49dc-aa08-187f03c43096_1600x840.png" title="" width="1456" /><div></div></div></a></figure></div><p>Run Airflow without the hassle and management complexity. Take Astro (the fully managed Airflow solution) for a test drive today and unlock a suite of features designed to simplify, optimize, and scale your data pipelines. For a limited time, new sign ups will receive a complimentary Airflow Fundamentals Certification exam (normally $150).</p><p class="button-wrapper"><a class="button primary button-wrapper" href="https://bit.ly/Astronomer_082024"><span>Get Started &#8212;&gt;</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the Uber Engineering Blog. All credit for the technical details goes to the Uber engineering team. The links to the original articles are present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>Ledgers are the source of truth of any financial event. By their very nature, ledgers are immutable. Also, we usually want to access data stored in these ledgers in various combinations.</p><p>With billions of trips and deliveries, Uber performs tens of billions of financial transactions. Merchants, riders, and customers are involved in these financial transactions. Money flows from the ones spending to the ones earning.&nbsp;</p><p>To manage this mountain of financial transaction data, the LedgerStore is an extremely critical storage solution for Uber. The myriad access patterns for the data stored in LedgerStore also create the need for a huge number of indexes.</p><p></p><p>In this post, we&#8217;ll look at how Uber implemented the indexing architecture for LedgerStore to handle trillions of indexes and how they migrated a trillion entries of Uber&#8217;s Ledger Data from DynamoDB to LedgerStore.</p><h2>What is LedgerStore?</h2><p>LedgerStore is Uber&#8217;s custom-built storage solution for managing financial transactions. Think of it as a giant, super-secure digital ledger book that keeps track of every financial event at Uber, from ride payments to food delivery charges.</p><p>What makes LedgerStore special is its ability to handle an enormous amount of data. We&#8217;re talking about trillions of entries.</p><p>Two main features supported by LedgerStore are:</p><ul><li><p><strong>Immutability: </strong>LedgerStore is designed to be immutable, which means once a record is written, it cannot be changed. This ensures the integrity of financial data.</p></li><li><p><strong>Indexes: </strong>LedgerStore allows quick look-up of information using various types of indexes. For example, if someone needs to check all transactions for a particular user or all payments made on a specific date, LedgerStore can retrieve this information efficiently.</p></li></ul><p>Ultimately, LedgerStore helps Uber manage its financial data more effectively, reducing costs compared to previous solutions.</p><h2>Types of Indexes</h2><p>LedgerStore supports three main types of indexes:</p><ul><li><p>Strongly consistent indexes</p></li><li><p>Eventually consistent indexes</p></li><li><p>Time-range indexes</p></li></ul><p>Let&#8217;s look at each of them in more detail.</p><h3>Strongly Consistent Indexes</h3><p>These indexes provide immediate read-your-write guarantees, crucial for scenarios like credit card authorization flows. For example, when a rider starts an Uber trip, a credit card hold is placed, which must be immediately visible to prevent duplicate charges.</p><p>See the diagram below that shows the credit-card payment flow for an Uber trip supported by strongly consistent indexes.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f08af7a-0a4d-4690-bd83-fbb99992f861_1600x983.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="895" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f08af7a-0a4d-4690-bd83-fbb99992f861_1600x983.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>If the index is not strongly consistent, the hold may take a while to be visible upon reading. This can result in duplicate charges on the user&#8217;s credit card.</p><p>Strongly consistent indexes at Uber are built using the two-phase commit approach. Here&#8217;s how this approach works in the write path and read path.</p><h4>1 - The Write Path</h4><p>The write path consists of the following steps:</p><ul><li><p>When a new record needs to be inserted, the system first writes an &#8220;index intent&#8221; to the index table. It could even be multiple indexes.</p></li><li><p>This intent signifies that a new record is about to be written. If the index intent write fails, the whole insert operation fails.</p></li><li><p>After the index intent is successfully written, the actual record is written to the main data store.</p></li><li><p>If the record write is also successful, the system commits the index. This is done asynchronously to avoid affecting the end-user insert latency.</p></li></ul><p>The diagram below shows this entire process.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57aa8987-01ef-489b-8fff-59074076d1b8_1600x983.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="895" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57aa8987-01ef-489b-8fff-59074076d1b8_1600x983.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>There is one special case to consider here: if the index intent write succeeds, but the record write fails, the index intent has to be rolled back to prevent the accumulation of unused intents. This part is handled during the read path.</p><h4>2 - The Read Path</h4><p>The below steps happen during the read path:</p><ul><li><p>If a committed index entry is found, the response data is returned to the client.</p></li><li><p>If an index entry is found but with a &#8220;pending&#8221; status, the system must resolve its state. This is done by checking the main data store for the corresponding record.</p></li><li><p>If the record exists, the index is asynchronously committed and the record is returned to the user.</p></li><li><p>If the record doesn&#8217;t exist, the index intent is deleted or rolled back and the read operation does not return a result for the query.</p></li></ul><p>The diagram below shows the process steps in more detail.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2403ad00-8922-4ef7-b953-37f1a582f496_1600x1540.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1401" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2403ad00-8922-4ef7-b953-37f1a582f496_1600x1540.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2><a href="https://bit.ly/TechForProduct_082024">Reserve Your Seat Now! | Upcoming Cohort on Aug 26th, 2024 (Sponsored)&nbsp;</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://maven.com/tech-for-product/tech-fundamentals?utm_campaign=MTM3MTk5&amp;utm_medium=clp_share_link&amp;utm_source=instructorhttps://bit.ly/TechForProduct_082024" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb960f66c-6691-44ce-b3ae-17b44e6fe1b8_1600x840.png" title="" width="1456" /><div></div></div></a></figure></div><p><strong>Build confidence without getting lost in technical jargon.</strong></p><p>This cohort is designed to help you build a foundational understanding of software applications. You won&#8217;t just memorize a bunch of terms - you&#8217;ll actually understand how software products are designed and deployed to handle millions of users.</p><p>And our community will be here to give you the support, guidance, and accountability you&#8217;ll need to finally stick with it.</p><p>After only 4 weeks, you&#8217;ll look back and think.. &#8220;WOW! I can&#8217;t believe I did that.&#8221;</p><p><strong>Now imagine if you could:</strong></p><p>&#9989; Master technical concepts without getting lost in an internet maze.</p><p>&#9989; Stop asking engineers to dumb down concepts when talking to you.</p><p>&#9989; Predict risks, anticipate issues, and avoid endless back-and-forth.</p><p>&#9989; Improve your communication with engineers, users, and technical stakeholders.</p><p>Grab your spot now with an exclusive 25% off discount for ByteByteGo Readers. See you there!</p><p class="button-wrapper"><a class="button primary button-wrapper" href="https://bit.ly/TechForProduct_082024"><span>Register Now!</span></a></p><div><hr /></div><h3>Eventually Consistent Indexes</h3><p>These indexes are designed for scenarios where real-time consistency is not critical, and a slight delay in index updates is acceptable. They offer better performance and availability at the cost of immediate consistency.</p><p>From a technical implementation point of view, the eventually consistent indexes are generated using the Materialized Views feature of Uber&#8217;s Docstore.&nbsp;</p><p>Materialized views are pre-computed result sets stored as a table, based on a query against the base table(s). The materialized view is updated asynchronously when the base table changes.</p><p>When a write occurs to the main data store, it doesn&#8217;t immediately update the index. Instead, a separate process periodically scans for changes and updates the materialized view. The consistency window is configurable and determines how frequently the background process runs to update the indexes.</p><p>In Uber&#8217;s case, the Payment History Display screen uses the eventually consistent indexes.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007126e2-dc2a-4b12-a60c-0c1e28934d56_1600x1547.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1408" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007126e2-dc2a-4b12-a60c-0c1e28934d56_1600x1547.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://www.uber.com/en-IN/blog/how-ledgerstore-supports-trillions-of-indexes/">Uber Engineering Blog</a></figcaption></figure></div><h3>Time-range Indexes</h3><p>Time-range indexes are a crucial component of LedgerStore, designed to query data within specific time ranges efficiently.</p><p>These indexes are important for operations like offloading older ledger data to cold storage or sealing data for compliance purposes. The main characteristic of these indexes is their ability to handle deterministic time-range batch queries that are significantly larger in scope compared to other index types.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2af67e1-9a70-4855-bca6-fa3c76b016f1_1600x1078.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="981" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2af67e1-9a70-4855-bca6-fa3c76b016f1_1600x1078.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Earlier, the time-range indexes were implemented using a dual-table design approach in DynamoDB. However, it was operationally complex.</p><p>The migration of LedgerStore to Uber&#8217;s Docstore paved the path for a simpler implementation of the time-range index. Here&#8217;s a detailed look at the Docstore implementation for the time-range indexes:</p><ul><li><p><strong>Single Table Design: </strong>Only one table is used for time-range indexes in Docstore.</p></li><li><p><strong>Partitioning Strategy: </strong>Index entries are partitioned based on full timestamp value. This ensures a uniform distribution of writes across partitions, eliminating the chances of hot partitions and write throttling.</p></li><li><p><strong>Sorted Data Storage: </strong>Data is stored in a sorted manner based on the primary key (partition + sort keys).&nbsp;</p></li><li><p><strong>Read Operation: </strong>Reads involve a prefix scanning of each shard of the table up to a certain time granularity. For example, to read 30 minutes of data, the operation might be broken down into three 10-minute interval scans. Each scan is bounded by start and end timestamps. After scanning, a scatter-gather operation is performed, followed by sort merging across shards to obtain all time-range index entries in the given window, in a sorted fashion.</p></li></ul><p>For clarity, consider a query to fetch all ledger entries between &#8220;2024-08-09 10:00:00&#8221; and &#8220;2024-08-09 10:30:00&#8221;. The query would be broken down into three 10-minute scans:</p><ul><li><p>2024-08-09 10:00:00 to 2024-08-09 10:10:00</p></li><li><p>2024-08-09 10:10:00 to 2024-08-09 10:20:00</p></li><li><p>2024-08-09 10:20:00 to 2024-08-09 10:30:00</p></li></ul><p>Each of these scans would be executed across all shards in parallel. The results would then be merged and sorted to provide the final result set.</p><p>The diagram below shows the overall process:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916dc967-4d72-4c7f-9df1-18b3a7e225df_1600x1045.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="951" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916dc967-4d72-4c7f-9df1-18b3a7e225df_1600x1045.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Index Lifecycle Management</h2><p>Index lifecycle management is another component of LedgerStore&#8217;s architecture that handles the design, modification, and decommissioning of indexes.</p><p>Let&#8217;s look at the main parts of the index lifecycle management system.</p><h2>Index Lifecycle State Machine</h2><p>This component orchestrates the entire lifecycle of an index:</p><ul><li><p>Creating the index table</p></li><li><p>Backfilling it with historical index entries</p></li><li><p>Validating the entries for completeness</p></li><li><p>Swapping the old index with the new one for read/write operations</p></li><li><p>Decommissioning the old index</p></li></ul><p>The state machine ensures that each step is completed correctly before moving to the next, maintaining data integrity throughout the process.</p><p>The diagram below shows all the steps:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9e87701-86c6-4ab9-9174-fdbf0cf3558c_1600x914.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="832" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9e87701-86c6-4ab9-9174-fdbf0cf3558c_1600x914.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Historical Index Data Backfill</h3><p>When new indexes are defined or existing ones are modified, it&#8217;s essential to backfill historical data to ensure completeness.</p><p>The historical index data backfill component performs the following tasks:</p><ul><li><p>Builds indexes from historical data stored in cold storage.</p></li><li><p>Backfills the data to the storage layer in a scalable manner.</p></li><li><p>Uses configurable rate-limiting and batching to manage the process efficiently.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bdd9cd9-5ac9-4a1b-a519-da6b28f57e8f_1600x942.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="857" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bdd9cd9-5ac9-4a1b-a519-da6b28f57e8f_1600x942.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Index Validation</h3><p>After indexes are backfilled, they need to be verified for completeness. This is done through an offline job that:</p><ul><li><p>Computes order-independent checksums at a certain time-window granularity.</p></li><li><p>Compares these checksums across the source of truth data and the index table.</p></li></ul><p>From a technical point of view, the component uses a time-window approach i.e. computing checksums for every 1-hour block of data. Even if a single entry is missed, the aggregate checksum for that time window will lead to a mismatch.&nbsp;</p><p>For example, If checksums are computed for 1-hour blocks, and an entry from 2:30 PM is missing, the checksum for the 2:00 PM - 3:00 PM block will not match.</p><h2>Migration of Uber&#8217;s Payment Data to LedgerStore</h2><p>Now that we have understood about LedgerStore&#8217;s indexing architecture and capabilities, let&#8217;s look at the massive migration of Uber&#8217;s payment data to LedgerStore.</p><p>Uber&#8217;s payment platform, Gulfstream, was initially launched in 2017 using Amazon DynamoDB for storage. However, as Uber&#8217;s operations grew, this setup became increasingly expensive and complex.&nbsp;</p><p>By 2021, Gulfstream was using a combination of three storage systems:</p><ul><li><p>DynamoDB for the most recent 12 weeks of data. This was the hot data.</p></li><li><p>TerraBlob (Uber&#8217;s internal blob store like AWS S3) for older or cold data.</p></li><li><p>LedgerStore (LSG) where new data was being written and where they wanted to migrate all data.</p></li></ul><p>The primary reasons for migrating to LedgerStore were as follows:</p><ul><li><p><strong>Cost savings: </strong>Moving to LedgerStore promised significant recurring cost savings compared to DynamoDB.</p></li><li><p><strong>Simplification: </strong>Consolidating from three storage systems to one would simplify the code and design of the Gulfstream services.</p></li><li><p><strong>Improved Performance: </strong>LedgerStore offered shorter indexing lag and reduced latency due to being on-premise.</p></li><li><p><strong>Purpose-Built Design: </strong>LedgerStore was specifically designed for storing payment-style data, offering features like verifiable immutability and tiered storage for cost management.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f7e5a5e-1849-4d6f-9fb1-f1d719d029a9_1600x895.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="814" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f7e5a5e-1849-4d6f-9fb1-f1d719d029a9_1600x895.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The migration was a massive undertaking. Some statistics are as follows:</p><ul><li><p>1.2 Petabytes of compressed data</p></li><li><p>Over 1 trillion entries</p></li><li><p>0.5 PB of uncompressed data for secondary indexes.</p></li></ul><p>For reference, storing this data on typical 1 TB hard drives requires a total of 1200 hard drives just for the compressed data.</p><h3>Checks</h3><p>One of the key goals of the migration was to ensure that the backfill was correct and acceptable. Also, the current traffic requirements needed to be fulfilled.</p><p>Key validation methods adopted were as follows:</p><h4>1 - Shadow Validation</h4><p>This ensured that the new LedgerStore system could handle current traffic patterns without disruption.</p><p>Here&#8217;s how it worked:</p><ul><li><p>The system would compare responses from the existing DynamoDB-based system with what the LedgerStore would return for the same queries. This allowed the team to catch any discrepancies in real time.&nbsp;</p></li><li><p>An ambitious goal was to ensure 99.99% completeness and correctness with an upper bound of 99.9999%.</p></li><li><p>To achieve six nines of confidence, the team needed to compare at least 100 million records. At a rate of 1000 comparisons per second, this would take more than a day to collect sufficient data.</p></li><li><p>During shadow validation, production traffic was duplicated on LedgerStore. This helped the team verify the LedgerStore&#8217;s ability to handle the production load.</p></li></ul><h4>2 - Offline Validation</h4><p>While shadow validation was effective for current traffic patterns, it couldn&#8217;t provide strong guarantees about rarely-accessed historical data. This is where offline validation came into play.&nbsp;</p><p>Here&#8217;s how it worked:</p><ul><li><p>Offline validation involved comparing complete data dumps from DynamoDB with the data in LedgerStore. The largest offline validation job compared 760 billion records, involving 70 TB of compressed data.</p></li><li><p>The team used Apache Spark for these massive comparison jobs, leveraging distributed shuffle-as-a-service for Spark.</p></li></ul><h3>Backfill Issues</h3><p>The process of migrating Uber&#8217;s massive ledger data from DynamoDB to LedgerStore involved several backfill challenges that had to be solved:</p><ul><li><p><strong>Scalability: </strong>The engineering team learned that starting small and gradually increasing the scale was crucial. Blindly pushing beyond the system&#8217;s limit could create a DDoS attack on their systems.</p></li><li><p><strong>Incremental Backfills: </strong>Given the enormous volume of data, attempting to backfill all at once would generate 10 times the normal traffic load. The solution was to break the backfill into smaller, manageable batches that could be completed within minutes.</p></li><li><p><strong>Rate Control: </strong>To ensure consistent behavior during backfill, the team implemented rate control using Guava&#8217;s RateLimiter in Java/Scala.&nbsp; The team also developed a system to dynamically adjust the backfill rate based on the current system load. For this, they used an additive increase/multiplicative decrease approach similar to TCP congestion control.</p></li><li><p><strong>Data File Size Management: </strong>The team found that managing the size of data files was important. They aimed to keep the file sizes around 1 GB, with flexibility between 100 MB and 10 GB. This approach helped avoid issues like MultiPart limitations in various tools and prevented problems associated with having too many small files.</p></li><li><p><strong>Fault Tolerance: </strong>Data quality issues and data corruption were inevitable. The team&#8217;s solution was to monitor statistics. If the failure rate was high, they would manually stop the backfill, fix the issue, and continue. For less frequent issues, they let the backfill continue while addressing problems in parallel.</p></li><li><p><strong>Logging Challenges: </strong>Excessive logging during backfill could overload the logging infrastructure. The solution was to use a rate limiter for logging. For example, they might log only once every 30 seconds for routine operations while logging all errors if they occurred infrequently.</p></li></ul><h2>Conclusion</h2><p>The impact of Uber&#8217;s ledger data migration to LedgerStore has been amazing, with over 2 trillion unique indexes successfully transferred without a single data inconsistency detected in over six months of production use.&nbsp;</p><p>This migration, involving 1.2 PB of compressed data and over 1 trillion entries, showcases Uber&#8217;s ability to handle massive-scale data operations without disrupting critical financial processes. It also provides great learning points for the readers.</p><p>The cost savings from this migration have been substantial, with estimated yearly savings exceeding $6 million due to reduced spend on DynamoDB. Performance improvements have been notable, with LedgerStore offering shorter indexing lag and better network latency due to its on-premise deployment within Uber&#8217;s data centers.</p><p><strong>References:</strong></p><ul><li><p><a href="https://www.uber.com/en-IN/blog/how-ledgerstore-supports-trillions-of-indexes/">How LedgerStore Supports Trillions of Indexes at Uber</a></p></li><li><p><a href="https://www.uber.com/en-IN/blog/migrating-from-dynamodb-to-ledgerstore/">Migrating a Trillion Entries of Uber&#8217;s Ledger Data from DynamoDB to LedgerStore</a></p></li><li><p><a href="https://www.uber.com/en-IN/blog/dynamodb-to-docstore-migration">How Uber Migrated Financial Data from DynamoDB to Docstore</a></p></li></ul>
]]></content:encoded>
<pubDate>Tue, 20 Aug 2024 15:31:12 GMT</pubDate>
</item>
<item>
<title>EP125: How does Garbage Collection work?</title>
<link>https://blog.bytebytego.com/p/ep125-how-does-garbage-collection</link>
<guid>https://blog.bytebytego.com/p/ep125-how-does-garbage-collection</guid>
<content:encoded><![CDATA[
<div> Linux Performance Tools, Garbage Collection, Fault-Tolerant Systems, System Design Tradeoffs, WorkOS
<br />
<br />
总结:本文介绍了Linux性能工具、垃圾回收、设计容错系统的重要性和原则、系统设计中不可忽视的权衡，以及WorkOS的用户管理解决方案。Garbage Collection是一种自动内存管理特性，Java、Python和Go等编程语言都有不同的垃圾收集器。设计容错系统的六个原则包括复制、冗余、负载均衡、故障转移机制、优雅降级以及监控和警报。系统设计中必须考虑的权衡包括垂直vs水平扩展、SQLvsNoSQL、批处理vs流处理等。WorkOS提供的用户管理解决方案适用于企业级应用。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Linux Performance Tools! (Youtube video)</p></li><li><p>How does Garbage Collection work? </p></li><li><p>A Cheat Sheet for Designing Fault-Tolerant Systems</p></li><li><p>10 System Design Tradeoffs You Cannot Ignore </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/WorkOS_081724">WorkOS: Modern Identity Platform for B2B SaaS (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/WorkOS_081724" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="837" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2caec8f-a0c8-45ac-8339-477ffb093e8b_2560x1472.png" width="1456" /><div></div></div></a></figure></div><p>Start selling to enterprises with just a few lines of code.</p><p>&#8594; WorkOS provides a complete user management solution along with SSO, SCIM,&nbsp;Audit Logs, &amp; Fine-Grained Authorization.</p><p>&#8594; Unlike other auth providers that rely on user-centric models, WorkOS is designed for B2B SaaS with an org modeling approach.</p><p>&#8594; The APIs are flexible, easy-to-use, and modular. Pick and choose what you need and integrate in minutes.</p><p>&#8594; User management is free up to 1 million MAUs&nbsp;and comes standard with RBAC, bot protection, MFA, &amp; more.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/WorkOS_081724"><span>Get Started Today</span></a></p><div><hr /></div><h2>Linux Performance Tools!</h2><div class="youtube-wrap" id="youtube2-iJ_eIsA5E1U"><div class="youtube-inner"></div></div><div><hr /></div><h2>How does Garbage Collection work? </h2><p>Garbage collection is an automatic memory management feature used in programming languages to reclaim memory no longer used by the program. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F303b80e4-5cd9-41e6-87e3-d76510cd60bd_1536x1536.gif" title="No alternative text description for this image" /><div></div></div></a></figure></div><ul><li><p>Java <br />Java provides several garbage collectors, each suited for different use cases: <br /> <br />1. Serial Garbage Collector: Best for single-threaded environments or small applications. <br /> <br />2. Parallel Garbage Collector: Also known as the "Throughput Collector." <br /> <br />3. CMS (Concurrent Mark-Sweep) Garbage Collector: Low-latency collector aiming to minimize pause times. <br /> <br />4. G1 (Garbage-First) Garbage Collector: Aims to balance throughput and latency. <br /> <br />5. Z Garbage Collector (ZGC): A low-latency garbage collector designed for applications that require large heap sizes and minimal pause times. <br /></p></li><li><p>Python <br />Python's garbage collection is based on reference counting and a cyclic garbage collector: <br /> <br />1. Reference Counting: Each object has a reference count; when it reaches zero, the memory is freed. <br /> <br />2. Cyclic Garbage Collector: Handles circular references that can't be resolved by reference counting. <br /></p></li><li><p>GoLang <br />Concurrent Mark-and-Sweep Garbage Collector: Go's garbage collector operates concurrently with the application, minimizing stop-the-world pauses.</p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1760" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b1af0d4-fcea-4dc4-9296-dbd752b536b3_2250x2720.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-architectural-scalability">A Crash Course on Architectural Scalability</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservices-design">A Crash Course on Microservices Design Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design">A Crash Course on Domain-Driven Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/tidying-code">"Tidying" Code</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">A Crash Course on Relational Database Design</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>A Cheat Sheet for Designing Fault-Tolerant Systems</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1657" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1568f10-1350-4435-a06f-60d31d4ccbbf_1280x1657.gif" title="diagram" width="1280" /><div></div></div></a></figure></div><p>Designing fault-tolerant systems is crucial for ensuring high availability and reliability in various applications. Here are six top principles of designing fault-tolerant systems: </p><ol><li><p>Replication <br />Replication involves creating multiple copies of data or services across different nodes or locations. </p></li><li><p>Redundancy <br />Redundancy refers to having additional components or systems that can take over in case of a failure. </p></li><li><p>Load Balancing <br />Load balancing distributes incoming network traffic across multiple servers to ensure no single server becomes a point of failure. </p></li><li><p>Failover Mechanisms <br />Failover mechanisms automatically switch to a standby system or component when the primary one fails. </p></li><li><p>Graceful Degradation <br />Graceful degradation ensures that a system continues to operate at reduced functionality rather than completely failing when some components fail.</p></li><li><p>Monitoring and Alerting <br />Continuously monitor the system's health and performance, and set up alerts for any anomalies or failures.</p></li></ol><div><hr /></div><h2>10 System Design Tradeoffs You Cannot Ignore </h2><p>If you don&#8217;t know trade-offs, you DON'T KNOW system design. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="998" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c3e3af8-5a12-4036-8a93-ef17c5461d8b_800x998.gif" title="graphical user interface" width="800" /><div></div></div></a></figure></div><ol><li><p>Vertical vs Horizontal Scaling <br />Vertical scaling is adding more resources (CPU, RAM) to an existing server.</p><p>Horizontal scaling means adding more servers to the pool. <br /></p></li><li><p>SQL vs NoSQL <br />SQL databases organize data into tables of rows and columns. </p><p>NoSQL is ideal for applications that need a flexible schema. <br /></p></li><li><p>Batch vs Stream Processing <br />Batch processing involves collecting data and processing it all at once. For example, daily billing processes. </p><p>Stream processing processes data in real time. For example, fraud detection processes. <br /></p></li><li><p>Normalization vs Denormalization <br />Normalization splits data into related tables to ensure that each piece of information is stored only once. </p><p>Denormalization combines data into fewer tables for better query performance. <br /></p></li><li><p>Consistency vs Availability <br />Consistency is the assurance of getting the most recent data every single time. </p><p>Availability is about ensuring that the system is always up and running, even if some parts are having problems. <br /></p></li><li><p>Strong vs Eventual Consistency <br />Strong consistency is when data updates are immediately reflected. </p><p>Eventual consistency is when data updates are delayed before being available across nodes. <br /></p></li><li><p>REST vs GraphQL <br />With REST endpoints, you gather data by accessing multiple endpoints. </p><p>With GraphQL, you get more efficient data fetching with specific queries but the design cost is higher. <br /></p></li><li><p>Stateful vs Stateless <br />A stateful system remembers past interactions. </p><p>A stateless system does not keep track of past interactions. <br /></p></li><li><p>Read-Through vs Write-Through Cache <br />A read-through cache loads data from the database in case of a cache miss. </p><p>A write-through cache simultaneously writes data updates to the cache and storage. <br /></p></li><li><p>Sync vs Async Processing <br />In synchronous processing, tasks are performed one after another. </p><p>In asynchronous processing, tasks can run in the background. New tasks can be started without waiting for a new task. <br /></p></li></ol><p>Over to you: Which other tradeoffs have you encountered?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:sponsorship@bytebytego.com">sponsorship@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 17 Aug 2024 15:30:37 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Architectural Scalability</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-architectural-scalability</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-architectural-scalability</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件应用，全球范围，可伸缩性，应对突发流量，建设架构
总结:<br /><br />
软件应用在今天的互连世界中拥有全球用户，需要具备可伸缩的架构以适应突发流量的挑战。可伸缩性能够动态调整应用程序以适应不断变化的工作负载需求，确保性能和可用性不受影响。设计和建设具有可伸缩性的架构是开发团队的重要任务，以应对突发用户需求带来的压力，同时确保良好的用户体验。这篇文章深入探讨了可伸缩性的真正含义和各种技术原则，为后续深入研究应用架构各层和组件的可伸缩性做好准备。 <div>
<p>In today's interconnected world, software applications have a global reach, serving users from diverse geographical locations.&nbsp;</p><p>With the rapid growth of social media and viral content, a single tweet or post can lead to a sudden and massive surge in traffic to an application. The importance of building applications with scalable architecture from the ground up has never been higher.&nbsp;</p><p>Being prepared for unexpected traffic spikes is indispensable for development teams building applications. A sudden increase in user demand may be just around the corner. Not being prepared for it can put immense pressure on the application's infrastructure. It not only causes performance degradation but can also, in some cases, result in a complete system failure.&nbsp;</p><p>To mitigate these risks and ensure a good user experience, teams must proactively design and build scalable architectures.</p><p>But what makes scalability such a desirable characteristic?</p><p>Scalability allows the application to dynamically adapt to changing workload requirements without compromising performance or availability.</p><p>In this post, we&#8217;ll understand the true meaning of scalability from different perspectives followed by the various techniques and principles that can help you scale the application&#8217;s architecture. Also, in subsequent posts in the coming weeks, we&#8217;ll take deeper dives into the scalability of each layer and component of a typical architecture.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b1af0d4-fcea-4dc4-9296-dbd752b536b3_2250x2720.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1760" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4b1af0d4-fcea-4dc4-9296-dbd752b536b3_2250x2720.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>What is Scalability?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-architectural-scalability">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 15 Aug 2024 15:30:52 GMT</pubDate>
</item>
<item>
<title>Counting Billions of Content Usage at Canva</title>
<link>https://blog.bytebytego.com/p/counting-billions-of-content-usage</link>
<guid>https://blog.bytebytego.com/p/counting-billions-of-content-usage</guid>
<content:encoded><![CDATA[
<div> MySQL, DynamoDB, Snowflake, OLAP, ELT
总结:<br /><br />本文介绍了Canva工程团队在实现计数服务的过程中的各种架构设计和经验教训。最初他们使用MySQL数据库设计计数服务，但由于数据量增长和性能限制，转向DynamoDB并最终使用Snowflake的OLAP解决方案。新架构消除了以往的技术瓶颈，提高了数据处理的速度和精度。尽管面临一些挑战，如数据处理复杂性、数据卸载和基础架构复杂性，但Canva成功地实现了计数服务的高效和可靠运行。整个过程体现出简单性、迭代改进、综合可观察性、鲁棒的基础架构等重要设计原则和关键点。 <div>
<h2><a href="https://bit.ly/ScyllaDB_081324">Hands-on Rust Developer Workshop: Build a Low-Latency Social Media App (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/ScyllaDB_081324" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b3316b7-c138-42fd-9e2b-59ea511f109d_1600x840.png" width="1456" /><div></div></div></a></figure></div><p>During this free interactive workshop oriented for developers, engineers, and architects, you will learn how to:&nbsp;</p><ul><li><p>Create and compile a sample social media app with Rust</p></li><li><p>Connect the application to ScyllaDB (NoSQL data store) and Redpanda (streaming data)</p></li><li><p>Negotiate tradeoffs related to data modeling and querying</p></li><li><p>Manage and monitor the database for consistently low latencies</p></li></ul><p>If you&#8217;re an application developer with an interest in Rust, Tokio, and event-driven architectures this workshop is for you! This is a great way to discover the NoSQL strategies used by top teams and apply them in a guided, supportive environment.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/ScyllaDB_081324"><span>Register for Free</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the Canva Engineering Blog. All credit for the technical details goes to the Canva engineering team. The links to the original articles are present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>What if incorrect counting results in incorrect payments?&nbsp;</p><p>Either the company making the payment or the users receiving that payment based on the incorrect count lose money. Both scenarios are problematic from the business perspective.</p><p>This is exactly the situation that Canva faced when they launched the Creators Program.</p><p>As you might already know, Canva is a tool that makes design accessible to everyone worldwide. One of the main ways they make this possible is through the Canva Creators Program.</p><p>In the three years since its launch, the use of content from this program has doubled every 18 months. They process billions of content uses monthly based on which the creators are paid. This includes the use of templates, images, videos, and more.</p><p>It is a critical requirement for Canva to count the usage data of this content accurately since the payments made to the creators depend on this data. However, it also presents some big challenges:</p><ul><li><p><strong>Accuracy:</strong> The count has to be correct to maintain creator trust and ensure fair pay.</p></li><li><p><strong>Scalability:</strong> The system needs to handle rapidly growing amounts of data</p></li><li><p><strong>Operability:</strong> As data increases, so does the complexity of maintenance and problem-solving.</p></li></ul><p>In this post, we will look at the various architectures Canva&#8217;s engineering team experimented with to implement a robust counting service and the lessons they learned in the process.</p><div><hr /></div><h2>The Initial Counting Service Design</h2><p>Canva's original design for the content usage counting service was built on a MySQL database, a familiar and widely-used technology stack.</p><p>This initial design comprised several key components:&nbsp;</p><ul><li><p>A MySQL database for storing all usage data (including raw events, deduplicated usage, and aggregated counts).</p></li><li><p>Separate worker services handling different pipeline stages (data collection, deduplication, and aggregation).</p></li><li><p>The persistence of multiple layers of reusable intermediary output at various stages.&nbsp;</p></li></ul><p>The process flow for the solution could be broken down into three main steps:</p><ul><li><p><strong>Data Collection: </strong>Usage events from various sources (web, and mobile apps) were collected and stored in MySQL.</p></li><li><p><strong>Deduplication: </strong>A worker service identifies duplicated usage events and matches them with a specific set of rules.&nbsp;</p></li><li><p><strong>Aggregation: </strong>Another worker scanned the updated deduplication table, incrementing counters in a separate table.</p></li></ul><p>The diagram below shows the architecture on a high level.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F506f7f4d-63de-40ee-9e46-b72fe51b001f_1474x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1580" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F506f7f4d-63de-40ee-9e46-b72fe51b001f_1474x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>This architecture employed a single-threaded sequential process for deduplication, using a pointer to track the latest scanned record. While this approach made it easier to reason about and verify data processing, especially during troubleshooting or incident recovery, it faced significant scalability challenges.&nbsp;</p><p>The system required at least one database round trip per usage record, resulting in O(N) database queries for N records, which became increasingly problematic as data volume grew.&nbsp;</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe308b14f-4b1f-4d97-ba32-ea57116388ab_1600x973.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="885" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe308b14f-4b1f-4d97-ba32-ea57116388ab_1600x973.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The initial MySQL-based architecture prioritized simplicity and familiarity over scalability. It allowed for quick implementation but created substantial challenges as the system expanded.&nbsp;</p><ul><li><p>The heavy reliance on MySQL for both storage and processing created a bottleneck, failing to leverage the strengths of distributed systems or parallel processing.&nbsp;</p></li><li><p>MySQL RDS does not horizontally scale through partitioning by itself. Every time they needed more storage, they doubled the RDS instance size. This happened every 8-10 months, resulting in significant operational overhead.&nbsp;</p></li><li><p>Once the MySQL RDS instance reached several TBs, maintaining it became costly.</p></li><li><p>Lastly, finding and fixing issues in case of incidents was difficult because engineers had to look into databases and manually fix the incorrect data.</p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1820" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee02bbe9-ee3c-4028-a05e-36e5274202a3_2250x2812.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservices-design">A Crash Course on Microservices Design Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design">A Crash Course on Domain-Driven Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/tidying-code">"Tidying" Code</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">A Crash Course on Relational Database Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">A Crash Course on Distributed Systems</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>Migration to DynamoDB</h2><p>Faced with the scalability limitations of the MySQL-based counting service, the team initially looked to DynamoDB as a potential solution.</p><p>This decision was primarily driven by DynamoDB's reputation for handling large-scale, high-throughput workloads - a perfect fit for Canva's rapidly growing data needs.&nbsp;</p><p>The migration process began with moving raw usage events from the data collection stage to DynamoDB, which provided immediate relief to the storage constraints. This initial success prompted the team to consider moving the entirety of their data to DynamoDB. It was a move that would have necessitated a substantial rewrite of their codebase.</p><p>However, after careful evaluation, Canva decided against a full migration to DynamoDB.&nbsp;</p><p>While DynamoDB could have effectively addressed the storage scalability issues, it wouldn't have solved the fundamental problem of processing scalability. The team found it challenging to eliminate the need for frequent database round trips, which was a key bottleneck in their existing system.&nbsp;</p><p>This reveals a crucial lesson in system design: sometimes, what appears to be a storage problem is a processing problem in disguise.</p><p>Canva's approach clearly shows the importance of thoroughly analyzing the root causes of system limitations before committing to major architectural changes. It also highlights the complexity of scaling data-intensive applications, where the interplay between storage and processing capabilities can be subtle and non-obvious.</p><h2>The OLAP-based Counting Service</h2><p>Canva's latest architecture for the content usage counting service shows a shift from traditional OLTP databases to an OLAP-based solution, specifically using Snowflake.&nbsp;</p><p>The change came after realizing that previous attempts with MySQL and DynamoDB couldn't adequately address their scalability and processing needs. The new architecture altered how Canva processed and stored the usage data, adopting an ELT (Extract, Load, Transform) approach.</p><p>The diagram below shows the new architecture:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1de81af8-487c-4113-b105-bd3130824ff2_1474x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1580" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1de81af8-487c-4113-b105-bd3130824ff2_1474x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In the extraction phase, Canva pulled raw usage data from various sources, including web browsers and mobile apps. This data was then loaded into Snowflake using a reliable data replication pipeline provided by Canva&#8217;s data platform team. The reliability of this data replication was crucial, as it formed the foundation for all subsequent processing.</p><p>The transformation phase used Snowflake's powerful computational capabilities. It also utilized DBT (Data Build Tool) to define complex transformations.&nbsp;</p><p>These transformations were written as SQL-like queries, allowing for end-to-end calculations directly on the source data. For example, one transformation aggregated usages per brand using a SQL query that selected data from a previous step named 'daily_template_usages' and grouped it by &#8216;day_id&#8217; and &#8216;template_brand&#8217;.</p><p>The SQL below shows the aggregate query.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b40bcc3-48b4-4af7-a0c5-96d476135214_1600x582.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="530" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b40bcc3-48b4-4af7-a0c5-96d476135214_1600x582.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://www.canva.dev/blog/engineering/scaling-to-count-billions">Canva Engineering Blog</a></figcaption></figure></div><p>The main steps in the transformation process were as follows:</p><ul><li><p>Extraction of source event data in JSON format from DynamoDB, which was not optimal for data warehouse query processing. Therefore, some JSON properties were projected into separate table columns within Snowflake for optimization.</p></li><li><p>Deduplicate and aggregate the usage events.</p></li></ul><p>A key aspect of this new architecture was the elimination of intermediary outputs. Instead of persisting data at various pipeline stages, Canva materialized intermediate transformation outputs as SQL Views.&nbsp;</p><h3>The Advantage of OLAP Database</h3><p>The separation of storage and computing in an OLAP database like Snowflake was a game-changer for Canva. It enabled them to scale computational resources independently.&nbsp;</p><p>As a result, they could now aggregate billions of usage records within minutes, a task that previously took over a day. This improvement was largely due to most of the computation being done in memory, which is several orders of magnitude faster than the database round trips required in their previous architecture.</p><p>There were several improvements such as:</p><ul><li><p>The pipeline latency was reduced from over a day to under an hour.</p></li><li><p>Incident handling became more manageable. Most issues could be resolved by simply re-running the pipeline end-to-end, without manual database interventions.</p></li><li><p>Reduction in over 50% of the stored data and elimination of thousands of lines of deduplication and aggregation calculation code. The logic rewritten in SQL was simpler compared to the previous code.</p></li><li><p>The number of incidents dropped to once every few months or fewer.</p></li></ul><h3>Challenges of the New Solution</h3><p>Despite the advantages, the solution also introduced new challenges such as:</p><ul><li><p><strong>Transformation Complexity:</strong> The data transformation jobs, written in an SQL-like language and deployed as a standalone service, introduced new deployment and compatibility considerations.</p></li><li><p><strong>Data Unloading:</strong> Canva needed to build a reliable pipeline to unload data from Snowflake into databases used by other services. This involved using S3 as intermediary storage and integrating with SQS for durability. Optimizing the ingestion query and carefully tuning rate limits was crucial to prevent service database throttling.</p></li><li><p><strong>Infrastructure Complexity:</strong> The new architecture increased infrastructure complexity due to data replication integration and standalone services running transformation jobs. This required additional effort to maintain observability across different toolsets.</p></li></ul><h2>Conclusion</h2><p>Canva&#8217;s journey of implementing the counting service for the Creators Program is full of learning for software developers and architects.&nbsp;</p><p>Some of the key points to take away are as follows:</p><ul><li><p>Simplicity is crucial for designing reliable services. In other words, reducing code and data complexity is the key. For example, minimizing intermediary output in various counting pipeline stages using OLAP and ELT helped simplify the system.</p></li><li><p>It&#8217;s good to start small and be pragmatic. The initial MySQL-based design served its purpose for the first two years and allowed timely delivery of the functionality to the users. Once scalability became a problem, they looked at alternative solutions.</p></li><li><p>Comprehensive observability, while requiring extra overhead, helps identify and resolve problems. Close monitoring from day one of every part of the pipeline was crucial to make the right decisions.</p></li><li><p>Recognizing when solutions are no longer adequate and being open to change is important. In Canva&#8217;s case, this was demonstrated by the willingness to pivot from familiar MySQL to a more suitable solution using OLAP database.</p></li><li><p>Big changes happen in increments. For example, the journey from MySQL to DynamoDB and finally to an OLAP solution showed the power of iterative improvements.</p></li><li><p>Reliable infrastructure is important to build a stable platform.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://www.canva.dev/blog/engineering/scaling-to-count-billions">Scaling to Count Billions</a></p></li><li><p><a href="https://aws.amazon.com/dynamodb/">AWS DynamoDB</a></p></li><li><p><a href="https://docs.snowflake.com/">Snowflake Documentation</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:sponsorship@bytebytego.com">sponsorship@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Tue, 13 Aug 2024 15:30:12 GMT</pubDate>
</item>
<item>
<title>EP124: How does SSH work?</title>
<link>https://blog.bytebytego.com/p/ep124-how-does-ssh-work</link>
<guid>https://blog.bytebytego.com/p/ep124-how-does-ssh-work</guid>
<content:encoded><![CDATA[
<div> SSH, 学校, Large Language Models, 系统设计, Nginx

系统设计中介绍了SSH的工作原理，以及8个常见问题及解决方案。学校应该添加一些新的必修课程，如LLM和系统设计。Nginx之所以受欢迎是因为其高性能和多功能性。想要推广产品可以通过广告位在技术专业人士面前展示。总结: 系统设计中介绍了SSH的工作原理和解决方案，学校应该增加新的课程，Nginx因为高性能和多功能性而受欢迎，想要推广产品可以通过广告位。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>How does SSH work?</p></li><li><p>List of Subjects That Should be Mandatory in Schools</p></li><li><p>8 Common System Design Problems and Solutions</p></li><li><p>Why is Nginx so popular? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/NewRelic_081024">New Relic launched the industry's&nbsp;first fully-integrated, AI-driven Digital Experience Monitoring (DEM) solution (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/NewRelic_081024" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="819" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7cac714b-6a9b-46ec-8311-f8659d0041cb_1920x1080.png" width="1456" /><div></div></div></a></figure></div><p>New Relic DEM makes it easy for businesses to quickly identify and resolve user friction points across mobile, web, and AI-powered applications.</p><p>New Relic&#8217;s advanced DEM capabilities include:</p><ul><li><p>Actionable user journeys without event duplication</p></li><li><p>The most comprehensive list of mobile platforms</p></li><li><p>Superior insights without the high costs</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/NewRelic_081024"><span>Get started</span></a></p><div><hr /></div><h2>How does SSH work?</h2><p>SSH (Secure Shell) is a network protocol used to securely connect to remote machines over an unsecured network. It encrypts the connection and provides various mechanisms for authentication and data transfer. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, text, application" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed998b2e-fbc8-4c3c-b339-eca5abd85ce3_1289x1536.gif" title="graphical user interface, text, application" width="1289" /><div></div></div></a></figure></div><p>SSH has two versions: SSH-1 and SSH-2. SSH-2 was standardized by the IETF. <br />It has three main layers: Transport Layer, Authentication Layer, and Connection Layer. </p><ol><li><p>Transport Layer <br />The Transport Layer provides encryption, integrity, and data protection to ensure secure communication between the client and server. <br /></p></li><li><p>Authentication Layer <br />The Authentication Layer verifies the identity of the client to ensure that only authorized users can access the server. <br /></p></li><li><p>Connection Layer <br />The Connection Layer multiplexes the encrypted and authenticated communication into multiple logical channels.</p></li></ol><div><hr /></div><h2>An interesting list of subjects that should be mandatory in schools</h2><p>While academics are essential, it's crucial to acknowledge that many elements in this diagram would have been beneficial to learn earlier. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="990" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98ced99c-1e91-4926-ae09-d81779bd454c_800x990.jpeg" title="No alt text provided for this image" width="800" /><div></div></div></a></figure></div><p>Over to you: What else should be on the list? What are the top 3 skills you wish schools would teach? <br /> <br />Credit: Instagram accounts on startup_rules</p><div><hr /></div><h2><a href="https://bit.ly/TheAIEdge_081024">The Train, Fine-Tune, and Deploy Large Language Models Bootcamp (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/TheAIEdge_081024" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d55f42a-137d-40e2-9d51-4a8966975ea7_1600x840.png" title="" width="1456" /><div></div></div></a></figure></div><p>In the past few years, we saw a revolution with the advent of Large Language Models. Rarely has a discovery changed the world of Machine Learning that much, and the hype around LLM is real! That is something that very few experts predicted, and preparing for the future is essential. This boot camp is meant to train the new generation of engineers who will continue leading this revolution. You will learn:</p><ul><li><p>The Transformer Architecture</p></li><li><p>Training LLMs to Follow Instruction</p></li><li><p>How to Scale Model Training</p></li><li><p>How to Fine-Tune LLMs</p></li><li><p>How to Deploy LLMs</p></li><li><p>How to Build the Application Layer</p></li></ul><p class="button-wrapper"><a class="button primary button-wrapper" href="https://bit.ly/TheAIEdge_081024"><span>Enroll 20% Discount</span></a></p><div><hr /></div><h2>8 Common System Design Problems and Solutions</h2><p>Do you know those 8 common problems in large-scale production systems and their solutions? Time to test your skills! </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ccb1c38-5e69-4284-a34c-d7be7b458f8f_1280x1600.gif" title="graphical user interface" width="1280" /><div></div></div></a></figure></div><ol><li><p>Read-Heavy System <br />Use caching to make the reads faster. </p></li><li><p>High-Write Traffic <br />Use async workers to process the writes <br />Use databases powered by LSM-Trees </p></li><li><p>Single Point of Failure <br />Implement redundancy and failover mechanisms for critical components like databases. </p></li><li><p>High Availability <br />Use load balancing to ensure that requests go to healthy server instances. <br />Use database replication to improve durability and availability. </p></li><li><p>High Latency <br />Use a content delivery network to reduce latency </p></li><li><p>Handling Large Files <br />Use block storage and object storage to handle large files and complex data. </p></li><li><p>Monitoring and Alerting <br />Use a centralized logging system using something like the ELK stack. </p></li><li><p>Slower Database Queries <br />Use proper indexes to optimize queries. <br />Use sharding to scale the database horizontally. </p></li></ol><p>Over to you: What other common problems and solutions have you seen?</p><div><hr /></div><h2>Why is Nginx so popular? </h2><p>Nginx is a high-performance web server and reverse proxy. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa0a6754-63e9-4377-b7fc-c29018e4fcf5_1311x1536.gif" title="No alternative text description for this image" width="1311" /><div></div></div></a></figure></div><p>It follows a master-worker process model that contributes to its stability, scalability, and efficient resource utilization. <br /> <br />The master process is responsible for reading the configuration and managing worker processes. Worker processes handle incoming connections using an event-driven non-blocking I/O model. <br /> <br />Due to its architecture, Nginx excels in supporting multiple features such as:</p><ol><li><p>High-Performance Web Server </p></li><li><p>Reverse Proxy and Load Balancing </p></li><li><p>Content Cache </p></li><li><p>SSL Termination </p></li></ol><p>Over to you: Do you know any other features supported by Nginx?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:sponsorship@bytebytego.com">sponsorship@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 10 Aug 2024 15:30:59 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Microservices Design Patterns</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-microservices-design</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-microservices-design</guid>
<content:encoded><![CDATA[
<div> 灵活性 测试性 可扩展性 数据一致性 安全性 

设计模式为微服务架构中常见问题提供了有效解决方案。适用适当的设计模式可以有效解决数据一致性和最终一致性、安全性、可扩展性和数据库性能等挑战。常见的设计模式包括API网关模式、数据库每个服务模式和CQRS模式等。微服务架构通过拆分单块应用为独立部署的服务，提高了系统的灵活性、测试性和可扩展性。然而，微服务架构的实施也伴随着挑战，如数据一致性和最终一致性、安全性、可扩展性和数据库性能。通过合适的设计模式，可以有效应对这些问题。 

<br /><br />总结:设计模式为微服务架构中的关键问题提供了有效解决方案，包括数据一致性、安全性、可扩展性和数据库性能。微服务架构通过拆分单块应用为独立部署的服务，提高了系统的灵活性、测试性和可扩展性。 <div>
<p>Microservices architecture has gained popularity for its ability to improve the flexibility, testability, and scalability of software systems.&nbsp;</p><p>By breaking down a monolithic application into smaller, independently deployable services, microservices enable teams to develop, deploy, and scale each service independently.</p><p>However, the implementation of microservices architecture comes with its own set of challenges such as:</p><ul><li><p><strong>Data Consistency and Eventual Consistency:</strong> In a microservices architecture, data is often distributed across multiple nodes, which can be located in different data centers or even different geographic regions. At any given point in time, there can be discrepancies in the state of data between various nodes. This phenomenon is known as eventual consistency.</p></li><li><p><strong>Security: </strong>Microservices architecture introduces a larger attack surface for malicious actors compared to monolithic systems. It&#8217;s crucial to establish appropriate security mechanisms while building microservices. Design patterns such as the API Gateway pattern can help.</p></li><li><p><strong>Scalability and Database Performance: </strong>Microservices are known for their scalability. However, while it is relatively easy to scale the application layer by adding more instances, databases can become performance bottlenecks if not designed for scalability. Patterns such as Database per Service and CQRS help solve this challenge.</p></li></ul><p>Design patterns provide proven solutions to common problems encountered in a microservices architecture. By applying an appropriate design pattern, these problems can be effectively addressed.</p><p>In this post, we&#8217;ll explore the most popular microservices design patterns along with their benefits and adoption challenges.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1820" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fee02bbe9-ee3c-4028-a05e-36e5274202a3_2250x2812.png" width="1456" /><div></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-microservices-design">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 08 Aug 2024 15:30:37 GMT</pubDate>
</item>
<item>
<title>How Facebook Syncs Time Across Millions of Servers</title>
<link>https://blog.bytebytego.com/p/how-facebook-syncs-time-across-millions</link>
<guid>https://blog.bytebytego.com/p/how-facebook-syncs-time-across-millions</guid>
<content:encoded><![CDATA[
<div> Facebook, 时间同步, NTP, PTP, 精确度
<br />
Facebook 在其基础设施中采用 Precision Time Protocol (PTP) 来确保精准可靠的时间同步，通过重新设计和重建各种组件，将PTP的可能性推向极限。PTP架构由PTP机架、PTP网络和PTP客户端组成，通过GNSS天线、时间设备、振荡器、网络接口卡等关键组件提供时钟服务。PTP网络利用透明时钟、避免边界钟等技术分发时钟。PTP客户端软件负责在需要准确时间的服务器上运行，使用ptp4l、fbclock、内核时间戳等组件。Facebook的PTP解决方案为我们展示了PTP的应用和优势。总结: <br />Facebook采用PTP确保时间同步，通过重新设计和重建各种组件，将PTP的可能性推向极限。PTP架构由PTP机架、PTP网络和PTP客户端组成，提供时钟服务，利用透明时钟、避免边界钟等技术分发时钟，采用ptp4l、fbclock、内核时间戳等组件运行在客户端。 <div>
<h2><a href="https://bit.ly/FusionAuth_080624">FusionAuth: Auth. Built for devs, by devs. (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/FusionAuth_080624" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="373.8" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5ba85cc8-6394-4f42-be7b-d4192540c533_640x336.png" width="712" /><div></div></div></a></figure></div><ul><li><p>Hosting Flexibility: You host or we host - the choice is yours with no loss of features</p></li><li><p>Scale Confidently: Lightning-fast performance for 10 users or 10 million users (or more)</p></li><li><p>Developer-Centric: True API first design, quick integration, built on standards, highly flexible &amp; customizable</p></li><li><p>Total Control: Deploy on any computer, anywhere in the world and integrate easily with any tech stack</p></li><li><p>Data Isolation: Single tenant by design means your data is physically isolated from everyone else's</p></li><li><p>Unlimited: Unlimited IDPs, unlimited users, unlimited tenants, unlimited applications, always free</p></li></ul><p>FusionAuth is a complete auth &amp; user platform that has&nbsp;10M+ downloads and is trusted by industry leaders!</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/FusionAuth_080624"><span>Start for Free</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the Facebook/Meta Engineering Blog. All credit for the technical details goes to the Facebook engineering team. The links to the original articles are present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>A clock showing the wrong time is worse than a faulty clock.</p><p>This is the challenge Facebook had to deal with while operating millions of servers connected to the Internet and each other.&nbsp;</p><p>All of these devices have onboard clocks that are expected to be accurate. However, many onboard clocks contain inaccurate internal oscillators, which cause seconds of inaccuracy per day and need to be periodically corrected.&nbsp;</p><p>Think of these internal oscillators as the &#8220;heartbeat&#8221; of the clock. Just like how an irregular heartbeat can affect a person&#8217;s health, an inaccurate oscillator can cause the clock to gain or lose time.</p><p>Incorrect time can lead to issues with varying degrees of impact. It could be missing a simple reminder or failing a spacecraft launch.</p><p>As Facebook&#8217;s infrastructure has grown, time precision has become extremely important. For example, knowing the accurate time difference between two random servers in a data center is critical to preserving the order of transactions across these servers.</p><p>In this post, we&#8217;ll learn how Facebook achieved time precision across its millions of servers with NTP and later with PTP.</p><div><hr /></div><h2>Network Time Protocol</h2><p>Facebook started with Network Time Protocol (NTP) to keep the devices in sync.</p><p>NTP is a way for computers to synchronize their clocks over a network. It helps ensure that all devices on the network have the same, accurate time.</p><p>Having synchronized clocks is critical for many tasks, such as:</p><ul><li><p>Scheduling events and meetings</p></li><li><p>Logging and tracking activities</p></li><li><p>Ensuring a proper sequence of transactions</p></li><li><p>Coordinating actions between different systems</p></li></ul><p>NTP uses a hierarchical system of time servers where the most accurate servers are at the top. There is a 3-step process to how NTP works:</p><ul><li><p>Computers on the network periodically request the current time from these servers.&nbsp;</p></li><li><p>The servers respond with their current time taking into account the network delay.&nbsp;</p></li><li><p>The requesting computer adjusts its clock based on the information received from the server.</p></li></ul><p>The diagram below shows the hierarchical system of servers used by NTP.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38b4e-9b69-4bbb-a38c-836fc06b7245_1562x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1491" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38b4e-9b69-4bbb-a38c-836fc06b7245_1562x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Facebook built an NTP service at scale. They used <strong>chrony</strong>, a modern NTP server implementation. While they used the <strong>ntpd </strong>service initially, testing revealed that <strong>chrony</strong> was far more accurate and scalable.</p><p>Chrony was a fairly new daemon at the time, but it offered a chance to bring the precision down to nanoseconds. Also, from a resource consumption perspective, chrony consumed less RAM compared to ntpd.</p><p>See the diagram below that shows the difference of around 1MB when it came to RAM consumption between chrony and ntpd.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F210d00e2-c251-45df-8f90-684d6a831d22_1600x900.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="819" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F210d00e2-c251-45df-8f90-684d6a831d22_1600x900.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://engineering.fb.com/2020/03/18/production-engineering/ntp-service/">Facebook Engineering Blog</a></figcaption></figure></div><p>They designed the NTP service in four layers based on the hierarchical structure of NTP.</p><ul><li><p>Stratum 0 is a layer of satellites with precise atomic clocks from a global navigation satellite system (GNSS), such as GPS, GLONASS, or Galileo.</p></li><li><p>Stratum 1 is a Facebook atomic clock synchronizing with a GNSS.</p></li><li><p>Stratum 2 is a pool of NTP servers synchronizing to the Stratum 1 devices.&nbsp;</p></li><li><p>Lastly, Stratum 3 is a tier of servers configured for a larger scale.</p></li></ul><p>The diagram below shows the layers of Facebook&#8217;s NTP service.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F666832a9-c43e-4cda-a44c-fef945fbb401_1536x864.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="819" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F666832a9-c43e-4cda-a44c-fef945fbb401_1536x864.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://engineering.fb.com/2020/03/18/production-engineering/ntp-service/">Facebook Engineering Blog</a></figcaption></figure></div><p>There are a couple of interesting concepts to note over here:&nbsp;</p><ul><li><p>Leap second</p></li><li><p>Smearing</p></li></ul><p>The Earth&#8217;s rotation is not consistent and can vary slightly over time. Therefore, clocks are kept in sync with the Earth&#8217;s rotation by occasionally adding or removing a second. This is called a leap second.</p><p>While adding or removing a leap second is hardly noticeable to humans, it can cause server issues. Servers expect time to move forward continuously, and a sudden change of a second can cause them to miss important tasks.&nbsp;</p><p>To mitigate the impact of leap seconds on servers, a technique called &#8220;smearing&#8221; is used.&nbsp;</p><p>Instead of adding or removing a full second at once, the time is gradually adjusted in small increments over several hours. It&#8217;s similar to masking a train&#8217;s delay by spreading the adjustment across multiple stations.</p><p>In the case of Facebook&#8217;s NTP service, the Leap-second smearing happens at Stratum 2. The Stratum 3 servers receive smeared time and are ignorant of leap seconds.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1838" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F813befc8-72c0-45fc-9568-b9bc5ca9a69d_2250x2840.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design">A Crash Course on Domain-Driven Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/tidying-code">"Tidying" Code</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">A Crash Course on Relational Database Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">A Crash Course on Distributed Systems</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">A Crash Course in Database Scaling Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>The Arrival of Precision Time Protocol</h2><p>NTP adoption was quite successful for Facebook. It helped them improve accuracy from 10 milliseconds to 100 microseconds.&nbsp;</p><p>However, as Facebook wanted to scale to more advanced systems and build the metaverse, they wanted even greater levels of accuracy.&nbsp;</p><p>Therefore, in late 2022, Facebook moved from NTP to Precision Time Protocol (PTP).</p><p>There were some problems with NTP, which are as follows:</p><ul><li><p><strong>NTP and Asynchronous Systems:</strong> Systems using NTP are asynchronous, meaning they work independently without a shared global clock. These systems periodically check in with each other to ensure synchronization. However, as the system grows larger, more check-ins are required, which can slow down the network.</p></li><li><p><strong>NTP and Timekeeping Methods: </strong>NTP is susceptible to variance and latency due to its timekeeping methods of using physical clocks. In other words, NTP is like a microwave clock that keeps time on-device. If there&#8217;s a time change (e.g., daylight savings), the clock needs to be manually adjusted.</p></li></ul><p>In contrast, PTP works like a smartphone clock that updates its time automatically. When there&#8217;s a time change or the phone moves to a new time zone, the clock updates itself by referencing the time over a network.</p><p>While NTP provided millisecond-level synchronization, PTP networks could hope to achieve nanosecond-level precision.</p><h3>What makes PTP More Effective?</h3><p>As discussed earlier, a special computer called a Stratum acts as a time reference for other computers on a network. When a computer needs to know the current time, it sends a request to the Stratum, which replies with the current time. This process is known as sync messaging.</p><p>When the Stratum sends the current time to another computer, the information travels across the network, resulting in some latency. Several factors can increase this latency, such as:</p><ul><li><p>The speed at which signals travel through the fiber optic cables.</p></li><li><p>The time it takes for the network devices to convert signals.</p></li><li><p>The quality of network equipment, like routers and switches.</p></li><li><p>The time it takes for software and drivers to process the time information.</p></li></ul><p>Due to latency, the time received by the other computer is no longer accurate when it arrives at the receiving computer.</p><p>The obvious solution is to measure the latency and add it to the time received by the other computer to get a more accurate time. However, measuring latency is challenging because each computer has its clock, and there is no universal clock to compare against.</p><p>To measure latency, two assumptions about consistency and symmetry are made:</p><ul><li><p>The latency a packet experiences while traveling across the network is consistent.</p></li><li><p>The latency from the Stratum to the other computer is equal to the latency from the other computer back to the Stratum. In other words, the network is symmetric.</p></li></ul><p>Therefore, it follows that the accuracy of time synchronization can be improved by maximizing consistency and symmetry in the network.</p><p>PTP is a solution that helps achieve this.</p><ul><li><p>PTP uses hardware timestamping to improve consistency. This means that timestamps are added to the time information at the hardware level, reducing the impact of software and driver delays.</p></li><li><p>PTP also uses transparent clocks, which are special devices that measure and compensate for the time the information spends passing through network equipment.</p></li></ul><h2>The Need for PTP</h2><p>Let&#8217;s look at a practical case where PTP is needed.</p><p>Imagine you&#8217;re using Facebook and you post a new status update. When you try to view your post, there&#8217;s a chance that your request to see the post is handled by a different server than the one that originally processed your post.</p><p>If the server handling your view request doesn&#8217;t have the latest updated data, you might not see your post. This is annoying for users and goes against the promise that interacting with a distributed system like Facebook should work the same as interacting with a single server that has all the data.</p><p>In the old solution, Facebook used to send your view request to multiple servers and wait for a majority of them to agree on the data before showing it to you. But this takes up extra computing resources and adds delay because of the back-and-forth communication over the network.</p><p>By using PTP to keep precise time synchronization across all its servers, they can simply have the view request wait until the server has caught up to the timestamp of your original post. There is no need for multiple requests and responses.</p><p>The diagram below shows this scenario.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa69c52f-d90f-42eb-b83a-1bad27555321_1600x1088.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="990" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa69c52f-d90f-42eb-b83a-1bad27555321_1600x1088.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>However, this only works if all the server clocks are closely synchronized. Also, the difference between a server&#8217;s clock and the reference time needs to be known.&nbsp;</p><p>PTP provides this tight synchronization. It could synchronize time about 100 times more precisely than NTP, which was necessary for Facebook&#8217;s requirement.</p><p>This was just one example. There were several additional use cases where PTP excelled such as:</p><ul><li><p>Event tracing</p></li><li><p>Cache invalidations</p></li><li><p>Privacy violation detection improvements</p></li><li><p>Latency compensation in the metaverse</p></li></ul><h2>The PTP Architecture</h2><p>Facebook&#8217;s PTP architecture consists of three main components:</p><ul><li><p>The PTP Rack</p></li><li><p>The PTP Network</p></li><li><p>The PTP Client</p></li></ul><p>See the diagram below for a high-level view of the architecture:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7339a422-51ef-4ca7-a1cd-8db48d09805f_1600x1128.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1026" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7339a422-51ef-4ca7-a1cd-8db48d09805f_1600x1128.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://engineering.fb.com/2022/11/21/production-engineering/precision-time-protocol-at-meta/">Facebook Engineering Blog</a></figcaption></figure></div><p>Let&#8217;s look at each component and understand how they work together to provide precise timekeeping.</p><h3>The PTP Rack</h3><p>The PTP rack houses the hardware and software that serve time to clients.</p><p>It consists of critical components such as:</p><ol><li><p><strong>GNSS Antenna: </strong>This is where time originates on Earth. The antenna receives time signals from GPS, Galileo, and other satellite constellations. Facebook uses a GNSS-over-fiber technology to distribute the signal, which is more reliable and easier to install than traditional coaxial cables.</p></li><li><p><strong>Time Appliance: </strong>This is the heart of the timing infrastructure. It disciplines the time received from the GNSS antenna using atomic clocks for improved accuracy and stability. Facebook has developed a new Time appliance that can support up to 1 million clients without compromising accuracy.</p></li><li><p><strong>Oscillatord: </strong>This is a software component that configures and monitors the Time appliance, including the GNSS receiver and atomic clocks. It exports data that helps decide if the Time Appliance should serve clients or be taken offline.</p></li><li><p><strong>Network Card (NIC): </strong>It&#8217;s the interface between the Time Appliance and the network. It timestamps PTP packets using its clock, which is synchronized with the Time Appliance for nanosecond-level accuracy.</p></li><li><p><strong>Ptp4u: </strong>This is Facebook&#8217;s custom-built PTP server software that can handle over 1 million clients per server, far more than existing solutions. It runs on the Time Appliance and sends PTP messages to the clients.</p></li></ol><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab9fbd1b-dc1e-43ed-b576-8b8d242cefa0_1600x920.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="837" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fab9fbd1b-dc1e-43ed-b576-8b8d242cefa0_1600x920.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">The GNSS Antenna in a Datacenter (Source: <a href="https://engineering.fb.com/2022/11/21/production-engineering/precision-time-protocol-at-meta">Facebook Engineering Blog</a>)</figcaption></figure></div><h3>The PTP Network</h3><p>The PTP network is responsible for distributing time from the PTP rack to clients. Facebook uses PTP over a standard IP network with a few key enhancements:</p><ol><li><p><strong>PTP Unicast: </strong>They use unicast PTP instead of multicast for simpler network configuration and better scalability. Clients request time from servers, and servers grant requests and send PTP messages.</p></li><li><p><strong>Transparent Clocks:</strong> Each network switch between the client and server acts as a transparent clock. It measures the time each PTP packet spends in the switch and records it in the packet. This allows clients to accurately account for network delays.</p></li><li><p><strong>Boundary Clock Avoidance: </strong>&nbsp;Facebook avoided using boundary clocks, which act as both clients and servers, to reduce complexity. They rely solely on transparent clocks in the network switches.</p></li></ol><p>A typical PTP unicast flow consists of the following steps:</p><ul><li><p><strong>Client Initiates Negotiation: </strong>The PTP client starts the process by requesting unicast transmission from the PTP server. It sends three types of requests:</p><ul><li><p><strong>Sync Grant Request: </strong>The client asks the server to send a specified number of Sync and Follow-Up messages per second, containing the current time, for a certain duration. This helps the client adjust its clock to match the server&#8217;s clock.</p></li><li><p><strong>Announce Grant Request: </strong>The client requests the server to send a specific number of Announce messages per second, containing the server&#8217;s status, for a certain duration. This helps the client make sure that the server hasn&#8217;t stopped or gone haywire.</p></li><li><p><strong>Delay Response Grant Request: </strong>The client informs the server that it will send Delay Request messages, and asks the server to respond with Delay Response packets for a specified duration. This helps the client account for any delay in communication.</p></li></ul></li><li><p><strong>Server Grants Requests:</strong> The PTP server needs to grant these requests and send corresponding grant responses to the client.</p></li><li><p><strong>Server Sends PTP Messages: </strong>Once the requests are granted, the server starts sending the requested PTP messages</p></li><li><p><strong>Client Sends Delay Requests: </strong>The client sends Delay Request messages to the server at the agreed-upon interval to determine the network path delay.</p></li><li><p><strong>Client Refreshes Grant: </strong>The client needs to periodically refresh the grant by repeating the negotiation process before the current grant expires.</p></li></ul><p>The diagram below shows the PTP Exchange Process</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9ce734-68f3-4059-99ef-aaa32ae024f8_1600x961.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="875" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9ce734-68f3-4059-99ef-aaa32ae024f8_1600x961.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>The PTP Client</h3><p>The PTP client software runs on each server that needs accurate time. Facebook uses a few different components:</p><ol><li><p><strong>ptp4I: </strong>An open-source PTP client that receives PTP messages from the server and disciplines the NIC hardware clock. Facebook has made several enhancements to ptp4I to handle its scale and unique requirements.</p></li><li><p><strong>fbclock: </strong>This is Facebook&#8217;s custom API that provides PTP time to applications. Instead of a single timestamp, it gives a &#8220;window of uncertainty&#8221; - a time range that is guaranteed to contain the true time with a high degree of certainty.</p></li><li><p><strong>Kernel Timestamping: </strong>The Linux kernel on each server timestamps incoming and outgoing PTP packets in hardware for maximum accuracy. This relies on NIC driver support and careful configuration.</p></li></ol><h2>Conclusion</h2><p>To conclude, Facebook&#8217;s adoption of Precision Time Protocol (PTP) across its infrastructure is a significant step forward in ensuring precise and reliable timekeeping at an unprecedented scale. By redesigning and rebuilding various components, Facebook has pushed the boundaries of what&#8217;s possible with PTP.</p><p>Also, the open-source nature of most of the work helps us learn from the PTP solution implemented by them.</p><p><strong>References:</strong></p><ul><li><p><a href="https://engineering.fb.com/2020/03/18/production-engineering/ntp-service/">Building a more accurate time service at Facebook scale</a></p></li><li><p><a href="https://engineering.fb.com/2022/11/21/production-engineering/future-computing-ptp">PTP: Timing accuracy and precision for the future of computing</a></p></li><li><p><a href="https://engineering.fb.com/2022/11/21/production-engineering/precision-time-protocol-at-meta/">How Precision Time Protocol is being deployed at Meta</a></p></li></ul><p></p>
]]></content:encoded>
<pubDate>Tue, 06 Aug 2024 15:30:43 GMT</pubDate>
</item>
<item>
<title>EP123: What is a Load Balancer?</title>
<link>https://blog.bytebytego.com/p/ep123-what-is-a-load-balancer</link>
<guid>https://blog.bytebytego.com/p/ep123-what-is-a-load-balancer</guid>
<content:encoded><![CDATA[
<div> credit card, load balancer, k8s design patterns, QA Wolf, Kubernetes

credit card被称为银行中最赚钱的产品，通过信用卡支付流程经济学图解说明了VISA/Mastercard如何盈利。Load Balancer是分配网络或应用流量到多个服务器的设备或软件应用。k8s设计模式分为基础、结构和行为等几种模式，包括健康探测、预测需求、批处理和有状态服务等。QA Wolf提供AI原生解决方案，在短时间内进行高容量、高速度的测试覆盖，减少QA周期。总结: credit card通过支付流程实现盈利，Load Balancer用于流量分配，k8s设计模式包括基础、结构和行为几种模式，QA Wolf提供高效的自动化测试解决方案。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>25 Computer Papers You Should Read (Youtube video)</p></li><li><p>Why is the credit card called &#8220;the most profitable product in banks&#8221;? </p></li><li><p>What is a Load Balancer? </p></li><li><p>Top 10 k8s Design Patterns </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><strong><a href="https://bit.ly/QAWolf_080324">&#128075;Goodbye low test coverage and slow QA cycles (Sponsored)</a></strong></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_080324" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="736" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb179cdc8-c1f6-4481-860e-bfaf78db67c8_1473x745.png" width="1456" /><div></div></div></a></figure></div><p>Bugs sneak out when less than 80% of user flows are tested before shipping. However, getting that kind of coverage (and staying there) is hard and pricey for any team.</p><p><a href="https://bit.ly/QAWolf_080324">QA Wolf&#8217;s</a> AI-native solution provides high-volume, high-speed test coverage for web and mobile app, reducing your organization&#8217;s QA cycle to minutes.</p><p>They can get you:</p><ul><li><p><a href="https://bit.ly/QAWolf_080324">80% automated E2E test coverage in weeks</a>&#8212;not years</p></li><li><p><a href="https://bit.ly/QAWolf_080324">Unlimited parallel test runs</a></p></li><li><p>24-hour maintenance and on-demand test creation</p></li><li><p>Zero flakes, guaranteed</p></li></ul><p>The benefit? No more manual E2E testing. No more slow QA cycles. No more bugs reaching production.</p><p>With QA Wolf, <a href="https://bit.ly/QAWolf_080324CaseStudy">Drata&#8217;s team of 80+ engineer</a>s achieved 4x more test cases and 86% faster QA cycles.</p><p>&#127775; Rated 4.8/5 on G2</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_080324"><span>Schedule a demo to learn more</span></a></p><div><hr /></div><h2>25 Computer Papers You Should Read<strong>!</strong></h2><div class="youtube-wrap" id="youtube2-_kynGl5hr9U"><div class="youtube-inner"></div></div><div><hr /></div><h2>Why is the credit card called &#8220;the most profitable product in banks&#8221;? </h2><p>How does VISA/Mastercard make money? </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1456" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72563e98-8a4c-4257-b1fa-9369bd43adf3_1536x1536.gif" title="No alternative text description for this image" width="1456" /><div></div></div></a></figure></div><p>The diagram below shows the economics of the credit card payment flow. <br /> <br />1. The cardholder pays a merchant $100 to buy a product. <br /> <br />2. The merchant benefits from the use of the credit card with higher sales volume, and needs to compensate the issuer and the card network for providing the payment service. The acquiring bank sets a fee with the merchant, called the &#8220;&#119846;&#119838;&#119851;&#119836;&#119841;&#119834;&#119847;&#119853; &#119837;&#119842;&#119852;&#119836;&#119848;&#119854;&#119847;&#119853; &#119839;&#119838;&#119838;.&#8221; <br /> <br />3 - 4. The acquiring bank keeps $0.25 as the &#119834;&#119836;&#119850;&#119854;&#119842;&#119851;&#119842;&#119847;&#119840; &#119846;&#119834;&#119851;&#119844;&#119854;&#119849;, and $1.75 is paid to the issuing bank as the &#119842;&#119847;&#119853;&#119838;&#119851;&#119836;&#119841;&#119834;&#119847;&#119840;&#119838; &#119839;&#119838;&#119838;. The merchant discount fee should cover the interchange fee. <br /> <br />The interchange fee is set by the card network because it is less efficient for each issuing bank to negotiate fees with each merchant. <br /> <br />5. The card network sets up the &#119847;&#119838;&#119853;&#119856;&#119848;&#119851;&#119844; &#119834;&#119852;&#119852;&#119838;&#119852;&#119852;&#119846;&#119838;&#119847;&#119853;&#119852; &#119834;&#119847;&#119837; &#119839;&#119838;&#119838;&#119852; with each bank, which pays the card network for its services every month. For example, VISA charges a 0.11% assessment, plus a $0.0195 usage fee, for every swipe. <br /> <br />6. The cardholder pays the issuing bank for its services. <br /> <br />Why should the issuing bank be compensated? </p><ul><li><p>The issuer pays the merchant even if the cardholder fails to pay the issuer.</p></li><li><p>The issuer pays the merchant before the cardholder pays the issuer. </p></li><li><p>The issuer has other operating costs, including managing customer accounts, providing statements, fraud detection, risk management, clearing &amp; settlement, etc. </p></li></ul><p>Over to you: Does the card network charge the same interchange fee for big merchants as for small merchants? </p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1838" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F813befc8-72c0-45fc-9568-b9bc5ca9a69d_2250x2840.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design">A Crash Course on Domain-Driven Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/tidying-code">"Tidying" Code</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">A Crash Course on Relational Database Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">A Crash Course on Distributed Systems</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">A Crash Course in Database Scaling Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>What is a Load Balancer? </h2><p>A load balancer is a device or software application that distributes network or application traffic across multiple servers. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4ec75d1-6996-40d7-971e-ba67a59a204a_1536x1536.gif" title="graphical user interface" /><div></div></div></a></figure></div><ul><li><p>What Does a Load Balancer Do? <br />1. Distributes Traffic <br />2. Ensures Availability and Reliability <br />3. Improves Performance <br />4. Scales Applications <br /></p></li><li><p>Types of Load Balancers <br />1. Hardware Load Balancers: These are physical devices designed to distribute traffic across servers. <br /> <br />2. Software Load Balancers: These are applications that can be installed on standard hardware or virtual machines. <br /> <br />3. Cloud-based Load Balancers: Provided by cloud service providers, these load balancers are integrated into the cloud infrastructure. Examples include AWS Elastic Load Balancer, Google Cloud Load Balancing, and Azure Load Balancer. <br /> <br />4. Layer 4 Load Balancers (Transport Layer): Operate at the transport layer (OSI Layer 4) and make forwarding decisions based on IP address and TCP/UDP ports. <br /> <br />5. Layer 7 Load Balancers (Application Layer): Operate at the application layer (OSI Layer 7) . <br /> <br />6. Global Server Load Balancing (GSLB): Distributes traffic across multiple geographical locations to improve redundancy and performance on a global scale.</p></li></ul><div><hr /></div><h2>Top 10 k8s Design Patterns </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F820fba4c-56d0-4a18-8203-accc2c405d03_1536x1536.gif" title="graphical user interface" /><div></div></div></a></figure></div><ul><li><p>Foundational Patterns <br />These patterns are the fundamental principles for applications to be automated on k8s, regardless of the application's nature. <br /> <br />1. Health Probe Pattern <br />This pattern requires that every container must implement observable APIs for the platform to manage the application. <br /> <br />2. Predictable Demands Pattern <br />This pattern requires that we should declare application requirements and runtime dependencies. Every container should declare its resource profile. <br /> <br />3. Automated Placement Pattern <br />This pattern describes the principles of Kubernetes&#8217; scheduling algorithm. <br /></p></li><li><p>Structural Patterns <br />These patterns focus on structuring and organizing containers in a Pod. <br /> <br />4. Init Container Pattern <br />This pattern has a separate life cycle for initialization-releated tasks. <br /> <br />5. Sidecar Pattern <br />This pattern extends a container&#8217;s functionalities without changing it. <br /></p></li><li><p>Behavioral Patterns <br />These patterns describe the life cycle management of a Pod. Depending on the type of the workload, it can run as a service or a batch job. <br /> <br />6. Batch Job Pattern <br />This pattern is used to manage isolated atomic units of work. <br /> <br />7. Stateful Service Pattern <br />This pattern creates distributed stateful applications. <br /> <br />8. Service Discovery Pattern <br />This pattern describes how clients discover the services. <br /></p></li><li><p>Higher-Level Patterns <br />These patterns focus on higher-level application management. <br /> <br />9. Controller Pattern <br />This pattern monitors the current state and reconciles with the declared target state. <br /> <br />10. Operator Pattern <br />This pattern defines operational knowledge in an algorithmic and automated form. </p></li></ul><p>Reference: developers.redhat. com/blog/2020/05/11/top-10-must-know-kubernetes-design-patterns</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:sponsorship@bytebytego.com">sponsorship@bytebytego.com</a></strong><br /> </p>
]]></content:encoded>
<pubDate>Sat, 03 Aug 2024 15:31:05 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Domain-Driven Design</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design</guid>
<content:encoded><![CDATA[
<div> 领域驱动设计，模型，业务逻辑，软件开发，可维护，可扩展<br />
领域驱动设计是一种软件开发方法，强调将主要关注点放在核心领域上，并基于该领域的模型构建复杂设计。通过建立技术和领域专家之间的合作关系，可以更好地理解和呈现业务概念、规则和流程。在当今微服务和云计算架构盛行的时代，没有清晰和明确定义的领域模型指导设计的系统容易变成“大球形泥块”。领域驱动设计帮助我们建立与核心领域和业务逻辑相一致的、更具可维护性和可扩展性的系统。 <br /><br />总结:领域驱动设计强调将主要关注点放在核心领域上，重视领域模型的建立，促进技术和领域专家的合作，有助于构建更具可维护性和可扩展性的系统。 <div>
<p>Developing software for complex domains is a challenging task.&nbsp;</p><p>As the complexity of the problem domain grows, it becomes increasingly difficult to create software that accurately represents the business concepts, rules, and processes. Poorly designed software can quickly turn into an incomprehensible tangle of code that is difficult to understand, maintain, and extend.</p><p>Domain-Driven Design (DDD) offers a solution to this problem.</p><p>DDD is an approach to software development that tackles domain complexity by emphasizing the importance of modeling the core domain and business logic and using those models as the foundation for software design.</p><p>At its heart, Domain-Driven Design is about:</p><ul><li><p>Placing the primary focus on the core domain.</p></li><li><p>Basing complex designs on a model of the domain</p></li><li><p>Building collaboration between technical and domain experts.</p></li></ul><p>The need for Domain-Driven Design has become more pressing in recent years. Architectures based on microservices and cloud computing have resulted in systems composed of numerous small components that interact in intricate ways. Without a clear and well-defined model of the domain guiding their design, such systems can quickly become a "big ball of mud".&nbsp;</p><p>In this article, we&#8217;ll understand the basics of Domain-Driven Design and its key concepts that can help us build more maintainable and extensible systems that are aligned with the core domain and business logic.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F813befc8-72c0-45fc-9568-b9bc5ca9a69d_2250x2840.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1838" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F813befc8-72c0-45fc-9568-b9bc5ca9a69d_2250x2840.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-domain-driven-design">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 01 Aug 2024 15:31:02 GMT</pubDate>
</item>
<item>
<title>EP122: API Gateway 101</title>
<link>https://blog.bytebytego.com/p/ep122-api-gateway-101</link>
<guid>https://blog.bytebytego.com/p/ep122-api-gateway-101</guid>
<content:encoded><![CDATA[
<div> Session JWT API Gateway Pub-Sub ETL

<br /><br />总结:
本文介绍了系统设计中的一些重要概念和模式。首先讲解了Session和JWT之间的差异，接着介绍了9种用于数据和通信流的架构模式，包括API Gateway、Pub-Sub、ETL等。文章还详细解释了为什么CDN如此受欢迎，以及全栈开发的技术栈。最后，介绍了ScyllaDB，并推荐了相关资源。整体来说，本文提供了丰富的系统设计知识，对于想深入了解系统设计的读者是一份有价值的参考资料。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Session Vs JWT: The Differences You May Not Know! (Youtube video)</p></li><li><p>Top 9 Architectural Patterns for Data and Communication Flow </p></li><li><p>API Gateway 101 </p></li><li><p>Why are Content Delivery Networks (CDN) so Popular? </p></li><li><p>A Roadmap for Full-Stack Development</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/ScyllaDB_072724">Learn ScyllaDB from Discord Engineer Bo Ingram [FREE BOOK] (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/ScyllaDB_072724" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b65ca93-39bc-4a25-8aa2-a6be2e8eebac_1600x840.png" width="1456" /><div></div></div></a></figure></div><p>Get practical tips for building low latency, high throughput apps with ScyllaDB</p><p><em>ScyllaDB in Action</em> is a practical guide to everything you need to know about ScyllaDB, from your first queries to running it in a production environment. It&#8217;s written by Discord Staff Engineer Bo Ingram, author of the famous blog on how Discord migrated trillions of messages from Cassandra to ScyllaDB.&nbsp;</p><p>This early access preview covers:</p><ul><li><p>Working with ScyllaDB vs. working with other databases</p></li><li><p>How ScyllaDB runs in practice</p></li><li><p>What matters most in real-world deployments</p></li><li><p>How to launch your first cluster, add tables, and run queries</p></li><li><p>How to perform effective data modeling in ScyllaDB</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/ScyllaDB_072724"><span>Free Book Download</span></a></p><div><hr /></div><h2>Session Vs JWT: The Differences You May Not Know!</h2><div class="youtube-wrap" id="youtube2-fyTxwIa-1U0"><div class="youtube-inner"></div></div><div><hr /></div><h2>Top 9 Architectural Patterns for Data and Communication Flow </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8725cbb8-4c30-413c-b623-4ca9e235f6d0_1280x1664.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ul><li><p>Peer-to-Peer <br />The Peer-to-Peer pattern involves direct communication between two components without the need for a central coordinator. <br /></p></li><li><p>API Gateway <br />An API Gateway acts as a single entry point for all client requests to the backend services of an application. <br /></p></li><li><p>Pub-Sub <br />The Pub-Sub pattern decouples the producers of messages (publishers) from the consumers of messages (subscribers) through a message broker. <br /> </p></li><li><p>Request-Response <br />This is one of the most fundamental integration patterns, where a client sends a request to a server and waits for a response. <br /></p></li><li><p>Event Sourcing <br />Event Sourcing involves storing the state changes of an application as a sequence of events. <br /></p></li><li><p>ETL <br />ETL is a data integration pattern used to gather data from multiple sources, transform it into a structured format, and load it into a destination database. <br /></p></li><li><p>Batching <br />Batching involves accumulating data over a period or until a certain threshold is met before processing it as a single group. <br /></p></li><li><p>Streaming Processing <br />Streaming Processing allows for the continuous ingestion, processing, and analysis of data streams in real-time. <br /></p></li><li><p>Orchestration <br />Orchestration involves a central coordinator (an orchestrator) managing the interactions between distributed components or services to achieve a workflow or business process.</p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="802" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9e76434-5699-479f-8731-c287002e1cd4_1600x881.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/tidying-code">"Tidying" Code</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">A Crash Course on Relational Database Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">A Crash Course on Distributed Systems</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">A Crash Course in Database Scaling Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">A Crash Course in Database Sharding</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>API Gateway 101 </h2><p>An API gateway is a server that acts as an API front-end, receiving API requests, enforcing throttling and security policies, passing requests to the back-end service, and then returning the appropriate result to the client. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="785.87" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdaa3f829-4026-4c5e-bc42-59417bf64f86_800x883.gif" title="graphical user interface, application" width="712" /><div></div></div></a></figure></div><p>It is essentially a middleman between the client and the server, managing and optimizing API traffic. <br /> <br />Key Functions of an API Gateway:</p><ul><li><p>Request Routing: Directs incoming API requests to the appropriate backend service. </p></li><li><p>Load Balancing: Distributes requests across multiple servers to ensure no single server is overwhelmed. </p></li><li><p>Security: Implements security measures like authentication, authorization, and data encryption. </p></li><li><p>Rate Limiting and Throttling: Controls the number of requests a client can make within a certain period. </p></li><li><p>API Composition: Combines multiple backend API requests into a single frontend request to optimize performance. </p></li><li><p>Caching: Stores responses temporarily to reduce the need for repeated processing.</p></li></ul><div><hr /></div><h2>Why are Content Delivery Networks (CDN) so Popular? </h2><p>The CDN market is expected to reach nearly $38 billion by 2028. Companies like Akamai, Cloudflare, and Amazon CloudFront are investing heavily in this area. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1563" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F057a34e5-b671-414a-a54c-c68a1e96a3de_1280x1563.gif" title="diagram" width="1280" /><div></div></div></a></figure></div><p>There are several factors behind the popularity of CDNs </p><ol><li><p>The Impact of CDN <br />CDNs improve performance, increase availability, and enhance bandwidth costs. With the use of CDN, there is a significant reduction in latency. </p><p></p></li><li><p>CDN Request Flow <br />After DNS resolution, the user&#8217;s device sends the content request to the CDN edge server. <br />The edge server checks its local cache for the content. If found, the edge server serves the content to the user. <br />If not found, the edge server forwards the request to the origin server. <br />After receiving the content from the origin server, the edge server stores a copy in its cache and delivers it to the user. <br /></p></li><li><p>The Architecture of CDN <br />There are multiple components in a CDN&#8217;s architecture: <br /> <br />Origin Server: This is the primary source of content. <br />Edge Servers: They cache and server content to the users and are distributed across the world. <br />DNS: The DNS resolves the domain name to the IP address of the nearest edge server <br />Control Plane: Responsible for configuring and managing the edge servers. </p><p></p></li><li><p>CDN Request Routing <br />GSLB: Routes user requests to the server based on factors like geographic proximity, server load, network conditions <br />Anycast DNS: Allows multiple servers to share the same IP address. It helps route incoming traffic to the nearest data center. <br />Internet Exchange Points: CDN providers establish a presence at major IXPs, allowing them to exchange traffic directly with ISPs and other networks. <br /></p></li><li><p>Best Practices <br />Some key best practices to optimize CDN performance are related to security aspects, caching optimizations, and content optimizations. <br /></p></li></ol><p>Over to you: What do you think makes CDNs popular?</p><div><hr /></div><h2>A Roadmap for Full-Stack Development</h2><p>A full-stack developer needs to be proficient in a wide range of technologies and tools across different areas of software development. Here&#8217;s a comprehensive look at the technical stacks required for a full-stack developer. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="826.265" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6138c1f4-4c94-47b4-b3b0-9e6764e368e9_800x913.gif" title="graphical user interface, application" width="724" /><div></div></div></a></figure></div><ol><li><p>Frontend Development <br />Frontend development involves creating the user interface and user experience of a web application. </p></li><li><p>Backend Development <br />Backend development involves managing the server-side logic, databases, and integration of various services. </p></li><li><p>Database Development <br />Database development involves managing data storage, retrieval, and manipulation. </p></li><li><p>Mobile Development <br />Mobile development involves creating applications for mobile devices. </p></li><li><p>Cloud Computing <br />Cloud computing involves deploying and managing applications on cloud platforms. </p></li><li><p>UI/UX Design <br />UI/UX design involves designing the user interface and experience of applications. </p></li><li><p>Infrastructure and DevOps <br />Infrastructure and DevOps involve managing the infrastructure, deployment, and continuous integration/continuous delivery (CI/CD) of applications.</p></li></ol><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:sponsorship@bytebytego.com">sponsorship@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 27 Jul 2024 15:30:25 GMT</pubDate>
</item>
<item>
<title>"Tidying" Code</title>
<link>https://blog.bytebytego.com/p/tidying-code</link>
<guid>https://blog.bytebytego.com/p/tidying-code</guid>
<content:encoded><![CDATA[
<div> 敏捷，重构，Kent Beck，TDD，书籍

敏捷开发领域著名人物Kent Beck最新著作《Tidy First》介绍了代码重构的重要性。文章介绍了Kent在软件行业的重要贡献，包括签署敏捷宣言、推动测试驱动开发等实践。他曾在多家知名公司工作，并且积极撰写有关软件设计和开发的新闻。文章还描述了作者与Kent交流讨论书籍内容的经历。Kent提及他19年前就开始构思《Tidy First》，强调代码整洁对软件开发的重要性。总结：文章介绍了敏捷软件开发领域的重要人物Kent Beck及其新书《Tidy First》，强调了代码重构在软件开发中的重要性，突出了作者对此书的热切期盼。 <div>
<p>I&#8217;ve found my new favorite book on refactoring code. It&#8217;s &#8220;<a href="https://www.amazon.com/Tidy-First-Personal-Exercise-Empirical/dp/1098151240/">Tidy First?</a>&#8221; by Kent Beck.</p><p>Kent Beck is a renowned figure in the software industry. One of Kent&#8217;s notable contributions is his role as a signatory of the Agile Manifesto that was created in 2001 and laid the foundation for the agile software development methodology.</p><p>Kent has also been a key figure in the industry&#8217;s rediscovery of test-driven development (TDD). TDD is a software development practice that emphasizes writing tests before writing the code.</p><p>Throughout his career, Kent has worked at several prominent companies, including Facebook, Apple Computer, and Gusto. In addition to his professional work, Kent is also an active writer. He publishes a newsletter titled &#8220;<a href="https://tidyfirst.substack.com/bytebytego">Software Design: Tidy First?</a>&#8221; which explores various aspects of software design and development. For readers interested in subscribing, here is a <a href="https://tidyfirst.substack.com/bytebytego">20% discount offer</a>.</p><p>Recently, I had the opportunity to meet Kent and talk about his book &#8220;Tidy First&#8221;.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6ea57ee-22dc-43a6-ada7-a4a60275e5d1_1200x1600.jpeg" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6ea57ee-22dc-43a6-ada7-a4a60275e5d1_1200x1600.jpeg" width="1200" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Story of Tidy First&nbsp;</h2><p>I came to learn from Kent that the idea of the book Tidy First came to him around 19 years ago.</p>
      <p>
          <a href="https://blog.bytebytego.com/p/tidying-code">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 25 Jul 2024 15:31:02 GMT</pubDate>
</item>
<item>
<title>How Stripe Scaled to 5 Million Database Queries Per Second</title>
<link>https://blog.bytebytego.com/p/how-stripe-scaled-to-5-million-database</link>
<guid>https://blog.bytebytego.com/p/how-stripe-scaled-to-5-million-database</guid>
<content:encoded><![CDATA[
<div> Stripe, DocDB, Data Movement Platform, Sharding, 数据迁移
<br />
<br />
总结:Stripe的DocDB和Data Movement Platform对实现99.999%的可用性及零停机数据迁移起到了关键作用。DocDB扩展了MongoDB社区版，通过分片来横向扩展数据库，并使用Data Movement Platform实现跨分片在线迁移。迁移过程包括注册、数据导入、异步复制、检查正确性、流量切换和注销，均经过仔细规划和实施。 Data Movement Platform不仅支持数据迁移，还用于拆分DocDB分片、优化数据库基础架构等。Stripe的基础设施架构展现了其技术实力和可靠性。 <div>
<h2><a href="https://bit.ly/WorkOS_072324">WorkOS: modern identity platform for B2B SaaS (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/WorkOS_072324" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="763" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3fcf8b91-ac0f-4e95-9215-449469ef555f_1600x838.png" width="1456" /><div></div></div></a></figure></div><p>Start selling to enterprises with just a few lines of code.</p><p>&#8594; WorkOS provides a complete User Management solution along with SSO, SCIM, RBAC, &amp; FGA.</p><p>&#8594; Unlike other auth providers that rely on user-centric models, WorkOS is designed for B2B SaaS with an org modeling approach.</p><p>&#8594; The APIs are flexible, easy-to-use, and modular. Pick and choose what you need and integrate in minutes.</p><p>&#8594; Best of all, User Management is free up to 1 million MAUs&nbsp;and comes standard with RBAC, bot protection, impersonation, MFA, &amp; more.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/WorkOS_072324"><span>Get started today</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the Stripe Engineering Blog. All credit for the architectural details goes to Stripe&#8217;s engineering team. The links to the original articles are present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>As of 2023, only 19 countries had a GDP surpassing $1 trillion. Also, in 2023, Stripe alone processed $1 trillion in total payment value.</p><p>To make the achievement even more remarkable, they managed these numbers while supporting 5 million database queries per second at five-nines (99.999%) of availability.</p><p>What was behind the success of Stripe&#8217;s infrastructure?</p><p>The secret lies in the horizontal scaling capabilities of their database.</p><p>Stripe&#8217;s database infrastructure team built an internal database-as-a-service (DBaaS) offering called DocDB. It was created as an extension of MongoDB&#8217;s community edition because of MongoDB&#8217;s flexibility and ability to handle a massive volume of real-time data at scale.</p><p>In this post, we&#8217;ll explore how DocDB works and the various features it provides that allow Stripe to operate at such an incredible scale.</p><div><hr /></div><h2>Why the Need for DocDB?</h2><p>The first question while looking at DocDB is this: what forced Stripe to build a DBaaS offering?</p><p>Stripe launched in 2011. At the time, they chose MongoDB as the online database because its schema-less approach made it more productive for developers than standard relational databases. MongoDB also supports horizontal scaling through its robust sharding architecture, which is shown in the diagram below:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3fab4a6-83e8-49a8-986d-d272cda54583_1600x1002.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="912" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3fab4a6-83e8-49a8-986d-d272cda54583_1600x1002.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>However, to unlock the best developer experience, Stripe needed a database service that could work like a product for the development teams. MongoDB Atlas didn&#8217;t exist in 2011 and they couldn&#8217;t find an off-the-shelf DBaaS that met key requirements such as:</p><ul><li><p>Maintain the highest standards of availability, durability, and performance.</p></li><li><p>Expose a minimal set of database functions to prevent issues from suboptimal client queries. For example, queries running on a large collection based on a specific field that does not have a corresponding index. It also includes unbounded queries on large result sets and complex aggregations.</p></li><li><p>Support horizontal scalability with sharding.</p></li><li><p>First-class support for multi-tenancy with quotas</p></li><li><p>Strong security with authorization policies.</p></li></ul><p>The solution was to build DocDB with MongoDB as the underlying storage engine. The DocDB deployment was also highly customized to provide low latency and diverse access. Some interesting stats related to DocDB are as follows:</p><ul><li><p>It supports over 10,000 distinct query types that run over petabytes of important financial data.</p></li><li><p>The data is spread across 5000+ collections.</p></li><li><p>The collections are distributed over 2000 database shards.</p></li></ul><p>At the heart of DocDB is the Data Movement Platform. It was originally built as a horizontal scaling solution to overcome the vertical scaling limits of MongoDB.</p><p>The Data Movement Platform made it possible to transition from running a small number of database shards (each storing tens of terabytes of data) to thousands of database shards (each with a fraction of the original data).</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F890ed9c7-5215-492d-bad2-9b637361036e_1600x1088.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="990" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F890ed9c7-5215-492d-bad2-9b637361036e_1600x1088.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The platform performs multiple functions such as:</p><ul><li><p>Handling maintenance tasks like database engine upgrades.</p></li><li><p>Transitioning databases from a multitenant arrangement to single tenancy for large users. In a multitenant database arrangement, multiple users or applications share the same resources. In contrast, single tenancy means that a user or application has dedicated database resources for better isolation, customization, and performance.</p></li><li><p>Supporting migrations with zero downtime and no impact on the clients.</p></li><li><p>Splitting database shards during traffic surges and consolidating thousands of databases through bin packing when traffic is low.</p></li></ul><p>For reference, bin packing is an optimization problem where the goal is to pack a set of objects (in this case, data) into a minimum number of bins (database shards) of a fixed capacity. The objective is to minimize the number of bins used while ensuring that the total size or weight of the objects in each bin does not exceed its capacity.</p><h2>How Applications Access DocDB?</h2><p>DocDB leverages sharding to achieve horizontal scalability for its database infrastructure. With thousands of database shards distributed across Stripe&#8217;s product applications, sharding enables efficient data distribution and parallel processing.</p><p>However, the use of database sharding introduces a challenge for applications when determining the appropriate destination shard for their queries.&nbsp;</p><p>To address this issue, Stripe&#8217;s database infrastructure team developed a fleet of database proxy servers implemented in Golang. These proxy servers handle the task of routing queries to the correct shard.</p><p>The diagram shows DocDB&#8217;s high-level infrastructure overview.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07434131-eaae-43b4-8805-b2808307eeac_1600x1160.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1056" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07434131-eaae-43b4-8805-b2808307eeac_1600x1160.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>When an application sends a query to a database proxy server, it performs the following steps:</p><ul><li><p>Parsing the query</p></li><li><p>Routing it to one or more shards</p></li><li><p>Combining the results received from the shards</p></li><li><p>Returning the final result to the application</p></li></ul><p>But how do database proxy servers make the routing decisions?</p><p>The database proxy servers rely on the chunk metadata service to make routing decisions.&nbsp;</p><p>A chunk represents a small subset of data within a larger collection. Each shard contains a fraction of the total data, and these fractions are referred to as <em>chunks</em>.</p><p>For example, consider that Stripe has a large collection called &#8220;Transactions&#8221; that contains millions of documents representing financial transactions. To scale this collection horizontally, they might split the data into chunks based on a sharding key, such as customer ID or the transaction timestamp. Each chunk would then be assigned to a specific database shard.</p><p>The chunk metadata service manages the mapping between these chunks and their corresponding shards. It keeps track of which chunk resides on which shard, allowing the proxy servers to route queries and requests to the appropriate shard.</p><h3>Data Organization in DocDB</h3><p>At Stripe, product teams use an in-house tool called the <em>document database control plane </em>to create and manage their databases. When a team provisions a new database using this tool, they are creating a &#8220;logical database.&#8221;</p><p>A logical database is like a virtual container holding one or more data collections known as DocDB collections. Each DocDB collection contains related documents that serve a specific purpose for the product team.</p><p>Even though a logical database appears as a single entity to the product team, the data within the collections is spread across multiple physical databases behind the scenes. These physical databases are the actual databases running on Stripe&#8217;s infrastructure.</p><p>The diagram below shows this arrangement:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa593f9c1-4f71-4e6a-8b38-e2775f458eee_1600x1162.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1057" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa593f9c1-4f71-4e6a-8b38-e2775f458eee_1600x1162.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Each physical database contains a small portion (or &#8220;chunk&#8221;) of the data from the DocDB collection and is deployed on a shard. The shard consists of a primary database node and several secondary database nodes. These nodes work together as a replica set.&nbsp;</p><p>The primary node handles all the write operations and replicates the data to the secondary nodes. If the primary node fails, one of the secondary nodes automatically takes over as the new primary, ensuring continuous operation and availability.&nbsp;</p><p>The diagram below shows a different representation of the database hierarchy</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd19ab03f-2b27-4da6-bcd1-5760ac535dba_2050x1194.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="848" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd19ab03f-2b27-4da6-bcd1-5760ac535dba_2050x1194.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://stripe.com/blog/how-stripes-document-databases-supported-99.999-uptime-with-zero-downtime-data-migrations">Stripe Engineering Blog</a></figcaption></figure></div><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7e87813-2921-4379-a1c9-c101092fda5d_1241x1600.png" title="" width="1241" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">A Crash Course on Relational Database Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">A Crash Course on Distributed Systems</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">A Crash Course in Database Scaling Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">A Crash Course in Database Sharding</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>The Data Movement Platform</h2><p>What&#8217;s the most important ability required to build a DBaaS platform that is horizontally scalable and highly elastic?</p><p>It&#8217;s the ability to migrate data across database shards with zero downtime and no impact on the client.&nbsp;</p><p>Stripe achieved this ability with their Data Movement Platform. The platform had a few important requirements such as:</p><ul><li><p>Ensure that the data getting migrated is consistent and complete across both the source and target shards.</p></li><li><p>Prevent a situation of prolonged downtime. Millions of businesses rely 24/7 on Stripe to accept payments from their customers.</p></li><li><p>Support the migration of an arbitrary number of chunks from any number of sources to target shards. Moreover, the migration should take place at a high throughput.</p></li><li><p>Prevent any performance impact on the source shard during the migration process.</p></li></ul><p>The diagram below shows the architecture of the Data Movement Platform:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2f3b3e-67f8-4dac-b334-a72e1c142f23_1545x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1508" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e2f3b3e-67f8-4dac-b334-a72e1c142f23_1545x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The heart of the platform is the Coordinator component, which is responsible for orchestrating the various steps involved in online data migrations.</p><h3>Step 1: Chunk Migration Registration</h3><p>The first step is registering a request to migrate database chunks from source shards to target shards.</p><p>Once the request is created, indexes are built on the target shards.&nbsp;</p><p>An index is a data structure that improves the speed of data retrieval operations on a database table or collection. Building the index first on the target shard has some advantages:50</p><ul><li><p><strong>Query Performance: </strong>By creating indexes on the target shards before data migration, Stripe ensures that the target shards are ready to handle queries efficiently as soon as the data is available. Without pre-built indexes, queries on the newly migrated data would have to perform full collection scans, leading to slower query response times until the indexes are created.</p></li><li><p><strong>Consistency: </strong>Building indexes on the target shards before data migration helps maintain consistency between the source and target shards. If indexes were created after the data migration, it would result in inconsistent query behavior for some time.</p></li><li><p><strong>Seamless Transition: </strong>Having the indexes ready on the target shards minimizes the impact on the applications and users querying the data.&nbsp;</p></li></ul><h3>Step 2: Bulk Data Import</h3><p>The next step involves using a snapshot of the chunks on the source shard at a specific point in time. This snapshot is used to load the data onto one or more target database shards.</p><p>The service performing the bulk data import accepts data filters, allowing for the selective import of chunks that satisfy the specified filtering criteria. This step initially appeared straightforward. However, Stripe&#8217;s infra team encountered throughput limitations when they tried to bulk load data onto a DocDB shard.</p><p>Efforts to address the issue by batching writes and adjusting DocDB engine parameters were not successful.</p><p>A significant breakthrough came when the team explored methods to optimize the insertion order by using the fact that DocDB organizes its data using a B-tree data structure. By sorting the data based on the most common index attributes in the collections and inserting it in sorted order, the write proximity was enhanced, resulting in a 10X boost in write throughput.</p><h3>Step 3: Async Replication</h3><p>After the bulk data import step is completed, the next step ensures that any subsequent writes or mutations that occur on the source shard after time T are replicated to the target shard.</p><p>This is where async replication comes into play.</p><p>Stripe&#8217;s async replication systems rely on the Change Data Capture (CDC) mechanism to capture and replicate the mutations from the source shards to the target shards.&nbsp;</p><p>Here&#8217;s how it works:</p><ul><li><p><strong>Operations Log (Oplog):</strong> Each DocDB shard maintains a special collection called the Oplog, which records all the operations that modify data on the shard. Wherever a write operation occurs on the source shard, it is logged in the Oplog.</p></li><li><p><strong>Oplog Transport: </strong>Oplog entries from each DocDB shard are transported to Kafka which acts as a message broker, allowing Oplog events to be consumed by downstream systems. Additionally, these events are archived in a cloud object storage service like Amazon S3 for durability and long-term storage.</p></li><li><p><strong>Replication Service: </strong>Stripe built a dedicated service to handle the replication of mutations from the source shards to the target shards. This service consumes Oplog events from Kafka and S3 and applies the corresponding writes to the target shards. By relying on Oplog events from the CDC systems, the replication service avoids impacting the performance of user queries on the source shard. It doesn&#8217;t consume read throughput on the source shard, which would otherwise be available for serving user queries.</p></li><li><p><strong>Bidirectional Replication: </strong>Mutations are replicated bidirectionally, meaning that writes are replicated from the source shards to the target shards and vice versa. This is done to provide flexibility in case there is a need to revert traffic to the source shards if any issues arise when directing traffic to the target shards.</p></li></ul><h3>Step 4: Correctness Check</h3><p>After the replication sync between the source and target shard, the Coordinator conducts a comprehensive check for data completeness and correctness.</p><p>This is done by comparing point-in-time snapshots. It was a deliberate design choice to avoid impacting the shard&#8217;s throughput.</p><h3>Step 5: Traffic Switch</h3><p>The next step is to switch the traffic of incoming requests from the source shard to the target shard.</p><p>The Coordinator orchestrates the traffic switch after the data is imported to the target shard and the mutations are replicated. The process consists of three steps:</p><ul><li><p>Stop the traffic on the source shard for a brief period</p></li><li><p>Update the routes in the chunk metadata service</p></li><li><p>Make the proxy server redirect reads and writes to the target shards.</p></li></ul><p>The traffic switch protocol uses the concept of versioned gating.&nbsp;</p><p>To support this, the infra team added a custom patch to MongoDB that allows a shard to enforce a version number check before serving a request. Each proxy server annotates requests to the DocDB shard with a version token number. The shard first checks the version token number and serves the request only if the token number is newer than the earlier one.</p><p>The diagram below shows the detailed process flow for the traffic switch protocol:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77bbaf29-d872-4580-a3ae-63b3aa50ef38_1600x1023.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="931" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77bbaf29-d872-4580-a3ae-63b3aa50ef38_1600x1023.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s how the process works:</p><ul><li><p>The version token number is stored in a document in a special collection in DocDB. They increase the token number on the source DocDB shard. This allows all reads and writes on the chunk on the source shard to be rejected.</p></li><li><p>Then, they wait for the replication service to replicate any outstanding writes on the source.</p></li><li><p>Once the replication is over, they update the route for the chunk to point to the target shard. Also, the version token number in the chunk metadata service is updated.</p></li><li><p>The proxy servers fetch the updated routes for the chunk along with the most up-to-date token number from the chunk metadata service. Using the updated routes, the proxy servers route the traffic to the target shard.</p></li></ul><p>The entire traffic switch protocol takes less than two seconds to execute. Any failed reads and writes to the source shard succeed on retries that go to the target shard.</p><h3>Step 6: Chunk Migration Deregistration</h3><p>Finally, the migration process is concluded by marking the migration as complete in the chunk metadata service.</p><p>Also, the chunk data is dropped from the source shard to reclaim the resources.</p><h2>Conclusion</h2><p>Stripe&#8217;s custom-built database-as-a-service, DocDb, and its Data Movement Platform have been instrumental in achieving 99.999% uptime while enabling zero-downtime data migrations.</p><p>Some key takeaways are as follows:</p><ul><li><p>DocDB extends the MongoDB Community edition to provide a highly available and scalable database solution.</p></li><li><p>Sharding is employed to horizontally scale the database, with data distributed across thousands of shards.</p></li><li><p>The Data Movement Platform enables online migrations across shards while ensuring data consistency, availability, and adaptability.</p></li><li><p>The six-step migration process consists of chunk migration registration, bulk data import, async replication, correctness checks, traffic switching, and chunk migration deregistration.</p></li><li><p>The Data Movement Platform is used for various purposes such as splitting DocDB shards for size and throughput, bin-packing underutilized databases, and upgrading the database infrastructure fleet.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://stripe.com/blog/how-stripes-document-databases-supported-99.999-uptime-with-zero-downtime-data-migrations">How Stripe&#8217;s Document Databases Supported 99.999% uptime with zero downtime data migrations?</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/Bin_packing_problem">Bin Packing Problem</a></p></li><li><p><a href="https://www.mongodb.com/resources/products/capabilities/sharding">What is MongoDB Sharding?</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p><br /><br /><br /><br /><br /><br /></p><p></p>
]]></content:encoded>
<pubDate>Tue, 23 Jul 2024 15:30:54 GMT</pubDate>
</item>
<item>
<title>EP121: 9 Essential Components of a Production Microservice Application</title>
<link>https://blog.bytebytego.com/p/ep121-9-essential-components-of-a</link>
<guid>https://blog.bytebytego.com/p/ep121-9-essential-components-of-a</guid>
<content:encoded><![CDATA[
<div> Linux Crash Course, Production Microservice Application, Design Patterns, Software Development Life Cycle, Sponsorship  
总结：<br /><br />本文介绍了Linux系统设计面试，并深入讲解了文件权限的理解。接着详细介绍了生产微服务应用的9个关键组件，包括API网关、服务注册表、服务层、授权服务器、数据存储、分布式缓存、异步微服务通信、度量可视化以及日志聚合和可视化。接着是软件开发生命周期的不同模型介绍，如瀑布模型、敏捷模型、V模型、迭代模型、螺旋模型等。最后介绍了设计模式的小抄，包括工厂模式、建造者模式、原型模式、单例模式等。最后，文章提及了赞助机会，可以将产品推广给100万以上的技术专业人士。 <div>
<p>This week&#8217;s system design interview:</p><ul><li><p>Linux Crash Course - Understanding File Permissions (Youtube video)</p></li><li><p>9 Essential Components of a Production Microservice Application </p></li><li><p>Iterative, Agile, Waterfall, Spiral Model, RAD Model... What are the differences?</p></li><li><p>Design Patterns Cheat Sheet - Part 1 and Part 2 </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/QAWolf_072024">&#9986;&#65039;Cut your QA cycles down to minutes with automated testing (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_072024" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="736" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F090fca3b-6480-4321-b93f-c3a80486dd1a_1473x745.png" title="" width="1456" /><div></div></div></a></figure></div><p>Are slow test cycles bottlenecking your dev teams&#8217; release velocity? With QA Wolf, your organization can run entire test suites in minutes for faster feedback and developer confidence to ship.</p><p><a href="https://bit.ly/QAWolf_072024">QA Wolf</a> takes testing off your plate. They can get you:</p><ul><li><p><a href="https://bit.ly/QAWolf_071324Head">80% automated test coverage in weeks</a>&#8212;not years</p></li><li><p><a href="https://bit.ly/QAWolf_072024">Unlimited parallel test runs</a></p></li><li><p>24-hour maintenance and on-demand test creation</p></li><li><p>Zero flakes, guaranteed</p></li></ul><p>The benefit? No more manual E2E testing. No more slow QA cycles. No more bugs reaching production.</p><p>With QA Wolf, <a href="https://bit.ly/QAWolf_072024CaseStudy">Drata&#8217;s team of 80+ engineers</a> achieved 4x more test cases and 86% faster QA cycles.</p><p><strong>&#127775;</strong>Rated 4.8/5 on G2</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_072024"><span>Schedule a demo to learn more</span></a></p><div><hr /></div><h2>Linux Crash Course - Understanding File Permissions</h2><div class="youtube-wrap" id="youtube2-4N4Q576i3zA"><div class="youtube-inner"></div></div><div><hr /></div><h2>9 Essential Components of a Production Microservice Application </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ccf7c0-51e8-4243-953d-37ccd28df10e_1329x1536.gif" title="diagram" width="1329" /><div></div></div></a></figure></div><ol><li><p>API Gateway <br />The gateway provides a unified entry point for client applications. It handles routing, filtering, and load balancing. <br /></p></li><li><p>Service Registry <br />The service registry contains the details of all the services. The gateway discovers the service using the registry. For example, Consul, Eureka, Zookeeper, etc. <br /></p></li><li><p>Service Layer <br />Each microservices serves a specific business function and can run on multiple instances. These services can be built using frameworks like Spring Boot, NestJS, etc. <br /></p></li><li><p>Authorization Server <br />Used to secure the microservices and manage identity and access control. Tools like Keycloak, Azure AD, and Okta can help over here. <br /></p></li><li><p>Data Storage <br />Databases like PostgreSQL and MySQL can store application data generated by the services. <br /></p></li><li><p>Distributed Caching <br />Caching is a great approach for boosting the application performance. Options include caching solutions like Redis, Couchbase, Memcached, etc. <br /></p></li><li><p>Async Microservices Communication <br />Use platforms such as Kafka and RabbitMQ to support async communication between microservices. <br /></p></li><li><p>Metrics Visualization <br />Microservices can be configured to publish metrics to Prometheus and tools like Grafana can help visualize the metrics. <br /></p></li><li><p>Log Aggregation and Visualization <br />Logs generated by the services are aggregated using Logstash, stored in Elasticsearch, and visualized with Kibana. <br /></p></li></ol><p>Over to you: What else would you add to your production microservice architecture?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7e87813-2921-4379-a1c9-c101092fda5d_1241x1600.png" width="1241" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">A Crash Course on Relational Database Design</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">A Crash Course on Distributed Systems</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">A Crash Course in Database Scaling Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">A Crash Course in Database Sharding</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>Iterative, Agile, Waterfall, Spiral Model, RAD Model... What are the differences?</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853579e5-3dc8-4746-9da3-4f25d7be44a2_1514x1536.gif" title="No alternative text description for this image" /><div></div></div></a></figure></div><p>The Software Development Life Cycle (SDLC) is a framework that outlines the process of developing software in a systematic way. Here are some of the most common ones: </p><ol><li><p>Waterfall Model: <br />- A linear and sequential approach. <br />- Divides the project into distinct phases: Requirements, Design, Implementation, Verification, and Maintenance. <br /></p></li><li><p>Agile Model: <br />- Development is done in small, manageable increments called sprints. <br />- Common Agile methodologies include Scrum, Kanban, and Extreme Programming (XP). <br /></p></li><li><p>V-Model (Validation and Verification Model): <br />- An extension of the Waterfall model. <br />- Each development phase is associated with a testing phase, forming a V shape. <br /></p></li><li><p>Iterative Model: <br />- Focuses on building a system incrementally. <br />- Each iteration builds upon the previous one until the final product is achieved. <br /></p></li><li><p>Spiral Model: <br />- Combines iterative development with systematic aspects of the Waterfall model. <br />- Each cycle involves planning, risk analysis, engineering, and evaluation. <br /></p></li><li><p>Big Bang Model: <br />- All coding is done with minimal planning, and the entire software is integrated and tested at once. <br /></p></li><li><p>RAD Model (Rapid Application Development): <br />- Emphasizes rapid prototyping and quick feedback. <br />- Focuses on quick development and delivery. <br /></p></li><li><p>Incremental Model: <br />- The product is designed, implemented, and tested incrementally until the product is finished. </p></li></ol><p>Each of these models has its advantages and disadvantages, and the choice of which to use often depends on the specific requirements and constraints of the project at hand.</p><div><hr /></div><h2>Design Patterns Cheat Sheet - Part 1 and Part 2 </h2><p>The cheat sheet briefly explains each pattern and how to use it. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="2002" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e6d06c7-9947-4525-a5f0-3b92f7d76691_1280x2002.jpeg" title="diagram" width="1280" /><div></div></div></a></figure></div><p>What's included? </p><ul><li><p>Factory </p></li><li><p>Builder </p></li><li><p>Prototype </p></li><li><p>Singleton </p></li><li><p>Chain of Responsibility </p></li><li><p>And many more!</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 1,000,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 20 Jul 2024 15:30:46 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Relational Database Design</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-relational-database</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-relational-database</guid>
<content:encoded><![CDATA[
<div> 关键词：关系数据库，数据管理，数据库设计，规范化，索引

总结:<br /><br />关系数据库在今天的数据驱动世界中扮演着至关重要的角色，它提供了一个结构化的框架，用于存储和检索数据，并基于实体之间定义的关系进行操作。有效的数据库设计是优化性能，确保数据完整性，促进高效数据检索的关键。数据库设计原则如规范化、索引、连接和关系，在创建结构良好、高效的数据库中扮演着重要的角色。通过掌握关系数据库的关键概念、管理系统以及有效数据库设计的原则，可以帮助企业和组织更好地利用数据获取有意义的见解。 <div>
<p>In today's data-driven world, efficient storage and management of information are critical requirements for businesses and organizations of all sizes.</p><p>Relational databases provide a robust framework for storing and retrieving data based on well-defined relationships between entities. They offer a structured approach to data management, enabling users to:</p><ul><li><p>Define tables&nbsp;</p></li><li><p>Establish relationships</p></li><li><p>Perform complex queries to extract meaningful insights from the stored information</p></li></ul><p>However, just using a relational database is not enough to gain its benefits.&nbsp;</p><p>Effective database design is crucial for optimizing performance, ensuring data integrity, and facilitating efficient data retrieval. The principles of database design, such as normalization, indexing, joins, and relationships, play a vital role in creating a well-structured and performant database.</p><p>In this post, we&#8217;ll look at the fundamentals of relational databases, exploring their key concepts, management systems, and the principles that underpin effective database design.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7e87813-2921-4379-a1c9-c101092fda5d_1241x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7e87813-2921-4379-a1c9-c101092fda5d_1241x1600.png" width="1241" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-relational-database">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 18 Jul 2024 15:31:12 GMT</pubDate>
</item>
<item>
<title>Where to get started with GenAI</title>
<link>https://blog.bytebytego.com/p/where-to-get-started-with-genai</link>
<guid>https://blog.bytebytego.com/p/where-to-get-started-with-genai</guid>
<content:encoded><![CDATA[
<div> Generative AI, Terminologies, Model APIs, Building Applications, RAG  
总结:  
理解人工智能术语，包括AI、机器学习、自然语言处理、深度学习等。学习使用模型API构建应用程序。建立AI模型，例如RAG和微调模型，以满足特定领域需求。探索GenAI应用程序，如内容创作、客户支持、商业金融和教育。集成LLM提供的外部信息源，通过RAG技术生成更准确的回应。通过微调模型，优化AI模型，提高在特定领域任务中的性能。 <div>
<h2>Introduction to Generative AI</h2><p>The world of Generative AI (GenAI) is moving at a breakneck pace.&nbsp;</p><p>New models, techniques, and applications emerge every day, pushing the boundaries of what's possible with artificial intelligence.&nbsp;</p><p>Considering this fast-evolving landscape, developers and technology professionals need to keep their skills sharp and stay ahead of the curve.</p><p>To help you get started with GenAI, <a href="https://www.linkedin.com/in/pvergadia/">Priyanka Vergadia</a> and I have put together a concise guide covering essential steps, including:</p><ul><li><p>Understanding the terminologies</p></li><li><p>Using the Model APIs</p></li><li><p>Building applications using the AI Models</p></li><li><p>Making models your own:</p><ul><li><p>RAG&nbsp;</p></li><li><p>Fine-Tuning AI models</p></li></ul></li></ul><p>Here&#8217;s a sneak peek at all the cool topics we will cover.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c132d99-646b-4593-913c-9f136388e088_1600x1493.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1359" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c132d99-646b-4593-913c-9f136388e088_1600x1493.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Let&#8217;s start with the first step.</p><p><em>Also, don't forget to follow <a href="https://www.linkedin.com/in/pvergadia/">Priyanka Vergadia&#8217;s LinkedIn</a>, which is a must-read for anyone working on cloud and GenAI.</em></p><div><hr /></div><h2>Understanding the GenAI Terminologies</h2><p>One of the biggest obstacles to getting started with GenAI is not understanding the basic terminologies.</p><p>Let&#8217;s cover the most important things to know about.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a64c9fb-afaf-46d7-aabc-ca34adb17649_1600x1200.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1092" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6a64c9fb-afaf-46d7-aabc-ca34adb17649_1600x1200.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Artificial Intelligence</h3><p>AI refers to the development of computer systems that can perform tasks that typically require human intelligence. It is a discipline like Physics.</p><p>It encompasses various subfields, such as Machine Learning, Natural Language Processing, Computer Vision, etc.</p><p>AI systems can be narrow (focused on specific tasks) or general (able to perform a wide range of tasks).</p><h3>Machine Learning</h3><p>Machine Learning is a subset of AI that focuses on enabling computers to learn and improve from experience without being explicitly programmed.</p><p>It involves training models on data to recognize patterns, make predictions, or take actions. There are three main types of ML:</p><ul><li><p>Supervised Learning</p></li><li><p>Unsupervised Learning</p></li><li><p>Reinforcement Learning.</p></li></ul><p>Lastly, there is Deep Learning, which uses artificial neural networks and is a subfield of Machine Learning.</p><p>The diagram below shows the key difference between a typical machine learning workflow and Deep Learning.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5caed1b-24bb-4d93-9ebf-59b9725f6b1a_1600x1200.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1092" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5caed1b-24bb-4d93-9ebf-59b9725f6b1a_1600x1200.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Natural Language Processing (NLP)</h3><p>NLP is a subfield of AI that focuses on enabling computers to understand, interpret, and generate human language.</p><p>It involves tasks such as text classification, sentiment analysis, entity recognition, machine translation, and text generation.</p><p>Deep learning models, particularly Transformer models, have revolutionized NLP in recent years.</p><h3>Transformer Models</h3><p>Transformer models are a type of deep learning model architecture introduced in the famous paper &#8220;Attention is All You Need&#8221; in 2017.</p><p>They rely on self-attention mechanisms to process and generate sequential data, such as text.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9de37a4-8d3b-422f-b74e-09de5d9ee5b5_1600x1384.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1259" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9de37a4-8d3b-422f-b74e-09de5d9ee5b5_1600x1384.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Transformers have become the foundation for state-of-the-art models in NLP, such as BERT, GPT, and T5. They have also been adapted for other domains, like computer vision and audio processing.</p><h3>GenAI</h3><p>GenAI, short for Generative Artificial Intelligence, refers to AI systems that can generate new content, such as text, images, or music. It can be considered a subset of Deep Learning.</p><p>GenAI models can generate novel and coherent outputs that resemble the training data. They use machine learning models, particularly deep learning models, to learn patterns and representations from existing data.</p><p>NLP is a key area of focus within GenAI, as it deals with generating and understanding human language. Transformer models have become the backbone of many GenAI systems, particularly language models.&nbsp;</p><p>The ability of Transformers to learn rich representations and generate coherent text has made them well-suited for GenAI applications. For reference, a transformer model is a type of neural network that excels at understanding the context of sequential data, such as text or speech, and generating new data. It uses a mechanism called &#8220;attention&#8221; to weigh the importance of different parts of the input sequence and better understand the overall context.</p><p>There are various types of GenAI Models:</p><ol><li><p>Language models that specialize in processing and generating text data. Examples include Google&#8217;s Gemini, GPT-4, Claude Opus, Llama3</p></li><li><p>Multimodal Models that can handle multiple modalities, like text, images, and audio. Examples include DALL-E, Midjourney, Stable Diffusion.</p></li><li><p>Audio Models that can generate and process speech, music, and other audio data. Examples: Google&#8217;s Imagen, Wavenet.</p></li></ol><h3>Prompt Engineering</h3><p>Prompt engineering is the practice of designing effective prompts to get desired outputs from GenAI models. It involves understanding the model&#8217;s capabilities, limitations, and biases.&nbsp;</p><p>Effective prompts provide clear instructions, relevant examples, and context to guide the model&#8217;s output.</p><p>Prompt engineering is a crucial skill for getting the most out of GenAI models.</p><h2>Using the Model APIs</h2><p>Most Generative AI (GenAI) models are accessible through REST APIs, which allow developers to integrate these powerful models seamlessly into their applications.&nbsp;</p><p>To get started, you'll need to obtain API access from the desired platform, such as Google&#8217;s Vertex AI, OpenAI, Anthropic, or Hugging Face.&nbsp;</p><p>Each platform has its process for granting API access, typically involving&nbsp;</p><ul><li><p>Signing up for an account</p></li><li><p>Creating an API key</p></li><li><p>Completing a verification or approval process.</p></li></ul><p>Once you have your API key, you can authenticate your requests to the GenAI model endpoints.&nbsp;</p><p>Authentication usually involves providing the API key in the request headers or as a parameter. It's crucial to keep your API key secure and avoid sharing it publicly.</p><p>It&#8217;s also important to follow best practices to ensure reliability and efficiency. Here are a couple of important best practices:</p><ul><li><p>Handle API errors gracefully by checking the response status code.</p></li><li><p>Optimize API usage by carefully selecting the model parameters, such as the maximum number of tokens. This is necessary to balance the desired output quality with costs.</p></li><li><p>When making API requests, be mindful of the rate limits imposed by the platform. Rate limits determine the maximum number of requests you can make within a specific time frame. Exceeding the rate limits may result in API errors or temporary access restrictions.&nbsp;</p></li><li><p>Use frameworks and libraries like Langchain to simplify the API interactions. These frameworks offer high-level abstractions and utilities for working with GenAI model APIs.</p></li></ul><h2>Building Application using the AI Model</h2><p>There are several use cases for GenAI-powered applications across various domains:</p><ul><li><p><strong>Content Creation and Marketing:</strong> GenAI applications can help create outlines for articles, ad copy generation, and product descriptions.</p></li><li><p><strong>Customer Support: </strong>AI-powered chatbots can understand user queries and provide accurate, context-aware responses.</p></li><li><p><strong>Business and Finance: </strong>GenAI applications can help generate financial reports, summaries, or analyses based on company data.</p></li><li><p><strong>Education and Learning: </strong>GenAI applications can generate customized learning material and explanations based on a student&#8217;s learning style.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bd2b569-35e8-4965-8e35-8ec55480c2ee_1600x1384.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1259" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8bd2b569-35e8-4965-8e35-8ec55480c2ee_1600x1384.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Let&#8217;s say we want to build a chatbot application that uses an LLM to provide personalized book recommendations based on user preferences.</p><p>Here are the high-level steps involved.</p><h3>1 - Choose an LLM Provider</h3><p>Research and compare different LLM providers, such as Google AI, Open AI, or a Hugging Face.&nbsp;</p><p>Before choosing, you can consider multiple factors such as pricing, availability, API documentation, and community support.</p><h3>2 - Set up the Development Environment</h3><p>Typically, the LLM providers give access to their LLM via APIs.&nbsp;</p><p>You must sign up for an API key from the chosen provider and install the necessary libraries and frameworks.</p><p>For example, if you build your application using Python, you should set up a Python project and configure the API credentials according to the best practices.</p><h3>3 - Design the Chatbot Conversation Flow</h3><p>Plan out the conversation flow for the book recommendation chatbot. Define the key questions the chatbot will ask users to gather preferences, such as favorite genres, authors, or book themes.</p><p>Determine the structure and format of the chatbot&#8217;s responses, including the recommended books and any additional information to provide.</p><h3>4 - Implement the Chatbot Application</h3><p>Use a web framework like Flask or Django to build the chatbot application.&nbsp;</p><p>Create a user interface for the chatbot, either as a web page or a messaging interface. Implement the necessary routes and views to handle user interactions and generate chatbot responses.</p><h3>5 - Integrate the LLM</h3><p>Most LLM providers have released libraries to talk to their model APIs. Initialize the model with the appropriate parameters, such as the model name, version, and temperature.</p><p>Define the prompts and instructions for the LLM to generate personalized book recommendations based on user preferences.</p><p>For example, you can create prompts like: &#8220;Recommend a science fiction book for a user who enjoys fast-paced plots and space exploration.&#8221;</p><p>Pass the user&#8217;s preferences and the prompts to the LLM using the API and retrieve the generated book recommendations.</p><h3>6 - Process and Display the Recommendations</h3><p>Process the LLM-generated book recommendations to extract the relevant information, such as book titles, authors, and descriptions.</p><p>Display the recommended books in a clear and visually appealing format. Provide options for users to interact with the recommendations, such as saving them for later or requesting more details about a specific book.</p><h3>7 - Refine and Expand</h3><p>Test the chatbot application with various user preferences and prompts to ensure it generates relevant and diverse book recommendations.</p><p>Gather user feedback and iterate on the chatbot&#8217;s conversation flow, prompts, and recommendation formatting based on suggestions.</p><p>Integrate additional features, such as providing book reviews, suggesting similar authors, and so on, to expand the chatbot's capabilities.</p><h3>8 - Deploy and Monitor</h3><p>Deploy the chatbot application to a hosting platform or cloud service provider, making it accessible to users via a web URL.</p><p>Set up monitoring and analytics to track user interactions, chatbot performance, and any errors or issues.</p><p>Regularly update the LLM prompts and application logic based on user feedback and new book releases.</p><h2>Making Models Your Own</h2><p>There is significant interest in making models more adaptable and customizable to suit the specific needs of the domain.&nbsp;</p><p>Let&#8217;s look at the main techniques to achieve this goal.</p><h3>Retrieval-Augmented Generation (RAG)</h3><p>RAG is a technique that helps improve the accuracy and relevance of the generated responses based on your use case.&nbsp;</p><p>It allows your LLM to have external information sources like your databases, documents, and even the Internet in real time. This way the LLM can get the most up-to-date and relevant information to answer the queries specific to your business.</p><p>Here&#8217;s a high-level overview of how a RAG system works:</p><ul><li><p>The user poses a question to the RAG system.</p></li><li><p>The retrieval component searches the knowledge corpus using the question as a query and retrieves the most relevant passages or documents.</p></li><li><p>The retrieved passages go through the augmentation step where this information is fed as input to the large language model. This step is crucial as it augments the model&#8217;s knowledge with relevant context from external sources.</p></li><li><p>The language model processes the input and generates an answer by combining the information from the retrieved passages and its base knowledge.</p></li><li><p>The generated answer is returned to the user.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c1eac76-dd82-4059-8ba7-dd240c61135d_1600x998.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="908" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c1eac76-dd82-4059-8ba7-dd240c61135d_1600x998.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>RAG has shown promising results in improving the accuracy and relevance of generated responses, especially in scenarios where the answer requires synthesizing information from multiple sources. It leverages the strengths of both information retrieval and language generation to provide better answers.</p><h3>Fine-Tuning AI Models</h3><p>Fine-tuning a base model on domain-specific data is a powerful technique to improve the performance and accuracy of AI models for specific tasks or industries.</p><p>Let&#8217;s understand how it&#8217;s done.</p><h4>1 - Understanding Base Models</h4><p>Base models, also known as pre-trained models, are AI models that have been trained on large, general-purpose datasets.</p><p>These models have learned general knowledge and patterns from the training data, making them versatile and applicable to a wide range of tasks.</p><p>Examples of base models include Google&#8217;s BERT and GPT, which have been trained on massive amounts of text or image data.</p><h4>2 - The Need for Fine-Tuning</h4><p>While base models are powerful, they may not always perform optimally for specific domains or tasks.&nbsp;</p><p>The reasons for fine-tuning a foundation model are as follows:</p><ul><li><p>Adding a specific task (such as code generation or content generation) to the foundation model.</p></li><li><p>Generating responses based on your company&#8217;s proprietary dataset.</p></li><li><p>Adapting to the unique vocabularies, writing styles, or data distribution that might differ in your specific use case.</p></li><li><p>Reducing hallucination, which is output that is not factually correct or reasonable.</p></li></ul><p>Fine-tuning allows us to adapt the base model to better understand and generate content specific to a particular domain.</p><h4>3 - Fine-Tuning Process</h4><p>The fine-tuning process consists of several steps such as:</p><ul><li><p><strong>Data Preparation: </strong>Collect a dataset that is representative of the target domain or task while ensuring that it is of sufficient size and quality. Preprocess the data to match the input requirements of the base model.</p></li><li><p><strong>Model Initialization</strong>: Start with the pre-trained base model that is most suitable for the target task. Load the pre-trained weights of the base model.</p></li><li><p><strong>Training: </strong>Feed the domain-specific dataset into the modified base model and train the model using techniques like transfer learning. Fine-tune the model&#8217;s parameters by backpropagating the errors and updating the weights based on the domain-specific data.</p></li><li><p><strong>Evaluation and Iteration: </strong>Evaluate the fine-tuned model&#8217;s performance on a validation set from the domain-specific data. Based on the metrics, iterate on the fine-tuning process.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11dc86ba-d135-46f7-a4b0-c0ce14cd49a7_1600x1120.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1019" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11dc86ba-d135-46f7-a4b0-c0ce14cd49a7_1600x1120.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h4>4 - Benefits of Fine-Tuning</h4><p>There are significant benefits to fine-tuning:</p><ul><li><p>It allows the model to capture the nuances and characteristics of the target domain, leading to better accuracy and performance on domain-specific tasks.</p></li><li><p>Starting with a pre-trained base model, fine-tuning requires less training data and computational resources than training a model from scratch.</p></li><li><p>Fine-tuning enables the model to leverage the knowledge learned from the general-purpose training data and adapt it to the specific domain.</p></li></ul><h2>Conclusion</h2><p>In conclusion, getting started with Generative AI is an exciting journey that opens up a world of possibilities for developers and businesses alike.&nbsp;</p><p>By understanding the key concepts, exploring the available models and APIs, and following best practices, you can harness GenAI's power to build innovative applications and solve complex problems.</p><p>Whether you're interested in natural language processing, image generation, or audio synthesis, there are numerous GenAI models and platforms to choose from. You can create highly accurate and efficient AI solutions tailored to your specific needs by leveraging pre-trained models and fine-tuning them on domain-specific data.</p><p></p>
]]></content:encoded>
<pubDate>Tue, 16 Jul 2024 15:30:47 GMT</pubDate>
</item>
<item>
<title>EP120: What do version numbers mean?</title>
<link>https://blog.bytebytego.com/p/ep120-what-do-version-numbers-mean</link>
<guid>https://blog.bytebytego.com/p/ep120-what-do-version-numbers-mean</guid>
<content:encoded><![CDATA[
<div> 并发性，并行性，版本号，网络安全，Kubernetes
总结:<br /><br />本文介绍了并发性和并行性的区别，版本号的含义，网络安全的基础知识，以及Kubernetes容器编排系统的概述。版本号采用语义化版本控制，包括主版本号、次版本号和补丁号，用于表示软件更新的含义。网络安全涉及CIA三要素、常见威胁和基本防御机制，如防火墙、杀毒软件和加密等。Kubernetes是一个容器编排系统，由控制平面和节点组成，用于容器的部署和管理，具有高可用和容错性。控制平面包括API服务器、调度器、控制器管理器和etcd，节点包括Pods、Kubelet和Kube Proxy。这些信息涵盖了本文的主要内容。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Concurrency Vs Parallelism!  (Youtube video)</p></li><li><p>What do version numbers mean? </p></li><li><p>Looking for a Job? This Free AI Tool Can Get You More Interviews!</p></li><li><p>Cybersecurity 101 in one picture</p></li><li><p>What is k8s (Kubernetes)? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/QAWolf_071324Head">&#9986;&#65039;Cut your QA cycles down to minutes with automated testing (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_071324Head" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="736" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F090fca3b-6480-4321-b93f-c3a80486dd1a_1473x745.png" width="1456" /><div></div></div></a></figure></div><p>Are slow test cycles bottlenecking your dev teams&#8217; release velocity? With QA Wolf, your organization can run entire test suites in minutes for faster feedback and developer confidence to ship.</p><p><a href="https://bit.ly/QAWolf_071324Head">QA Wolf</a> takes testing off your plate. They can get you:</p><ul><li><p><a href="https://bit.ly/QAWolf_071324Head">80% automated test coverage in weeks</a>&#8212;not years</p></li><li><p><a href="https://bit.ly/QAWolf_071324Head">Unlimited parallel test runs</a></p></li><li><p>24-hour maintenance and on-demand test creation</p></li><li><p>Zero flakes, guaranteed</p></li></ul><p>The benefit? No more manual E2E testing. No more slow QA cycles. No more bugs reaching production.</p><p>With QA Wolf, <a href="https://bit.ly/QAWolf_071624CaseStudy">Drata&#8217;s team of 80+ engineers</a> achieved 4x more test cases and 86% faster QA cycles.</p><p><strong>&#127775;</strong>Rated 4.8/5 on G2</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_071324Head"><span>Schedule a demo to learn more</span></a></p><div><hr /></div><h2>Concurrency Vs Parallelism!</h2><div class="youtube-wrap" id="youtube2-RlM9AfWf1WU"><div class="youtube-inner"></div></div><div><hr /></div><h2>What do version numbers mean? </h2><p>Semantic Versioning (SemVer) is a versioning scheme for software that aims to convey meaning about the underlying changes in a release. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="988" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefaeb917-d62e-4f04-b3bc-0644d50fa948_800x988.gif" title="diagram" width="800" /><div></div></div></a></figure></div><ul><li><p>SemVer uses a three-part version number: MAJOR.MINOR.PATCH. </p><ul><li><p>MAJOR version: Incremented when there are incompatible API changes. </p></li><li><p>MINOR version: Incremented when functionality is added in a backward-compatible manner. </p></li><li><p>PATCH version: Incremented when backward-compatible bug fixes are made. </p></li></ul></li><li><p>Example Workflow <br />1 - Initial Development Phase <br />Start with version 0.1.0. </p><p><br />2 - First Stable Release <br />Reach a stable release: 1.0.0. <br /><br />3 - Subsequent Changes <br />Patch Release: A bug fix is needed for 1.0.0. Update to 1.0.1. <br /><br />Minor Release: A new, backward-compatible feature is added to 1.0.3. Update to 1.1.0. <br /><br />Major Release: A significant change that is not backward-compatible is introduced in 1.2.2. Update to 2.0.0. <br /><br />4 - Special Versions and Pre-releases <br />Pre-release Versions: 1.0.0-alpha, 1.0.0-beta, 1.0.0-rc.1. <br />Build Metadata: 1.0.0+20130313144700. </p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1812" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d6ff61-09a2-493d-84e1-59c2568fd611_2250x2800.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">A Crash Course on Distributed Systems</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">A Crash Course in Database Scaling Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">A Crash Course in Database Sharding</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>Looking for a Job? This Free AI Tool Can Get You More Interviews!</h2><p>If you're looking for a job, you should check this out.</p><p>My good friend<a href="https://www.linkedin.com/in/ericcheng26/"> </a>Eric Cheng and his team have built a fantastic AI tool called Jobright.ai that makes your job search much easier.</p><p>Here are some great features I wish I had when I was job hunting</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://jobright.ai/?utm_source=1043&amp;utm_campaign=Alex" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="819" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ef17784-e58c-41d4-902f-9117cfcb72fa_1999x1125.png" width="1456" /><div></div></div></a></figure></div><p class="button-wrapper"><a class="button primary" href="https://jobright.ai/?utm_source=1043&amp;utm_campaign=Alex"><span>Try Jobright for Free</span></a></p><ul><li><p>Aggregates all jobs in one place (8 million in total / 400K new jobs daily)</p></li><li><p>Match you with the right opportunities where you are a standout candidate</p></li><li><p>Create customized resumes for each job in seconds.</p></li><li><p>Automatically suggest past colleagues or alumni who can help with referrals.</p></li><li><p>It's completely free right now</p></li></ul><div><hr /></div><h2>Cybersecurity 101 in one picture</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="Image preview" class="sizing-normal" height="800" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4cd9bbc-d7ec-4da1-87aa-577e43f4a5d2_800x800.gif" title="Image preview" width="800" /><div></div></div></a></figure></div><ol><li><p>Introduction to Cybersecurity</p></li><li><p>The CIA Triad</p></li><li><p>Common Cybersecurity Threats</p></li><li><p>Basic Defense Mechanisms<br />To combat these threats, several basic defense mechanisms are employed:</p><ul><li><p>Firewalls: Network security devices that monitor and control incoming and outgoing network traffic.</p></li><li><p>Antivirus Software: Programs designed to detect and remove malware.</p></li><li><p>Encryption: The process of converting information into a code to prevent unauthorized access.</p></li></ul></li><li><p>Cybersecurity Frameworks</p></li></ol><div><hr /></div><h2>What is k8s (Kubernetes)? </h2><p>k8s is a container orchestration system. It is used for container deployment and management. Its design is greatly impacted by Google&#8217;s internal system Borg. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1092" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9321e6a8-602a-4c4c-9fa0-10c5921c92b2_800x1092.gif" title="graphical user interface, application" width="800" /><div></div></div></a></figure></div><p>A k8s cluster consists of a set of worker machines, called nodes, that run containerized applications. Every cluster has at least one worker node. </p><p>The worker node(s) host the Pods that are the components of the application workload. The control plane manages the worker nodes and the Pods in the cluster. In production environments, the control plane usually runs across multiple computers and a cluster usually runs multiple nodes, providing fault-tolerance and high availability. </p><ul><li><p>Control Plane Components <br /> <br />1. API Server <br />The API server talks to all the components in the k8s cluster. All the operations on pods are executed by talking to the API server. <br /> <br />2. Scheduler <br />The scheduler watches the workloads on pods and assigns loads on newly created pods. <br /> <br />3. Controller Manager <br />The controller manager runs the controllers, including Node Controller, Job Controller, EndpointSlice Controller, and ServiceAccount Controller. <br /> <br />4. etcd <br />etcd is a key-value store used as Kubernetes' backing store for all cluster data.\</p></li><li><p>Nodes </p><p><br />1. Pods <br />A pod is a group of containers and is the smallest unit that k8s administers. Pods have a single IP address applied to every container within the pod. <br /> <br />2. Kubelet <br />An agent that runs on each node in the cluster. It ensures containers are running in a Pod. <br /> <br />3. Kube Proxy <br />kube-proxy is a network proxy that runs on each node in your cluster. It routes traffic coming into a node from the service. It forwards requests for work to the correct containers.</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 13 Jul 2024 15:30:35 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Distributed Systems</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems</guid>
<content:encoded><![CDATA[
<div> 分布式系统、节点、网络、协调、失败
总结:<br /><br />分布式系统是由多个节点组成的计算机集合，通过网络协作执行特定任务或提供服务。这些节点在物理上分离，并通过网络传递消息进行通信。分布式系统具有统一的外部视角，用户无需关心系统内部结构。节点需要协调并就行一致操作，但也可能出现独立故障及网络消息丢失等问题。分布式系统具有很高的灵活性，可以不断加入或移除节点。通过多个计算机协同工作，分布式系统能提供流畅且响应迅速的用户体验。 <div>
<p>A distributed system is a collection of computers, also known as nodes, that collaborate to perform a specific task or provide a service.</p><p>These nodes are physically separate and communicate with each other by passing messages over a network. Distributed systems can span geographical boundaries, enabling them to utilize resources from different locations.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb145d610-0804-4a50-b74b-bf13cac6fb8f_1600x1005.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="915" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb145d610-0804-4a50-b74b-bf13cac6fb8f_1600x1005.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Distributed systems have several characteristics that distinguish them from traditional centralized systems:</p><ul><li><p>The computers in a distributed system are physically separate and connected via a network. They do not share a memory or a common clock.</p></li><li><p>From an external perspective, a distributed system appears as a single, unified entity to the end user.</p></li><li><p>Distributed systems offer the flexibility to add or remove computers from the system.</p></li><li><p>The nodes in a distributed system need to coordinate and agree with each other to perform actions consistently.</p></li><li><p>Nodes in a distributed system can fail independently, and messages can be lost or delayed over the network.</p></li></ul><p>Distributed systems are ubiquitous in our daily lives. Examples include large web applications like Google Search, online banking systems, multiplayer games, etc. These systems leverage the power of multiple computers working together to provide a seamless and responsive user experience.</p><p>In this post, we&#8217;ll explore the benefits and challenges of distributed systems. We will also discuss common approaches and techniques used to address these challenges and ensure the reliable operation of distributed systems.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d6ff61-09a2-493d-84e1-59c2568fd611_2250x2800.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1812" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50d6ff61-09a2-493d-84e1-59c2568fd611_2250x2800.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>Understanding Distributed Systems&nbsp;</h2><p>The term &#8220;distributed systems&#8221; can sometimes confuse developers.&nbsp;</p>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-distributed-systems">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 11 Jul 2024 15:30:43 GMT</pubDate>
</item>
<item>
<title>EP119: What do Amazon, Netflix, and Uber have in common?</title>
<link>https://blog.bytebytego.com/p/ep119-what-do-amazon-netflix-and</link>
<guid>https://blog.bytebytego.com/p/ep119-what-do-amazon-netflix-and</guid>
<content:encoded><![CDATA[
<div> scaling, strategies, database, testing, functionality
<br />
要点: 
- 介绍了8种必须掌握的系统扩展策略，包括无状态服务、水平扩展、负载均衡、自动扩展、缓存、数据库复制、数据库分片和异步处理；
- 讨论了Figma如何实现100倍Postgres扩展，包括垂直扩展、复制、垂直分区和水平分区；
- 探讨了测试系统功能的最佳方式，包括单元测试、集成测试、系统测试、负载测试、错误测试和测试自动化；
- 强调了New Relic和NVIDIA发布的观测集成，使公司能够监控构建在NVIDIA NIM上的AI应用程序的健康和性能；
- 引入了赞助机会，以让产品直接面向50万以上的技术专业人士。 

总结: 
本文介绍了系统设计中的必备策略，包括扩展策略、数据库扩展实例、系统功能测试方式、AI监控新特性以及赞助机会。文章通过具体案例和实践经验，为读者提供了丰富的系统设计知识和实用技巧。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>7 Must-know Strategies to Scale Your Database (Youtube video)</p></li><li><p>What do Amazon, Netflix, and Uber have in common?</p></li><li><p>100X Postgres Scaling at Figma</p></li><li><p>Best ways to test system functionality</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/NewRelic_070624">Monitor AI Applications Built with NVIDIA NIM (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/NewRelic_070624" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="675" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77f05e92-21dd-4034-b054-7fac7e375d6e_1200x675.png" width="1200" /><div></div></div></a></figure></div><p>New Relic and NVIDIA released the first observability integration making it easy for companies to monitor the health and performance of their AI applications built with NVIDIA NIM.</p><p>Key features and use cases for AI monitoring include:</p><ul><li><p>Full AI stack integration</p></li><li><p>Deep trace insights for every response&nbsp;</p></li><li><p>Model inventory&nbsp;</p></li><li><p>Deep GPU insights</p></li><li><p>Enhanced data security</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/NewRelic_070624"><span>Get started</span></a></p><div><hr /></div><h2>7 Must-know Strategies to Scale Your Database</h2><div class="youtube-wrap" id="youtube2-_1IKwnbscQU"><div class="youtube-inner"></div></div><div><hr /></div><h2>What do Amazon, Netflix, and Uber have in common?</h2><p>They are extremely good at scaling their system whenever needed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1683" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2497aa7-95ab-45b0-a8f7-0af03b663342_1280x1683.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>Here are 8 must-know strategies to scale your system.</p><ol><li><p>Stateless Services<br />Design stateless services because they don&#8217;t rely on server-specific data and are easier to scale.</p></li><li><p>Horizontal Scaling<br />Add more servers so that the workload can be shared.</p></li><li><p>Load Balancing<br />Use a load balancer to distribute incoming requests evenly across multiple servers.</p></li><li><p>Auto Scaling<br />Implement auto-scaling policies to adjust resources based on real-time traffic.</p></li><li><p>Caching<br />Use caching to reduce the load on the database and handle repetitive requests at scale.</p></li><li><p>Database Replication<br />Replicate data across multiple nodes to scale the read operations while improving redundancy. </p></li><li><p>Database Sharding<br />Distribute data across multiple instances to scale the writes as well as reads.</p></li><li><p>Async Processing<br />Move time-consuming and resource-intensive tasks to background workers using async processing to scale out new requests.</p></li></ol><p>Over to you: Which other strategies have you used?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cff25a5-b061-4fd4-8831-fab148e8926b_1401x1600.png" width="1401" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">A Crash Course in Database Scaling Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">A Crash Course in Database Sharding</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe?"><span>Subscribe now</span></a></p><div><hr /></div><h2>100X Postgres Scaling at Figma</h2><p>With 3 million monthly users, Figma&#8217;s user base has increased by 200% since 2018. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1638" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F110264f5-e3b5-40bd-85bf-d7975ff345f9_1280x1638.gif" title="diagram" width="1280" /><div></div></div></a></figure></div><p>As a result, its Postgres database witnessed a whopping 100X growth. </p><ol><li><p>Vertical Scaling and Replication <br />Figma used a single, large Amazon RDS database. <br /> <br />As a first step, they upgraded to the largest instance available (from r5.12xlarge to r5.24xlarge). <br /> <br />They also created multiple read replicas to scale read traffic and added PgBouncer as a connection pooler to limit the impact of a growing number of connections. <br /></p></li><li><p>Vertical Partitioning <br />The next step was vertical partitioning. <br /> <br />They migrated high-traffic tables like &#8220;Figma Files&#8221; and &#8220;Organizations&#8221; into their separate databases. <br /> <br />Multiple PgBouncer instances were used to manage the connections for these separate databases. <br /></p></li><li><p>Horizontal Partitioning <br />Over time, some tables crossed several terabytes of data and billions of rows. <br /> <br />Postgres Vacuum became an issue and max IOPS exceeded the limits of Amazon RDS at the time. <br /> <br />To solve this, Figma implemented horizontal partitioning by splitting large tables across multiple physical databases. <br /> <br />A new DBProxy service was built to handle routing and query execution. </p></li></ol><p>Over to you - Would you have done something differently?</p><div><hr /></div><h2>Best ways to test system functionality</h2><p>Testing system functionality is a crucial step in software development and engineering processes.<br /><br />It ensures that a system or software application performs as expected, meets user requirements, and operates reliably.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4886cb0-e840-4d4a-84c7-8d9543d98101_1280x1664.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>Here we delve into the best ways:</p><ol><li><p>Unit Testing: Ensures individual code components work correctly in isolation.</p></li><li><p>Integration Testing: Verifies that different system parts function seamlessly together.</p></li><li><p>System Testing: Assesses the entire system's compliance with user requirements and performance.</p></li><li><p>Load Testing: Tests a system's ability to handle high workloads and identifies performance issues.</p></li><li><p>Error Testing: Evaluates how the software handles invalid inputs and error conditions.</p></li><li><p>Test Automation: Automates test case execution for efficiency, repeatability, and error reduction.</p></li></ol><p>Over to you: </p><ul><li><p>How do you approach testing system functionality in your software development or engineering projects?</p></li><li><p>What's your company's release process look like?</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 06 Jul 2024 15:30:46 GMT</pubDate>
</item>
<item>
<title>A Crash Course in Database Scaling Strategies</title>
<link>https://blog.bytebytego.com/p/a-crash-course-in-database-scaling</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-in-database-scaling</guid>
<content:encoded><![CDATA[
<div> 数据库、应用开发、数据库扩展、性能优化、索引<br />
<br />总结：<br />数据库是现代应用开发的重要组成部分，通过索引等技术来改进数据库的可扩展性和性能。数据库扩展是通过采用各种技术和策略来适应数据增长和维持性能，以确保应用程序的正常运行。选择合适的数据库扩展策略至关重要，否则可能会带来更多问题。 <div>
<p>Databases form the backbone of modern application development. They play a vital role in storing, managing, and retrieving data, enabling applications and services to function effectively.</p><p>As applications gain popularity and attract a growing user base, databases face the challenge of handling ever-increasing data volumes, concurrent users, and complex queries.</p><p>It becomes critical to scale databases effectively to ensure optimal performance and a good user experience.&nbsp;</p><p>Database scaling is the process of adapting and expanding the database infrastructure to accommodate growth and maintain performance under increased load. It involves employing various techniques and strategies to distribute data efficiently, optimize query execution, and utilize hardware resources judiciously.</p><p>Organizations and developers must understand and implement the right database scaling strategy. Choosing the wrong strategies for a particular situation can result in more harm than good.</p><p>In this post, we will cover the most popular database scaling strategies in detail, discussing their benefits and trade-offs.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cff25a5-b061-4fd4-8831-fab148e8926b_1401x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4cff25a5-b061-4fd4-8831-fab148e8926b_1401x1600.png" width="1401" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>Indexing</h2><p>Indexing is one of the foundational techniques to enhance the scalability and performance of databases.&nbsp;</p>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-in-database-scaling">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 15:31:12 GMT</pubDate>
</item>
<item>
<title>EP118: What are the differences among database locks?</title>
<link>https://blog.bytebytego.com/p/ep118-what-are-the-differences-among</link>
<guid>https://blog.bytebytego.com/p/ep118-what-are-the-differences-among</guid>
<content:encoded><![CDATA[
<div> 数据库锁、API设计中的分页、架构模式（MVC、MVP、MVVM、MVVM-C、VIPER）、浏览器输入URL的过程、扫描二维码支付

总结:<br /><br />
数据库锁是用来保证数据完整性和一致性的机制，常见类型包括Shared Lock、Exclusive Lock等。分页在API设计中是为了高效处理大型数据集，常用技术有Offset-based Pagination、Cursor-based Pagination等。架构模式MVC、MVP、MVVM、MVVM-C、VIPER各有特点，都包含视图、模型和控制器/Presenter/ViewModel。浏览器输入URL时，经过DNS查询、建立TCP连接、发送HTTP请求等步骤。扫描二维码支付过程分为商家生成QR码和消费者扫描支付。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>What are the differences among database locks? </p></li><li><p>How do we Perform Pagination in API Design? </p></li><li><p>What distinguishes MVC, MVP, MVVM, MVVM-C, and VIPER architecture patterns from each other?</p></li><li><p>What happens when you type a URL into your browser?</p></li><li><p>How do you pay from your digital wallet, such as Paypal, Venmo, Paytm, by scanning the QR code? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Paragon_062924">Ship every native SaaS integration your users need (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Paragon_062924" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="756" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98d88922-60bc-483c-86ca-b5916742f99a_7747x4021.png" width="1456" /><div></div></div></a></figure></div><p>Is product asking your team to build native product integrations with 3rd party services (ie. Salesforce, Slack, etc.)?</p><p>Save 70% of the engineering effort with Paragon, so you can stay focused on your core competencies.</p><p>Offload the plumbing around integrations with:</p><ul><li><p>Fully managed authentication (OAuth token refresh)</p></li><li><p>Webhook triggers &amp; API abstractions</p></li><li><p>Built-in error and 3rd party rate limit handling</p></li><li><p>100+ pre-built integrations &amp; custom integration builder</p></li><li><p>Enterprise-ready serverless infrastructure</p></li></ul><p>See how 100+ SaaS companies orchestrate ingestion jobs, real-time sync, and event-driven automations with 3rd party SaaS apps in weeks, not months.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Paragon_062924"><span>Learn more</span></a></p><div><hr /></div><h2>What are the differences among database locks? </h2><p>In database management, locks are mechanisms that prevent concurrent access to data to ensure data integrity and consistency. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42c5f5c6-b7d8-46ac-895f-06edd3d7fb7a_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><p>Here are the common types of locks used in databases: </p><ol><li><p>Shared Lock (S Lock) <br />It allows multiple transactions to read a resource simultaneously but not modify it. Other transactions can also acquire a shared lock on the same resource. <br /></p></li><li><p>Exclusive Lock (X Lock) <br />It allows a transaction to both read and modify a resource. No other transaction can acquire any type of lock on the same resource while an exclusive lock is held. <br /></p></li><li><p>Update Lock (U Lock) <br />It is used to prevent a deadlock scenario when a transaction intends to update a resource. <br /></p></li><li><p>Schema Lock <br />It is used to protect the structure of database objects. <br /></p></li><li><p>Bulk Update Lock (BU Lock) <br />It is used during bulk insert operations to improve performance by reducing the number of locks required. <br /></p></li><li><p>Key-Range Lock <br />It is used in indexed data to prevent phantom reads (inserting new rows into a range that a transaction has already read). <br /></p></li><li><p>Row-Level Lock <br />It locks a specific row in a table, allowing other rows to be accessed concurrently. <br /></p></li><li><p>Page-Level Lock <br />It locks a specific page (a fixed-size block of data) in the database. <br /></p></li><li><p>Table-Level Lock <br />It locks an entire table. This is simple to implement but can reduce concurrency significantly.</p></li></ol><div><hr /></div><h2>How do we Perform Pagination in API Design? </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1ec91193-f890-4942-bb23-21f706d9524a_1306x1536.gif" title="No alternative text description for this image" /><div></div></div></a></figure></div><p>Pagination is crucial in API design to handle large datasets efficiently and improve performance. Here are six popular pagination techniques: </p><ul><li><p>Offset-based Pagination: <br />This technique uses an offset and a limit parameter to define the starting point and the number of records to return. <br />- Example: GET /orders?offset=0&amp;limit=3 <br />- Pros: Simple to implement and understand. <br />- Cons: Can become inefficient for large offsets, as it requires scanning and skipping rows. <br /></p></li><li><p>Cursor-based Pagination: <br />This technique uses a cursor (a unique identifier) to mark the position in the dataset. Typically, the cursor is an encoded string that points to a specific record. </p><ul><li><p>Example: GET /orders?cursor=xxx <br />- Pros: More efficient for large datasets, as it doesn't require scanning skipped records. <br />- Cons: Slightly more complex to implement and understand. <br /></p></li></ul></li><li><p>Page-based Pagination: <br />This technique specifies the page number and the size of each page. </p><ul><li><p>Example: GET /items?page=2&amp;size=3 <br />- Pros: Easy to implement and use. <br />- Cons: Similar performance issues as offset-based pagination for large page numbers. <br /></p></li></ul></li><li><p>Keyset-based Pagination: <br />This technique uses a key to filter the dataset, often the primary key or another indexed column. </p><ul><li><p>Example: GET /items?after_id=102&amp;limit=3 <br />- Pros: Efficient for large datasets and avoids performance issues with large offsets. <br />- Cons: Requires a unique and indexed key, and can be complex to implement. <br /></p></li></ul></li><li><p>Time-based Pagination: <br />This technique uses a timestamp or date to paginate through records.</p><ul><li><p>Example: GET /items?start_time=xxx&amp;end_time=yyy <br />- Pros: Useful for datasets ordered by time, ensures no records are missed if new ones are added. <br />- Cons: Requires a reliable and consistent timestamp. <br /></p></li></ul></li><li><p>Hybrid Pagination: <br />This technique combines multiple pagination techniques to leverage their strengths. <br />Example: Combining cursor and time-based pagination for efficient scrolling through time-ordered records. </p><ul><li><p>Example: GET /items?cursor=abc&amp;start_time=xxx&amp;end_time=yyy <br />- Pros: Can offer the best performance and flexibility for complex datasets. <br />- Cons: More complex to implement and requires careful design.</p></li></ul></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F571827ac-b3da-44a3-886a-8ca9770bb443_1337x1600.png" width="1337" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">A Crash Course in Database Sharding</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>What distinguishes MVC, MVP, MVVM, MVVM-C, and VIPER architecture patterns from each other?<br /></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1755" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c35aada-289b-4ac5-8c23-8b55065a5d60_1280x1755.jpeg" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>These architecture patterns are among the most commonly used in app development, whether on iOS or Android platforms. Developers have introduced them to overcome the limitations of earlier patterns. So, how do they differ?</p><ul><li><p>MVC, the oldest pattern, dates back almost 50 years</p></li><li><p>Every pattern has a "view" (V) responsible for displaying content and receiving user input</p></li><li><p>Most patterns include a "model" (M) to manage business data</p></li><li><p>"Controller," "presenter," and "view-model" are translators that mediate between the view and the model ("entity" in the VIPER pattern)</p></li><li><p>These translators can be quite complex to write, so various patterns have been proposed to make them more maintainable</p></li></ul><div><hr /></div><h2>What happens when you type a URL into your browser?</h2><p>The diagram below illustrates the steps.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1178" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3cf6a7cb-3aec-4db8-9bdc-fda0dc70c9fe_1898x1536.jpeg" title="No alt text provided for this image" width="1456" /><div></div></div></a></figure></div><ol><li><p>Bob enters a URL into the browser and hits Enter. In this example, the URL is composed of 4 parts:<br />&#128313; scheme - &#119945;&#119957;&#119957;&#119953;://. This tells the browser to send a connection to the server using HTTP.<br />&#128313; domain - &#119942;&#119961;&#119938;&#119950;&#119953;&#119949;&#119942;.&#119940;&#119952;&#119950;. This is the domain name of the site.<br />&#128313; path - &#119953;&#119955;&#119952;&#119941;&#119958;&#119940;&#119957;/&#119942;&#119949;&#119942;&#119940;&#119957;&#119955;&#119946;&#119940;. It is the path on the server to the requested resource: phone.<br />&#128313; resource - &#119953;&#119945;&#119952;&#119951;&#119942;. It is the name of the resource Bob wants to visit.</p><p></p></li><li><p>The browser looks up the IP address for the domain with a domain name system (DNS) lookup. To make the lookup process fast, data is cached at different layers: browser cache, OS cache, local network cache, and ISP cache. <br /><br />2.1 If the IP address cannot be found at any of the caches, the browser goes to DNS servers to do a recursive DNS lookup until the IP address is found (this will be covered in another post). </p><p></p></li><li><p>Now that we have the IP address of the server, the browser establishes a TCP connection with the server.<br /></p></li><li><p>The browser sends an HTTP request to the server. The request looks like this:<br /><br />&#120334;&#120332;&#120347; /&#120369;&#120361;&#120368;&#120367;&#120358; &#120335;&#120347;&#120347;&#120343;/1.1<br />&#120335;&#120368;&#120372;&#120373;: &#120358;&#120377;&#120354;&#120366;&#120369;&#120365;&#120358;.&#120356;&#120368;&#120366;</p><p></p></li><li><p>The server processes the request and sends back the response. For a successful response (the status code is 200). The HTML response might look like this: <br /><br />&#120335;&#120347;&#120347;&#120343;/1.1 200 &#120342;&#120338;<br />&#120331;&#120354;&#120373;&#120358;: &#120346;&#120374;&#120367;, 30 &#120337;&#120354;&#120367; 2022 00:01:01 &#120334;&#120340;&#120347;<br />&#120346;&#120358;&#120371;&#120375;&#120358;&#120371;: &#120328;&#120369;&#120354;&#120356;&#120361;&#120358;<br />&#120330;&#120368;&#120367;&#120373;&#120358;&#120367;&#120373;-&#120347;&#120378;&#120369;&#120358;: &#120373;&#120358;&#120377;&#120373;/&#120361;&#120373;&#120366;&#120365;; &#120356;&#120361;&#120354;&#120371;&#120372;&#120358;&#120373;=&#120374;&#120373;&#120359;-8<br /><br />&lt;!&#120331;&#120342;&#120330;&#120347;&#120352;&#120343;&#120332; &#120361;&#120373;&#120366;&#120365;&gt;<br />&lt;&#120361;&#120373;&#120366;&#120365; &#120365;&#120354;&#120367;&#120360;="&#120358;&#120367;"&gt;<br />&#120335;&#120358;&#120365;&#120365;&#120368; &#120376;&#120368;&#120371;&#120365;&#120357;<br />&lt;/&#120361;&#120373;&#120366;&#120365;&gt;<br /></p></li><li><p>The browser renders the HTML content.</p></li></ol><div><hr /></div><h2>How do you pay from your digital wallet, such as Paypal, Venmo, Paytm, by scanning the QR code? </h2><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31897073-e7f9-422a-9dbf-2f6dc18e6a6d_1280x1780.jpeg" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1780" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31897073-e7f9-422a-9dbf-2f6dc18e6a6d_1280x1780.jpeg" title="diagram" width="1280" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To understand the process involved, we need to divide the &#8220;scan to pay&#8221; process into two sub-processes: </p><ol><li><p>Merchant generates a QR code and displays it on the screen </p></li><li><p>Consumer scans the QR code and pays </p></li></ol><p>Here are the steps for generating the QR code: </p><ol><li><p>When you want to pay for your shopping, the cashier tallies up all the goods and calculates the total amount due, for example, $123.45. The checkout has an order ID of SN129803. The cashier clicks the &#8220;checkout&#8221; button. </p></li><li><p>The cashier&#8217;s computer sends the order ID and the amount to PSP. </p></li><li><p>The PSP saves this information to the database and generates a QR code URL. </p></li><li><p>PSP&#8217;s Payment Gateway service reads the QR code URL. </p></li><li><p>The payment gateway returns the QR code URL to the merchant&#8217;s computer. </p></li><li><p>The merchant&#8217;s computer sends the QR code URL (or image) to the checkout counter. </p></li><li><p>The checkout counter displays the QR code. </p></li></ol><p>These 7 steps complete in less than a second. Now it&#8217;s the consumer&#8217;s turn to pay from their digital wallet by scanning the QR code: </p><ol><li><p>The consumer opens their digital wallet app to scan the QR code. </p></li><li><p>After confirming the amount is correct, the client clicks the &#8220;pay&#8221; button. </p></li><li><p>The digital wallet App notifies the PSP that the consumer has paid the given QR code. </p></li><li><p>The PSP payment gateway marks this QR code as paid and returns a success message to the consumer&#8217;s digital wallet App. </p></li><li><p>The PSP payment gateway notifies the merchant that the consumer has paid the given QR code. </p></li></ol><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 15:30:59 GMT</pubDate>
</item>
<item>
<title>A Crash Course in Database Sharding</title>
<link>https://blog.bytebytego.com/p/a-crash-course-in-database-sharding</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-in-database-sharding</guid>
<content:encoded><![CDATA[
<div> 数据库，横向扩展，性能，挑战，分片
<br />
分片是一种解决数据库横向扩展挑战的技术，将数据库划分为更小、更易管理的单元称为分片。当应用程序接收到更多流量和数据时，数据库可能成为性能瓶颈，影响用户体验。通过分片，可以解决数据库横向扩展的挑战，提高性能，确保应用程序的可伸缩性。不同的公司已经成功实施了分片技术来扩展他们的数据库，有效应对业务增长的需求。
<br /><br />总结: 数据库的横向扩展面临着性能挑战，分片技术能够有效解决这一问题，提升性能，并确保应用程序的可伸缩性。通过对数据库进行分片，可以更好地应对增加的流量和数据量，确保用户体验。 <div>
<p>As an application grows in popularity, it attracts more active users and incorporates additional features. This growth leads to a daily increase in data generation, which is a positive indicator from a business perspective.&nbsp;</p><p>However, it can also pose challenges to the application's architecture, particularly in terms of database scalability.</p><p>The database is a critical component of any application, but it is also one of the most difficult components to scale horizontally. When an application receives increased traffic and data volume, the database can become a performance bottleneck, impacting the user experience.</p><p>Sharding is a technique that addresses the challenges of horizontal database scaling. It involves partitioning the database into smaller, more manageable units called shards.</p><p>In this post, we&#8217;ll cover the fundamentals of database sharding, exploring its various approaches, technical considerations, and real-world case studies showcasing how companies have implemented sharding to scale their databases.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F571827ac-b3da-44a3-886a-8ca9770bb443_1337x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F571827ac-b3da-44a3-886a-8ca9770bb443_1337x1600.png" width="1337" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>What is Sharding?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-in-database-sharding">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 15:30:37 GMT</pubDate>
</item>
<item>
<title>How Netflix Manages 238 Million Memberships?</title>
<link>https://blog.bytebytego.com/p/how-netflix-manages-238-million-memberships</link>
<guid>https://blog.bytebytego.com/p/how-netflix-manages-238-million-memberships</guid>
<content:encoded><![CDATA[
<div> 关键词: DevOps, Netflix, membership platform, architecture, technical stack

总结:<br /><br />文章介绍了Netflix的会员平台架构及技术堆栈。该平台负责管理用户的订阅生命周期，经历从简单的库到可处理百万请求的强大架构的演变。采用微服务架构，使用CockroachDB和Cassandra等数据库存储会员数据，通过CDC追踪历史数据变更。开发堆栈中使用Java和Spring Boot，涉及Kafka、Spark和Flink等工具，保证高可用性和数据一致性。运维方面强调可观测性和监控，使用日志、仪表盘、分布式跟踪等工具快速识别和解决问题。总体而言，Netflix的会员平台是其成功的关键组成部分，为亿万用户提供持续流畅的观影体验。 <div>
<h2><a href="https://bit.ly/Datadog_062524">Guide to Accelerating DevOps Transformation (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Datadog_062524" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1356" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25b41cc2-06b7-4572-8996-94c1353483f2_2482x2312.png" width="1456" /><div></div></div></a></figure></div><p>The DevOps model can engender faster development cycles and enhanced agility in responding to market needs. <br /><br />Datadog's DevOps Kit gives you the resources to create and strengthen cultures of observability, collaboration, and data sharing within organizations&#8212;key pillars of the DevOps movement.</p><p><strong>Gain instant access to:</strong></p><ul><li><p><strong>2 eBooks</strong> detailing methods for building and enabling effective development and operations teams</p></li><li><p><strong>A Solutions Brief</strong> describing ways to get full visibility into your DevOps tools</p></li><li><p><strong>A Technical Talk Video</strong> detailing the benefits of adopting a data-driven DevOps mindset</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Datadog_062524"><span>Get the kit</span></a></p></li></ul><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the articles/presentations made by the Netflix engineering team. All credit for the architectural details goes to the Netflix engineering team. The links to the original articles are present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>As a subscription-based streaming service, Netflix's primary revenue source is its membership business. With a staggering 238 million members worldwide, managing memberships efficiently is crucial for the company's success and continued growth.&nbsp;</p><p>The membership platform at Netflix plays a vital role in handling the entire lifecycle of a user's subscription.</p><p>The membership lifecycle consists of various stages and scenarios:</p><ul><li><p><strong>Signup: </strong>A user may begin their Netflix journey by signing up for the service, either directly or through partner channels such as T-Mobile and others.</p></li><li><p><strong>Plan Changes:</strong> Existing members can modify their subscription plans according to their preferences and needs.</p></li><li><p><strong>Renewal: </strong>As a subscription service, Netflix automatically attempts to renew a user&#8217;s plan using the payment method associated with the account.</p></li><li><p><strong>Payment Issues: </strong>In case of problems with the payment gateway or insufficient funds, a user&#8217;s account may be put on hold or granted a grace period to resolve the issue.</p></li><li><p><strong>Membership Pause or Cancellation: </strong>Users have the option to temporarily pause their membership or permanently cancel their subscriptions.</p></li></ul><p>In the following sections, we will explore the architectural decisions made by the Netflix engineering team to support the various capabilities and scalability of its membership platform.</p><div><hr /></div><h2>The High-Level Architecture of Netflix Membership Platform</h2><p>Before diving into the details of Netflix's membership platform, let's take a step back and examine how the company's original pricing architecture was designed.&nbsp;</p><p>In the early days, Netflix's pricing model was relatively straightforward, with only a handful of plans to manage and basic functionality to support.</p><p>To meet these initial requirements, Netflix employed a lightweight, in-memory library. This approach proved to be quite efficient, as the limited scope of the pricing system allowed for a simple and streamlined design.</p><p>The diagram below illustrates this basic architecture:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37775e14-0fb5-4edf-a82a-33c6d77fb195_1600x916.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="834" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37775e14-0fb5-4edf-a82a-33c6d77fb195_1600x916.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As Netflix expanded its global presence and diversified its offerings, the lightweight, in-memory library that initially served the pricing architecture became insufficient.&nbsp;</p><p>The growing complexity and scope of the pricing catalog, coupled with its increasing importance across multiple applications, led to operational challenges. The library's size and dependencies made it difficult to maintain and scale, necessitating a transition to a more robust and scalable architecture.</p><p>The diagram below shows the high-level architecture of Netflix&#8217;s modern membership platform:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38f27d43-db0e-4f28-b763-21b2260f5fa0_1600x1060.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="965" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38f27d43-db0e-4f28-b763-21b2260f5fa0_1600x1060.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The membership platform consists of a dozen microservices and is designed to support four nines (99.99%) availability.&nbsp;</p><p>This high availability requirement originates from the platform's critical role in various user-facing flows. If any of the services experience downtime, it can directly impact the user experience.</p><p>The platform supports several key functionalities:</p><ul><li><p>When a user hits the play button on Netflix, a direct call is made to the membership systems to determine the quality of service associated with their plan. Factors such as the allowed concurrent streams and supported devices for the user are considered. This flow handles the highest traffic volume, as Netflix serves billions of streaming requests every day.</p></li><li><p>The membership flow is triggered when a user accesses their account page. Actions like changing plans, managing extra members, and cancellations directly interact with the membership services.</p></li><li><p>The platform serves as the authoritative source for the total membership count at any given point in time. It emits events and writes to a persistent store, which is consumed by downstream analytics systems within and outside Netflix.</p></li></ul><p>The key points about the architecture diagram are as follows:</p><ul><li><p>The membership platform manages the membership plan and pricing catalog globally, with variations across different regions. The Plan Pricing Catalog Service handles rule management based on location-specific offerings.</p></li><li><p>Two CockroachDB databases are utilized to store plan pricing and code redemption information. The Member Pricing Service supports member actions, such as changing plans or adding extra members.</p></li><li><p>A dedicated microservice handles partner interactions, including bundle activations, signups, and integration with platforms like Apple's App Store.</p></li><li><p>Membership data is stored in Cassandra databases, which support the Subscription Service and History Tracking Service.</p></li><li><p>The platform not only caters to the 238 million active memberships but also focuses on former members and rejoin experiences.</p></li><li><p>The data generated by the platform is shipped to downstream consumers for deriving insights on signups and revenue projections.</p></li></ul><p>Netflix&#8217;s choice of using CockroachDB and Cassandra is interesting.&nbsp;</p><p>While CockroachDB provides strong consistency, making it suitable for critical data such as the plan pricing information, Cassandra is a highly scalable NoSQL database for handling large volumes of membership data.</p><p>Also, the 99.99% availability indicates a strong focus on resilience and fault tolerance. Netflix is anyways famous for its comprehensive chaos engineering practices to proactively test the system&#8217;s resilience.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb22a8b-a5fc-455d-b09b-f8e810d81cd9_1600x890.pnghttps%3A%2F%2Fblog.bytebytego.com%2Fsubscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="810" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffeb22a8b-a5fc-455d-b09b-f8e810d81cd9_1600x890.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>The Signup Process Flow</h2><p>Once users embark on their Netflix journey, they encounter plan selection options.</p><p>Rendering the plan selection page accurately is of utmost importance due to the geographical variations in currency, pricing, and available plans. Netflix's membership platform ensures that users are presented with the appropriate options based on their location and device type.</p><p>The diagram below shows the detailed steps involved in the Netflix signup process and the services that are triggered during the flow:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F721d4ccf-6623-4484-a0d8-7872e1cbe8e3_1600x1284.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1168" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F721d4ccf-6623-4484-a0d8-7872e1cbe8e3_1600x1284.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s a look at each step in more detail.</p><ol><li><p>The journey begins with users selecting a plan through Netflix's growth engineering apps. The plan details are retrieved from the Membership Plan Catalog service, which is backed by CockroachDB.&nbsp;</p></li><li><p>The Membership Plan Catalog Service loads and reads the plans based on predefined region and device type rules.</p></li><li><p>The retrieved plans are then presented to the user, allowing them to make an informed decision based on their preferences and budget.</p></li><li><p>Once the user chooses a plan, the flow progresses to the payment confirmation screen. Here, users provide their payment details and confirm their subscription.</p></li><li><p>Upon confirmation, the user clicks the "Start Membership" button, triggering the Membership State Service. This service persists the relevant information, such as the selected plan, price tier, and country, into the Cassandra database.</p></li><li><p>The Membership State Service also notifies the Billing Engineering Apps about the payment.&nbsp;</p></li><li><p>The Billing Engineering Apps generate an invoice based on the signup data obtained from the Membership Pricing Service.</p></li><li><p>The membership data is simultaneously written to the Membership History Service, ensuring a comprehensive record of the user's subscription history.</p></li><li><p>Events are published to signal the activation of the membership. These events trigger messaging pipelines responsible for sending welcome emails to the user and informing downstream systems for analytics purposes.</p></li></ol><h2>How Member History Is Tracked?</h2><p>In the early stages of Netflix's membership platform, member history and data were tracked through application-level events.&nbsp;</p><p>While this approach sufficed initially, it became evident that a more granular and persistent data tracking solution was necessary as Netflix expanded and the complexity of member data increased.</p><p>To address this need, Netflix developed a robust solution based on the Change Data Capture (CDC) pattern.&nbsp;</p><p>For reference, CDC is a design pattern that directly captures changes made to a database and propagates those changes to downstream systems for further processing or analysis.</p><p>The diagram below shows how the CDC process works:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19620f0c-746b-4aa7-bd31-d0e6e7329acb_1600x1002.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="445.97802197802196" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19620f0c-746b-4aa7-bd31-d0e6e7329acb_1600x1002.png" width="712" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Adopting a CDC-like approach ensures that all delta changes made to the membership data sources are recorded in an append-only log system, which is backed by a Cassandra database.</p><p>The diagram below shows the flow of historical data in Netflix&#8217;s membership platform:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10297f35-e1ce-4889-906b-3fbd2e84ae6f_1600x1218.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1108" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10297f35-e1ce-4889-906b-3fbd2e84ae6f_1600x1218.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Let&#8217;s walk through the steps in this process:</p><ol><li><p>Suppose there is an update request to modify the billing partner for a member. The request is received by the Membership Subscription Service.</p></li><li><p>The Membership Subscription Service processes the request and updates the relevant information in the Cassandra database.</p></li><li><p>In addition to updating the primary database, the updated data for the user is appended to the Membership History Service. This service is responsible for maintaining a historical record of all changes made to membership data.</p></li><li><p>The Membership History Service takes the appended data and inserts it into the Member History Table. This table serves as a persistent store for the historical data.</p></li><li><p>Finally, an event is emitted to notify downstream systems about the membership update. This allows other services and processes to react to the change and perform any necessary actions.</p></li></ol><p>There are multiple benefits to this design:</p><ul><li><p><strong>Detailed Debugging:</strong> By maintaining a comprehensive history of membership data changes, the system enables detailed debugging and troubleshooting. Developers can trace the sequence of events and understand how the data evolved.</p></li><li><p><strong>Event Replay and Reconciliation:</strong> The append-only nature of the log system allows for the ability to replay events. In case of data corruption or inconsistencies, the system can reconcile the data by replaying the events from a known good state.</p></li><li><p><strong>Customer Service Analysis:</strong> The historical data captured by the Member History Service makes customer service analysis easy.&nbsp;</p></li></ul><h2>Technical Footprint of the Netflix Membership Platform</h2><p>The technical landscape of the Netflix membership platform can be broadly categorized into two main areas: development and operations/monitoring.&nbsp;</p><p>Let's look at each area in detail.</p><h3>Development Stack</h3><p>The development stack of Netflix&#8217;s membership platform can be described by the following key points:</p><ul><li><p>Netflix's architecture is optimized for handling high read requests per second (RPS) to support its massive user base.</p></li><li><p>The membership platform comprises over 12 microservices that communicate using gRPC at the HTTP layer. On a typical day, the platform can handle an impressive 3-4 million requests per second. To support this high volume, Netflix employs techniques like client-side caching at the gRPC level and in-memory caching of entire records to prevent CockroachDB from becoming a single point of failure.</p></li><li><p>The primary programming language used in the membership platform is Java with Spring Boot. However, in certain rewrite scenarios, Netflix is gradually transitioning to Kotlin.</p></li><li><p>Kafka plays a key role in message passing and interfacing with other teams, such as messaging and downstream analytics. This ensures smooth communication and data flow across different systems.</p></li><li><p>Netflix utilizes Spark and Flink for offline reconciliation tasks on their big data. These reconciliation jobs are crucial for maintaining data consistency and alignment between various systems of record within the membership platform, such as subscriptions and member history databases. The accuracy of data also extends to external systems, ensuring a consistent state across the entire ecosystem.</p></li><li><p>To ensure data consistency in online systems, Netflix employs lightweight transactions and uses databases like Cassandra. This approach guarantees the integrity and reliability of data across different services.</p></li></ul><h3>Operations and Monitoring</h3><p>Netflix places a strong emphasis on observability and monitoring to ensure the smooth operation of its membership platform:</p><ul><li><p>Extensive logging, dashboards, and distributed tracing mechanisms enable rapid error detection and resolution. In the complex microservice landscape of Netflix, these tools are essential for identifying and troubleshooting issues.</p></li><li><p>Production alerts are set up to track operational metrics and guarantee optimal service levels.&nbsp;</p></li><li><p>Operational data is leveraged to fuel machine learning models that enhance anomaly detection and enable automated issue resolution processes. All of this is done to try and maintain an uninterrupted streaming experience for the users.</p></li><li><p>Netflix utilizes tools like Kibana and Elasticsearch to create dashboards and analyze log data. In case of a spike in error rates, these dashboards allow the team to quickly identify the specific endpoint causing the issue and take corrective action.</p></li></ul><h2>Conclusion</h2><p>In conclusion, Netflix's membership platform is a critical component of the company's success, enabling it to manage the entire lifecycle of a user's subscription. The platform has evolved from a simple, lightweight library to a robust, scalable architecture that can handle millions of requests per second</p><p>Some key takeaways to remember are as follows:</p><ul><li><p>The membership platform is responsible for managing user signups, plan changes, renewals, and cancellations.</p></li><li><p>It utilizes a microservices architecture and makes use of databases like CockroachDB and Cassandra for storing membership data.</p></li><li><p>The platform captures and stores historical changes to membership data using CDC for debugging, event replay, and analytics.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://youtu.be/fCQKek_J3lQ?si=ibssD2zAHtbW7aG9">Managing 238M memberships at Netflix</a></p></li><li><p><a href="https://www.infoq.com/articles/managing-memberships-netflix/">Netflix&#8217;s Membership Platform</a></p></li><li><p><a href="https://www.infoq.com/presentations/netflix-scalability/">Presentation on Managing 238M memberships at Netflix</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p><br /></p>
]]></content:encoded>
<pubDate>Tue, 25 Jun 2024 15:31:15 GMT</pubDate>
</item>
<item>
<title>EP117: What makes HTTP2 faster than HTTP1?</title>
<link>https://blog.bytebytego.com/p/ep117-what-makes-http2-faster-than</link>
<guid>https://blog.bytebytego.com/p/ep117-what-makes-http2-faster-than</guid>
<content:encoded><![CDATA[
<div> Kafka, RabbitMQ, Messaging Middleware, Pulsar, HTTP2 <br />
总结:<br />
HTTP2相比HTTP1更快的原因在于其具有以下关键特点：二进制帧层使消息编码为二进制格式，实现更高效的处理；多路复用允许客户端和服务器在传输过程中交错发送请求和响应，提高效率；流优先级可定制请求或流的相对权重，确保高优先级请求得到更快响应；服务器推送允许服务器在响应请求时向客户端一并发送附加资源；HPACK头部压缩算法可减小多个请求的头部大小，节省带宽。这些特点使HTTP2实现更快速的传输，但在特定技术场景下也可能存在缓慢情况，因此开发人员需要对其进行测试和优化。Idempotency在各种场景中至关重要，特别是在可能重试或多次执行操作的情况下。Netflix利用缓存技术来保持用户关注度并增强用户体验。包括EVCache的不同用例，如Lookaside Cache、Transient Data Store、Primary Store和High Volume Data。日志解析常用命令包括GREP、CUT、SED、AWK、SORT、UNIQ，结合使用可以快速从日志文件中提取有用信息。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Kafka vs. RabbitMQ vs. Messaging Middleware vs. Pulsar (Youtube video)</p></li><li><p>What makes HTTP2 faster than HTTP1? </p></li><li><p>Top 6 Cases to Apply Idempotency</p></li><li><p>4 Ways Netflix Uses Caching to Hold User Attention</p></li><li><p>Log Parsing Cheat Sheet</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Postman_062224Headline">Collaborating on APIs Is Easier with Postman (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Postman_062224CTA" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ca59bbc-bd0c-4825-a4f5-b896c84aa121_1600x840.png" width="1456" /><div></div></div></a></figure></div><p><a href="https://bit.ly/Postman_062224Headline">API Collaboration</a> improves developer productivity by empowering producers and consumers to share, discover, and reuse high-quality API assets.</p><p>Postman revolutionizes the experience of collaborative API development with Postman <a href="https://bit.ly/Postman_062224Collections">Collections</a> and <a href="https://bit.ly/Postman_062224Workspaces">Workspaces</a>. Used together, they enable API design, testing, and documentation, while providing a shared canvas for collaborating on API assets.&nbsp;</p><p>Learn how companies like <a href="https://bit.ly/Postman_062224Cvent">Cvent</a>, <a href="https://bit.ly/Postman_062224Visma">Visma</a>, <a href="https://bit.ly/Postman_062224BuiltTech">Built Technologies</a>, and <a href="https://bit.ly/Postman_062224Amadeus">Amadeus</a> use Postman to collaborate more easily and deliver better APIs faster.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Postman_062224CTA"><span>Learn More</span></a></p><div><hr /></div><h2><strong>Kafka vs. RabbitMQ vs. Messaging Middleware vs. Pulsar</strong></h2><div class="youtube-wrap" id="youtube2-x4k1XEjNzYQ"><div class="youtube-inner"></div></div><div><hr /></div><h2>What makes HTTP2 faster than HTTP1? </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1727" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69df47d1-db12-4ad8-8dfa-033d391baa0e_1280x1727.gif" title="graphical user interface" width="1280" /><div></div></div></a></figure></div><p>The key features of HTTP2 play a big role in this. Let&#8217;s look at them: </p><ol><li><p>Binary Framing Layer <br />HTTP2 encodes the messages into binary format. <br /> <br />This allows the messages into smaller units called frames, which are then sent over the TCP connection, resulting in more efficient processing. <br /></p></li><li><p>Multiplexing <br />The Binary Framing allows full request and response multiplexing. <br /> <br />Clients and servers can interleave frames during transmissions and reassemble them on the other side. <br /></p></li><li><p>Stream Prioritization <br />With stream prioritization, developers can customize the relative weight of requests or streams to make the server send more frames for higher-priority requests. <br /></p></li><li><p>Server Push <br />Since HTTP2 allows multiple concurrent responses to a client&#8217;s request, a server can send additional resources along with the requested page to the client. <br /></p></li><li><p>HPACK Header Compression <br />HTTP2 uses a special compression algorithm called HPACK to make the headers smaller for multiple requests, thereby saving bandwidth. </p></li></ol><p>Of course, despite these features, HTTP2 can also be slow depending on the exact technical scenario. Therefore, developers need to test and optimize things to maximize the benefits of HTTP2. <br /> <br />Over to you: Have you used HTTP2 in your application?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribehttps://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1652" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5db07039-ccc9-4fb2-afc3-d9a3b1093d6a_3438x3900.jpeg" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">A Crash Course on Microservice Communication Patterns</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Top 6 Cases to Apply Idempotency</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1568" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7da1d252-88b8-4d74-b026-1626cbbb8d59_1280x1568.gif" title="graphical user interface" width="1280" /><div></div></div></a></figure></div><p>Idempotency is essential in various scenarios, particularly where operations might be retried or executed multiple times. Here are the top 6 use cases where idempotency is crucial: </p><ol><li><p>RESTful API Requests <br />We need to ensure that retrying an API request does not lead to multiple executions of the same operation. Implement idempotent methods (like PUT and DELETE) to maintain consistent resource states. <br /></p></li><li><p>Payment Processing <br />We need to ensure that customers are not charged multiple times due to retries or network issues. Payment gateways often need to retry transactions; idempotency ensures only one charge is made. <br /></p></li><li><p>Order Management Systems <br />We need to ensure that submitting an order multiple times results in only one order being placed. We design a safe mechanism to prevent duplicate inventory deductions or updates. <br /></p></li><li><p>Database Operations <br />We need to ensure that reapplying a transaction does not change the database state beyond the initial application. <br /></p></li><li><p>User Account Management <br />We need to ensure that retrying a registration request does not create multiple user accounts. Also, we need to ensure that multiple password reset requests result in a single reset action. <br /></p></li><li><p>Distributed Systems and Messaging <br />We need to ensure that reprocessing messages from a queue does not result in duplicate processing. We Implement handlers that can process the same message multiple times without side effects.</p></li></ol><div><hr /></div><h2>4 Ways Netflix Uses Caching to Hold User Attention</h2><p>The goal of Netflix is to keep you streaming for as long as possible. But a user&#8217;s typical attention span is just 90 seconds.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94417c7a-9711-4103-8677-9fc64c645490_1344x1536.gif" title="No alt text provided for this image" width="1344" /><div></div></div></a></figure></div><p>They use EVCache (a distributed key-value store) to reduce latency so that the users don&#8217;t lose interest.<br /><br />However, EVCache has multiple use cases at Netflix.</p><ol><li><p>Lookaside Cache<br />When the application needs some data, it first tries the EVCache client and if the data is not in the cache, it goes to the backend service and the Cassandra database to fetch the data.<br /><br />The service also keeps the cache updated for future requests.<br /></p></li><li><p>Transient Data Store<br />Netflix uses EVCache to keep track of transient data such as playback session information. <br /><br />One application service might start the session while the other may update the session followed by a session closure at the very end.<br /></p></li><li><p>Primary Store<br />Netflix runs large-scale pre-compute systems every night to compute a brand-new home page for every profile of every user based on watch history and recommendations. <br /><br />All of that data is written into the EVCache cluster from where the online services read the data and build the homepage.<br /></p></li><li><p>High Volume Data<br />Netflix has data that has a high volume of access and also needs to be highly available. For example, UI strings and translations that are shown on the Netflix home page. <br /><br />A separate process asynchronously computes and publishes the UI string to EVCache from where the application can read it with low latency and high availability.</p></li></ol><p>Reference: <a href="https://www.youtube.com/watch?v=Rzdxgx3RC0Q">"Caching at Netflix: The Hidden Microservice" by Scott Mansfield</a></p><div><hr /></div><h2>Log Parsing Cheat Sheet</h2><p>The diagram below lists the top 6 log parsing commands. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1683" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc28f0cbc-a40f-4bdb-88be-f2a0ab900bbc_1280x1683.jpeg" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ol><li><p>GREP <br />GREP searches any given input files, selecting lines that match one or more patterns. <br /></p></li><li><p>CUT <br />CUT cuts out selected portions of each line from each file and writes them to the standard output. <br /></p></li><li><p>SED <br />SED reads the specified files, modifying the input as specified by a list of commands. <br /></p></li><li><p>AWK <br />AWK scans each input file for lines that match any of a set of patterns. <br /></p></li><li><p>SORT <br />SORT sorts text and binary files by lines. <br /></p></li><li><p>UNIQ <br />UNIQ reads the specified input file comparing adjacent lines and writes a copy of each unique input line to the output file. </p></li></ol><p>These commands are often used in combination to quickly find useful information from the log files. For example, the below commands list the timestamps (column 2) when there is an exception happening for xxService. <br /> <br />grep &#8220;xxService&#8221; service.log | grep &#8220;Exception&#8221; | cut -d&#8221; &#8220; -f 2 <br /> <br />Over to you: What other commands do you use when you parse logs?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 22 Jun 2024 15:31:01 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Microservice Communication Patterns</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication</guid>
<content:encoded><![CDATA[
<div> 网络挑战,进程通信,通信模式,性能可扩展性,优劣点

总结:<br /><br />微服务架构带来了独立服务开发的优势，但服务间仍需相互通信以构建一个协调的系统。然而，微服务间通信存在网络挑战和进程通信等困难。开发者在选择通信模式时需要考虑问题的特殊需求，否则会导致性能和可扩展性不佳。本文探讨了微服务的各种通信模式，包括其优势、劣势和最佳使用情况。Microservices architecture promotes the development of independent services. However, these services still need to communicate with each other to function as a cohesive system. Getting the communication right between microservices is often a challenge. There are two primary reasons for this: When microservices communicate over a network, they face inherent challenges associated with inter-process communication. Developers often choose a communication pattern without carefully considering the specific needs of the problem. This can lead to suboptimal performance and scalability. In this post, we explore various communication patterns for microservices and discuss their strengths, weaknesses, and ideal use cases. But first, let’s look at the key challenges associated with microservice communication. <div>
<p>Microservices architecture promotes the development of independent services. However, these services still need to communicate with each other to function as a cohesive system.&nbsp;</p><p>Getting the communication right between microservices is often a challenge. There are two primary reasons for this:</p><ul><li><p>When microservices communicate over a network, they face inherent challenges associated with inter-process communication.</p></li></ul><ul><li><p>Developers often choose a communication pattern without carefully considering the specific needs of the problem. This can lead to suboptimal performance and scalability.</p></li></ul><p>In this post, we explore various communication patterns for microservices and discuss their strengths, weaknesses, and ideal use cases.</p><p>But first, let&#8217;s look at the key challenges associated with microservice communication.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1652" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5db07039-ccc9-4fb2-afc3-d9a3b1093d6a_3438x3900.jpeg" width="1456" /><div></div></div></a></figure></div><h2>Why is Microservice Communication Challenging?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-microservice-communication">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 20 Jun 2024 15:30:51 GMT</pubDate>
</item>
<item>
<title>Scaling to 1.2 Billion Daily API Requests with Caching at RevenueCat</title>
<link>https://blog.bytebytego.com/p/scaling-to-12-billion-daily-api-requests</link>
<guid>https://blog.bytebytego.com/p/scaling-to-12-billion-daily-api-requests</guid>
<content:encoded><![CDATA[
<div> BoldSign, Syncfusion, 缓存, RevenueCat, 数据一致性
总结: BoldSign是Syncfusion提供的电子签名服务，易于开发人员集成。RevenueCat是一个管理应用内订阅和购买的平台，处理大量API请求。RevenueCat通过多种策略保持缓存服务器热。缓存一致性是一个重要挑战，RevenueCat使用写入失败跟踪和一致的CRUD操作来维护数据一致性。缓存服务器迁移时，他们通过逐步切换读取流量来保持数据一致性。 <div>
<h2><a href="https://bit.ly/BoldSign_061824Image">Effortlessly Integrate E-Signatures into Your App with BoldSign (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/BoldSign_061824Image" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="762" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef0928fd-63b8-4e6f-b510-0eb50b2958fe_2400x1256.png" width="1456" /><div></div></div></a></figure></div><p>BoldSign by Syncfusion makes it easy for developers to integrate e-signatures into applications.</p><p>Our powerful <a href="https://bit.ly/BoldSign_061824Image">e-signature API</a> allows you to embed signature requests, create templates, add custom branding, and more.&#8239;&nbsp;</p><p>It&#8217;s so easy to get started that 60% of our customers integrated BoldSign into their apps within one day.&#8239;&nbsp;</p><p>Why BoldSign stands out:&nbsp;</p><ul><li><p>99.999% uptime.&nbsp;</p></li><li><p>Trusted by Ryanair, Cost Plus Drugs, and more.&nbsp;</p></li><li><p>Complies with eIDAS, ESIGN, GDPR, SOC 2, and HIPAA standards.&nbsp;</p></li><li><p>No hidden charges.&nbsp;</p></li><li><p>Free migration support.&#8239;&nbsp;</p></li><li><p>Rated 4.7/5 on G2.&nbsp;</p></li><li><p>Get 20% off the first year with code BYTEBYTEGO20. Valid until Sept. 31, 2024.</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/BoldSign_061824Image"><span>Get started</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the article originally published on the RevenueCat Engineering Blog. All credit for the details about RevenueCat&#8217;s architecture goes to their engineering team. The link to the original article is present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>RevenueCat is a platform that makes it easy for mobile app developers to implement and manage in-app subscriptions and purchases.&nbsp;</p><p>The staggering part is that they handle over 1.2 billion API requests per day from the apps.&nbsp;</p><p>At this massive scale, a fast and reliable performance becomes critical. Some of it is achieved by distributing the workload uniformly across multiple servers.</p><p>However, an efficient caching solution also becomes the need of the hour.</p><p>Caching allows frequently accessed data to be quickly retrieved from fast memory rather than slower backend databases and systems. This can dramatically speed up response times.&nbsp;</p><p>But caching also adds complexity since the cached data must be kept consistent with the source of truth in the databases. Stale or incorrect data in the cache can lead to serious issues.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36d24246-df04-441c-992b-8fad8774a5a5_1600x989.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36d24246-df04-441c-992b-8fad8774a5a5_1600x989.png" /><div></div></div></a></figure></div><p>For an application operating at the scale of RevenueCat, even small inefficiencies or inconsistencies in the caching layer can have a huge impact.&nbsp;</p><p>In this post, we will look at how RevenueCat overcame multiple challenges to build a truly reliable and scalable caching solution using Memcached.</p><div><hr /></div><h2>The Three Key Goals of Caching</h2><p>RevenueCat has three key goals for its caching infrastructure:</p><ul><li><p><strong>Low latency</strong>: The cache needs to be fast because even small delays in the caching layer can have significant consequences at this request volume. Retrying requests and opening new connections are detrimental to the overall performance.&nbsp;</p></li><li><p><strong>Keeping cache servers up and warm</strong>: Cache servers need to stay available and full of frequently accessed data to offload the backend systems.&nbsp;</p></li><li><p><strong>Maintaining data consistency</strong>: Data in the cache needs to be consistent. Inconsistency can lead to serious application issues.&nbsp;</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd66e961c-d13b-4b35-95e9-92354e2aea7e_1600x1102.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd66e961c-d13b-4b35-95e9-92354e2aea7e_1600x1102.png" /><div></div></div></a></figure></div><p>While these main goals are highly relevant to applications operating at scale, a robust caching solution also needs supporting features such as monitoring and observability, optimization, and some sort of automated scaling.</p><p>Let&#8217;s look at each of these goals in more detail and how RevenueCat&#8217;s engineering team achieved them.</p><h2>Low Latency</h2><p>There&#8217;s no doubt that latency has a huge impact on user experience.&nbsp;</p><p>As per a statistic by Amazon, every 100ms of latency costs them 1% in sales. While it&#8217;s hard to confirm whether this is 100% true, there&#8217;s no denying the fact that latency impacts user experience.</p><p>Even small delays of a few hundred milliseconds can make an application feel sluggish and unresponsive. As latency increases, user engagement and satisfaction plummet.</p><p>RevenueCat achieves low latency in its caching layer through two key techniques.</p><h3>1 - Pre-established connections</h3><p>Their cache client maintains a pool of open connections to the cache servers.&nbsp;</p><p>When the application needs to make a cache request, it borrows a connection from the pool instead of establishing a new TCP one. This is because a TCP handshake could nearly double the cache response times. Borrowing the connection avoids the overhead of the TCP handshake on each request.&nbsp;</p><p>But no decision comes without some tradeoff.</p><p>Keeping connections open consumes memory and other resources on both the client and server. Therefore, it&#8217;s important to carefully tune the number of connections to balance resource usage with the ability to handle traffic spikes.</p><h3>2 - Fail-fast approach</h3><p>If a cache server becomes unresponsive, the client immediately marks it as down for a few seconds and fails the request, treating it as a cache miss.&nbsp;</p><p>In other words, the client will not retry the request or attempt to establish new connections to the problematic server during this period.</p><p>The key insight here is that even brief retry delays of 100ms can cause cascading failures under heavy load. Requests pile up, servers get overloaded, and the "retry storm" can bring the whole system down. Though it might sound counterintuitive, failing fast is crucial for a stable system.</p><p>But what&#8217;s the tradeoff here?</p><p>There may be a slight increase in cache misses when servers have temporary issues. But this is far better than risking a system-wide outage. A 99.99% cache hit rate is meaningless if 0.01% of requests trigger cascading failures. Prioritizing stability over perfect efficiency is the right call.</p><p>One potential enhancement over here could be circuit breaking where requests to misbehaving servers can be disabled based on error rates and latency measurements. This is something that Uber uses in their integrated cache solution called CacheFront.</p><p>However, the aggressive timeouts and managing connection pools likely achieve similar results with far less complexity.</p><h2>Keeping Cache Servers Warm</h2><p>The next goal RevenueCat had was keeping the cache servers warm.</p><p>They employed several strategies to achieve this.</p><h3>1 - Planning for Failure with Mirrored and Gutter pool</h3><p>RevenueCat uses fallback cache pools to handle failures.&nbsp;</p><p>Their strategy is designed to handle cache server failures and maintain high availability. The two approaches they use are as follows:</p><ul><li><p><strong>Mirrored pool:</strong> A fully synchronized secondary cache pool that receives all writes and can immediately take over reads if the primary pool fails.</p></li><li><p><strong>Gutter pool:</strong> A small, empty cache pool that temporarily caches values with a short TTL when the primary pool fails, reducing the load on the backend until the primary recovers. For reference, the gutter pool technique was also used by Facebook when they built their caching architecture with Memcached.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50aeb09f-579f-4df0-bb95-31c37134dafb_1600x925.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50aeb09f-579f-4df0-bb95-31c37134dafb_1600x925.png" /><div></div></div></a></figure></div><p>Here also, there are trade-offs to consider concerning server size:</p><p>For example, having smaller servers provides benefits such as:</p><ul><li><p><strong>Granular failure impact:</strong> With many small cache servers, the failure of a single server affects a smaller portion of the cached data. This can make the fallback pool more effective, as it needs to handle a smaller subset of the total traffic.</p></li><li><p><strong>Faster warmup:</strong> When a small server fails and the gutter pool takes over, it can warm up the cache for that server&#8217;s key space more quickly due to the smaller data volume.</p></li></ul><p>However, small servers also have drawbacks:</p><ul><li><p>Increased operational complexity of managing a larger number of servers adds operational complexity.&nbsp;</p></li><li><p>A higher connection overhead where each application server has to maintain connections to all cache servers.&nbsp;</p></li></ul><p>The diagram below from RevenueCat&#8217;s article shows this comparison:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20cacb99-819b-4a42-925c-7eed2bbc2626_1534x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1519" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20cacb99-819b-4a42-925c-7eed2bbc2626_1534x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><ul><li><p><strong>Simplified management:</strong> Fewer large servers are easier to manage and maintain compared to many small instances. There are fewer moving parts and less complexity in the overall system.</p></li><li><p><strong>Improved resource utilization:</strong> Larger servers can more effectively utilize the available CPU, memory, and network resources, leading to better cost efficiency.</p></li><li><p><strong>Fewer connections:</strong> With fewer cache servers, the total number of connections from the application servers is reduced, minimizing connection overhead.</p></li></ul><p>Bigger servers also have some trade-offs:</p><ul><li><p>When a large server fails, a larger portion of the cached data becomes unavailable. The fallback pool needs to handle a larger volume of traffic, potentially increasing the load on the backend.</p></li><li><p>In the case of a failure, warming up the cache for a larger key space may take longer due to the increased data volume.</p></li></ul><p>This is where the strategy of using a mirrored pool for fast failover and a gutter pool for temporary caching strikes a balance between availability and cost.&nbsp;</p><p>The mirrored pool ensures immediate availability. The gutter pool, on the other hand, provides a cost-effective way to handle failures temporarily.</p><p>Generally speaking, it&#8217;s better to design the cache tier based on a solid understanding of the backend capacity. Also, when using sharding, the cache, and the backend sharding should be orthogonal so that a cache server going down translates into a moderate increase on backend servers.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="883" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84724fef-c993-411d-9ad9-07aabc1d7542_1600x970.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>2 - Dedicated Pools</h3><p>Another technique they employ to keep cache servers warm is to use dedicated cache pools for certain use cases.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48b6bfd0-9267-4a51-bf23-dc1f0cae76c7_1600x1191.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1084" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48b6bfd0-9267-4a51-bf23-dc1f0cae76c7_1600x1191.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s how the strategy works:</p><ul><li><p><strong>Identifying high-value data</strong>: The first step is to analyze the application's data access patterns and identify datasets that are crucial for performance, accuracy, or user experience. This could include frequently accessed configuration settings, important user-specific data, or computationally expensive results.</p></li><li><p><strong>Creating dedicated pools: </strong>Instead of relying on a single shared cache pool, create separate pools for each identified high-value dataset. These dedicated pools have their own allocated memory and operate independently from the main cache pool.</p></li><li><p><strong>Reserving memory:</strong> By allocating dedicated memory to each pool, they ensure that the high-value data has a guaranteed space in the cache. This prevents other less critical data from evicting the important information, even under high memory pressure.</p></li><li><p><strong>Tailored eviction policies:</strong> Each dedicated pool can have its eviction policy tailored to the specific characteristics of the dataset. For example, a pool holding expensive-to-recompute data might have a longer TTL or a different eviction algorithm compared to a pool with frequently updated data.</p></li></ul><p>The dedicated pools strategy has several advantages:</p><ul><li><p>Improved cache hit ratio for critical data</p></li><li><p>Increased data accuracy</p></li><li><p>Flexibility in cache management</p></li></ul><h3>3 - Handling Hot Keys</h3><p>Hot keys are a common challenge in caching systems.&nbsp;</p><p>They refer to keys that are accessed more frequently than others, leading to a high concentration of requests on a single cache server. This can cause performance issues and overload the server, potentially impacting the overall system.</p><p>There are two main strategies for handling hot keys:</p><h4>Key Splitting</h4><p>The below points explain how key splitting works:</p><ul><li><p>Key splitting involves distributing the load of a hot key across multiple servers.</p></li><li><p>Instead of having a single key, the key is split into multiple versions, such as keyX/1, keyX/2, keyX/3, etc.</p></li><li><p>Each version of the key is placed on a different server, effectively spreading the load.</p></li><li><p>Clients read from one version of the key (usually determined by their client ID) but write to all versions to maintain consistency.</p></li><li><p>The challenge with key splitting is detecting hot keys in real time and coordinating the splitting process across all clients.</p></li><li><p>It requires a pipeline to identify hot keys, determine the splitting factor, and ensure that all clients perform the splitting simultaneously to avoid inconsistencies.</p></li><li><p>The list of hot keys is dynamic and can change based on real-life events or trends, so the detection and splitting process needs to be responsive.</p></li></ul><h4>Local Caching</h4><p>Local caching is simpler when compared to key splitting.</p><p>Here are some points to explain how it works:</p><ul><li><p>Local caching involves caching hot keys directly on the client-side, rather than relying solely on the distributed cache.</p></li><li><p>A key is cached locally on the client with a short TTL (Time-To-Live) when a key is identified as hot.</p></li><li><p>Subsequent requests for that key are served from the local cache, reducing the load on the distributed cache servers.</p></li><li><p>Local caching doesn't require coordination among clients.</p></li><li><p>However, local caching provides weaker consistency guarantees since the locally cached data may become stale if updates occur frequently.</p></li><li><p>To mitigate this, it&#8217;s important to use short TTLs for locally cached keys and only apply local caching to data that changes rarely.</p></li></ul><h3>Avoiding Thundering Herds</h3><p>When a popular key expires, all clients may request it from the backend simultaneously, causing a spike. This is known as the &#8220;thundering herd situation&#8221;.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6d6a925-6fea-4c79-b9c1-7256764f94c0_1532x992.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6d6a925-6fea-4c79-b9c1-7256764f94c0_1532x992.png" /><div></div></div></a></figure></div><p>RevenueCat avoids this situation since it tries to maintain cache consistency by updating it during the writes. However, when using low TTLs and invalidations from DB changes, the thundering herd can cause a lot of problems.</p><p>Some other potential solutions to avoid thundering herds are as follows:</p><ul><li><p><strong>Recache policy: </strong>The GET requests can include a recache policy. When the remaining TTL is less than the given value, one of the clients will get a miss and re-populate the value in the cache while other clients continue to use the existing value.</p></li><li><p><strong>Stale policy: </strong>In the delete command, the key is marked as stale. A single client gets a miss while others keep using the old value.</p></li><li><p><strong>Lease policy:</strong> In this policy, only one client wins the right to repopulate the value while the losers just have to wait for the winner to re-populate. For reference, Facebook uses leasing in its Memcache setup.</p></li></ul><h3>Cache Server Migrations</h3><p>Sometimes cache servers have to be replaced while minimizing impact on hit rates and user experience.</p><p>RevenueCat has built a coordinated cache server migration system that consists of the following steps:</p><ol><li><p>Warming up the new cluster:</p><ul><li><p>Before switching traffic, the team starts warming up the new cache cluster.</p></li><li><p>They populate the new cluster by mirroring all the writes from the existing cluster.</p></li><li><p>This ensures that the new cluster has the most up-to-date data before serving any requests.</p></li></ul></li><li><p>Switching a percentage of reads:</p><ul><li><p>After the new cluster is sufficiently warm, the team gradually switches a percentage of read traffic to it.</p></li><li><p>This allows them to test the new cluster&#8217;s performance and stability under real-world load.</p></li></ul></li><li><p>Flipping all traffic:</p><ul><li><p>Once the new cluster has proven its stability and performance, the traffic is flipped over to it.</p></li><li><p>At this point, the new cluster becomes the primary cache cluster, serving all read and write requests.</p></li><li><p>The old cluster is kept running for a while, with writes still being mirrored to it. This allows quick fallback in case of any issues.</p></li></ul></li><li><p>Decommissioning the old cluster:</p><ul><li><p>After a period of stable operation with the new cluster as the primary, the old cluster is decommissioned.</p></li><li><p>This frees up resources and completes the migration process.</p></li></ul></li></ol><p>The diagram below shows the entire migration process.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4d8294c-1c80-4b9a-aa1c-14e3f8e819d9_1575x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1479" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4d8294c-1c80-4b9a-aa1c-14e3f8e819d9_1575x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Maintaining data consistency is one of the biggest challenges when using caching in distributed systems.&nbsp;</p><p>The fundamental issue is that data is stored in multiple places - the primary data store (like a database) and the cache. Keeping the data in sync across these locations in the face of concurrent reads and writes is a non-trivial problem.</p><p>See the example below that shows how a simple race condition can result in a consistency problem between the database and the cache.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede53f17-11f8-400e-9067-a70b78ca3238_1600x948.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede53f17-11f8-400e-9067-a70b78ca3238_1600x948.png" /><div></div></div></a><figcaption class="image-caption">Source: <a href="https://www.revenuecat.com/blog/engineering/data-caching-revenuecat/">RevenueCat Engineering Blog</a></figcaption></figure></div><p>What&#8217;s going on over here?</p><ul><li><p>Web Server 1 gets a cache miss and fetches data from the database.</p></li><li><p>A second request results in Web Server 2 performing a DB Write for the same data. It also updates the cache with the new data</p></li><li><p>Web Server 2 refills the cache with the stale data that it had fetched in step 1.</p></li></ul><p>RevenueCat uses two main strategies to maintain cache consistency.</p><h3>1 - Write Failure Tracking</h3><p>In RevenueCat's system, a cache write failure is a strong signal that there may be an inconsistency between the cache and the primary store.&nbsp;</p><p>However, there are better options than simply retrying the write because that can lead to cascading failures and overload as discussed earlier.</p><p>Instead, RevenueCat's caching client records all write failures. After recording, it deduplicates them and ensures that the affected keys are invalidated in the cache at least once (retrying as needed until successful). This guarantees that the next read for those keys will fetch fresh data from the primary store, resynchronizing the cache.</p><p>This write failure tracking allows them to treat cache writes as if they should always succeed, significantly simplifying their consistency model. They can assume the write succeeded, and if it didn't, the tracker will ensure eventual consistency.</p><h3>2 - Consistent CRUD Operations</h3><p>For each type of data operation (Create, Read, Update, Delete), they have developed a strategy to keep the cache and primary store in sync.</p><p>For reads, they use the standard cache-aside pattern: read from the cache, and on a miss, read from the primary store and populate the cache. They always use an "add" operation to populate, which only succeeds if the key doesn't already exist, to avoid overwriting newer values.</p><p>For updates, they use a clever strategy as follows:</p><ul><li><p>Before the update, they reduce the cache entry's TTL to a low value like 30 seconds</p></li><li><p>They update the primary data store</p></li><li><p>After the update, they update the cache with the new value and reset the TTL</p></li></ul><p>If a failure occurs between steps 1 and 2, the cache remains consistent as the update never reaches the primary store. If a failure occurs between 2 and 3, the cache will be stale, but only for a short time until the reduced TTL expires. Also, any complete failures are caught by the write failure tracker that we talked about earlier.</p><p>For deletes, they use a similar TTL reduction strategy before the primary store delete.&nbsp;</p><p>However, for creation, they rely on the primary store to provide unique IDs to avoid conflicts.</p><h2>Conclusion</h2><p>RevenueCat&#8217;s approach illustrates the complexities of running caches at a massive scale. While some details may be specific to their Memcached setup, the high-level lessons are widely relevant.</p><p>Here are some key takeaways to consider from this case study:</p><ul><li><p>Use low timeouts and fail fast on cache misses. Retries can cause cascading failures under load.</p></li><li><p>Plan cache capacity for failure scenarios. Ensure the system can handle multiple cache servers going down without overloading backends.</p></li><li><p>Use fallback and dedicated cache pools. Mirrored fallback pools and dedicated pools for critical data help keep caches warm and handle failures.</p></li><li><p>Handle hot keys through splitting or local caching. Distribute load from extremely popular keys across servers or cache them locally with low TTLs.</p></li><li><p>Avoid "thundering herds" with techniques like stale-while-revalidate and leasing.</p></li><li><p>Track and handle cache write failures. Assume writes always succeed but invalidate on failure to maintain consistency.</p></li><li><p>Implement well-tested strategies for cache updates during CRUD operations. Techniques like TTL reduction before writes help maintain consistency across cache and database.</p></li></ul><p>References:</p><ul><li><p><a href="https://www.revenuecat.com/blog/engineering/data-caching-revenuecat/">Scaling Smoothly: RevenueCat&#8217;s data-caching techniques for 1.2 billion daily API requests</a></p></li><li><p><a href="https://www.infoq.com/news/2024/01/revenuecat-cache-management/">How RevenueCat Manages Caching for Handling over 1.2 Billion API Requests</a></p></li><li><p><a href="https://research.facebook.com/publications/scaling-memcache-at-facebook/">Scaling Memcache at Facebook</a></p></li><li><p><a href="https://www.uber.com/en-IN/blog/how-uber-serves-over-40-million-reads-per-second-using-an-integrated-cache/">How Uber Serves Over 40 Million Reads Per Second from Online Storage Using Integrated Cache</a></p></li><li><p><a href="https://www.gigaspaces.com/blog/amazon-found-every-100ms-of-latency-cost-them-1-in-sales">Amazon Found Every 100ms of Latency Cost Them 1% in Sales</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></p><p></p>
]]></content:encoded>
<pubDate>Tue, 18 Jun 2024 15:30:55 GMT</pubDate>
</item>
<item>
<title>EP116: 11 steps to go from Junior to Senior Developer</title>
<link>https://blog.bytebytego.com/p/ep116-11-steps-to-go-from-junior</link>
<guid>https://blog.bytebytego.com/p/ep116-11-steps-to-go-from-junior</guid>
<content:encoded><![CDATA[
<div> Data Pipeline, Senior Developer, Docker concepts, Microservice architecture, Open-Source Databases
<br />
Data Pipeline是什么？为什么这么受欢迎？数据管道是数据处理流程的自动化，十分流行。成为高级开发人员的11个步骤包括使用合作工具、精通编程语言、API开发、Web服务器与托管、身份验证与测试、数据库、CI/CD、数据结构与算法、系统设计、设计模式、AI工具等。Docker有8个重要概念，如Dockerfile、Docker镜像、容器、注册表、卷、Compose、网络、CLI等。典型微服务架构包括负载均衡器、CDN、API网关、身份验证提供者、服务注册与发现、管理及微服务等组件。最受欢迎的开源数据库包括MySQL、PostgreSQL、MariaDB、Apache Cassandra、Neo4j、SQLite、CockroachDB、Redis、MongoDB、Couchbase等。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>What is Data Pipeline? | Why Is It So Popular? (Youtube video)</p></li><li><p>11 steps to go from Junior to Senior Developer</p></li><li><p>Top 8 must-know Docker concepts </p></li><li><p>What does a typical microservice architecture look like? </p></li><li><p>Top 10 Most Popular Open-Source Databases </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/NewRelic_061524">New Relic Digital Monitoring Experience (DEM) (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/NewRelic_061524" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="680" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2750532-75bd-4c68-ba57-78c3a39bfb9e_1296x680.png" width="1296" /><div></div></div></a></figure></div><p>New Relic DEM solutions are designed to provide comprehensive insights into digital operations, allowing teams to optimize user experiences in real time.</p><p>Download the datasheet&nbsp;for an overview of New Relic DEM capabilities:</p><ul><li><p><strong>Real user monitoring (RUM):</strong> Browser monitoring and mobile monitoring&nbsp;&nbsp;</p></li><li><p><strong>Pixel-perfect replays:</strong> Session replay</p></li><li><p><strong>Proactive issue detection:&nbsp;</strong>Synthetic monitoring, mobile user journeys (crash analysis), and error tracking (errors inbox)</p></li><li><p><strong>Integration and collaboration:</strong> In-app collaboration capabilities&nbsp;</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/NewRelic_061524"><span>Download the data sheet</span></a></p><div><hr /></div><h2>What is Data Pipeline? | Why Is It So Popular?</h2><div class="youtube-wrap" id="youtube2-kGT4PcTEPP8"><div class="youtube-inner"></div></div><div><hr /></div><h2>11 steps to go from Junior to Senior Developer</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1562" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F507dbf27-df25-4d96-b09a-0a89e4b27ea4_1280x1562.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><ol><li><p>Collaboration Tools <br />Software development is a social activity. Learn to use collaboration tools like Jira, Confluence, Slack, MS Teams, Zoom, etc. <br /></p></li><li><p>Programming Languages <br />Pick and master one or two programming languages. Choose from options like Java, Python, JavaScript, C#, Go, etc. <br /></p></li><li><p>API Development <br />Learn the ins and outs of API Development approaches such as REST, GraphQL, and gRPC. <br /></p></li><li><p>Web Servers and Hosting <br />Know about web servers as well as cloud platforms like AWS, Azure, GCP, and Kubernetes <br /></p></li><li><p>Authentication and Testing <br />Learn how to secure your applications with authentication techniques such as JWTs, OAuth2, etc. Also, master testing techniques like TDD, E2E Testing, and Performance Testing <br /></p></li><li><p>Databases <br />Learn to work with relational (Postgres, MySQL, and SQLite) and non-relational databases (MongoDB, Cassandra, and Redis). <br /></p></li><li><p>CI/CD <br />Pick tools like GitHub Actions, Jenkins, or CircleCI to learn about continuous integration and continuous delivery. <br /></p></li><li><p>Data Structures and Algorithms <br />Master the basics of DSA with topics like Big O Notation, Sorting, Trees, and Graphs. <br /></p></li><li><p>System Design <br />Learn System Design concepts such as Networking, Caching, CDNs, Microservices, Messaging, Load Balancing, Replication, Distributed Systems, etc. <br /></p></li><li><p>Design patterns <br />Master the application of design patterns such as dependency injection, factory, proxy, observers, and facade. <br /></p></li><li><p>AI Tools <br />To future-proof your career, learn to leverage AI tools like GitHub Copilot, ChatGPT, Langchain, and Prompt Engineering. </p></li></ol><p>Over to you: What else would you add to the roadmap?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="938" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2490fa0-671a-4248-81d9-7106dd8411eb_1600x1031.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">A Crash Course on Cell-based Architecture</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Top 8 must-know Docker concepts </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F033ac539-080f-4ad6-87e5-643b18ec3956_1498x1536.gif" title="graphical user interface, application" /><div></div></div></a></figure></div><ol><li><p>Dockerfile: It contains the instructions to build a Docker image by specifying the base image, dependencies, and run command. <br /> </p></li><li><p>Docker Image: A lightweight, standalone package that includes everything (code, libraries, and dependencies) needed to run your application. Images are built from a Dockerfile and can be versioned. <br /></p></li><li><p>Docker Container: A running instance of a Docker image. Containers are isolated from each other and the host system, providing a secure and reproducible environment for running your apps. <br /></p></li><li><p>Docker Registry: A centralized repository for storing and distributing Docker images. For example, Docker Hub is the default public registry but you can also set up private registries. <br /></p></li><li><p>Docker Volumes: A way to persist data generated by containers. Volumes are outside the container&#8217;s file system and can be shared between multiple containers. <br /></p></li><li><p>Docker Compose: A tool for defining and running multi-container Docker applications, making it easy to manage the entire stack. <br /></p></li><li><p>Docker Networks: Used to enable communication between containers and the host system. Custom networks can isolate containers or enable selective communication. <br /></p></li><li><p>Docker CLI: The primary way to interact with Docker, providing commands for building images, running containers, managing volumes, and performing other operations. </p></li></ol><p>Over to you: What other concept should one know about Docker?</p><div><hr /></div><h2>What does a typical microservice architecture look like? &#128071;</h2><p>The diagram below shows a typical microservice architecture.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1779" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c8d4eab-24cb-49c6-92fa-6e914603b21b_1280x1779.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ul><li><p>Load Balancer: This distributes incoming traffic across multiple backend services.</p></li><li><p>CDN (Content Delivery Network): CDN is a group of geographically distributed servers that hold static content for faster delivery. The clients look for content in CDN first, then progress to backend services.</p></li><li><p>API Gateway: This handles incoming requests and routes them to the relevant services. It talks to the identity provider and service discovery.</p></li><li><p>Identity Provider: This handles authentication and authorization for users.</p></li><li><p>Service Registry &amp; Discovery: Microservice registration and discovery happen in this component, and the API gateway looks for relevant services in this component to talk to.</p></li><li><p>Management: This component is responsible for monitoring the services.</p></li><li><p>Microservices: Microservices are designed and deployed in different domains. Each domain has its database.</p></li></ul><p>Over to you: </p><ol><li><p>What are the drawbacks of the microservice architecture?</p></li><li><p>Have you seen a monolithic system be transformed into microservice architecture? How long does it take?</p></li></ol><div><hr /></div><h2>Top 10 Most Popular Open-Source Databases </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="diagram" class="sizing-normal" height="1622" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ea57069-5a32-4f02-b015-2bdb883dd135_1280x1622.gif" title="diagram" width="1280" /><div></div></div></a></figure></div><p>This list is based on factors like adoption, industry impact, and the general awareness of the database among the developer community. </p><ol><li><p>MySQL </p></li><li><p>PostgreSQL </p></li><li><p>MariaDB </p></li><li><p>Apache Cassandra </p></li><li><p>Neo4j </p></li><li><p>SQLite </p></li><li><p>CockroachDB </p></li><li><p>Redis </p></li><li><p>MongoDB </p></li><li><p>Couchbase </p></li></ol><p>Over to you: Which other database would you add to this list?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 15:31:04 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Cell-based Architecture</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture</guid>
<content:encoded><![CDATA[
<div> bulkheads, cell-based architecture, independent, failure isolation, workload
<br />
cell-based architecture是一种软件开发架构，类似于船只内部的防水隔舱，将工作负载分割成多个独立的cell，每个cell独立运行，不共享状态，处理部分流量请求。这种架构减小了故障影响范围，一旦一个cell发生故障，仅影响部分工作负载，不会引起整体系统崩溃。通过实现故障隔离，cell-based architecture提高了系统的稳定性和可靠性。 <div>
<p>No one wants to sail in a ship that can sink because of a single hull breach.</p><p>This led to the development of bulkheads, which are vertical partition walls that divide a ship&#8217;s interior into watertight compartments.</p><p>Cell-based architecture attempts to follow the same concept in software development.</p><p>In cell-based architecture, there are multiple isolated instances of a workload, where each instance is known as a cell. There are three properties of a cell:</p><ul><li><p>Each cell is independent.</p></li><li><p>A cell does not share the state with other cells.</p></li><li><p>Each cell handles a subset of the overall traffic.</p></li></ul><p>For example, imagine a web application that handles user requests. In a cell-based architecture, multiple cells of the same web application would be deployed, each serving a subset of the user requests. These cells are copies of the same application working together to distribute the workload.</p><p>This approach reduces the blast radius of impact. If a workload uses 5 cells to service 50 requests, a failure in only one cell means that 80% of the requests are unaffected by the failure.</p><p>In other words, failure isolation is the biggest benefit of a cell-based architecture.</p><p>In this post, we will learn about the various aspects of cell-based architecture and its various components in more detail.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2490fa0-671a-4248-81d9-7106dd8411eb_1600x1031.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="938" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2490fa0-671a-4248-81d9-7106dd8411eb_1600x1031.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>What is a Workload?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-cell-based-architecture">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 15:30:19 GMT</pubDate>
</item>
<item>
<title>How PayPal Scaled Kafka to 1.3 Trillion Daily Messages</title>
<link>https://blog.bytebytego.com/p/how-paypal-scaled-kafka-to-13-trillion</link>
<guid>https://blog.bytebytego.com/p/how-paypal-scaled-kafka-to-13-trillion</guid>
<content:encoded><![CDATA[
<div> Kafka, PayPal, Cluster Management, Monitoring, ACLs
<br />
Kafka是PayPal的关键组件，他们在Cluster Management和Monitoring方面进行了重要的改进。他们引入了ACLs来控制Kafka集群的访问权限。此外，他们建立了专门的QA环境，用于测试和验证变更。总结: PayPal在Kafka平台上的操作经验为大规模运营提供了重要的启示。他们强调工具化操作和持续监控，通过引入ACLs提高安全性，建立QA环境提高开发效率。 <div>
<h2><a href="https://bit.ly/ScyllaDB_061124">Database Performance at Scale: A Practical Guide [FREE BOOK] (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/ScyllaDB_061124" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Face0df4f-42a2-4e55-aab7-1a4841ad3a4e_1600x840.png" width="1456" /><div></div></div></a></figure></div><p>Discover new ways to optimize database performance &#8211; and avoid common pitfalls &#8211; in this free 270-page book.</p><p>This book shares best practices for achieving predictable low latency at high throughput. It&#8217;s based on learnings from thousands of real-world database use cases &#8211; including Discord, Disney, Strava, Expedia, Epic Games &amp; more.</p><ul><li><p>Explore often-overlooked factors that impact database performance at scale</p></li><li><p>Recognize the performance challenges teams face with different types of workloads</p></li><li><p>Select database infrastructure and topology that&#8217;s suited to your needs</p></li><li><p>Optimize how you benchmark and monitor performance</p></li><li><p>Avoid common mistakes that impact latency and throughput</p></li><li><p>Get practical advice for navigating performance tradeoffs</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/ScyllaDB_061124"><span>Download for free</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from the article originally published on the PayPal Tech Blog. All credit for the details about PayPal&#8217;s architecture goes to their engineering team. The link to the original article is present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>In the 2022 Retail Friday, PayPal&#8217;s Kafka setup witnessed a traffic volume of 21 million messages per second.</p><p>This was about 1.3 trillion messages in a single day.&nbsp;</p><p>Similarly, Cyber Monday resulted in 19 million messages per second coming to around 1.23 trillion messages in a single day.</p><p>How did PayPal scale Kafka to achieve these incredible numbers?</p><p>In this post, we will go through the complete details of PayPal&#8217;s high-performance Kafka setup that made it possible.</p><div><hr /></div><h2>Kafka at PayPal</h2><p>Apache Kafka is an open-source distributed event streaming platform.</p><p>PayPal adopted Kafka in 2015 and they use it for building data streaming pipelines, integration, and ingestion.</p><p>At present, PayPal&#8217;s Kafka fleet consists of over 1500 brokers hosting 20,000 topics. The 85+ clusters are expected to maintain a 99.99% availability.</p><p>Over the years, PayPal has seen tremendous growth in streaming data and they wanted to ensure high availability, fault tolerance, and optimal performance.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f4ab7cc-f445-44f3-8f13-a1b70a41b13b_1600x1512.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1376" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2f4ab7cc-f445-44f3-8f13-a1b70a41b13b_1600x1512.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Some of the specific use cases where PayPal uses Kafka are as follows:&nbsp;</p><ul><li><p><strong>First-party Tracking: </strong>Tracking user interactions and clickstream data on PayPal&#8217;s website and mobile app for real-time analytics and personalization.</p></li><li><p><strong>Application Health Metrics: </strong>Collecting and aggregating performance metrics from various PayPal services to monitor system health and detect anomalies.</p></li><li><p><strong>Database Synchronization: </strong>Synchronizing data between PayPal&#8217;s primary database and secondary databases for disaster recovery and high availability.</p></li><li><p><strong>Application Log Aggregation: </strong>Collecting and centralizing log data from different PayPal applications and services for troubleshooting, monitoring, and analysis.</p></li><li><p><strong>Batch Processing: </strong>Processing large batches of payment transaction data using Kafka as a buffer for decoupling the data ingestion and processing stages.</p></li><li><p><strong>Risk Detection and Management: </strong>Streaming real-time payment data through Kafka for feeding the fraud detection and risk assessment models.</p></li><li><p><strong>Analytics and Compliance: </strong>Capturing and analyzing financial transaction data in real-time for regulatory reporting and audit purposes.</p></li></ul><h2>How PayPal Operates Kafka?</h2><p>PayPal&#8217;s infrastructure is spread across multiple geographically distributed data centers and security zones. Kafka clusters are deployed across these zones.</p><p>There are some key differences between data centers and security zones:</p><ul><li><p>A data center is a physical facility that houses computing infrastructure. A security zone is a logical partition with a data center or across data centers, created through network segmentation.</p></li><li><p>While data centers help with isolation and availability, security zones provide an additional level of security isolation beyond the physical boundaries.</p></li><li><p>Security zones are often defined based on data classification levels, such as highly sensitive, confidential, or public data.</p></li></ul><p>In the context of PayPal, Kafka clusters handling sensitive payment data may be placed in a high-security zone with restricted access. Clusters processing less sensitive data may reside in a different security zone.</p><p>One thing, however, is common.</p><p>Whether it is data centers or security zones, MirrorMaker is used to mirror the data across the data centers, which helps with disaster recovery and communication across security zones.&nbsp;</p><p>For reference, Kafka MirrorMaker is a tool for mirroring data between Apache Kafka clusters. It leverages the Kafka Connect framework to replicate data, which improves resiliency.&nbsp;</p><p>See the diagram below to get an idea about PayPal&#8217;s Kafka setup across data centers and security zones:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf13b1a8-70b3-42b5-8a07-dd61adc91818_1388x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf13b1a8-70b3-42b5-8a07-dd61adc91818_1388x1600.png" width="1388" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Operating Kafka at the scale of PayPal is a challenging task. To manage the ever-growing fleet of Kafka clusters, PayPal has focused on some key areas such as:</p><ul><li><p>Cluster Management</p></li><li><p>Monitoring and Alerting</p></li><li><p>Configuration Management</p></li><li><p>Enhancements and Automation</p></li></ul><p>The diagram below shows a high-level view of PayPal&#8217;s Kafka Landscape:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc267306b-64d1-45e2-bc0a-e61e340dbc04_1600x1015.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="924" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc267306b-64d1-45e2-bc0a-e61e340dbc04_1600x1015.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In the subsequent sections, we will look at each area in greater detail.</p><h2>Cluster Management</h2><p>Cluster management deals with controlling Kafka clusters and reducing operational overhead. Some of the key improvements were done in areas like:</p><ul><li><p>Kafka Config Service</p></li><li><p>ACLs</p></li><li><p>Kafka Libraries for PayPal</p></li><li><p>QA environment</p></li></ul><p>Let&#8217;s look at each improvement in more detail.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1005" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2785489-6c63-40cf-bb4a-1b8656a81d01_1600x1104.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>Kafka Config Service</h3><p>PayPal built a special Kafka config service to make it easy for clients to connect to the Kafka clusters.</p><p>Before the config service, clients had to hardcode the broker IPs in the connection configuration.&nbsp;</p><p>This created a maintenance nightmare due to a couple of reasons:</p><ul><li><p>Firstly, replacing a broker for upgrades, patching, or disk failures required updates to the client. Missing to update one broker IP somewhere would often lead to multiple incidents.</p></li><li><p>Second, Kafka is configuration-heavy, making it tough for developers to figure out a suitable set of configurations. Often, the Kafka clients would override certain properties without knowing the implications, resulting in support issues due to unexpected behavior.</p></li></ul><p>The Kafka config service solved these issues. The service makes it easy for the Kafka clients to follow a standard configuration. Ultimately, it reduces operational and support overhead across teams.</p><p>The diagram below shows the Kafka client retrieving bootstrap servers and configuration from the config service using the topic information.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaa0d294-4b44-4c17-b7a8-26b7f8dc2513_1600x1021.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="929" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcaa0d294-4b44-4c17-b7a8-26b7f8dc2513_1600x1021.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Kafka ACLs</h3><p>Initially, any PayPal application could connect to any of the existing Kafka topics. This was an operational risk for the platform considering that it streams business-critical data.</p><p>To ensure controlled access to Kafka clusters, ACLs were introduced.</p><p>For reference, ACLs are used to define which users, groups, or processes have access to specific objects such as files, directories, applications, or network resources. It&#8217;s like a table or list specifying a particular object's permissions.</p><p>With the introduction of ACLs, applications had to authenticate and authorize access to Kafka clusters and topics.&nbsp;</p><p>Apart from making the platform secure, ACLs also provided a record of every application accessing a particular topic or cluster.</p><h3>PayPal Kafka Libraries&nbsp;</h3><p>It was important to ensure that Kafka clusters and the clients connecting to them operate securely. Also, there was a need to ensure easy integration to multiple frameworks and programming languages. They didn&#8217;t want each engineering team to reinvent the wheel.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac03b947-fed2-455d-a3df-9a538691c336_946x624.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="624" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac03b947-fed2-455d-a3df-9a538691c336_946x624.png" width="946" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Supported tech stack for Kafka Libraries. Source: <a href="https://medium.com/paypal-tech/scaling-kafka-to-support-paypals-data-growth-a0b4da420fab">PayPal Tech Blog</a></figcaption></figure></div><p>To facilitate these needs, PayPal built a few important libraries:</p><ul><li><p><strong>Resilient Client Library: </strong>When a client tries to establish a connection to the cluster, this library gets the Kafka broker details and the required configuration for the producer or consumer application.</p></li><li><p><strong>Monitoring Library: </strong>This library publishes critical metrics for client applications, allowing applications to set alerts and get notifications in case of any issues.</p></li><li><p><strong>Kafka Security Library: </strong>The Kafka platform supports more than 800 applications. This library takes care of the required certificates and tokens to enable SSL authentication for applications connecting to the Kafka clusters. It avoids a lot of overhead around key management, certificate updates, and key rotations.</p></li></ul><h3>QA Platform</h3><p>One of the great things PayPal did was to set up a production-like QA platform for Kafka for developers to test changes confidently.</p><p>This is a common problem in many organizations where the testing performed by developers is hardly indicative of the production environment, resulting in issues after launch.&nbsp;</p><p>A dedicated QA platform solves this by providing a direct mapping between production and QA clusters.&nbsp;</p><p>The same security standards are followed. The same topics are hosted on the clusters with the brokers spread across multiple zones within the Google Cloud Platform.</p><h3>Monitoring and Alerting</h3><p>Monitoring and alerting are extremely important aspects for systems operating at a high scale. Teams want to know about issues and incidents quickly so that cascading failures can be avoided.</p><p>At PayPal, the Kafka platform is integrated with the monitoring and alerting systems.</p><p>Apache Kafka provides multiple metrics. However, they have taken out a subset of metrics that help them identify issues faster.&nbsp;</p><p>The Kafka Metrics library filters out the metrics and sends them to the SignalFX backend via SignalFX agents running on all brokers, Zookeepers, MirrorMakers, and Kafka clients. Individual alerts associated with these metrics are triggered whenever abnormal thresholds are breached.&nbsp;</p><h2>Configuration Management</h2><p>Operating a critical system requires one to guard against data loss. This is not only applicable to the application data but also to the infrastructure information.</p><p>What if the infrastructure gets wiped out and we&#8217;ve to rebuild it from scratch?</p><p>At PayPal, configuration management helps them store the complete infrastructure details. This is the single source of truth that allows PayPal to rebuild the clusters in a couple of hours if needed.</p><p>They store the Kafka metadata such as topic details, clusters, and applications in an internal configuration management system. The metadata is also backed up to ensure that they have the most recent data in case it&#8217;s required to re-create clusters and topics in case of a recovery.</p><h2>Enhancements and Automation</h2><p>Large-scale systems require special tools to carry out operational tasks as quickly as possible.</p><p>PayPal built multiple such tools for operating their Kafka cluster. Let&#8217;s look at a few important ones:</p><h3>Patching Security Vulnerabilities</h3><p>PayPal uses BareMetal for deploying the Kafka brokers and virtual machines for Zookeeper and MirrorMakers.</p><p>As we can expect, all of these hosts need to be patched at frequent intervals to fix any security vulnerabilities.&nbsp;</p><p>Patching requires BM restart which can cause partitions to lag. This can also lead to data loss in the case of Kafka topics that are configured with a replica set of three.&nbsp;</p><p>They built a plugin to query whether a partition was lagging before patching the host, thereby ensuring only a single broker is patched at a time with no chances of data loss.</p><h3>Topic Onboarding</h3><p>Application teams require topics for their application functionality. To make this process standardized, PayPal built an Onboarding Dashboard to submit a new topic request.</p><p>The diagram below shows the onboarding workflow for a topic.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5171a6df-fad2-4dad-9709-de223718bb5f_1600x1002.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="912" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5171a6df-fad2-4dad-9709-de223718bb5f_1600x1002.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>A special review team checks the capacity requirements for the new topic and onboards it to one of the available clusters. They use a capacity analysis tool integrated into the onboarding workflow to make the decision.</p><p>For each new application being onboarded to the Kafka system, a unique token is generated. This token is used to authenticate the client&#8217;s access to the Kafka topic. As discussed earlier, an ACL is created for the specific application and topic based on their role.</p><h3>MirrorMaker Onboarding</h3><p>As mentioned earlier, PayPal uses MirrorMaker for mirroring the data from one cluster to another.</p><p>For this setup, developers also use the Kafka Onboarding UI to register their requirements. After due checks by the Kafka team, the MirrorMaker instances are provisioned.</p><p>The diagram below shows the process flow for the same:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdd0e9ef-6fbb-4c47-b748-9d04bdd0617a_1600x851.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="774" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdd0e9ef-6fbb-4c47-b748-9d04bdd0617a_1600x851.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Conclusion</h2><p>The Kafka platform at PayPal is a key ingredient for enabling seamless integration between multiple applications and supporting the scale of their operation.</p><p>Some important learnings to take away from this study are as follows:</p><ul><li><p>Tooling is a must when operating Kafka on a large scale. This involves operations such as cluster installation, topic management, patching VMs, etc.</p></li><li><p>Availability is as good as the ability of alerting and monitoring systems to provide timely inputs to the infrastructure team.</p></li><li><p>ACLs are a great way to have a better understanding of how the various applications are connected with Kafka.</p></li><li><p>A dedicated QA environment is critical for developers to ship changes with confidence and speed.</p></li></ul><p><strong>References</strong></p><ul><li><p><a href="https://medium.com/paypal-tech/scaling-kafka-to-support-paypals-data-growth-a0b4da420fab">Scaling Kafka to Support PayPal&#8217;s Data Growth</a></p></li><li><p><a href="https://www.confluent.io/resources/kafka-summit-2020/marching-toward-a-trillion-kafka-messages-per-day-running-kafka-at-scale-at-paypal/">Marching towards a Trillion Kafka Messages Per Day</a></p></li><li><p><a href="https://developers.redhat.com/articles/2023/11/13/demystifying-kafka-mirrormaker-2-use-cases-and-architecture">Demystifying Kafka MirrorMaker2</a></p></li><li><p><a href="https://kafka.apache.org/uses">Kafka Use Cases</a></p></li></ul><div><hr /></div><h2>SPONSOR US</h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p><br /></p>
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 15:30:53 GMT</pubDate>
</item>
<item>
<title>EP115: Life is Short, Use Dev Tools</title>
<link>https://blog.bytebytego.com/p/ep115-life-is-short-use-dev-tools</link>
<guid>https://blog.bytebytego.com/p/ep115-life-is-short-use-dev-tools</guid>
<content:encoded><![CDATA[
<div> KISS, SOLID, CAP, BASE, Dev Tools, Production Web Application, Frontend Performance, Developer Standards, Sponsorship<br /><br />总结: 本文介绍了系统设计中的重要术语和开发工具，以及如何构建高性能的生产级Web应用程序。通过讨论8个前端性能提升技巧和开发人员需要了解的8个标准，全面展示了技术行业的最新趋势。此外，还提供了赞助机会，让产品和服务能够直接接触到50万以上的技术专业人士。通过这些内容，读者可以了解如何提升自己在开发领域的水平，以及如何将产品推广给相关目标群体。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>KISS, SOLID, CAP, BASE: Important Terms You Might Not Know! (Youtube video)</p></li><li><p>Life is Short, Use Dev Tools </p></li><li><p>10 Essential Components of a Production Web Application</p></li><li><p>How to load your websites at lightning speed</p></li><li><p>Top 8 Standards Every Developer Should Know</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/LinearB_060824">What You Need to Know About Software Engineering Intelligence [Workshop]&nbsp;(Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/LinearB_060824" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="359.010989010989" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22df6e02-75ef-476b-9cca-3926e28b8dd9_1600x798.png" width="720" /><div></div></div></a></figure></div><p>How can you get holistic visibility across your SDLC, insights about your engineering performance, and implement automations that unblock your bottlenecks? </p><p>Software Engineering Intelligence (SEI) Platforms are solving visibility and operations challenges for engineering teams. Join LinearB&#8217;s workshop on June 20th or 27th to learn about how SEI tools are rapidly accelerating developer productivity in enterprises.</p><p>We&#8217;ll demonstrate how you can use SEI to take on:</p><ul><li><p>Developer Productivity - accelerating output</p></li><li><p>Profitable Engineering - the data behind resourcing and costs</p></li><li><p>Developer Experience - protecting team health and reducing toil</p></li><li><p>GenAI (Copilot) Impact - the effects it&#8217;s having on your software pipelines</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/LinearB_060824"><span>Register now</span></a></p><div><hr /></div><h2>KISS, SOLID, CAP, BASE: Important Terms You Might Not Know!</h2><div class="youtube-wrap" id="youtube2-cTyZ_hbmbDw"><div class="youtube-inner"></div></div><div><hr /></div><h2>Life is Short, Use Dev Tools </h2><p>The right dev tool can save you precious time, energy, and perhaps the weekend as well. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1565" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e5b9d5-3426-42ab-b690-2413ab249270_1280x1565.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><p>Here are our favorite dev tools: </p><ol><li><p>Development Environment <br />A good local dev environment is a force multiplier. Powerful IDEs like VSCode, IntelliJ IDEA, Notepad++, Vim, PyCharm &amp; Jupyter Notebook can make your life easy. <br /></p></li><li><p>Diagramming <br />Showcase your ideas visually with diagramming tools like DrawIO, Excalidraw, mindmap, Mermaid, PlantUML, Microsoft Visio, and Miro <br /></p></li><li><p>AI Tools <br />AI can boost your productivity. Don&#8217;t ignore tools like ChatGPT, GitHub Copilot, Tabnine, Claude, Ollama, Midjourney, and Stable Diffusion. <br /></p></li><li><p>Hosting and Deployment <br />For hosting your applications, explore solutions like AWS, Cloudflare, GitHub, Fly, Heroku, and Digital Ocean. <br /></p></li><li><p>Code Quality <br />Quality code is a great differentiator. Leverage tools like Jest, ESLint, Selenium, SonarQube, FindBugs, and Checkstyle to ensure top-notch quality. <br /></p></li><li><p>Security <br />Don&#8217;t ignore the security aspects and use solutions like 1Password, LastPass, OWASP, Snyk, and Nmap. <br /></p></li><li><p>Note-taking <br />Your notes are a reflection of your knowledge. Streamline your note-taking with Notion, Markdown, Obsidian, Roam, Logseq, and Tiddly Wiki. <br /></p></li><li><p>Design <br />Elevate your visual game with design tools like Figma, Sketch, Adobe Illustrator, Canva, and Adobe Photoshop. <br /></p></li></ol><p>Over to you: Which dev tools do you use? </p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1198" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F203c1745-28f1-405c-80c1-b456e391c708_1600x1317.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">A Crash Course on Content-Delivery Networks (CDN)</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>10 Essential Components of a Production Web Application</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1568" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5cae662e-b5f0-4015-b4b7-7d9eac154903_1280x1568.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><ol><li><p>It all starts with CI/CD pipelines that deploy code to the server instances. Tools like Jenkins and GitHub help over here.</p></li><li><p>The user requests originate from the web browser. After DNS resolution, the requests reach the app servers.</p></li><li><p>Load balancers and reverse proxies (such as Nginx &amp; HAProxy) distribute user requests evenly across the web application servers.</p></li><li><p>The requests can also be served by a Content Delivery Network (CDN).</p></li><li><p>The web app communicates with backend services via APIs.</p></li><li><p>The backend services interact with database servers or distributed caches to provide the data.</p></li><li><p>Resource-intensive and long-running tasks are sent to job workers using a job queue.</p></li><li><p>The full-text search service supports the search functionality. Tools like Elasticsearch and Apache Solr can help here.</p></li><li><p>Monitoring tools (such as Sentry, Grafana, and Prometheus) store logs and help analyze data to ensure everything works fine. </p></li><li><p>In case of issues, alerting services notify developers through platforms like Slack for quick resolution. </p></li></ol><p>Over to you: What other components would you add to the architecture of a production web app?</p><div><hr /></div><h2>How to load your websites at lightning speed?</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1585" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0167296-81d2-46ad-bea6-183cac627c4d_1280x1585.gif" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>Check out these 8 tips to boost frontend performance:</p><ol><li><p>Compression<br />Compress files and minimize data size before transmission to reduce network load.</p><p></p></li><li><p>Selective Rendering/Windowing<br />Display only visible elements to optimize rendering performance. For example, in a dynamic list, only render visible items.<br /></p></li><li><p>Modular Architecture with Code Splitting<br />Split a bigger application bundle into multiple smaller bundles for efficient loading.<br /></p></li><li><p>Priority-Based Loading<br />Prioritize essential resources and visible (or above-the-fold) content for a better user experience.<br /></p></li><li><p>Pre-loading<br />Fetch resources in advance before they are requested to improve loading speed.<br /></p></li><li><p>Tree Shaking or Dead Code Removal<br />Optimize the final JS bundle by removing dead code that will never be used.<br /></p></li><li><p>Pre-fetching<br />Proactively fetch or cache resources that are likely to be needed soon.<br /></p></li><li><p>Dynamic Imports<br />Load code modules dynamically based on user actions to optimize the initial loading times.</p></li></ol><p>Over to you: What other frontend performance tips would you add to this cheat sheet?</p><div><hr /></div><h2>Top 8 Standards Every Developer Should Know</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef0ca4ec-4ab6-4bd3-a0f2-bf49da47748b_1536x1536.gif" title="No alternative text description for this image" /><div></div></div></a></figure></div><ul><li><p>TCP/IP <br />Developed by the IETF organization, the TCP/IP protocol is the foundation of the Internet and one of the best-known networking standards. <br /> </p></li><li><p>HTTP <br />The IETF has also developed the HTTP protocol, which is essential for all web developers. <br /> </p></li><li><p>SQL <br />Structured Query Language (SQL) is a domain-specific language used to manage data. <br /> </p></li><li><p>OAuth <br />OAuth (Open Authorization) is an open standard for access delegation commonly used to grant websites or applications limited access to user information without exposing their passwords. <br /> </p></li><li><p>HTML/CSS <br />With HTML, web pages are rendered uniformly across browsers, which reduces development effort spent on compatibility issues.HTML tags. <br /> <br />CSS standards are often used in conjunction with HTML. <br /> </p></li><li><p>ECMAScript <br />ECMAScript is a standardized scripting language specification that serves as the foundation for several programming languages, the most well-known being JavaScript. <br /> </p></li><li><p>ISO Date <br />It is common for developers to have problems with inconsistent time formats on a daily basis. ISO 8601 is a date and time format standard developed by the ISO (International Organization for Standardization) to provide a common format for exchanging date and time data across borders, cultures, and industries. <br /> </p></li><li><p>OpenAPI <br />OpenAPI, also known as the OpenAPI Specification (OAS), is a standardized format for describing and documenting RESTful APIs.</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 08 Jun 2024 15:30:59 GMT</pubDate>
</item>
<item>
<title>A Crash Course on Content-Delivery Networks (CDN)</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-content-delivery</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-content-delivery</guid>
<content:encoded><![CDATA[
<div> Latency, Conversion Rate, E-commerce, Content-Delivery Network, Market Size
<br />
凭借内容交付网络（CDN）可以减少延迟，提高网站性能。根据Portent的研究，页面加载速度快，转化率会更高，电子商务转化率随着加载时间增加而下降。优化的加载时间是少于2秒。CDN是一个地理分布的服务器网络，通过将用户请求重定向到最近的CDN服务器，提供快速可靠的内容传递。CDN市场预计到2028年将达到近380亿美元，Akamai、Cloudflare和亚马逊CloudFront等公司正在大力投资改进CDN解决方案。总结: CDN的使用可以降低延迟，提高网站性能，有效解决了现代网络时代组织面临的性能问题。 <div>
<p>In the era of the modern web, latency can directly impact an organization&#8217;s bottom line.</p><p>Here are some stats from a study by Portent:</p><ul><li><p>A page that loads in 1 second has a 3x higher conversion rate than a page that takes 5 seconds to load.</p></li><li><p>E-commerce conversion rates decrease by 0.3% for every second of load time.</p></li><li><p>The optimal loading time to maximize sales is less than 2 seconds.</p></li></ul><p>One of the most effective strategies to reduce latency is using a Content-Delivery Network or a CDN.</p><p>A CDN is a geographically distributed network of servers that work together to deliver fast and reliable content delivery across the globe.</p><p>When a user requests content from a website or application that uses a CDN, the request is redirected to the nearest CDN server, which serves the content to the user. This reduces the distance data travels and improves overall performance.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98c2b44b-f305-4e3c-90d1-24e6c181bd93_1600x896.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="815" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98c2b44b-f305-4e3c-90d1-24e6c181bd93_1600x896.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Think of a CDN like an ATM. If money were available only from one bank branch in town, everyone would have to make a time-consuming trip to that branch. With ATMs in every locality, everyone has fast and easy access to money.&nbsp;</p><p>The market size for CDN-related solutions is expected to reach nearly $38 billion by 2028, with companies like Akamai, Cloudflare, and Amazon CloudFront investing heavily in improving their CDN offerings.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95404fea-d1ef-45ec-96e2-17796bf260d5_1999x1755.jpeg" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1278" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95404fea-d1ef-45ec-96e2-17796bf260d5_1999x1755.jpeg" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Why the Need for a CDN?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-content-delivery">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 06 Jun 2024 15:30:28 GMT</pubDate>
</item>
<item>
<title>AWS Lambda Under the Hood</title>
<link>https://blog.bytebytego.com/p/aws-lambda-under-the-hood</link>
<guid>https://blog.bytebytego.com/p/aws-lambda-under-the-hood</guid>
<content:encoded><![CDATA[
<div> AWS Lambda, Assignment Service, Firecracker, Chunking, SnapStart  
总结:<br /><br />本文介绍了AWS Lambda的架构和内部机制。AWS Lambda是一个无服务器计算服务，支持同步和异步调用模式。介绍了同步调用和异步调用的工作流程，以及Assignment Service的引入解决了Worker Manager的挑战。Firecracker是用于运行AWS Lambda和AWS Fargate等无服务器工作负载的轻量级虚拟机管理器。讨论了Firecracker的重要技术细节，以及SnapStart功能如何减少冷启动延迟。最后，介绍了AWS Lambda作为存储服务的功能，包括代码和数据的有效存储、共享常用数据和使用SnapStart加速初始化等。AWS Lambda通过这些先进技术实现了高效的无服务器计算服务。 <div>
<h2><a href="https://bit.ly/WorkOS_060424">WorkOS: enterprise-grade auth for modern SaaS apps (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/WorkOS_060424" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="763" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79e9b43-75d7-4a65-a598-c9fe68df9033_1600x838.png" width="1456" /><div></div></div></a></figure></div><p>WorkOS helps companies become Enterprise Ready ridiculously fast.</p><p>&#8594; It supports a complete User Management solution along with SSO, SCIM, RBAC, &amp; FGA.</p><p>&#8594; Unlike other auth providers that rely on user-centric models, WorkOS is designed for B2B SaaS with an org modeling approach.</p><p>&#8594; The APIs are flexible, easy-to-use, and modular. Pick and choose what you need and integrate in minutes.</p><p>&#8594; Best of all, User Management is free up to 1 million MAUs&nbsp;and includes bot protection, impersonation, MFA, &amp; more.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/WorkOS_060424"><span>Future-proof your auth stack with WorkOS</span></a></p><div><hr /></div><p><em>Disclaimer: The details in this post have been derived from multiple AWS reInvent talks and articles by the Amazon engineering team. All credit for information about AWS Lambda&#8217;s internals goes to the presenters and authors. The link to these videos and articles is present in the references section at the end of the post. We&#8217;ve attempted to analyze the details and provide our input about them. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><p>AWS Lambda is a serverless compute service that allows developers to run code without provisioning or managing servers.</p><p>Lambda functions can be triggered by various AWS services, HTTP endpoints, or custom events generated by applications. This makes it highly versatile for building event-driven architectures.</p><p>There are some interesting stats about AWS Lambda:</p><ul><li><p>Processes over 10 trillion invocations per month.</p></li><li><p>More than a million customers have built applications using AWS Lambda.</p></li><li><p>The customer base includes individuals, startups, enterprises, and large organizations.</p></li><li><p>Supports various applications, such as IT automation, data processing pipelines, microservices-based applications, web applications, and machine learning workloads.</p></li></ul><p>The timeline below shows the evolution of AWS Lambda over the years.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd69d56b0-4731-4bde-9b42-59925476826c_1600x852.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="775" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd69d56b0-4731-4bde-9b42-59925476826c_1600x852.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In this post, we will look at the architecture and internals of AWS Lambda.</p><h2>How is a Lambda Function Invoked?</h2><p>There are two types of invocation models supported by Lambda.</p><h3>1 - Synchronous Invocation</h3><p>In synchronous invocation, the caller directly calls the Lambda function. This can be done using the AWS CLI, SDK, or other services like the API Gateway.</p><p>The diagram below shows the entire process:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d363a4c-7e04-4244-81c1-247d2a4a038e_1600x986.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="897" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d363a4c-7e04-4244-81c1-247d2a4a038e_1600x986.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The process involves the following components:</p><ul><li><p><strong>Front-End Service: </strong>The front-end service performs authentication and authorization of the request. It also loads and caches metadata to optimize performance.</p></li><li><p><strong>Counting Service: </strong>This service checks quota limits based on account, burst, or reserved concurrency. It ensures high throughput and low latency while operating across multiple availability zones (AZs).</p></li><li><p><strong>Assignment Service: </strong>The assignment service routes invocation requests to available worker hosts. It coordinates the creation of secure execution environments, setting up limits such as memory and CPU allocation. We will talk more about it in a later section.</p></li><li><p><strong>Placement Service: </strong>The assignment service communicates with the placement service to determine the best worker host to handle the new execution environment. The placement service uses machine learning models to make informed decisions about where to place new execution environments. These models take into account variables such as packing density and fleet utilization to make the decisions.</p></li><li><p><strong>Worker Hosts: </strong>They are responsible for downloading, mounting, and running the function code within a microVM. They manage multiple runtimes (such as Node.js, Java, and Python) and Lambda agents for monitoring and operation.</p></li></ul><p>When an invocation occurs, it can have a warm or cold start.</p><p>If a warm (already running) execution environment is available, the payload is sent directly to it, and the function runs immediately.</p><p>If no warm environment is available, a new execution environment is created. The process involves initializing the runtime, downloading function code, and preparing the environment for execution.</p><p>The assignment service keeps track of execution environments. If there are errors during initialization, the environment is marked unavailable. When environments are near the end of their lease, they are gracefully shut down to ensure stability and resource efficiency.</p><h3>2 - Asynchronous Invocation</h3><p>In asynchronous invocation, the caller doesn&#8217;t wait for the function&#8217;s response. Instead, the event is placed in an internal queue and processed separately.</p><p>The process involves:</p><ul><li><p><strong>Event Invoke Frontend Service: </strong>This service handles asynchronous requests. It authenticates and authorizes the request, then places the event in an internal SQS queue.</p></li><li><p><strong>Polling Instances: </strong>A fleet of pollers reads messages from the SQS queues and sends them to the synchronous front-end service for processing.</p></li><li><p><strong>Synchronous Processing:</strong> Despite being an async request, the actual function execution uses the same synchronous processing pathway as described earlier.</p></li><li><p><strong>Event Destinations: </strong>These can be configured to handle callbacks after processing, providing notifications of success or failure.</p></li></ul><p>The diagram below shows the asynchronous invocation process:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87e33617-1c2e-43cd-8e40-a7e24105b189_1600x833.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="758" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87e33617-1c2e-43cd-8e40-a7e24105b189_1600x833.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Lambda manages multiple internal queues, scaling them dynamically based on load. The queue manager oversees the creation, deletion, and monitoring of these queues to ensure efficient processing.</p><p>As far as polling is concerned, Lambda can poll from various event sources like Kinesis, DynamoDB, SQS, Kafka, and Amazon MQ. The pollers perform the following functions:</p><ul><li><p><strong>Read and Filter: </strong>Poll messages from the sources, optionally filtering them to reduce traffic and simplify function code.</p></li><li><p><strong>Batch Processing: </strong>Batch records together before sending them to the function, optimizing performance and reducing costs.</p></li><li><p><strong>Synchronous Invocation: </strong>Use the same synchronous pathway to execute the function, ensuring consistency.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d97f56a-30a5-4e3d-b069-4bc8f3262ea1_1600x913.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="831" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d97f56a-30a5-4e3d-b069-4bc8f3262ea1_1600x913.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Control plane services (such as State Manager and Stream Tracker) manage the pollers, ensuring they are assigned correctly, scaling them up or down, and handling failures gracefully.</p><p>In case a function fails, the message is returned to the queue with a visibility timeout, allowing for retries.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="735" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90d1d63b-f864-41e2-8bec-80a41cc800ac_1600x808.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>State Management in Lambda</h2><p>In the earlier architecture of AWS Lambda, the Worker Manager service was responsible for coordinating the execution environments between the frontend invoke service and the worker hosts.</p><p>The worker manager performed a couple of important tasks:</p><ul><li><p><strong>State Management: </strong>The Worker Manager kept track of which execution environments were available and on which hosts they were running.</p></li><li><p><strong>Execution Lifecycle: </strong>It managed the lifecycle of these environments, ensuring that they were ready to process invocations and handling termination when no longer needed.</p></li></ul><p>There were some challenges with the worker manager:</p><ul><li><p><strong>Single Point of Failure: </strong>Each Worker Manager instance stored the state of execution environments in memory. If a Worker manager failed, the execution environments it managed could become orphaned.</p></li><li><p><strong>Orphaned Environments:</strong> Orphaned environments could continue processing current invocations but could not be used for new invocations, leading to cold starts and inefficient resource utilization.</p></li><li><p><strong>Zonal Failures:</strong> In case of a failure in an Availability Zone (AZ), Worker Managers in that AZ would become unavailable. This will also make the environments managed by them unavailable, resulting in capacity loss and increased cold start latencies.</p></li></ul><h3>Introduction of the Assignment Service</h3><p>To address the challenges with Worker Manager, AWS Lambda introduced the Assignment Service which offers a more robust and resilient way to manage execution environments.</p><p>The Assignment Service is written in Rust, which is chosen for its performance, memory safety, and low latency characteristics.&nbsp;</p><p>The diagram below shows the high-level design of the Assignment Service</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2fd3b32-d588-4aa9-a248-992db2be9894_1600x974.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="886" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2fd3b32-d588-4aa9-a248-992db2be9894_1600x974.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The architecture of the Assignment Service has some key properties:</p><h4>1 - Partitioned Design</h4><p>The Assignment Service is divided into multiple partitions. Each partition consists of one leader and two followers, spread across different Availability Zones (AZs). This ensures high availability and fault tolerance.</p><p>Multiple partitions run simultaneously, with each Assignment Service host managing several partitions. This helps with load distribution and provides redundancy.</p><h4>2 - External Journal Log Service</h4><p>The leader in each partition writes the state of execution environments to an external journal log service. The followers read from this log to keep their state in sync with the leader.</p><p>In case the leader fails, one of the followers can quickly take over as the new leader using the state information from the journal log.</p><h4>3 - Frontend Interaction</h4><p>The frontend invoke service interacts with the leader of the relevant partition to manage invocations.&nbsp;</p><p>The leader coordinates with the placement service to create new execution environments and writes this information to the log for followers to update their state.</p><h4>4 - Failure Handling</h4><p>If an AZ experiences an outage, the leader and followers in other AZs continue to operate. This means that execution environments in the unaffected AZs remain available and aren&#8217;t orphaned.</p><p>If a leader fails, a follower can take over quickly using the replicated state, ensuring that there are no interruptions in service and reducing the chances of cold starts.</p><h2>The Role of Firecracker MicroVM</h2><p>Firecracker is a lightweight virtual machine manager (VMM) designed specifically for running serverless workloads such as AWS Lambda and AWS Fargate. It uses Linux&#8217;s Kernel-based Virtual Machine to create and manage microVMs.</p><p>The primary goal of Firecracker is to provide secure and fast-booting microVMs.</p><p>Initially, AWS Lambda used EC2 instances to run functions, dedicating a T2 instance to each tenant. This was secure but inefficient, leading to high overhead due to the need for provisioning entire EC2 instances for each function.</p><p>In 2018, Lambda transitioned to using Firecracker for managing execution environments. This allowed for much smaller, lightweight microVMs, significantly reducing resource overhead and improving the fleet&#8217;s efficiency.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffac8de07-6586-4bf7-9d48-f6db8322b148_1600x1295.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1178" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffac8de07-6586-4bf7-9d48-f6db8322b148_1600x1295.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here are some key technical details of the Firecracker implementation.</p><h3>1 - MicroVMs and Isolation</h3><p>Firecracker enables the creation of microVMs, which are smaller and more efficient than traditional VMs. Each microVM runs its isolated execution environment, including the runtime, function code, and any extensions.</p><p>Firecracker ensures a strong solution between microVMs, which is crucial for multi-tenant environments where different customer functions run on the same physical host.</p><h3>2 - Startup Times</h3><p>Firecracker microVMs are designed to boot in milliseconds, significantly reducing the cold start latency for Lambda functions.&nbsp;</p><p>For further optimization, Lambda uses a feature called SnapStart (initially available for the Corretto Java 11 runtime). SnapStart pre-initializes execution environments and takes snapshots, which are restored on demand when needed. We will talk more about it in the next section.</p><h3>3 - Resource Utilization</h3><p>By running multiple microVMs on a single physical host, Firecracker improves CPU utilization, memory, and storage resources. This allows Lambda to handle more functions with fewer resources.</p><p>Also, Firecracker supports the dynamic scaling of resources for quick adjustment to changing workloads.</p><h3>4 - Storage and Networking</h3><p>Lambda uses a virtual file system driver to present an EXT4 file system to the microVMs. This driver handles file system calls and maps them to the underlying storage.</p><p>Firecracker optimizes network performance by providing high-speed virtual network interfaces, ensuring fast and reliable communication.</p><h2>Lambda as a Storage Service</h2><p>AWS Lambda is primarily known as a serverless compute service. However, it also incorporates significant storage service functionalities.</p><p>Think of Lambda not just as a compute service but also as a storage service because it deals with storing and managing a lot of data behind the scenes.</p><p>But why is storage important for Lambda?</p><p>It&#8217;s because when you run a function on Lambda, it needs three main things:</p><ul><li><p><strong>Input Data:</strong> The information or data your function will process</p></li><li><p><strong>Function Code:</strong> The code you wrote that tells Lambda what to do&nbsp;</p></li><li><p><strong>Execution Environment:</strong> The virtual machine (VM) where your code runs.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d4de897-b4c0-4f07-84bb-58b1eccf1732_1600x1242.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1130" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0d4de897-b4c0-4f07-84bb-58b1eccf1732_1600x1242.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To make all of this work smoothly, Lambda needs to manage and store these components efficiently.</p><h3>1 - Storing Code and Data Efficiently</h3><p>Instead of storing your entire code or data as one big piece, Lambda breaks it down into smaller pieces called chunks.</p><p>This process is known as chunking and it allows Lambda to handle large and complex functions more effectively.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f76a65b-82ed-47c3-80a4-33b2d2e6e477_1600x880.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="801" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9f76a65b-82ed-47c3-80a4-33b2d2e6e477_1600x880.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s how it works:</p><ul><li><p><strong>Breaking down container images: </strong>When you upload a container image (which can be up to 10 GB) to AWS Lambda, it doesn&#8217;t store the entire image as one big file. Instead, Lambda breaks this image down into smaller pieces or chunks. For example, the base OS layer is broken down into smaller pieces, the runtime layer into another set of pieces, and so on.</p></li><li><p><strong>Storage and Access: These chunks are then stored separately, making it easier to manage and retrieve them as needed. When your function runs, Lambda only loads the chunks it needs at that moment, rather than the entire image. This is much faster and more efficient.</strong></p></li><li><p><strong>Retrieving Chunks: When your function is invoked, Lambda checks which parts of the container image it needs to execute the function. It then retrieves only those specific chunks from storage.</strong></p></li><li><p><strong>Optimizing Performance: Since only the required chunks are loaded, this reduces the amount of data that needs to be transferred and processed, leading to faster startup times and better performance. Frequently accessed chunks can be cached to avoid fetching them from the main storage repeatedly.</strong></p></li></ul><h3>2 - Sharing Common Data</h3><p>Lambda often runs many functions that use similar code or data such as base operating system layer or common runtime libraries.&nbsp;</p><p>Instead of storing multiple copies of the same thing, it stores one copy and reuses it.</p><p>To make sure the shared data is secure, Lambda uses a technique called convergent encryption.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88eb699a-bd99-4d18-aea8-c9a3b96b554e_1600x881.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="802" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88eb699a-bd99-4d18-aea8-c9a3b96b554e_1600x881.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>But how does convergent encryption work?</p><ul><li><p><strong>Plaintext Chunk Creation: </strong>Lambda starts with a plaintext chunk, which is a segment of the flattened file system of a container image. Each chunk represents a specific range of the block device that makes up the file system.</p></li><li><p><strong>Appending Extra Data:</strong> To ensure security and integrity, additional data is appended to the chunk. This extra data is generated by the Lambda service and can include metadata or unique identifiers. The purpose of this extra data is to add a layer of uniqueness to the chunk.</p></li><li><p><strong>Hash Computation: </strong>A cryptographic hash function is used to compute a hash of the combined plaintext chunk and extra data. This hash serves as the encryption key for that specific chunk, ensuring that identical chunks produce the same hash and thus the same encryption key.</p></li><li><p><strong>Encryption: </strong>The plaintext chunk, along with the extra data, is then encrypted using the computed hash as the encryption key.</p></li><li><p><strong>Manifest Creation: </strong>Lambda creates a manifest file that contains the keys (hashes) and pointers to the encrypted chunks in the storage subsystem. The manifest itself is encrypted with a customer-specific AWS Key Management Service, ensuring that only authorized entities can access it.</p></li></ul><h3>3 - Making Initialization Faster with SnapStart</h3><p>When a Lambda function is invoked and there isn&#8217;t an already running execution environment, Lambda has to create a new one. This involves several steps:</p><ul><li><p><strong>Provisioning</strong>: Setting up a new virtual machine</p></li><li><p><strong>Downloading: </strong>Retrieving the function code from storage</p></li><li><p><strong>Initializing: </strong>Starting the runtime and initializing the function code.</p></li></ul><p>These steps can take time, especially for complex functions or runtimes like Java, which have longer startup times. This delay is known as cold start latency.</p><p>SnapStart is a feature designed to significantly reduce cold start latency by pre-initializing the execution environment and then using snapshots.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbda5bb9f-e59e-4248-b7f6-aaf55e6e1431_1600x875.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="796" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbda5bb9f-e59e-4248-b7f6-aaf55e6e1431_1600x875.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Here&#8217;s how it works:</p><ul><li><p>When you update your function code or deploy a new version, Lambda performs an initial setup and creates a new execution environment.</p></li><li><p>Once the execution environment is fully set up and ready to handle invocations, Lambda takes a snapshot of this environment. The snapshot captures the entire state of the VM, including the memory state, runtime state, and initialized data. The snapshot is then broken down into smaller pieces and encrypted to ensure security.</p></li><li><p>These encrypted chunks are stored securely.</p></li><li><p>When a new invocation request arrives, Lambda first checks if there&#8217;s an already running execution environment (a warm start). If not, it proceeds to use the snapshot. The necessary chunks are loaded and decrypted and the environment is brought back to the state it was in when the snapshot was taken.</p></li></ul><h2>Conclusion</h2><p>AWS Lambda revolutionized the way developers build and deploy applications by providing a serverless environment that abstracts away the complexities of infrastructure management.</p><p>Here are the main takeaways from the internals of AWS Lambda:</p><ul><li><p>To achieve the impressive statistics associated with Lambda, AWS leverages multiple advanced techniques such as chunking and convergent encryption to manage and share common data.&nbsp;</p></li><li><p>The introduction of SnapStart addressed the critical challenge of cold start latency, particularly for runtimes like Java.</p></li><li><p>The transition from the Worker Manager to the Assignment Service marked a significant improvement in state management.</p></li><li><p>With Firecracker microVMs, Lambda achieves lightweight and secure virtualization.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://youtu.be/0_jfH6qijVY?si=z_mHoo_lDT3OLrYG">A closer look at AWS Lambda</a></p></li><li><p><a href="https://www.infoq.com/presentations/aws-lambda-arch/">AWS Lambda Under the Hood</a></p></li><li><p><a href="https://youtu.be/AECR8WMHjv0?si=yB6O9FcnmCPyhnUq">AWS Lambda Under the Hood - YouTube</a></p></li><li><p><a href="https://youtu.be/QdzV04T_kec?si=X79wEB5zzmJQLogj">A Serverless Journey: AWS Lambda</a></p></li><li><p><a href="https://www.amazon.science/blog/how-awss-firecracker-virtual-machines-work">How do AWS Firecracker virtual machines work?</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></p>
]]></content:encoded>
<pubDate>Tue, 04 Jun 2024 15:31:00 GMT</pubDate>
</item>
<item>
<title>EP114: 7 Must-know Strategies to Scale Your Database</title>
<link>https://blog.bytebytego.com/p/ep114-7-must-know-strategies-to-scale</link>
<guid>https://blog.bytebytego.com/p/ep114-7-must-know-strategies-to-scale</guid>
<content:encoded><![CDATA[
<div> Scaling databases, Retry strategies, Reddit's architecture, Cross-Site Scripting, Sponsorship
<br />
数据库扩展，重试策略，Reddit架构，跨站脚本攻击，赞助
<br /><br />总结:
<br />
本文讨论了数据库扩展的7个策略，重试失败的方法，Reddit的核心架构，跨站脚本攻击以及赞助广告。数据库扩展策略包括索引、物化视图、去标准化、垂直扩展、缓存、复制和分片。重试策略涵盖了线性、指数和随机的不同方式。Reddit架构采用CDN、微服务以及多种存储和数据处理技术。跨站脚本攻击是常见漏洞，要加强用户意识和防范措施。赞助广告提供推广机会，影响大批技术专业人士。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>7 must-know strategies to scale your database</p></li><li><p>How do we retry on failures?</p></li><li><p>Reddit&#8217;s Core Architecture</p></li><li><p>Everything You Need to Know About Cross-Site Scripting (XSS)</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Nylas_060124CTA">Your ultimate guide to integrating email, calendars &amp; contacts (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Nylas_060124CTA" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1200" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37925e71-6a06-4d9f-811a-90b0336d8733_1200x1200.png" width="1200" /><div></div></div></a></figure></div><p>Launch native email, calendar, and contacts capabilities with the greatest possible ROI. This latest guide from Nylas walks you through the most common options to launch these integrations for all major email and calendar service providers (Gmail, Outlook, IMAP, etc.) including APIs vs. building yourself. <a href="https://bit.ly/Nylas_060124CTA">Read on to discover best practices and</a>:<br /></p><ul><li><p>How complex it is to build the email, calendar and contacts integration from scratch</p></li><li><p>The true cost of building your own email, calendar, contacts integration</p></li><li><p>6 Questions for CTOs and product managers to future-proof their business</p></li></ul><p>If you're interested in trying out an API that integrates these email and calendar service providers for you, <strong><a href="https://bit.ly/Nylas_060124dashboard">check out Nylas</a></strong>.&nbsp;</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Nylas_060124CTA"><span>Read More</span></a></p><div><hr /></div><h2>7 must-know strategies to scale your database</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f560185-6b26-4359-ae8a-123b44d8884a_1345x1536.gif" title="No alternative text description for this image" width="1345" /><div></div></div></a></figure></div><ol><li><p>Indexing: <br />Check the query patterns of your application and create the right indexes. <br /></p></li><li><p>Materialized Views: <br />Pre-compute complex query results and store them for faster access. <br /></p></li><li><p>Denormalization: <br />Reduce complex joins to improve query performance. <br /></p></li><li><p>Vertical Scaling <br />Boost your database server by adding more CPU, RAM, or storage. <br /></p></li><li><p>Caching <br />Store frequently accessed data in a faster storage layer to reduce database load. <br /></p></li><li><p>Replication <br />Create replicas of your primary database on different servers for scaling the reads. <br /></p></li><li><p>Sharding <br />Split your database tables into smaller pieces and spread them across servers. Used for scaling the writes as well as the reads. </p></li></ol><p>Over to you: What other strategies do you use for scaling your databases?</p><div><hr /></div><h2>How do we retry on failures?</h2><p>In distributed systems and networked applications, retry strategies are crucial for handling transient errors and network instability effectively. The diagram shows 4 common retry strategies.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F24495c00-fa48-45c0-90f4-6dbfb6cb1c95_1291x1536.gif" title="No alt text provided for this image" width="1291" /><div></div></div></a></figure></div><ul><li><p>Linear Backoff<br />Linear backoff involves waiting for a progressively increasing fixed interval between retry attempts. <br /><br />Advantages: Simple to implement and understand. <br /><br />Disadvantages: May not be ideal under high load or in high-concurrency environments as it could lead to resource contention or "retry storms".<br /></p></li><li><p>Linear Jitter Backoff<br />Linear jitter backoff modifies the linear backoff strategy by introducing randomness to the retry intervals. This strategy still increases the delay linearly but adds a random "jitter" to each interval. <br /><br />Advantages: The randomness helps spread out the retry attempts over time, reducing the chance of synchronized retries across instances.<br /><br />Disadvantages: Although better than simple linear backoff, this strategy might still lead to potential issues with synchronized retries as the base interval increases only linearly.<br /></p></li><li><p>Exponential Backoff<br />Exponential backoff involves increasing the delay between retries exponentially. The interval might start at 1 second, then increase to 2 seconds, 4 seconds, 8 seconds, and so on, typically up to a maximum delay. This approach is more aggressive in spacing out retries than linear backoff.<br /><br />Advantages: Significantly reduces the load on the system and the likelihood of collision or overlap in retry attempts, making it suitable for high-load environments.<br /><br />Disadvantages: In situations where a quick retry might resolve the issue, this approach can unnecessarily delay the resolution.<br /></p></li><li><p>Exponential Jitter Backoff<br />Exponential jitter backoff combines exponential backoff with randomness. After each retry, the backoff interval is exponentially increased, and then a random jitter is applied. The jitter can be either additive (adding a random amount to the exponential delay) or multiplicative (multiplying the exponential delay by a random factor). <br /><br />Advantages: Offers all the benefits of exponential backoff, with the added advantage of reducing retry collisions even further due to the introduction of jitter.<br /><br />Disadvantages: The randomness can sometimes result in longer than necessary delays, especially if the jitter is significant.</p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1158" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd70ae0a-7b12-4bf7-a15d-ed5a3f4a9117_1600x1272.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">A Crash Course on REST APIs</a></p></li><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Reddit&#8217;s Core Architecture</h2><p>A quick look at Reddit&#8217;s Core Architecture that helps it serve over 1 billion users every month. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application, Teams" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7c184477-46df-4f37-b224-262c64a6ec58_1280x1611.gif" title="graphical user interface, application, Teams" /><div></div></div></a></figure></div><p>This information is based on research from many Reddit engineering blogs. But since architecture is ever-evolving, things might have changed in some aspects. <br /> <br />The main points of Reddit&#8217;s architecture are as follows: </p><ol><li><p>Reddit uses a Content Delivery Network (CDN) from Fastly as a front for the application <br /></p></li><li><p>Reddit started using jQuery in early 2009. Later on, they started using Typescript and have now moved to modern Node.js frameworks. Over the years, Reddit has also built mobile apps for Android and iOS. <br /></p></li><li><p>Within the application stack, the load balancer sits in front and routes incoming requests to the appropriate services. <br /></p></li><li><p>Reddit started as a Python-based monolithic application but has since started moving to microservices built using Go. <br /></p></li><li><p>Reddit heavily uses GraphQL for its API layer. In early 2021, they started moving to GraphQL Federation, which is a way to combine multiple smaller GraphQL APIs known as Domain Graph Services (DGS). In 2022, the GraphQL team at Reddit added several new Go subgraphs for core Reddit entities thereby splitting the GraphQL monolith. <br /></p></li><li><p>From a data storage point of view, Reddit relies on Postgres for its core data model. To reduce the load on the database, they use memcached in front of Postgres. Also, they use Cassandra quite heavily for new features mainly because of its resiliency and availability properties. <br /></p></li><li><p>To support data replication and maintain cache consistency, Reddit uses Debezium to run a Change Data Capture process. <br /></p></li><li><p>Expensive operations such as a user voting or submitting a link are deferred to an async job queue via RabbitMQ and processed by job workers. For content safety checks and moderation, they use Kafka to transfer data in real-time to run rules over them. <br /></p></li><li><p>Reddit uses AWS and Kubernetes as the hosting platform for its various apps and internal services. <br /></p></li><li><p>For deployment and infrastructure, they use Spinnaker, Drone CI, and Terraform. </p></li></ol><p>Over to you: what other aspects do you know about Reddit&#8217;s architecture?</p><div><hr /></div><h2>Everything You Need to Know About Cross-Site Scripting (XSS)</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1668" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2debd75-6209-41a3-a13f-f2364c281444_1280x1668.jpeg" title="No alt text provided for this image" width="1280" /><div></div></div></a></figure></div><p>XSS, a prevalent vulnerability, occurs when malicious scripts are injected into web pages, often through input fields. Check out the diagram below for a deeper dive into how this vulnerability emerges when user input is improperly handled and subsequently returned to the client, leaving systems vulnerable to exploitation.<br /><br />Understanding the distinction between Reflective and Stored XSS is crucial. Reflective XSS involves immediate execution of the injected script, while Stored XSS persists over time, posing long-term threats. Dive into the diagrams for a comprehensive comparison of these attack vectors.<br /><br />Imagine this scenario: A cunning hacker exploits XSS to clandestinely harvest user credentials, such as cookies, from their browser, potentially leading to unauthorized access and data breaches. It's a chilling reality.<br /><br />But fret not! Our flyer also delves into effective mitigation strategies, empowering you to fortify your systems against XSS attacks. From input validation and output encoding to implementing strict Content Security Policies (CSP), we've got you covered.<br /><br />Over to you: How can we amplify user awareness to proactively prevent falling victim to XSS attacks? Share your insights and strategies below! Let's collaboratively bolster our web defenses and foster a safer digital environment.</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Sat, 01 Jun 2024 15:30:57 GMT</pubDate>
</item>
<item>
<title>A Crash Course on REST APIs</title>
<link>https://blog.bytebytego.com/p/a-crash-course-on-rest-apis</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-on-rest-apis</guid>
<content:encoded><![CDATA[
<div> APIs、软件、接口、通信、REST API<br />
REST API是软件之间通信的重要方式，通过定义一组规则、协议和方法，在不同的应用程序之间建立联系。从60年代的子程序和库到80年代的远程过程调用（RPC），再到2000年代的Web服务和最近的RESTful APIs，API的形式不断演变。如今，REST API已成为开发者的首选，其简单性和可扩展性备受推崇。API-first的软件开发方法也逐渐流行，强调构建解耦服务。通过探索REST API的基本和高级概念，我们能更深入了解这一领域。 <br /><br />总结: <br />APIs是软件之间的重要通信方式，REST API通过定义规则和方法促进了不同应用程序之间的联系，使得软件开发更加灵活和可扩展。 <div>
<p>Application Programming Interfaces (APIs) are the backbone of software communication.</p><p>In the acronym API, the word &#8220;Application&#8221; refers to software that performs a distinct function. An &#8220;Interface&#8221; is a contract between two applications that defines a set of rules, protocols, and methods for communication. &#8220;Programming&#8221; makes all of this possible.</p><p>APIs have been around for a long time in one form or the other:</p><ul><li><p>In the 60s and 70s, we had subroutines and libraries to share code and functionality between programs.&nbsp;</p></li><li><p>In the 1980s, Remote Procedure Calls (RPC) emerged, allowing programs running on different computers to execute procedures on each other.</p></li><li><p>With the widespread adoption of the Internet in the 2000s, web services such as SOAP became widely adopted.</p></li><li><p>The late 2000s and early 2010s marked the rise of RESTful APIs, which have since become the dominant approach due to their simplicity and scalability.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd70ae0a-7b12-4bf7-a15d-ed5a3f4a9117_1600x1272.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1158" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd70ae0a-7b12-4bf7-a15d-ed5a3f4a9117_1600x1272.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In recent years, the API-first approach to software development has gained significant traction, driven by the emphasis on building loosely coupled services. REST APIs, in particular, have emerged as the go-to choice for developers worldwide.</p><p>In this post, we will explore the world of REST APIs and cover basic to advanced concepts.</p><div><hr /></div><h2>Introduction to REST APIs</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-on-rest-apis">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 30 May 2024 15:30:25 GMT</pubDate>
</item>
<item>
<title>The Scaling Journey of LinkedIn</title>
<link>https://blog.bytebytego.com/p/the-scaling-journey-of-linkedin</link>
<guid>https://blog.bytebytego.com/p/the-scaling-journey-of-linkedin</guid>
<content:encoded><![CDATA[
<div> containerized environments, scaling, service-oriented architecture, caching, real-time analytics

总结：<br /><br />这篇文章主要介绍了LinkedIn在发展过程中的扩展之路。从最初的单一的单体系统到服务面向架构的转变，LinkedIn采取了多种技术手段来应对不断增长的需求。文章中详细介绍了LinkedIn如何通过构建新的服务来解决不同需求，包括成员连接管理、搜索功能、数据库复制等。LinkedIn还采用缓存技术和实时分析技术来支持其日益增长的数据需求。最后，LinkedIn还提出了解决授权管理问题的方案，以保护用户数据安全。LinkedIn的经验对于其他开发者团队来说是宝贵的参考，尤其是在面对快速扩展需求时。 <div>
<h2><a href="https://bit.ly/Datadog_052824Headline">10 Insights On Real-World Container Usage (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Datadog_052824Headline" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1080" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35436006-94db-4232-878b-cbbeae4ea59e_1080x1080.png" width="1080" /><div></div></div></a></figure></div><p>As organizations have scaled their containerized environments, many are now exploring the next technology frontier of containers by building next-gen applications, enhancing developer productivity, and optimizing costs.</p><p>Datadog analyzed telemetry data from over 2.4 billion containers to understand the present container landscape, with key insights into:</p><ul><li><p>Trends in adoption for technologies such as serverless containers and GPU-based compute on containers</p></li><li><p>How organizations are managing container costs and resources through ARM-based compute and horizontal pod autoscaling</p></li><li><p>Popular workload categories and languages for containers</p></li></ul><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Datadog_052824Headline"><span>Read the report</span></a></p><div><hr /></div><p>LinkedIn is one of the biggest social networks in the world with almost a billion members.</p><p>But the platform had humble beginnings.</p><p>The idea of LinkedIn was conceived in Reid Hoffman&#8217;s living room in 2002 and it was officially launched in May 2003. There were 11 other co-founders from Paypal and Socialnet who collaborated closely with Reid Hoffman on this project.</p><p>The initial start was slow and after the first month of operation, LinkedIn had just around 4300 members. Most of them came through personal invitations by the founding members.&nbsp;</p><p>However, LinkedIn&#8217;s user base grew exponentially over time and so did the content hosted on the platform. In a few years, LinkedIn was serving tens of thousands of web pages every second of every day to users all over the world.</p><p>This unprecedented growth had one major implication.</p><p>LinkedIn had to take on some extraordinary challenges to scale its application to meet the growing demand. While it would&#8217;ve been tough for the developers involved in the multiple projects, it&#8217;s a gold mine of lessons for any developer.</p><p>In this article, we will look at the various tools and techniques LinkedIn adopted to scale the platform.</p><div><hr /></div><h2>Humble Beginning with Leo</h2><p>Like many startups, LinkedIn also began life with a <strong>monolithic architecture</strong>.</p><p>There was one big application that took care of all the functionality needed for the website. It hosted web servlets for the various pages, handled business logic, and also connected to the database layer.&nbsp;</p><p>This monolithic application was internally known as Leo. Yes, it was as magnificent as MGM&#8217;s Leo the Lion.</p><p>The below diagram represents the concept of Leo on a high level.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcf884de-6fbe-4259-a6a5-fd174c2bbd34_1600x1344.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1223" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcf884de-6fbe-4259-a6a5-fd174c2bbd34_1600x1344.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>However, as the platform grew in terms of functionality and complexity, the monolith wasn&#8217;t enough.</p><h2>The First Need of Scaling</h2><p>The first pinch point came in the form of two important requirements:</p><ul><li><p>Managing member-to-member connections</p></li><li><p>Search capabilities</p></li></ul><p>Let&#8217;s look at both.</p><h3>Member Graph Service</h3><p>A social network depends on connections between people.&nbsp;</p><p>Therefore, it was critical for LinkedIn to effectively manage member to member connections. For example, LinkedIn shows the graph distance and common connections whenever we view a user profile on the site.</p><p>To display this small piece of data, they needed to perform low-latency graph computations, creating the need for a system that can query connection data using <strong>in-memory graph traversals</strong>. The in-memory requirement is key to realizing the performance goals of the system.&nbsp;</p><p>Such a system had a completely different usage profile and scaling need as compared to Leo.</p><p>Therefore, the engineers at LinkedIn built a <strong>distributed and partitioned graph system</strong> that can store millions of members and their connections. It could also handle hundreds of thousands of queries per second (QPS).</p><p>The system was called Cloud and it happened to be the first service at LinkedIn. It consisted of three major subcomponents:</p><ol><li><p><strong>GraphDB</strong> - a partitioned graph database that was also replicated for high availability and durability</p></li><li><p><strong>Network Cache Service</strong> - a distributed cache that stores a member&#8217;s network and serves queries requiring second-degree knowledge</p></li><li><p><strong>API Layer</strong> - the access point for the front end to query the data.</p></li></ol><p>The below diagram shows the high-level architecture of the member graph service.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F141d467c-35c1-4946-8f0e-a9b295e06fcd_1600x1041.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="947" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F141d467c-35c1-4946-8f0e-a9b295e06fcd_1600x1041.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To keep it separate from Leo, LinkedIn utilized Java RPC for communication between the monolith and the graph service.</p><h3>Search Service</h3><p>Around the same time, LinkedIn needed to support another critical functionality - <strong>the capability to search people and topics</strong>.&nbsp;</p><p>It is a core feature for LinkedIn where members can use the platform to search for people, jobs, companies, and other professional resources. Also, this search feature should aim to provide deeply personalized search results based on a member&#8217;s identity and relationships.</p><p>To support this requirement, a new search service was built using <strong>Lucene</strong>.&nbsp;</p><p>Lucene is an open-source library that provides three functionalities:</p><ul><li><p>Building a search index</p></li><li><p>Searching the index for matching entities</p></li><li><p>Determining the importance of these entities through relevant scores</p></li></ul><p>Once the search service was built, both the monolith and the new member graph service started feeding data into this service.</p><p>While the building of these services solved key requirements, the continued growth in traffic on the main website meant that Leo also had to scale.</p><p>Let&#8217;s look at how that was achieved.</p><h2>Scaling Leo</h2><p>As LinkedIn grew in popularity, the website grew and Leo&#8217;s roles and responsibilities also increased. Naturally, the once-simple web application became more complex.</p><p><strong>So - how was Leo scaled?</strong></p><p>One straightforward method was to spin up multiple instances of Leo and run them behind a Load Balancer that routes traffic to these instances.</p><p>It was a nice solution but it only involved the application layer of Leo and not the database. However, the increased workload was negatively impacting the performance of LinkedIn&#8217;s most critical system - its <strong>member profile database</strong> that stored the personal information of every registered user. Needless to say, this was the heart of LinkedIn.</p><p>A quick and easy fix for this was going for classic vertical scaling by throwing additional compute capacity and memory for running the database. It&#8217;s a good approach to buy some time and get some breathing space for the team to think about a long-term solution to scaling the database.</p><p>The member profile database had one major issue. It handled both read and write traffic, resulting in a heavy load.&nbsp;</p><p>To scale it out, the team turned to <strong>database replication</strong>.</p><p>New replica databases were created. These replicas were a copy of the primary database and stayed in sync with the primary using Databus. While writes were still handled by the primary database, the trick was to send the majority of read requests to the replica databases.</p><p>However, data replication always results in some amount of replication lag. If a request reads from the primary database and the replica database at the same time, it can get different results because the replication may not have completed. A classic example is a user updating her profile information and not able to see the updated data on accessing the profile just after the update.</p><p>To deal with issues like this, special logic was built to decide when it was safe or consistent to read from the replica database versus the primary database.</p><p>The below diagram tries to represent the architecture of LinkedIn along with database replication</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ae6342-e436-4fb9-87e8-319992fd6e71_1600x1035.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="942" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ae6342-e436-4fb9-87e8-319992fd6e71_1600x1035.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>While replication solved a major scaling challenge for LinkedIn, the website began to see more and more traffic. Also, from a product point of view, LinkedIn was evolving rapidly.</p><p>It created two major challenges:</p><ul><li><p>Leo was often going down in production and it was becoming more difficult to recover from failures</p></li><li><p>Releasing new features became tough due to the complexity of the monolithic application</p></li></ul><p>High availability is a critical requirement for LinkedIn. A social network being down can create serious ripple effects for user adoption. It soon became obvious that they had to kill Leo and break apart the monolithic application into more manageable pieces.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="840" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7bb39625-0f08-43c8-89fb-b9a0b90406f6_2496x1440.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Killing Leo with Service-Oriented Architecture</h2><p>While it sounds easy to break apart the monolithic application, it&#8217;s not easy to achieve in practice.</p><p>You want to perform the migration in a seamless manner without impacting the existing functionality. Think of it as changing a car&#8217;s tires while it is moving on the highway at 60 miles per hour.</p><p>The engineers at LinkedIn started to extract functionalities from the monolith in their own separate services. Each service contained APIs and business logic specific to a particular functionality.</p><p>Next, services to handle the <strong>presentation layer </strong>were built<strong> </strong>such as public profiles or recruiter products. For any new product, brand-new services were created completely outside of Leo.&nbsp;</p><p>Over time, the effort towards SOA led to the emergence of vertical slices where each slice handled a specific functional area.</p><ul><li><p>The frontend servers fetched data from different domains and handled the presentation logic to build the HTML via JSPs.</p></li><li><p>The mid-tier services provided API access to data models.</p></li><li><p>The backend data services provided consistent access to the database.</p></li></ul><p>By 2010, LinkedIn had already built over 150 separate services and by 2015, they had over 750 services.</p><p>The below diagram represents a glimpse of the SOA-based design at LinkedIn:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da33485-b160-4f78-ac18-37c6e613d63b_1377x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5da33485-b160-4f78-ac18-37c6e613d63b_1377x1600.png" width="1377" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At this point, you may wonder what was the benefit of this massive change.</p><ul><li><p>First, these services were built in a <strong>stateless manner</strong>. Scaling can be achieved by spinning up new instances of a service and putting them behind a load balancer. Such an approach is known as horizontal scaling and it was more cost-effective compared to scaling the monolithic application.</p></li><li><p>Second, each service was expected to define how much load it could take and the engineering team was able to build out early provisioning and performance monitoring capabilities to support any deviations.</p></li></ul><h2>Managing Hypergrowth with Caching</h2><p>It&#8217;s always a good thing for a business owner to achieve an exponential amount of growth.</p><p>Of course, it does create a bunch of problems. Happy problems but still problems that must be solved.</p><p>Despite moving to service-oriented architecture and going for replicated databases, LinkedIn had to scale even further.</p><p>This led to the adoption of caching.</p><p>Many applications started to introduce mid-tier caching layers like memcached or couchbase. These caches were storing derived data from multiple domains. Also, they added caches to the data layers by using Voldemort to store precomputed results when appropriate.</p><p>However, if you&#8217;ve worked with caching, you would know that caching brings along with it a bunch of new challenges in terms of invalidations, managing consistency, and performance.</p><p>Over time, the LinkedIn team got rid of many of the mid-tier caches.&nbsp;</p><p>Caches were kept close to the data store in order to reduce the latency and support horizontal scalability without the cognitive load of maintaining multiple caching layers.</p><h2>Data Collection with Kafka</h2><p>As LinkedIn&#8217;s footprint grew, it also found itself managing a huge amount of data.</p><p>Naturally, when any company acquires a lot of data, it wants to put that data to good use for growing the business and offering more valuable services to the users. However, to make meaningful conclusions from the data, they have to collect the data and bring it in one place such as a data warehouse.</p><p>LinkedIn started developing many custom data pipelines for streaming and queuing data from one system to another.</p><p>Some of the applications were as follows:</p><ul><li><p>Aggregating logs from every service</p></li><li><p>Collecting data regarding tracking events such as pageviews</p></li><li><p>Queuing of emails for LinkedIn&#8217;s inMail messaging system</p></li><li><p>Keeping the search system up to date whenever someone updates their profile</p></li></ul><p>As LinkedIn grew, it needed more of these custom pipelines and each individual pipeline also had to scale to keep up with the load.</p><p>Something had to be done to support this requirement.</p><p>This led to the development of Kafka, a distributed pub-sub messaging platform. It was built around the concept of a commit log and its main goal was to enable speed and scalability.</p><p>Kafka became a universal data pipeline at LinkedIn and enabled near real-time access to any data source. It empowered the various Hadoop jobs and allowed LinkedIn to build real-time analytics, and improve site monitoring and alerting.</p><p>See the below diagram that shows the role of Kafka at LinkedIn.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac326132-2101-4bdc-895b-0138e1ed9e28_1600x1438.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1309" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fac326132-2101-4bdc-895b-0138e1ed9e28_1600x1438.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Over time, Kafka became an integral part of LinkedIn&#8217;s architecture. Some latest facts about Kafka adoption at LinkedIn are as follows:</p><ul><li><p>Over 100 Kafka clusters with more than 4000 brokers</p></li><li><p>100K topics and 7 million partitions</p></li><li><p>7 trillion messages handled per day</p></li></ul><h2>Scaling the Organization with Inversion</h2><p>While scaling is often thought of as a software concern, LinkedIn realized very soon that this is not true.</p><p>At some time, you also need to scale up at an organizational level.&nbsp;</p><p>At LinkedIn, the organizational scaling was carried out via an internal initiative called <strong>Inversion</strong>.</p><p>Inversion put a pause on feature development and allowed the entire engineering organization to focus on improving the tooling and deployment, infrastructure and developer productivity. In other words, they decided to focus on improving the developer experience.</p><p>The goal of Inversion was to increase the engineering capability of the development teams so that new scalable products for the future could be built efficiently and in a cost-effective way.&nbsp;</p><p>Let&#8217;s look at a few significant tools that were built as part of this initiative:</p><h3>Rest.li</h3><p>During the transformation from Leo to a service-oriented architecture, the extracted APIs were based on Java-based RPC.&nbsp;</p><p>Java-based RPC made sense in the early days but it was no longer sufficient as LinkedIn&#8217;s systems evolved into a polyglot ecosystem with services being written in Java, Node.js, Python, Ruby and so on. For example, it was becoming hard for mobile services written in Node.js to communicate with Java object-based RPC services.</p><p>Also, the earlier APIs were tightly coupled with the presentation layer, making it difficult to make changes.</p><p>To deal with this, the LinkedIn engineers created a new API model called <strong>Rest.li</strong>.</p><p><strong>What made Rest.li so special?</strong></p><p>Rest.li was a framework for developing RESTful APIs at scale. It used simple JSON over HTTP, making it easy for non-Java-based clients to communicate with Java-based APIs.</p><p>Also, Rest.li was a step towards a data-model-based architecture that brought a consistent API model across the organization.&nbsp;</p><p>To make things even more easy for developers, they started using Dynamic Discovery (D2) with Rest.li services. With D2, there was no need to configure URLs for each service that you need to talk to. It provides multiple features such as client-based load balancing, service discovery and scalability.</p><p>The below diagram shows the use of Rest.li along with Dynamic Discovery.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faba00d83-f7b0-48c2-a0c3-6bcbaf05df3d_1508x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1545" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faba00d83-f7b0-48c2-a0c3-6bcbaf05df3d_1508x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Super Blocks</h3><p>A service-oriented architecture is great for decoupling domains and scale out services independently.</p><p>However, there are also downsides.</p><p>Many of the applications at LinkedIn depend on data from multiple sources. For example, any request for a user&#8217;s profile page not only fetches the profile data but includes other details such as photos, connections, groups, subscription information, following info, long-form blog posts and so on.</p><p>In a service-oriented architecture, it means making hundreds of calls to fetch all the needed data.&nbsp;</p><p>This is typically known as the &#8220;call graph&#8221; and you can see that this call graph can become difficult to manage as more and more services are created.</p><p>To mitigate this issue, LinkedIn introduced the concept of a <strong>super block</strong>.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F051be3c2-80fe-4b60-ba6f-e47027cfcd84_1600x1177.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1071" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F051be3c2-80fe-4b60-ba6f-e47027cfcd84_1600x1177.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>A super block is a grouping of related backend services with a single access API.&nbsp;</p><p>This allows teams to create optimized interfaces for a bunch of services and keep the call graph in check. You can think of the super block as the implementation of the facade pattern.</p><h3>Multi-Data Center</h3><p>In a few years after launch, LinkedIn became a global company with users joining from all over the world.</p><p>They had to scale beyond serving traffic from just one data center. Multiple data centers are incredibly important to maintain high availability and avoid any single point of failure. Moreover, this wasn&#8217;t needed just for a single service but the entire website.</p><p>The first move was to start serving public profiles out of two data centers (Los Angeles and Chicago).&nbsp;</p><p>Once it was proven that things work, they enhanced all other services to support the below features:</p><ul><li><p>Data replication</p></li><li><p>Callbacks from different origins</p></li><li><p>One-way data replication events</p></li><li><p>Pinning users to geographically-close data centers</p></li></ul><p>As LinkedIn has continued to grow, they have migrated the edge infrastructure to Azure Front Door (AFD). For those who don&#8217;t know, AFD is Microsoft&#8217;s global application and content delivery network and migrating to it provided some great benefits in terms of latency and resilience.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82dd657c-0cf0-495c-8e32-62c2445402ce_700x365.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="365" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82dd657c-0cf0-495c-8e32-62c2445402ce_700x365.png" width="700" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Image Source: <a href="https://www.linkedin.com/blog/engineering/scalability/linkedin-scales-edge-with-azure-front-door">Scaling LinkedIn&#8217;s Edge with Azure Front Door</a> </figcaption></figure></div><p>This move scaled them up to 165+ Points of Presence (PoPs) and helped improve median page load times by up to 25 percent.</p><p>The edge infrastructure is basically how our devices connect to LinkedIn today. Data from our device traverses the internet to the closest PoP that houses HTTP proxies that forward those requests to an application server in one of the LinkedIn data centers.</p><h2>Advanced Developments Around Scalability</h2><p>Running an application as complex and evolving as LinkedIn requires the engineering team to keep investing into building scalable solutions.</p><p>In this section, we will look at some of the more recent developments LinkedIn has undergone.</p><h3>Real Time Analytics with Pinot</h3><p>A few years ago, the LinkedIn engineering team hit a wall with regards to analytics</p><p>The scale of data at LinkedIn was growing far beyond what they could analyze. The analytics functionality was built using generic storage systems like Oracle and Voldemort. However, these systems were not specialized for OLAP needs and the data volume at LinkedIn was growing in both breadth and depth.</p><p>At this point, you might be wondering about the need for real-time analytics at LinkedIn.&nbsp;</p><p>Here are three very important use-cases:</p><ol><li><p>The <strong>Who&#8217;s Viewed Your Profile</strong> is LinkedIn&#8217;s flagship analytics product that allows members to see who has viewed their profile in real-time. To provide this data, the product needs to run complex queries on large volumes of profile view data to identify interesting insights.</p></li><li><p><strong>Company Page Analytics</strong> is another premium product offered by LinkedIn. The data provided by this product enables company admins to understand the demographic of the people following their page.</p></li><li><p>LinkedIn also heavily uses analytics internally to support critical requirements such as A/B testing.</p></li></ol><p>To support these key analytics products and many others at scale, the engineering team created Pinot.</p><p><strong>Pinot is a web-scale real-time analytics engine designed and built at LinkedIn</strong>.&nbsp;</p><p>It allows them to slice, dice and scan through massive quantities of data coming from a wide variety of products in real-time.</p><p><strong>But how does Pinot solve the problem?</strong></p><p>The below diagram shows a comparison between the pre-Pinot and post-Pinot setup.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23532699-4d61-491f-9476-05d57b3844b4_1274x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23532699-4d61-491f-9476-05d57b3844b4_1274x1600.png" width="1274" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As you can see, Pinot supports real-time data indexing from Kafka and Hadoop, thereby simplifying the entire process.</p><p>Some of the other benefits of Pinot are as follows:</p><ul><li><p>Pinot supports low latency and high QPS OLAP queries. For example, it&#8217;s capable of serving thousands of <strong>Who&#8217;s Viewed My Profile</strong> requests while maintaining SLA in the order of 10s of milliseconds</p></li><li><p>Pinot also simplifies operational aspects like cluster rebalancing, adding or removing nodes, and re-bootstrapping</p></li><li><p>Lastly, Pinot has been future-proofed to handle new data dimensions without worrying about scale</p></li></ul><h3>Authorization at LinkedIn Scale</h3><p>Users entrust LinkedIn with their personal data and it was extremely important for them to maintain that trust.</p><p>After the SOA transformation, LinkedIn runs a microservice architecture where each microservice retrieves data from other sources and serves it to the clients. Their philosophy is that a microservice can only access data with a valid business use case. It prevents the unnecessary spreading of data and minimizes the damage if an internal service gets compromised.</p><p>A common industry solution to manage the authorization is to define Access Control Lists (ACLs). An ACL contains a list of entities that are either allowed or denied access to a particular resource.</p><p>For example, let&#8217;s say there is a Rest.li resource to manage <strong>greetings</strong>. The ACL for this resource can look something like this.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F950bb2f6-8976-49e6-b7df-94003dc4782a_1600x1045.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="951" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F950bb2f6-8976-49e6-b7df-94003dc4782a_1600x1045.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In this case, the <strong>client-service</strong> can read but not write whereas the <strong>admin-service</strong> can both read and write to greetings.</p><p>While the concept of an ACL-based authorization is quite simple, it&#8217;s a challenge to maintain at scale. LinkedIn has over 700 services that communicate at an average rate of tens of millions of calls per second. Moreover, this figure is only growing.</p><p>Therefore, the team had to devise a solution to handle ACLs at scale. Mainly, there were three critical requirements:</p><ul><li><p>Check authorization quickly</p></li><li><p>Deliver ACL changes quickly</p></li><li><p>Track and manage a large number of ACLs</p></li></ul><p>The below diagram shows a high-level view of how LinkedIn manages authorization between services.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98ce60b8-b354-48cc-8f0f-6834403bedbb_1999x1207.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="879" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98ce60b8-b354-48cc-8f0f-6834403bedbb_1999x1207.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Some key points to consider over here are as follows:</p><ul><li><p>To make authorization checks quick, they built an authorization client module that runs on every service at LinkedIn. This module decides whether an action should be allowed or denied. New services pick up this client by default as part of the basic service architecture.</p></li><li><p>Latency is a critical factor during an authorization check and making a network call every time is not acceptable. Therefore, all relevant ACL data is kept in memory by the service.</p></li><li><p>To keep the ACL data fresh, every client reaches out to the server at fixed intervals and updates its in-memory copy. This is done at a fast enough cadence for any ACL changes to be realized quickly.</p></li><li><p>All ACLs are stored in LinkedIn&#8217;s Espresso database. It&#8217;s a fault-tolerant distributed NoSQL database that provides a simple interface.</p></li><li><p>To manage latency and scalability, they also keep a Couchbase cache in front of Espresso. This means even on the server side, the data is served from memory. To deal with stale data in the Couchbase, they use a Change Data Capture system based on LinkedIn&#8217;s Brooklin to notify the service when an ACL has changed so that the cache can be cleared.</p></li><li><p>Every authorization check is logged in the background. This is necessary for debugging and traffic analysis. LinkedIn uses Kafka for asynchronous, high-scale logging. Engineers can check the data in a separate monitoring system known as <strong>inGraphs</strong>.</p></li></ul><h2>Conclusion</h2><p>In this post, we&#8217;ve taken a brief look at the scaling journey of LinkedIn.</p><p>From its simple beginnings as a standalone monolithic system serving a few thousand users, LinkedIn has come a long way. It is one of the largest social networks in the world for professionals and companies, allowing seamless connection between individuals across the globe.</p><p>To support the growing demands, LinkedIn had to undertake bold transformations at multiple steps.&nbsp;</p><p>In the process, they&#8217;ve provided a lot of learnings for the wider developer community that can help you in your own projects.</p><p><strong>References</strong>:</p><ul><li><p><a href="https://engineering.linkedin.com/architecture/brief-history-scaling-linkedin">A Brief History of Scaling LinkedIn</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/scalability/linkedin-scales-edge-with-azure-front-door">Scaling LinkedIn&#8217;s Edge with Azure Front Door</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/open-source/apache-kafka-trillion-messages">How LinkedIn customizes Apache Kafka for 7 trillion messages per day</a></p></li><li><p><a href="https://engineering.linkedin.com/real-time-distributed-graph/using-set-cover-algorithm-optimize-query-latency-large-scale-distributed">Using Set Cover Algorithm to optimize query latency for a large-scale distributed graph</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/scalability/authorization-at-linkedins-scale">Authorization at LinkedIn&#8217;s Scale</a></p></li><li><p><a href="https://www.linkedin.com/blog/engineering/architecture/restli-restful-service-architecture-scale">Rest.li: RESTful Service Architecture at Scale</a></p></li><li><p><a href="https://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot">Real-time analytics at a massive scale with Pinot</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p><br /><br /><br /><br /><br /><br /><br /><br /></p>
]]></content:encoded>
<pubDate>Tue, 28 May 2024 15:31:05 GMT</pubDate>
</item>
<item>
<title>EP113: AWS Services Cheat Sheet</title>
<link>https://blog.bytebytego.com/p/ep113-aws-services-cheat-sheet</link>
<guid>https://blog.bytebytego.com/p/ep113-aws-services-cheat-sheet</guid>
<content:encoded><![CDATA[
<div> AWS Services, API designs, Postman, Azure Services, computer programs run

<br />
API设计和发布对于应用程序的成功至关重要。Postman为团队合作提供了有效的工具，使API设计、测试和文档编写更加简单和高效。AWS和Azure作为主要云服务平台，提供了丰富的服务和功能，满足了不同用户的需求。运行计算机程序涉及多个步骤，包括用户交互、程序预加载、依赖解析和加载、内存分配以及程序终止。这些技术和工具的发展不断推动着软件开发和云计算技术的进步。总结:API设计和发布对于应用程序至关重要，Postman为团队合作提供了有效工具，AWS和Azure作为云服务平台提供丰富服务，计算机程序的运行包括多个步骤，推动软件开发和云计算技术的发展。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Do You Know How Mobile Apps Are Released? (Youtube video)</p></li><li><p>AWS Services Cheat Sheet </p></li><li><p>A cheat sheet for API designs</p></li><li><p>Azure Services Cheat Sheet </p></li><li><p>How do computer programs run? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/Postman_052425Headline">Collaborating on APIs is Easier With Postman (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/Postman_052425Headline" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="819" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e4e769d-06a0-4464-b727-b9b39c6f2133_1660x934.png" width="1456" /><div></div></div></a></figure></div><p>Whether you&#8217;re a team of four or 40,000, development teams need to collaborate on APIs. <a href="https://bit.ly/Postman_052425Headline">API Collaboration</a>&nbsp;improves developer productivity by empowering both API producers and consumers to share, discover, and reuse high-quality API assets.</p><p>Postman revolutionizes the experience of collaborative API development with <a href="https://bit.ly/Postman_052524Collections">Collections</a> and <a href="https://bit.ly/Postman_052425Workspaces">Workspaces</a>. Used together, they enable API design, testing, and documentation, providing a shared canvas for collaborating on API assets.</p><p>Learn how Postman is giving teams of all sizes and functions the ability to rapidly iterate on API development, elevate the quality of their APIs, and extend their API workflows for large-scale initiatives.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/Postman_052425Headline"><span>Learn More</span></a></p><div><hr /></div><h2>Do You Know How Mobile Apps Are Released?</h2><div class="youtube-wrap" id="youtube2-RIX4ufelA58"><div class="youtube-inner"></div></div><div><hr /></div><h2>AWS Services Cheat Sheet </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F915d1659-0779-460e-b71f-a7dd9d812556_1415x1536.gif" title="No alternative text description for this image" width="1415" /><div></div></div></a></figure></div><p>AWS grew from an in-house project to the market leader in cloud services, offering so many different services that even experts can find it a lot to take in. <br /> <br />The platform not only caters to foundational cloud needs but also stays at the forefront of emerging technologies such as machine learning and IoT, establishing itself as a bedrock for cutting-edge innovation. AWS continuously refines its array of services, ensuring advanced capabilities for security, scalability, and operational efficiency are available. <br /> <br />For those navigating the complex array of options, this AWS Services Guide is a helpful visual aid. <br /> <br />It simplifies the exploration of AWS's expansive landscape, making it accessible for users to identify and leverage the right tools for their cloud-based endeavors. <br /> <br />Over to you: What improvements would you like to see in AWS services based on your usage?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1893" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66e9dc1a-3ca4-40a6-9578-ee59e9ae0ef8_3000x3900.png" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/api-security-best-practices">API Security Best Practices</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>A cheat sheet for API designs</h2><p>APIs expose business logic and data to external systems, so designing them securely and efficiently is important.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fae83c804-21ac-4baa-ab4a-56ca0ba0f4d2_1452x1536.gif" title="No alt text provided for this image" width="1452" /><div></div></div></a></figure></div><ul><li><p>API key generation<br />We normally generate one unique app ID for each client and generate different pairs of public key (access key) and private key (secret key) to cater to different authorizations. For example, we can generate one pair of keys for read-only access and another pair for read-write access. <br /></p></li><li><p>Signature generation<br />Signatures are used to verify the authenticity and integrity of API requests. They are generated using the secret key and typically involve the following steps:<br /><br />- Collect parameters<br />- Create a string to sign<br />- Hash the string: Use a cryptographic hash function, like HMAC (Hash-based Message Authentication Code) in combination with SHA-256, to hash the string using the secret key. <br /></p></li><li><p>Send the requests<br />When designing an API, deciding what should be included in HTTP request parameters is crucial. Include the following in the request parameters:<br /><br />- Authentication Credentials<br />- Timestamp: To prevent replay attacks.<br />- Request-specific Data: Necessary to process the request, such as user IDs, transaction details, or search queries.<br />- Nonces: Randomly generated strings included in each request to ensure that each request is unique and to prevent replay attacks.<br /></p></li><li><p>Security guidelines<br />To safeguard APIs against common vulnerabilities and threats, adhere to these security guidelines.</p></li></ul><div><hr /></div><h2>Azure Services Cheat Sheet </h2><p>Launching in 2010, Microsoft Azure has quickly grown to hold the No. 2 position in market share by evolving from basic offerings to a comprehensive, flexible cloud ecosystem.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alt text provided for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc905b80e-685f-4145-a12c-02d704f70efd_1414x1536.gif" title="No alt text provided for this image" width="1414" /><div></div></div></a></figure></div><p>Today, Azure not only supports traditional cloud applications but also caters to emerging technologies such as AI, IoT, and blockchain, making it a crucial platform for innovation and development.<br /><br />As it evolves, Azure continues to enhance its capabilities to provide advanced solutions for security, scalability, and efficiency, meeting the demands of modern enterprises and startups alike. This expansion allows organizations to adapt and thrive in a rapidly changing digital landscape.<br /><br />The attached illustration can serve as both an introduction and a quick reference for anyone aiming to understand Azure.<br /><br />Over to you: How does your experience with Azure compare to that with AWS?<br /><br />Over to you: Does the card network charge the same interchange fee for big merchants as for small merchants?</p><div><hr /></div><h2>How do computer programs run? </h2><p>The diagram shows the steps. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1536" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F416ff1bc-c6c4-475a-b45f-7842fbfcd726_1435x1536.gif" title="No alternative text description for this image" width="1435" /><div></div></div></a></figure></div><ul><li><p>User interaction and command initiation <br />By double-clicking a program, a user is instructing the operating system to launch an application via the graphical user interface. <br /></p></li><li><p>Program Preloading <br />Once the execution request has been initiated, the operating system first retrieves the program's executable file. <br /> <br />The operating system locates this file through the file system and loads it into memory in preparation for execution. <br /></p></li><li><p>Dependency resolution and loading <br />Most modern applications rely on a number of shared libraries, such as dynamic link libraries (DLLs). </p><p></p></li><li><p>Allocating memory space <br />The operating system is responsible for allocating space in memory. <br /> </p></li><li><p>Initializing the Runtime Environment <br />After allocating memory, the operating system and execution environment (e.g., Java's JVM or the .NET Framework) will initialize various resources needed to run the program. <br /></p></li><li><p>System Calls and Resource Management <br />The entry point of a program (usually a function named `main`) is called to begin execution of the code written by the programmer. <br /></p></li><li><p>Von Neumann Architecture <br />In the Von Neumann architecture, the CPU executes instructions stored in memory. <br /></p></li><li><p>Program termination <br />Eventually, when the program has completed its task, or the user actively terminates the application, the program will begin a cleanup phase. This includes closing open file descriptors, freeing up network resources, and returning memory to the system. </p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong><br /></p>
]]></content:encoded>
<pubDate>Sat, 25 May 2024 15:30:49 GMT</pubDate>
</item>
<item>
<title>API Security Best Practices</title>
<link>https://blog.bytebytego.com/p/api-security-best-practices</link>
<guid>https://blog.bytebytego.com/p/api-security-best-practices</guid>
<content:encoded><![CDATA[
<div> APIs, security vulnerabilities, threats, authentication, best practices

<br />
API安全性是现代应用程序的支柱。API暴露了很大的攻击面，增加了安全漏洞的风险。常见的威胁包括SQL注入、跨站脚本攻击和分布式拒绝服务（DDoS）攻击。因此，实施强大的安全措施来保护API和其处理的敏感数据至关重要。认证确保只有经授权的用户或应用程序可以访问受保护的资源或API端点。在实现认证之前，选择适当的认证机制非常重要，根据我们的用例、安全要求和与客户端应用程序的兼容性。以下是保护API的一些流行认证机制。

<br /><br />总结:API安全性至关重要，需要应对潜在的安全漏洞和威胁。认证是确保只有授权用户访问受保护资源或API端点的关键。选择适当的认证机制，并实施安全措施如身份验证、授权、安全通信和速率限制，是设计安全API的核心策略。 <div>
<p>APIs are the backbone of modern applications. They expose a very large surface area for attacks, increasing the risk of security vulnerabilities. Common threats include SQL injection, cross-site scripting, and distributed denial of service (DDoS) attacks.&nbsp;</p><p>That's why it's crucial to implement robust security measures to protect APIs and the sensitive data they handle. However, many companies struggle to achieve comprehensive API security coverage. They often rely solely on dynamic application security scanning or external pen testing. While these methods are valuable, they may not fully cover the API layer and its increasing attack surface.&nbsp;</p><p>In this week&#8217;s issue, we'll explore API security best practices. From authentication and authorization to secure communication and rate limiting, we&#8217;ll cover essential strategies for designing secure APIs.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66e9dc1a-3ca4-40a6-9578-ee59e9ae0ef8_3000x3900.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1893" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66e9dc1a-3ca4-40a6-9578-ee59e9ae0ef8_3000x3900.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>Authentication</h2><p>Authentication ensures that only authorized users or applications can access protected resources or API endpoints. Before implementing authentication, choosing the appropriate authentication mechanism is crucial based on our use case, security requirements, and compatibility with client applications.&nbsp;</p><p>Below are some popular authentication mechanisms for securing APIs:</p>
      <p>
          <a href="https://blog.bytebytego.com/p/api-security-best-practices">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 23 May 2024 15:30:58 GMT</pubDate>
</item>
<item>
<title>How Slack Built a Distributed Cron Execution System for Scale</title>
<link>https://blog.bytebytego.com/p/how-slack-built-a-distributed-cron</link>
<guid>https://blog.bytebytego.com/p/how-slack-built-a-distributed-cron</guid>
<content:encoded><![CDATA[
<div> Slack, cron execution system, scalability, reliability, Job Queue

总结:<br /><br />
Slack在处理大规模系统中的cron执行工作时遇到了挑战，决定重新构建分布式cron执行系统。他们采用了Scheduled Job Conductor、Job Queue和Vitess Database Table等组件来解决问题。Scheduled Job Conductor使用Go和Kubernetes实现，采用了Leader-Follower架构和灵活的横向扩展。Job Queue则处理资源密集的任务，通过Kafka和Redis实现高效的作业处理。最后，Vitess表用于数据重复处理和作业跟踪，提高了系统的可靠性和监控。Slack的经验表明，通过简单的解决方案构建大规模系统是可行的。 <div>
<h2><a href="https://bit.ly/QAWolf_052124">&#128075;Goodbye low test coverage and slow QA cycles (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_052124" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="750" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe2e17972-3779-4bb2-beb3-1fadf11f4c85_1000x750.png" width="1000" /><div></div></div></a></figure></div><p>Bugs sneak out when less than 80% of user flows are tested before shipping. But getting that kind of coverage &#8212; and staying there &#8212; is hard and pricey for any sized team.</p><p><a href="https://bit.ly/QAWolf_052124">QA Wolf</a> takes testing off your plate:</p><p>&#8594; Get to 80% test coverage in just 4 months.</p><p>&#8594; Stay bug-free with <a href="https://bit.ly/QAWolf_052124">24-hour maintenance</a> and on-demand test creation.</p><p>&#8594; Get <a href="https://bit.ly/QAWolf_052124">unlimited parallel test runs</a></p><p>&#8594; Zero Flakes guaranteed</p><p>QA Wolf has generated <a href="https://bit.ly/QAWolf_052124">amazing results</a> for companies like Salesloft, AutoTrader, Mailchimp, and Bubble.</p><p>&#127775; Rated 4.5/5 on G2</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_052124"><span>Learn more about their 90-day pilot</span></a></p><div><hr /></div><p>Have you ever stretched a simple tool to its absolute limits before you upgraded?</p><p>We do it all the time. And so do the big companies that operate on a massive scale. This is because simple things can sometimes take you much further than you initially think. Of course, you may have to pay with some toil and tears.</p><p>This is exactly what Slack, a $28 billion company with 35+ million users, did for its cron execution workflow that handles critical functionalities. Instead of moving to some other new-age solutions, they rebuilt their cron execution system from the ground up to run jobs reliably at their scale.&nbsp;</p><p>In today&#8217;s post, we&#8217;ll look at how Slack architected a distributed cron execution system and the choices made in the overall design.</p><div><hr /></div><h2>The Role of Cron Jobs at Slack</h2><p>As you already know, Slack is one of the most popular platforms for team collaboration.&nbsp;</p><p>Due to its primary utility as a communication tool, Slack is super dependent on the right notification reaching the right person at the right time.&nbsp;</p><p>However, as the platform witnessed user and feature growth, Slack faced challenges in maintaining the reliability of its notification system, which largely depended on cron jobs.&nbsp;</p><p>For reference, cron jobs are used to automate repetitive tasks. You can configure a cron job to ensure that specific scripts or commands run at predefined intervals without manual intervention.</p><p>Cron jobs play a crucial role in Slack's notification system by making sure that messages and reminders reach users on time. A lot of the critical functionality at Slack relies on these cron scripts. For example,&nbsp;</p><ul><li><p>Sending timely reminders to users.</p></li><li><p>Delivering email notifications to keep the users informed about important updates in the team.</p></li><li><p>Pushing message notifications to users so that they don&#8217;t miss critical conversations.</p></li><li><p>Performing regular database clean-ups to maintain system performance.</p></li></ul><p>As Slack grew, there has been a massive growth in the number of cron scripts and the amount of data processed by these scripts. Ultimately, this caused a dip in the overall reliability of the execution environment.</p><h2>The Issues with Cron Jobs</h2><p>Some of the challenges and issues Slack faced with their original cron execution approach were as follows:</p><ul><li><p><strong>Maintainability Issues:</strong> Managing many cron scripts on a single node became cumbersome and error-prone as Slack&#8217;s functionalities expanded. Tasks like updating, troubleshooting, and monitoring the scripts required a lot of effort from the engineering team.</p></li><li><p><strong>Cost-ineffective Vertical Scaling: </strong>As the number of cron scripts increased, Slack tried to vertically scale the node by adding more CPU and RAM. However, this approach quickly became cost-ineffective, as the hardware requirements grew disproportionately to the number of scripts.</p></li><li><p><strong>Single Point of Failure: </strong>Relying on a single node to execute all cron jobs introduced a significant risk to Slack&#8217;s critical functionality. Any misconfigurations, hardware failures, or software issues on the node could bring down the entire notification system.</p></li></ul><p>To solve these issues, Slack decided to build a brand new cron execution service that was more reliable and scalable than the original approach.</p><h2>The High-Level Cron Execution Architecture</h2><p>The below diagram shows the high-level cron execution architecture.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F494650c6-0993-4b60-b69f-f1cd05c464c6_1600x995.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="905" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F494650c6-0993-4b60-b69f-f1cd05c464c6_1600x995.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>There are 3 main components in this design. Let&#8217;s look at each of them in more detail.</p><h3>Scheduled Job Conductor</h3><p>Slack developed a new execution service. It was written in Go and deployed on Bedrock.</p><p>Bedrock is Slack&#8217;s in-house platform that wraps around Kubernetes, providing an additional abstraction layer and functionality for Slack&#8217;s specific needs. It builds upon Kubernetes and adds some key features such as:</p><ul><li><p>Simplified deployment</p></li><li><p>Custom resource definitions specific to Slack&#8217;s infrastructure</p></li><li><p>Enhanced monitoring and logging</p></li><li><p>Integration with Slack&#8217;s infrastructure</p></li></ul><p>The new service mimics the behavior of cron by utilizing a Go-based cron library while benefiting from the scalability and reliability provided by Kubernetes.&nbsp;</p><p>The below diagram shows how the Scheduled Job Conductor works in practice.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3c56544-a9d4-40e6-88b9-68fee6d3cefc_1600x998.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="908" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3c56544-a9d4-40e6-88b9-68fee6d3cefc_1600x998.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>It had some key properties that we should consider.</p><h4>1 - Scalability through Kubernetes Deployment</h4><p>By deploying the cron execution service on Bedrock, Slack gains the ability to easily scale up multiple pods as needed.&nbsp;</p><p>As you might be aware, Kubernetes provides a flexible infrastructure for containerized applications. You can dynamically adjust the number of pods based on the workload.</p><h4>2 - Leader Follower Architecture</h4><p>Interestingly, Slack's cron execution service does not process requests on multiple pods simultaneously.&nbsp;</p><p>Instead, they adopt a leader-follower architecture, where only one pod (the leader) is responsible for scheduling jobs, while the other pods remain in standby mode.&nbsp;</p><p>This design decision may seem counterintuitive, as it appears to introduce a single point of failure. However, the Slack team determined that synchronizing the nodes would be a more significant challenge than the potential risk of having a single leader.</p><p>A couple of advantages of the leader-follower architecture are as follows:</p><ul><li><p><strong>Rapid Failover: </strong>If the leader pod goes down, Kubernetes can quickly promote one of the standby pods to take over the work. This minimizes downtime and makes the cron execution service highly available.</p></li><li><p><strong>Simplified Synchronization: </strong>By having a single leader, Slacks avoids the complexity of dealing with conflicts.</p></li></ul><h4>3 - Offloading Resource-Intensive Tasks</h4><p>The job conductor service is only responsible for job scheduling. The actual execution is handled by worker nodes.</p><p>This separation of concerns allows the cron execution service to focus on job scheduling while the job queue handles resource-intensive tasks.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" title="" width="1109" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>The Job Queue</h3><p>Slack's cron execution service relies on a powerful asynchronous compute platform called the Job Queue to handle the resource-intensive task of running scripts.&nbsp;</p><p>The Job Queue is a critical component of Slack's infrastructure, processing a whopping 9 billion jobs per day.</p><p>The Job Queue consists of a series of so-called theoretical &#8220;queues&#8221; through which various types of jobs flow. Each script triggered by a cron job is treated as a single job within the Job Queue.</p><p>See the below diagram for reference:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9144169-fc4e-474b-b6e5-d900ae76ff66_1600x996.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="906" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9144169-fc4e-474b-b6e5-d900ae76ff66_1600x996.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The key components of the job queue architecture are as follows:</p><ul><li><p><strong>Kafka: </strong>Jobs are initially stored in Kafka since it provides durable storage. Kafka ensures that jobs are persisted and can be recovered in case of system failures or backups.</p></li><li><p><strong>Redis: </strong>From Kafka, jobs are moved into Redis (an in-memory data store) for short-term storage. Redis allows additional metadata, such as the identity of the worker executing the job, to be stored alongside the job itself. This metadata is important for tracking and managing job execution.</p></li><li><p><strong>Job Workers:</strong> Jobs are dispatched from Redis to job workers, which are nodes that execute the script. Each job worker is capable of running the scripts associated with the jobs it receives.</p></li></ul><p>Slack achieves several important benefits by using the Job Queue:</p><ul><li><p><strong>Offloading compute and memory concerns: </strong>The Job Queue is designed to handle a massive amount of work, with a capacity far exceeding the requirements of the cron execution service. Offloading the compute and memory demands of the running scripts helps keep the cron execution service lightweight.</p></li><li><p><strong>Isolation and performance: </strong>The Job Queue lets them keep the jobs isolated on their specific &#8220;queues&#8221; so that the jobs triggered by the cron execution service are processed smoothly. There is no impact on them due to other jobs in the system.</p></li><li><p><strong>Reliability and fault tolerance: </strong>The Job Queue&#8217;s architecture ensures that jobs are stored durably and recoverable in case of failures.</p></li><li><p><strong>Reduce development and maintenance efforts: </strong>This was probably the most important factor since leveraging an existing, battle-tested system like the Job Queue helped Slack reduce the development time required to build the cron execution service.</p></li></ul><h3>Vitess Database Table for Job Tracking</h3><p>To boost the reliability of their cron execution service, Slack also employed a Vitess table for deduplication and job tracking.</p><p>Vitess is a database clustering system for horizontal scaling of MySQL. It provides a scalable and highly available solution for managing large-scale data.</p><p>A couple of important requirements handled by Vitess are as described as follows:</p><h4>1 - Deduplication</h4><p>Within Slack&#8217;s original cron system, they used <strong>flocks</strong>, a Linux utility for managing locking in scripts so that only one copy of a script runs at a time.&nbsp;</p><p>While this approach worked fine, there were cases where a script&#8217;s execution time exceeded its recurrence intervals, leading to the possibility of two copies running concurrently.</p><p>To handle this issue, Slack introduced a Vitess table to handle deduplication.</p><p>Here&#8217;s how it works:</p><ul><li><p>When a new job is triggered, Slack records its execution as a new row in the Vitess table.</p></li><li><p>The job&#8217;s status is updated as it progresses through the system, with possible states including &#8220;enqueued&#8221;, &#8220;in progress&#8221;, and &#8220;done&#8221;.</p></li><li><p>Before kicking off a new run of a job, Slack queries the table to check if there are any active instances of the same job already running. This query is made efficient by using an index on the script names.</p></li></ul><p>The below diagram shows some sample data stored in Vitess.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbe4dc22-6be8-4a6d-b0b3-14029d47718b_1600x941.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="856" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdbe4dc22-6be8-4a6d-b0b3-14029d47718b_1600x941.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h4>2 - Job Tracking and Monitoring</h4><p>The Vitess table also helps with job tracking and monitoring since it contains information about the state of each job.</p><p>The job tracking functionality is exposed through a simple web page that displays the execution details. Developers can easily look up the state of their script runs and any errors encountered during execution.</p><h2>Conclusion</h2><p>One can debate whether using cron was the right decision for Slack when it came to job scheduling.</p><p>But it can also be said that organizations that choose the simplest solution for critical functionalities are more likely to grow into organizations of Slack&#8217;s size. On the other hand, companies that deploy solutions that try to solve all the problems when they have 0 customers never become that big. The difference is an unrelenting focus on solving the business problem rather than building fancy solutions from the beginning.</p><p>Slack&#8217;s journey from a single cron box to a sophisticated, distributed cron execution service shows how simple solutions can be used to build large-scale systems.</p><p><strong>References:</strong></p><ul><li><p><a href="https://slack.engineering/executing-cron-scripts-reliably-at-scale/">Executing Cron Scripts Reliably at Scale</a></p></li><li><p><a href="https://slack.engineering/scaling-slacks-job-queue/">Scaling Slack&#8217;s Job Queue</a></p></li><li><p><a href="https://slack.engineering/applying-product-thinking-to-slacks-internal-compute-platform/">Applying Product Thinking to Slack&#8217;s Internal Compute Platform</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><p></p>
]]></content:encoded>
<pubDate>Tue, 21 May 2024 15:31:08 GMT</pubDate>
</item>
<item>
<title>Cloudflare’s Trillion-Message Kafka Infrastructure: A Deep Dive</title>
<link>https://blog.bytebytego.com/p/cloudflares-trillion-message-kafka</link>
<guid>https://blog.bytebytego.com/p/cloudflares-trillion-message-kafka</guid>
<content:encoded><![CDATA[
<div> 云服务、Kafka、挑战、解决方案、扩展规模
<br />
总结:云服务公司Cloudflare通过Kafka处理了1万亿条消息。早期使用PHP的单块架构导致挑战，因此采用Kafka解决服务耦合和重试问题。后来使用Protocol Buffers标准化消息，提高传输效率。引入连接器框架简化数据同步流程。面临的扩展挑战包括可见性不足、过于频繁的告警以及无法跟上生产速率。通过改进健康检查，批量消费等技术，成功解决这些挑战。 <div>
<p><em>Disclaimer: The content (text and diagrams) in this post has been derived and compiled from the fantastic articles originally published on the Cloudflare Tech Blog by Matt Boyle, Andrea Medda, and Chris Shepherd. All credit for the details covered here goes to them. The links to the exact articles are in the references section at the end of the post. If you find any inaccuracies or omissions, please leave a comment, and we will do our best to fix them.</em></p><div><hr /></div><p>How much is 1 trillion?</p><p>If you were to start counting one number per second, it would take you over 31000 years to reach 1 trillion.</p><p>Now, imagine processing 1 trillion messages. This is the incredible milestone Cloudflare&#8217;s Kafka infrastructure achieved recently.</p><p>Cloudflare&#8217;s vision is to build a better Internet by providing a global network. They enable customers to secure and accelerate their websites, APIs, and applications.</p><p>However, as Cloudflare&#8217;s customer base grew rapidly, they needed to handle massive volumes of data and traffic while maintaining high availability and performance. Both scale and resilience were significant for their Kafka infrastructure.</p><p>Cloudflare has been using Kafka in production since 2014. They currently run 14 distinct Kafka clusters with roughly 330 nodes spread over multiple data centers.&nbsp;</p><p>In this article, we will explore the challenges solved and lessons learned by Cloudflare&#8217;s engineering team in their journey of scaling Kafka.</p><div><hr /></div><h2>The Early Days</h2><p>In the early days of Cloudflare, their architecture was built around a monolithic PHP application.&nbsp;</p><p>While this approach worked well initially, it created challenges as their product offerings grew. With numerous teams contributing to the same codebase, the monolithic architecture started to impact Cloudflare's ability to deliver features and updates safely and efficiently.</p><p>A couple of major issues were as follows:</p><ul><li><p>There was a tight coupling between services. Any change had a significant impact radius and required a lot of coordination between teams.&nbsp;</p></li><li><p>It was difficult to implement retry mechanisms to handle scenarios when something went wrong.</p></li></ul><p>To address these challenges, Cloudflare turned to Apache Kafka as a solution for decoupling services and enabling retry mechanisms.&nbsp;</p><p>See the diagram below that demonstrates this scenario.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9289fec1-bb42-4a98-9079-b5111f4df6cd_1600x927.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="844" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9289fec1-bb42-4a98-9079-b5111f4df6cd_1600x927.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>As you can notice, if multiple teams needed to emit messages that the audit log system was interested in, they could simply produce messages for the appropriate topics.&nbsp;</p><p>The audit log system could then consume from those topics without any direct coupling to the producing services. Adding a new service that needed to emit audit logs was as simple as producing for the right topics, without requiring any changes to the consuming side.</p><p>Kafka, a distributed streaming platform, had already proven its ability to handle massive volumes of data within Cloudflare's infrastructure.&nbsp;</p><p>As a first step, they created a message bus cluster on top of Kafka. It became the most general-purpose cluster available to all application teams at Cloudflare.&nbsp;</p><p>Onboarding to the cluster was made simple through a pull request process, which automatically set up topics with the desired replication strategy, retention period, and access control lists (ACLs).</p><p>The impact of the message bus cluster on loose coupling was evident.&nbsp;</p><ul><li><p>Teams could now emit messages to topics without being aware of the specific services consuming those messages.</p></li><li><p>Consuming services could listen to relevant topics without needing to know the details of the producing services.</p></li></ul><p>There was greater flexibility and independence among teams.&nbsp;</p><h2>Standardizing Communication</h2><p>As Cloudflare&#8217;s architecture evolved towards a decoupled and event-driven system, a new challenge emerged: unstructured communication between services.&nbsp;</p><p>There was no well-defined contract for message formats, leading to issues.</p><p>A common pitfall was the lack of agreement on message structure. For example, a producer might send a JSON blob with certain expected keys, but if the consumer wasn&#8217;t aware of this expectation, it could lead to unprocessable messages and tight coupling between services.</p><p>To address this challenge, Cloudflare turned to Protocol Buffers (Protobuf) as a solution for enforcing message contracts.</p><p>Protobuf, developed by Google, is a language-agnostic data serialization format that allows for defining strict message types and schemas.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff812fa60-0040-4dc0-b07e-2438cb6fe131_1600x946.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="861" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff812fa60-0040-4dc0-b07e-2438cb6fe131_1600x946.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption"><strong>Source: <a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Cloudflare Tech Blog</a></strong></figcaption></figure></div><p>It provided several benefits such as:</p><ul><li><p>Producers and consumers could have a shared understanding of message structures using a schema registry.</p></li><li><p>Since Protobuf supports versioning and schema evolution, it was possible to make changes to message formats without breaking existing consumers. This enabled both forward and backward compatibility.</p></li><li><p>Protobuf&#8217;s compact binary format results in smaller message sizes compared to JSON, improving efficiency.</p></li></ul><p>To streamline Kafka usage and enforce best practices, Cloudflare developed an internal message bus client library in Go. This library handled the complexities of configuring Kafka producers and consumers. All the best practices and opinionated defaults were baked into this library.</p><p>There was one controversial decision at this point.</p><p>The message bus client library enforced a one-to-one mapping between Protobuf message types and Kafka topics. This meant that each topic could only contain messages of a single Protobuf type. The idea was to avoid the confusion and complexity of handling multiple message formats within a single topic.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b9c584c-a7de-43af-9f7f-f9f9176786c0_1600x949.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="864" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b9c584c-a7de-43af-9f7f-f9f9176786c0_1600x949.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>There was a major trade-off to consider.&nbsp;</p><p>The strict one-to-one mapping between message types and topics resulted in a larger number of topics, partitions, and replicas while impacting resource utilization. On the other side, it also improved the developer experience, reduced coupling, and increased reliability.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="775" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F118d82e9-3c58-4214-b418-c6b270c6f968_1600x852.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Abstracting Common Patterns</h2><p>As Cloudflare&#8217;s adoption of Kafka grew and more teams started leveraging the message bus client library, a new pattern emerged.</p><p>Teams were using Kafka for similar styles of jobs. For example, many teams were building services that read data from one system of record and pushed it to another system, such as Kafka or Cloudflare edge database called Quicksilver. These services often involved similar configurations and boilerplate code.</p><p>There were a couple of problems such as:</p><ul><li><p>Duplicated efforts across teams.</p></li><li><p>Following best practices was harder.</p></li></ul><p>To address this, the application services team developed the connector framework.</p><p>Inspired by Kafka connectors, the framework allows engineers to quickly spin up services that can read from one system and push data to another with minimal configuration. The framework abstracts away the common patterns and makes it easy to build data synchronization pipelines.</p><p>The diagram below shows a high-level view of the connector approach.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4111e4-a323-41da-851a-3aa30be08adb_1600x945.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="860" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4111e4-a323-41da-851a-3aa30be08adb_1600x945.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Cloudflare Tech Blog</a></figcaption></figure></div><p>Using the connector framework is straightforward.</p><ul><li><p>The developers use a CLI tool to generate a ready-to-go service by providing just a few parameters.</p></li><li><p>The generated service includes all the necessary components, such as a reader, a writer, and optional transformations.</p></li><li><p>To configure the connector, you just need to tweak the environment variables, eliminating the need for code changes in most cases. For example, developers can specify the reader (let&#8217;s say, Kafka), the writer (let&#8217;s say Quicksilver), and any transformations using environment variables. The framework takes care of the rest.</p></li></ul><p>Here&#8217;s a more concrete example of how the connector framework is used in Cloudflare&#8217;s communication preferences service.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdaa21e79-97c5-46d3-9e11-57c6cc0880d1_1595x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1461" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdaa21e79-97c5-46d3-9e11-57c6cc0880d1_1595x1600.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Cloudflare Tech Blog</a></figcaption></figure></div><p>The communication preferences service allows customers to opt out of marketing information through the Cloudflare dashboard. When a customer updates their communication preferences, the service stores the change in its database and emits a message to Kafka.</p><p>To keep other systems in sync with the communication preferences, the team leverages the connector framework. They have set up three different connectors that read the communication preference changes from Kafka and synchronize them to three separate systems such as:</p><ul><li><p>Transactional email service</p></li><li><p>Customer management system</p></li><li><p>Marketing email system</p></li></ul><h2>Scaling Challenges and Solutions</h2><p>Cloudflare faced multiple scaling challenges with its Kafka adoption. Let&#8217;s look at a few of the major ones and how the team solved those challenges.</p><h3>1 - Visibility</h3><p>When Cloudflare experienced a surge in internet usage and customer growth during the pandemic, the audit logs system faced a lot of challenges in keeping up with the increased traffic.</p><p>Audit logs are a crucial feature for customers to track changes to their resources, such as the deletion of a website or modifications to security settings. As more customers relied on Cloudflare&#8217;s services, the audit logs systems struggled to process the growing volume of events on time.</p><p>As a first fix, the team invested in a pipeline that pushes audit log events directly into customer data buckets, such as R2 or S3.&nbsp;</p><p>See the diagram below:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32e096a0-91c8-42db-a652-520c04b2903c_1600x934.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="850" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F32e096a0-91c8-42db-a652-520c04b2903c_1600x934.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>However, when the pipeline was deployed to production, they encountered multiple issues.</p><ul><li><p>The system was accruing logs and failing to clear them fast enough.</p></li><li><p>Breaches in service level objectives (SLOs).</p></li><li><p>Unacceptable delays in delivering audit log data to customers.</p></li></ul><p>Initially, the team lacked the necessary tooling in their SDK to understand the root cause of the performance issues. They couldn&#8217;t determine whether the bottleneck was in reading from Kafka, performing transformations, or saving data to the database.</p><p>To gain visibility, they enhanced their SDK with Prometheus metrics, specifically using histograms to measure the duration of each step in the message processing flow. They also explored OpenTelemetry, a collection of SDKs and APIs that made it easy to collect metrics across services written in different programming languages.</p><p>With better visibility provided by Prometheus and OpenTelemetry, the team could identify the longest-running parts of the pipeline. Both reading from Kafka and pushing data to the bucket were slow.</p><p>By making targeted improvements, they were able to reduce the lag and ensure that audit logs were delivered to customers on time, even at high throughput rates of 250 to 500 messages per second.</p><h3>2 - Noisy On-call</h3><p>One thing leads to another.</p><p>Adding metrics to the Kafka SDK provided valuable insights into the health of the cluster and the services using it. However, it also led to a new challenge: a noisy on-call experience.</p><p>The teams started receiving frequent alerts related to unhealthy applications unable to reach the Kafka brokers. There were also alerts about lag issues and general Kafka cluster health problems.</p><p>The existing alerting pipeline was fairly basic. Prometheus collected the metrics and AlertManager continuously monitored them to page the team via PagerDuty.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe01a0ae3-a74c-40de-a1d4-5985cba79f5c_1600x934.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="850" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe01a0ae3-a74c-40de-a1d4-5985cba79f5c_1600x934.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>Most problems faced by services concerning Kafka were due to deteriorating network conditions. The common solution was to restart the service manually. However, this often required on-call engineers to wake up during the night to perform manual restarts or scale services up and down, which was far from ideal.</p><p>To address this challenge, the team decided to leverage Kubernetes and their existing knowledge to improve the situation. They introduced health checks.</p><p>Health checks allow applications to report their readiness to operate, enabling the orchestrator to take appropriate actions when issues arise.</p><p>In Kubernetes, there are three types of health checks:</p><ol><li><p><strong>Liveness Probe: </strong>They indicate whether a service is <em>ready to run</em>.</p></li><li><p><strong>Readiness Probe: </strong>They determine if a service is <em>prepared</em> to receive HTTP traffic.</p></li><li><p><strong>Startup Probes: </strong>They act as an extended liveness check for slow-starting services.</p></li></ol><p>Kubernetes periodically pings the service at a specific endpoint (example: /health), and the service must respond with a successful status code to be considered healthy.</p><p>For Kafka consumers, implementing a readiness probe doesn&#8217;t make much sense, as they typically don&#8217;t expose an HTTP server. Therefore, the team focused on implementing simple liveness checks that worked as follows:</p><ul><li><p>Perform a basic operation with the Kafka broker, such as listing topics.&nbsp;</p></li><li><p>If the operation fails, the health check fails, indicating an issue with the service&#8217;s ability to communicate with the broker.</p></li></ul><p>The diagram below shows the approach:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd1b41db-69ec-4047-8539-e51eb855a57b_1600x1194.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1087" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd1b41db-69ec-4047-8539-e51eb855a57b_1600x1194.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://blog.cloudflare.com/intelligent-automatic-restarts-for-unhealthy-kafka-consumers">Cloudflare Tech Blog</a></figcaption></figure></div><p>There were still cases where the application appeared healthy but was stuck and unable to produce or consume messages. To handle this, the team implemented smarter health checks for Kafka consumers.</p><p>The smart health checks rely on two key concepts:</p><ul><li><p>The current offset represents the last available offset on a partition.</p></li><li><p>The committed offset is the last offset committed by a specific consumer for that partition.</p></li></ul><p>Here&#8217;s what happens during the health check:</p><ul><li><p>The consumer retrieves both offsets.&nbsp;</p></li><li><p>If it fails to retrieve them, the consumer is considered unhealthy.&nbsp;</p></li><li><p>If the offsets are successfully retrieved, the consumer compares the last committed offset with the current offset.&nbsp;</p></li><li><p>If they are the same, no new messages have been appended to the partition, and the consumer is considered healthy.</p></li><li><p>If the last committed offset hasn&#8217;t changed since the previous check, the consumer is likely stuck and needs to be restarted.</p></li></ul><p>Implementing these smart health checks led to improvements in the on-call experience as well as overall customer satisfaction.</p><h3>3 - Inability to Keep Up</h3><p>Another challenge that sprang up as Cloudflare&#8217;s customer base grew was with the email system.&nbsp;</p><p>The email system is responsible for sending transactional emails to customers, such as account verification emails, password reset emails, and billing notifications. These emails were critical for customer engagement and satisfaction, and any delays or failures in delivering them can hurt the user experience.</p><p>During traffic spikes, the email system struggled to process the high volume of messages being produced to Kafka.&nbsp;</p><p>The system was designed to consume messages one at a time, process them, and send the corresponding emails. However, as the production rate increased, the email system fell behind, creating a growing backlog of messages and increased lag.</p><p>One thing was clear to the engineering team at Cloudflare. The existing architecture wasn&#8217;t scalable enough to handle the increasing production rates.</p><p>Therefore, they introduced batch consumption to optimize the email system&#8217;s throughput.</p><p>Batch consumption is a technique where instead of processing messages one at a time, the consumer retrieves a batch of messages from Kafka and processes them together. This approach has several advantages, particularly in scenarios with high production rates.</p><p>The diagram below shows the batching approach.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e3e82df-4d72-438c-8be7-1526950b2413_1600x830.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="755" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e3e82df-4d72-438c-8be7-1526950b2413_1600x830.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Source: <a href="https://youtu.be/_booBjCB7rU?si=TONQvvYstgGmmke0">Tales of Kafka Presentation</a></figcaption></figure></div><p>The changes made were as follows:</p><ul><li><p>The Kafka consumer was modified to retrieve a configurable number of messages in each poll.</p></li><li><p>They updated the email-sending logic to process the batch of messages. Techniques like bulk database inserts and parallel email dispatching were used.</p></li></ul><p>Batch consuming with emails was soon put to the test during a major product launch that generated a surge in sign-ups and account activations.&nbsp;</p><p>This resulted in a massive increase in the number of account verification emails that had to be sent. However, the email system was able to handle the increased load efficiently.</p><h2>Conclusion</h2><p>Cloudflare&#8217;s journey of scaling Kafka to handle 1 trillion messages is remarkable.&nbsp;</p><p>From the early days of their monolithic architecture to the development of sophisticated abstractions and tools, we&#8217;ve seen how Cloudflare tackled multiple challenges across coupling, unstructured communication, and common usage patterns.</p><p>Along the way, we&#8217;ve also learned valuable lessons that can be applied to any organization. Here are a few of them:</p><ul><li><p>It&#8217;s important to strike a balance between configuration and simplicity. While flexibility is necessary for diverse use cases, it&#8217;s equally important to standardize and enforce best practices.</p></li><li><p>Visibility is the key in distributed systems. If you can&#8217;t see what&#8217;s happening in a certain part of your application, it becomes hard to remove bottlenecks.</p></li><li><p>Clear and well-defined contracts between producers and consumers are essential for building loosely coupled systems that can evolve independently.</p></li><li><p>Sharing knowledge and best practices across the organization helps streamline the adoption process and creates opportunities for improvement.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://blog.cloudflare.com/using-apache-kafka-to-process-1-trillion-messages">Using Apache Kafka to process 1 trillion messages</a></p></li><li><p><a href="https://www.infoq.com/articles/kafka-clusters-cloudflare/">Tales of Kafka at Cloudflare</a></p></li><li><p><a href="https://blog.cloudflare.com/intelligent-automatic-restarts-for-unhealthy-kafka-consumers">Intelligent automatic restarts for unhealthy Kafka consumers</a></p></li><li><p><a href="https://youtu.be/_booBjCB7rU?si=M4UYkZ7ltxSC2GJW">Lessons learned on the way to 1 trillion messages</a></p></li><li><p><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">Configure Liveness, Readiness, and Startup Probes</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Mon, 20 May 2024 15:31:15 GMT</pubDate>
</item>
<item>
<title>EP112: What is a deadlock?</title>
<link>https://blog.bytebytego.com/p/ep112-what-is-a-deadlock</link>
<guid>https://blog.bytebytego.com/p/ep112-what-is-a-deadlock</guid>
<content:encoded><![CDATA[
<div> API Protocols, Deadlock, Authentication, ElasticSearch, CPU Usage
<br /><br />总结: 本周文章介绍了最流行的API协议、死锁、基于会话和JWT的身份验证区别、ElasticSearch的应用以及CPU使用率100%的常见情况。其中详细解释了死锁的概念、预防和恢复方法，以及基于会话和JWT的身份验证方式的比较。此外，还介绍了ElasticSearch在文本搜索、实时分析、机器学习、地理数据应用、日志和事件数据分析、安全信息与事件管理等方面的典型用例，以及导致CPU使用率达到100%的常见原因。整体来看，这篇文章涵盖了系统设计中的重要概念和技术，对读者了解和运用这些知识具有一定的参考价值。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Top 9 Most Popular API Protocols (Youtube video)</p></li><li><p>What is a deadlock? </p></li><li><p>What&#8217;s the difference between Session-based authentication and JWTs? </p></li><li><p>Top 6 ElasticSearch Use Cases</p></li><li><p>Top 9 Cases Behind 100% CPU Usage</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/LinearB_051824">[Complimentary Download] Gartner Market Guide: Software Engineering Intelligence (SEI) Platforms (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/LinearB_051824" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="371.0192307692308" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F47201120-d762-43fb-b2de-5ac248a959c1_1600x838.png" width="708" /><div></div></div></a></figure></div><p>Engineering teams are rapidly adopting Software Engineering Intelligence (SEI) Platforms to improve productivity and value delivery. According to Gartner&#8217;s recent Market Guide, use of SEI platforms by engineering organizations will rise to 50% by 2027, compared to 5% in 2024. LinearB was recognized by Gartner as a representative vendor, so we&#8217;re offering ByteByteGo readers a complimentary copy.&nbsp;</p><p>Learn how you can unlock the transformative potential of SEI platforms by leveraging key features like: </p><ul><li><p>Extensive data from DevOps tools for critical metrics and insights.</p></li><li><p>Customizable dashboards that highlight pivotal trends and inform strategic decisions.</p></li><li><p>Insights into KPIs that showcase your team's achievements.</p><p></p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/LinearB_051824"><span>Download your guide now</span></a></p></li></ul><div><hr /></div><h2>Top 9 Most Popular API Protocols</h2><div class="youtube-wrap" id="youtube2-zY2DMpCUfCg"><div class="youtube-inner"></div></div><div><hr /></div><h2>What is a deadlock? </h2><p>A deadlock occurs when two or more transactions are waiting for each other to release locks on resources they need to continue processing. This results in a situation where neither transaction can proceed, and they end up waiting indefinitely. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3702d55e-77eb-4dc6-9a57-2d3272fa5c4f_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><ul><li><p>Coffman Conditions <br />The Coffman conditions, named after Edward G. Coffman, Jr., who first outlined them in 1971, describe four necessary conditions that must be present simultaneously for a deadlock to occur: <br /> <br />- Mutual Exclusion <br />- Hold and Wait <br />- No Preemption <br />- Circular Wait <br /></p></li><li><p>Deadlock Prevention <br />- Resource ordering: impose a total ordering of all resource types, and require that each process requests resources in a strictly increasing order. <br /> <br />- Timeouts: A process that holds resources for too long can be rolled back. <br /> <br />- Banker&#8217;s Algorithm: A deadlock avoidance algorithm that simulates the allocation of resources to processes and helps in deciding whether it is safe to grant a resource request based on the future availability of resources, thus avoiding unsafe states. <br /></p></li><li><p>Deadlock Recovery <br />- Selecting a victim: Most modern Database Management Systems (DBMS) and Operating Systems implement sophisticated algorithms for detecting deadlocks and selecting victims, often allowing customization of the victim selection criteria via configuration settings. The selection can be based on resource utilization, transaction priority, cost of rollback etc. <br /> <br />- Rollback: The database may roll back the entire transaction or just enough of it to break the deadlock. Rolled-back transactions can be restarted automatically by the database management system. </p></li></ul><p>Over to you: have you solved any tricky deadlock issues?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" title="" width="1109" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">A Crash Course in GraphQL</a></p></li><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>What&#8217;s the difference between Session-based authentication and JWTs? </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1560" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02c27d00-914e-4626-b507-51627646af11_1280x1560.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><p>Here&#8217;s a simple breakdown for both approaches: <br /> <br /><strong>Session-Based Authentication</strong> <br /> <br />In this approach, you store the session information in a database or session store and hand over a session ID to the user. <br /> <br />Think of it like a passenger getting just the Ticket ID of their flight while all other details are stored in the airline&#8217;s database. <br /> <br />Here&#8217;s how it works: </p><ol><li><p>The user makes a login request and the frontend app sends the request to the backend server. </p></li><li><p>The backend creates a session using a secret key and stores the data in session storage.</p></li><li><p>The server sends a cookie back to the client with the unique session ID. </p></li><li><p>The user makes a new request and the browser sends the session ID along with the request. </p></li><li><p>The server authenticates the user using the session ID. </p></li></ol><p><strong>JWT-Based Authentication</strong> <br /> <br />In the JWT-based approach, you don&#8217;t store the session information in the session store. <br /> <br />The entire information is available within the token. <br /> <br />Think of it like getting the flight ticket along with all the details available on the ticket but encoded. <br /> <br />Here&#8217;s how it works: </p><ol><li><p>The user makes a login request and it goes to the backend server. </p></li><li><p>The server verifies the credentials and issues a JWT. The JWT is signed using a private key and no session storage is involved. </p></li><li><p>The JWT is passed to the client, either as a cookie or in the response body. Both approaches have their pros and cons but we&#8217;ve gone with the cookie approach. </p></li><li><p>For every subsequent request, the browser sends the cookie with the JWT. </p></li><li><p>The server verifies the JWT using the secret private key and extracts the user info.</p></li></ol><div><hr /></div><h2>Top 6 ElasticSearch Use Cases</h2><p>Elasticsearch is widely used for its powerful and versatile search capabilities. The diagram below shows the top 6 use cases: </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c1dd39f-3e32-4fd7-9360-7e460357e008_1280x1664.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><ul><li><p>Full-Text Search <br />Elasticsearch excels in full-text search scenarios due to its robust, scalable, and fast search capabilities. It allows users to perform complex queries with near real-time responses. <br /></p></li><li><p>Real-Time Analytics <br />Elasticsearch's ability to perform analytics in real-time makes it suitable for dashboards that track live data, such as user activity, transactions, or sensor outputs. <br /></p></li><li><p>Machine Learning <br />With the addition of the machine learning feature in X-Pack, Elasticsearch can automatically detect anomalies, patterns, and trends in the data. <br /></p></li><li><p>Geo-Data Applications <br />Elasticsearch supports geo-data through geospatial indexing and searching capabilities. This is useful for applications that need to manage and visualize geographical information, such as mapping and location-based services. <br /></p></li><li><p>Log and Event Data Analysis <br />Organizations use Elasticsearch to aggregate, monitor, and analyze logs and event data from various sources. It's a key component of the ELK stack (Elasticsearch, Logstash, Kibana), which is popular for managing system and application logs to identify issues and monitor system health. </p><p></p></li><li><p>Security Information and Event Management (SIEM) <br />Elasticsearch can be used as a tool for SIEM, helping organizations to analyze security events in real time. <br /></p></li></ul><p>Over to you: What did we miss?</p><div><hr /></div><h2>Top 9 Cases Behind 100% CPU Usage</h2><p>The diagram below shows common culprits that can lead to 100% CPU usage. Understanding these can help in diagnosing problems and improving system efficiency. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c1af2cb-4c71-424e-a0ef-f1c618a78666_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><ol><li><p>Infinite Loops </p></li><li><p>Background Processes </p></li><li><p>High Traffic Volume </p></li><li><p>Resource-Intensive Applications </p></li><li><p>Insufficient Memory </p></li><li><p>Concurrent Processes </p></li><li><p>Busy Waiting </p></li><li><p>Regular Expression Matching </p></li><li><p>Malware and Viruses </p></li></ol><p>Over to you: Did we miss anything important?</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Sat, 18 May 2024 15:30:55 GMT</pubDate>
</item>
<item>
<title>A Crash Course in GraphQL</title>
<link>https://blog.bytebytego.com/p/a-crash-course-in-graphql</link>
<guid>https://blog.bytebytego.com/p/a-crash-course-in-graphql</guid>
<content:encoded><![CDATA[
<div> GraphQL, API, maintenance costs, interface, connectivity 
<br />
GraphQL 是一项可改变客户端和服务器交互方式的工具。它可以作为在完全重构应用和什么也不做之间找到的一个折中点。虽然不是解决所有问题的灵丹妙药，但可以通过减少维护成本、简化开发流程来帮助解决应用程序接口日益复杂的问题。相比于REST API和BFFs，GraphQL具有各自的优缺点。在2023年，API协议的格局正在逐渐演变，适应这个变化的一个解决方案就是GraphQL。 <br /><br />总结:GraphQL作为一种新的API工具，可以帮助解决日益增长的维护成本和接口连接问题，是在API协议演变中的一种解决方案，以其灵活性和优势为用户提供了更好的开发体验。 <div>
<p></p><p>The complexity of software applications has grown by leaps and bounds over the years.</p><p>This has led to a rise in the number of interfaces between various systems, resulting in an ever-growing API footprint.</p><p>While APIs have revolutionized the connectivity between systems, the explosion of integrations between clients and servers often leads to maintenance problems. Even minor backend changes take more implementation time since developers must analyze and test more. Despite all the effort, there are still high chances that issues creep into the application.</p><p>Refactoring the application interfaces is one way to address growing maintenance costs. However, this is costly, and there&#8217;s no guarantee that we won&#8217;t encounter similar issues as the system evolves.</p><p>What&#8217;s the solution to this problem?</p><p>GraphQL is a tool that brings a major change in how clients and servers interact. While it&#8217;s not a silver bullet, it can be a sweet spot between a complete application overhaul and doing absolutely nothing</p><p>In this issue, we&#8217;ll explore GraphQL's features and concepts, compare it to REST API and BFFs, and discuss its advantages and disadvantages.</p><div><hr /></div><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1018.5752930568079" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4e965c2-b545-4f79-a489-e0e72d473c06_1109x1600.png" title="" width="706" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">The Evolving Landscape of API Protocols in 2023</figcaption></figure></div><h2>What is GraphQL?</h2>
      <p>
          <a href="https://blog.bytebytego.com/p/a-crash-course-in-graphql">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 16 May 2024 15:30:42 GMT</pubDate>
</item>
<item>
<title>How Facebook served billions of requests per second Using Memcached</title>
<link>https://blog.bytebytego.com/p/how-facebook-served-billions-of-requests</link>
<guid>https://blog.bytebytego.com/p/how-facebook-served-billions-of-requests</guid>
<content:encoded><![CDATA[
<div> Facebook, Memcached, scalability, challenges, optimizations
<br /><br />总结:
Facebook通过优化和实现Memcached，解决了处理海量数据和为数十亿用户提供服务的挑战。他们在架构决策和服务器优化方面取得了重要进展。重要的学习点是：接受最终一致性，设计系统以应对故障，以及可以在多个级别进行优化。 <div>
<h2><a href="https://bit.ly/WorkOS_051424">Creating stronger passwords with AuthKit (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/WorkOS_051424" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="764" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38010da7-970d-40ed-96fa-e17bc7a96a77_1600x840.png" width="1456" /><div></div></div></a></figure></div><p>A common cause of data breaches and account hijacking is customers using weak or common passwords.<br /><br />One way to mitigate this risk is to inform new users about the strength of their passwords as they create them.<br /><br />To solve this problem, Dropbox created zxcvbn, an open-source library that calculates password strength based on factors like entropy, dictionary checks, and pattern recognition.<br /><br />If you want an easy way to implement user password security in your app, check out AuthKit, an open-source login box that incorporates zxcvbn and other best practices to provide a much more secure onboarding experience for new users.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/WorkOS_051424"><span>Read the guide</span></a></p><div><hr /></div><p>There are two absolute truths about running a social network at the scale of Facebook:</p><ul><li><p>First, it cannot go down.</p></li><li><p>Second, it cannot run slow.</p></li></ul><p>These two factors determine whether people are going to stay on your social network or not.&nbsp;</p><p>Even a few people leaving impacts the entire user base because the users are interconnected. Most people are online because their friends or relatives are online and there&#8217;s a domino effect at play. If one user drops off due to issues, there are chances that other users will also leave.</p><p>Facebook had to deal with these issues early on because of its popularity. At any point in time, millions of people were accessing Facebook from all over the world.</p><p>In terms of software design, this meant a few important requirements:</p><ul><li><p>Facebook had to support real-time communication.</p></li><li><p>They had to build capabilities for on-the-fly content aggregation.</p></li><li><p>Scale to handle billions of user requests.</p></li><li><p>Store trillions of items across multiple geographic locations.</p></li></ul><p>To achieve these goals, Facebook took up the open-source version of Memcached and enhanced it to build a distributed key-value store.</p><p>This enhanced version was known as Memcache.</p><p>In this post, we will look at how Facebook solved the multiple challenges in scaling memcached to serve billions of requests per second.</p><div><hr /></div><h2>Introduction to Memcached</h2><p>Memcached is an in-memory key-value store that supports a simple set of operations such as set, get, and delete.</p><p>The open-source version provided a single-machine in-memory hash table. The engineers at Facebook took up this version as a basic building block to create a distributed key-value store known as Memcache.</p><p>In other words, &#8220;Memcached&#8221; is the source code or the running binary whereas &#8220;Memcache&#8221; stands for the distributed system behind it.</p><p>Technically, Facebook used Memcache in two main ways:</p><h3>Query Cache</h3><p>The job of the query cache was to reduce the load on the primary source-of-truth databases.</p><p>In this mode, Facebook used Memcache as a demand-filled look-aside cache. You may have also heard about it as the cache-aside pattern.</p><p>The below diagram shows how the look-aside cache pattern works for the read and write path.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10c6a41b-307f-45f2-b2e0-ff6da2454400_1600x959.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="873" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10c6a41b-307f-45f2-b2e0-ff6da2454400_1600x959.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>The read path utilizes a cache that is filled on-demand. This means that data is only loaded into the cache when a client specifically requests it.&nbsp;</p><p>Before serving the request, the client first checks the cache. If the desired data is not found in the cache (a cache miss), the client retrieves the data from the database and also updates the cache.</p><p>The write path takes a more interesting approach to updating data.&nbsp;</p><p>After a particular key is updated in the database, the system doesn&#8217;t directly update the corresponding value in the cache. Instead, it removes the data for that key from the cache entirely. This process is known as cache invalidation.</p><p>By invalidating the cache entry, the system ensures that the next time a client requests data for that key, it will experience a cache miss and be forced to retrieve the most up-to-date value directly from the database. This approach helps maintain data consistency between the cache and the database.</p><h3>Generic Cache</h3><p>Facebook also leverages Memcache as a general-purpose key-value store. This allows different teams within the organization to utilize Memcache for storing pre-computed results generated from computationally expensive machine learning algorithms.</p><p>By storing these pre-computed ML results in Memcache, other applications can quickly and easily access them whenever needed.</p><p>This approach offers several benefits such as improved performance and resource optimization.</p><h2>High-Level Architecture of Facebook</h2><p>Facebook&#8217;s architecture is built to handle the massive scale and global reach of its platform.&nbsp;</p><p>At the time of their Memcached adoption, Facebook&#8217;s high-level architecture consisted of three key components:</p><h3>1 - Regions</h3><p>Facebook strategically places its servers in various locations worldwide, known as regions. These regions are classified into two types:</p><ul><li><p><strong>Primary Region: </strong>The primary region is responsible for handling the majority of user traffic and data management.</p></li><li><p><strong>Secondary Region: </strong>Multiple secondary regions are distributed globally to provide redundancy, load balancing, and improved performance for users in different geographical areas.</p></li></ul><p>Each region, whether primary or secondary, contains multiple frontend clusters and a single storage cluster.</p><h3>2 - Frontend Clusters</h3><p>Within each region, Facebook employs frontend clusters to handle user requests and serve content. A frontend cluster consists of two main components:</p><ul><li><p><strong>Web Servers: </strong>These servers are responsible for processing user requests, rendering pages, and delivering content to the users.</p></li><li><p><strong>Memcache Servers: </strong>Memcache servers act as a distributed caching layer, storing frequently accessed data in memory for quick retrieval.</p></li></ul><p>The frontend clusters are designed to scale horizontally based on demand. As user traffic increases, additional web and Memcache servers can be added to the cluster to handle the increased load.</p><h3>3 - Storage Cluster</h3><p>At the core of each region lies the storage cluster. This cluster contains the source-of-truth database, which stores the authoritative copy of every data item within Facebook&#8217;s system.</p><p>The storage cluster takes care of data consistency, durability, and reliability.</p><p>By replicating data across multiple regions and employing a primary-secondary architecture, Facebook achieves high availability and fault tolerance.</p><p>The below diagram shows the high-level view of this architecture:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f8ebeb-fc61-4427-bb0b-dbc7aa8ef619_1600x923.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="840" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f8ebeb-fc61-4427-bb0b-dbc7aa8ef619_1600x923.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>One major philosophy that Facebook adopted was a willingness to expose slightly stale data instead of allowing excessive load on the backend.&nbsp;</p><p>Rather than striving for perfect data consistency at all times, Facebook accepted that users may sometimes see outdated information in their feeds. This approach allowed them to handle high traffic loads without crumbling under excessive strain on the backend infrastructure.</p><p>To make this architecture work at an unprecedented scale of billions of requests every day, Facebook had to solve multiple challenges such as:</p><ul><li><p>Managing latency and failures within a cluster.</p></li><li><p>Managing data replication within a region.</p></li><li><p>Managing data consistency across regions.</p></li></ul><p>In the next few sections, we will look at how Facebook handled each of these challenges.</p><h2>Within Cluster Challenges</h2><p>There were three important goals for the within-cluster operations:</p><ul><li><p>Reducing latency</p></li><li><p>Reducing the load on the database</p></li><li><p>Handling failures</p></li></ul><h3>1 - Reducing Latency</h3><p>As mentioned earlier, every frontend cluster contains hundreds of Memcached servers, and items are distributed across these servers using techniques like Consistent Hashing.</p><p>For reference, Consistent Hashing is a technique that allows the distribution of a set of keys across multiple nodes in a way that minimizes the impact of node failures or additions. When a node goes down or a new node is introduced, Consistent Hashing ensures that only a small subset of keys needs to be redistributed, rather than requiring a complete reshuffling of data.</p><p>The diagram illustrates the concept of Consistent Hashing where keys are mapped to a circular hash space, and nodes are assigned positions on the circle. Each key is assigned to the node that falls closest to it in a clockwise direction.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac03e7f-77db-4b52-9c30-bd2718bd8bfe_1600x1461.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1330" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac03e7f-77db-4b52-9c30-bd2718bd8bfe_1600x1461.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At Facebook's scale, a single web request can trigger hundreds of fetch requests to retrieve data from Memcached servers. Consider a scenario where a user loads a popular page containing numerous posts and comments.&nbsp;</p><p>Even a single request can require the web servers to communicate with multiple Memcached servers in a short timeframe to populate the necessary data.</p><p>This high-volume data fetching occurs not only in cache hit situations but also when there&#8217;s a cache miss. The implication is that a single Memcached server can turn into a bottleneck for many web servers, leading to increased latency and degraded performance for the end user.</p><p>To reduce the possibility of such a scenario, Facebook uses a couple of important tricks visualized in the diagram.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa67ef54c-971d-43fa-bba6-6ed418fdefcc_1600x1123.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1022" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa67ef54c-971d-43fa-bba6-6ed418fdefcc_1600x1123.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h4>Parallel Requests and Batching</h4><p>To understand the concept of parallel requests and batching, consider a simple analogy.&nbsp;</p><p>Imagine going to the supermarket every time you need an item. It would be incredibly time-consuming and inefficient to make multiple trips for individual items. Instead, it&#8217;s much more effective to plan your shopping trip and purchase a bunch of items together in a single visit.</p><p>The same optimization principle applies to data retrieval in Facebook's frontend clusters.&nbsp;</p><p>To maximize the efficiency of data retrieval, Facebook constructs a Directed Acyclic Graph (DAG) that represents the dependencies between different data items.</p><p>The DAG provides a clear understanding of which data items can be fetched concurrently and which items depend on others.</p><p>By analyzing the DAG, the web server can determine the optimal order and grouping of data fetches. It identifies data items that can be retrieved in parallel, without any dependencies, and groups them in a single batch request.</p><h4>Using UDP&nbsp;</h4><p>Facebook employed a clever strategy to optimize network communication between the web servers and the Memcache server.</p><p>For fetch requests, Facebook configured the clients to use UDP instead of TCP.&nbsp;</p><p>As you may know, UDP is a connectionless protocol and much faster than TCP. By using UDP, the clients can send fetch requests to the Memcache servers with less network overhead, resulting in faster request processing and reduced latency.</p><p>However, UDP has a drawback: it doesn&#8217;t guarantee the delivery of packets. If a packet is lost during transmission, UDP doesn&#8217;t have a built-in mechanism to retransmit it.&nbsp;</p><p>To handle such cases, they treated UDP packet loss as a cache miss on the client side. If a response isn&#8217;t received within a specific timeframe, the client assumes that the data is not available in the cache and proceeds to fetch it from the primary data source.</p><p>For update and delete operations, Facebook still used TCP since it provided a reliable communication channel that ensured the delivery of packets in the correct order. It removed the need for adding a specific retry mechanism, which is important when dealing with update and delete operations.</p><p>All these requests go through a special proxy known as <strong>mcrouter</strong> that runs on the same machine as the webserver. Think of the <strong>mcrouter</strong> as a middleman that performs multiple duties such as data serialization, compression, routing, batching, and error handling. We will look at <strong>mcrouter</strong> in a later section.</p><h3>2 - Reducing Load</h3><p>The most important goal for Memcache is to reduce the load on the database by reducing the frequency of data fetching from the database.&nbsp;</p><p>Using Memcache as a look-aside cache solves this problem significantly. But at Facebook&#8217;s scale, two caching-related issues can easily appear.</p><ul><li><p><strong>Stale Set: </strong>This happens when the cache is set with outdated data and there&#8217;s no easy way of invalidating it.</p></li><li><p><strong>Thundering Herd: </strong>This problem occurs in a highly concurrent environment when a cache miss triggers a thundering herd of requests to the database.</p></li></ul><p>The below diagram visualizes both of these issues.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3bd7af6-8955-4c31-a20f-40216163cab3_1396x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3bd7af6-8955-4c31-a20f-40216163cab3_1396x1600.png" title="" width="1396" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To minimize the probability of these two critical issues, Facebook used a technique known as leasing.</p><p>Leasing helped solve both stale sets and thundering herds, helping Facebook reduce peak DB query rates from 17K/second to 1.3K/second.</p><h4>Stale Sets</h4><p>Consider that a client requests memcache for a particular key and it results in a cache miss.</p><p>Now, it&#8217;s the client&#8217;s responsibility to fetch the data from the database and also update memcache so that future requests for the same key don&#8217;t result in a cache miss.</p><p>This works fine most of the time but in a highly concurrent environment, the data being set by the client may get outdated by the time it gets updated in the cache.</p><p>Leasing prevents this from happening.&nbsp;</p><p>With leasing, Memcache hands over a lease (a 64-bit token bound to a specific key) to a particular client to set data into the cache whenever there&#8217;s a cache miss.&nbsp;</p><p>The client has to provide this token when setting the value in the cache and memcache can verify whether the data should be stored by verifying the token. If the item was already invalidated by the time the client tried to update, Memcache will invalidate the lease token and reject the request.</p><p>The below diagram shows the concept of leasing in a much better manner.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fea2405-ad1a-4c6f-b378-268362482977_1573x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1481" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fea2405-ad1a-4c6f-b378-268362482977_1573x1600.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h4>Thundering Herds</h4><p>A slight modification to the leasing technique also helps solve the thundering herd issue.</p><p>In this modification, Memcache regulates the rate of issuing the lease tokens. For example, it may return a token once every 5 seconds per key.</p><p>For any requests for the key within 5 seconds of the lease token being issued, Memcache sends a special response requesting the client to wait and retry so that these requests don&#8217;t hit the database needlessly. This is because there&#8217;s a high probability that the client holding the lease token will soon update the cache and the waiting clients will get a cache hit when they retry.</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="927" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3e5a5e3-b6f2-4f89-98f5-8c5f59c5d795_1600x1019.png" title="" width="1456" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h3>3 - Handling Failures</h3><p>In a massive-scale system like Facebook, failures are an inevitable reality.</p><p>With millions of users using the platform, any disruption in data retrieval from Memcache can have severe consequences. If clients are unable to fetch data from Memcache, it places an excessive load on the backend servers, potentially leading to cascading failures in downstream services.</p><h3>Two Levels of Failure</h3><p>Facebook faced two primary levels of failures when it comes to Memcache:</p><ul><li><p><strong>Small-Scale Outages:</strong> A small number of hosts may become inaccessible due to network issues or other localized problems. While these outages are limited in scope, they can still impact the overall system performance.</p></li><li><p><strong>Widespread Outages: In more severe cases, an entire cluster may go down, affecting a significant percentage of the Memcache hosts. Such widespread outages create a greater threat to the stability and availability of the system.</strong></p></li></ul><h4>Handling Widespread Outages</h4><p>To mitigate the impact of a cluster going down, Facebook diverts web requests to other functional clusters.</p><p>By redistributing the load, Facebook ensures that the problematic cluster is relieved of its responsibilities until it can be restored to health.</p><h4>Automated Remediation for Small Outages</h4><p>For small-scale outages, Facebook relies on an automated remediation system that automatically detects and responds to host-level issues by bringing up new instances to replace the affected ones.</p><p>However, the remediation process is not instantaneous and can take some time to complete. During this time window, the backend services may experience a surge in requests as clients attempt to fetch data from the unavailable Memcache hosts.&nbsp;</p><p>The common way of handling this is to rehash keys and distribute them among the remaining servers.&nbsp;</p><p>However, Facebook&#8217;s engineering team realized that this approach was still prone to cascading failures. In their system, many keys can account for a significant portion of the requests (almost 20%) to a single server. Moving these high-traffic keys to another server during a failure scenario could result in overload and further instability.&nbsp;</p><p>To mitigate this risk, Facebook went with the approach of using Gutter machines. Within each cluster, they allocate a pool of machines (typically 1% of the Memcache servers) specifically designated as Gutter machines. These machines are designed to take over the responsibilities of the affected Memcache servers during an outage.</p><p>Here&#8217;s how they work:</p><ul><li><p>If a Memcache client receives no response (not even a cache miss), the client assumes that the server has failed and issues a request to the Gutter pool.</p></li><li><p>If the request to the Gutter pool returns a cache miss, the client queries the database and inserts the data into the Gutter pool so that subsequent requests can be served from Memcache.</p></li><li><p>Gutter entries expire quickly to remove the need for invalidations.</p></li></ul><p>The below diagram shows how the Gutter pool works:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1671dbf-d312-46f4-8de9-42c1062cdc5d_1600x916.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="834" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1671dbf-d312-46f4-8de9-42c1062cdc5d_1600x916.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Though there are chances of serving stale data, the backend is protected. Remember that this was an acceptable trade-off for them when compared to availability.</p><h2>Region Level Challenges</h2><p>At the region level, there were multiple frontend clusters to deal with and the main challenge was handling Memcache invalidations across all of them.</p><p>Depending on the load balancer, users can connect to different front-end clusters when requesting data. This results in caching a particular piece of data in multiple clusters.</p><p>In other words, you can have a scenario where a particular key is cached in the Memcached servers of multiple clusters within the region. The below diagram shows this scenario:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc775036-767c-4d47-b834-8ee6b8010f65_1600x926.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="843" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc775036-767c-4d47-b834-8ee6b8010f65_1600x926.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As an example, the keys &#8220;abc&#8221; and &#8220;xyz&#8221; are present in multiple frontend clusters within a region and need to be invalidated in case of an update to their values.</p><h3>Cluster Level Invalidation</h3><p>Invalidating this data at the cluster level is reasonably simpler. Any web server that modifies the data is responsible for invalidating the data in that cluster. This provides read-after-write consistency for the user who made the request. It also reduces the lifetime of the stale data within the cluster.</p><p>For reference, read-after-write consistency is a guarantee that if a user makes some updates, he/she should always see those updates when they reload the page.</p><h3>Region Level Invalidation</h3><p>For region-level invalidation, the invalidation process is a little more complex and the webserver doesn&#8217;t handle it.</p><p>Instead, Facebook created an invalidation pipeline that works like this:</p><ul><li><p>An invalidation daemon known as <strong>mcsqueal</strong> runs on every database server within the storage cluster.</p></li><li><p>This daemon inspects the commit log, extracts any deletes, and broadcasts them to the Memcache deployments in every frontend cluster within the region.</p></li><li><p>For better performance, <strong>mcsqueal</strong> batches these deletes into fewer packets and sends them to dedicated servers running <strong>mcrouter</strong> instances in each cluster.</p></li><li><p>The <strong>mcrouter </strong>instance iterates over the individual deletes within the batch and routes them to the correct Memcache server.</p></li></ul><p>The below diagram explains this process.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3cb6fbf-eb4d-496d-b11e-0235fbc12d95_1600x1070.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="974" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3cb6fbf-eb4d-496d-b11e-0235fbc12d95_1600x1070.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>Challenges with Global Regions</h2><p>Operating at the scale of Facebook requires them to run and maintain data centers globally.</p><p>However, expanding to multiple regions also creates multiple challenges. The biggest one is maintaining consistency between the data in Memcache and the persistent storage across the regions.</p><p>In Facebook&#8217;s region setup, one region holds the primary databases while other geographic regions contain read-only replicas. The replicas are kept in sync with the primary using MySQL&#8217;s replication mechanism.</p><p>However, when replication is involved, there is bound to be some replication lag. In other words, the replica databases can fall behind the primary database.</p><p>There are two main cases to consider when it comes to consistency here:</p><h3>Writes from the Primary Region</h3><p>Let&#8217;s say a web server in the primary region (US) receives a request from the user to update their profile picture.</p><p>To maintain consistency, this change needs to be propagated to other regions as well.</p><ul><li><p>The replica databases have to be updated.</p></li><li><p>Also, the Memcache instances in the secondary regions need to be invalidated.</p></li></ul><p>The tricky part is managing the invalidation along with the replication.</p><p>If the invalidation arrives in the secondary region (Europe) before the actual change is replicated to the database in the region, there are chances of a race condition as follows:</p><ul><li><p>Someone in the Europe region tries to view the profile picture.</p></li><li><p>The system fetches the information from the cache but it has been invalidated.</p></li><li><p>Data is fetched from the read-only database in the region, which is still lagging. This means that the fetch request gets the old picture and sets it within the cache.</p></li><li><p>Eventually, the replication is successful but the cache is already set with stale data and future requests will continue fetching this stale data from the cache.</p></li></ul><p>The below diagram shows this scenario:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51b29010-3717-46a9-8fb7-52403f6026db_1600x980.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="892" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51b29010-3717-46a9-8fb7-52403f6026db_1600x980.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>To avoid such race conditions, Facebook implemented a solution where the storage cluster having the most up-to-date information is responsible for sending invalidations within a region. It uses the same <strong>mcsqueal</strong> setup we talked about in the previous section.</p><p>This approach ensures that invalidations don&#8217;t get sent prematurely to the replica regions before the change has been fully replicated in the databases.</p><h3>Writes from the Non-Primary Region</h3><p>When dealing with writes originating from non-primary regions, the sequence of events is as follows:</p><ul><li><p>User updates their profile picture from a secondary region. While reads are served from the replica or secondary regions, the writes go to the primary region.</p></li><li><p>After the writes are successful, the changes also need to be replicated in the secondary region as well.</p></li><li><p>However, there&#8217;s a risk that before the replication catches up, a read request on the replica region may fetch and cache stale data in Memcache.</p></li></ul><p>To solve this problem, Facebook used the concept of a remote marker.</p><p>The remote marker is used to indicate whether the data in the local replica is potentially stale and it should be queried from the primary region.</p><p>It works as follows:</p><ul><li><p>When a client web server requests to update the data for key K, it sets a remote marker R for that key in the replica region.</p></li><li><p>Next, it performs the write to the primary region.</p></li><li><p>Also, the key K is deleted from the replica region&#8217;s Memcache servers.</p></li><li><p>A read request comes along for K in the replica region but the webserver would get a cache miss.</p></li><li><p>It checks whether the remote marker R exists and if found, the query is directed to the primary region.</p></li></ul><p>The below diagram shows all the steps in more detail.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e7903d4-f4e3-4d7e-8d10-641e507c8f7e_1600x981.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="893" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e7903d4-f4e3-4d7e-8d10-641e507c8f7e_1600x981.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At this point, you may think that this approach is inefficient because they are first checking the cache, then the remote marker, and then making the query to the primary region.</p><p>In this scenario, Facebook chose to trade off latency for a cache miss in exchange for a reduced probability of reading stale data.</p><h2>Single Server Optimizations</h2><p>As you can see, Facebook implemented some big architectural decisions to scale Memcached for their requirements. However, they also spent a significant time optimizing the performance of individual Memcache servers.</p><p>While the scope of these improvements may seem small in isolation, their cumulative impact at Facebook&#8217;s scale was significant.</p><p>Here are a few important optimizations that they made:</p><h3>Automatic Hash Table Expansion</h3><p>As the number of stored items grows, the time complexity of lookups in a hash table can degrade to O(n) if the table size remains fixed. This reduces the performance.</p><p>Facebook implemented an automatic expansion mechanism for the hash table. When the number of items reaches a certain threshold, the hash table automatically doubles in size, ensuring that the time complexity of the lookups remains constant even as the dataset grows.</p><h3>Multi-Threaded Server Architecture</h3><p>Serving a high volume of requests on a single thread can result in increased latency and reduced throughput.</p><p>To deal with this, they enhanced the Memcache server to support multiple threads and handle requests concurrently.</p><h3>Dedicated UDP Port for Each Thread</h3><p>When multiple threads share the same UDP port, contentions can occur and lead to performance problems.</p><p>They implemented support for each thread to have its own dedicated UDP port so that the threads can operate more efficiently.</p><h3>Adaptive Slab Allocator</h3><p>Inefficient memory allocation and management can lead to fragmentation and suboptimal utilization of system resources.</p><p>Facebook implemented an Adaptive Slab Allocator to optimize memory organization within each Memcache server. The slab allocator divides the available memory into fixed-size chunks called slabs. Each slab is further divided into smaller units of a specific size.&nbsp;</p><p>The allocator dynamically adapts the slab sizes based on the observed request patterns to maximize memory utilization.</p><h2>Conclusion</h2><p>Facebook&#8217;s journey in scaling Memcached serves as a fantastic case study for developers and engineers. It highlights the challenges that come up when building a globally distributed social network that needs to handle massive amounts of data and serve billions of users.</p><p>With their implementation and optimization of Memcache, Facebook demonstrates the importance of tackling scalability challenges at multiple levels. From high-level architectural decisions to low-level server optimizations, every aspect plays an important role in ensuring the performance, reliability, and efficiency of the system.</p><p>Three key learning points to take away from this study are as follows:</p><ul><li><p>Embracing eventual consistency is the key to performance and availability. However, every decision has to be taken based on a good understanding of the trade-offs.</p></li><li><p>Failures are inevitable and it&#8217;s critical to design your system for failures.</p></li><li><p>Optimization can be done at multiple levels.</p></li></ul><p><strong>References:</strong></p><ul><li><p><a href="https://research.facebook.com/publications/scaling-memcache-at-facebook/">Scaling Memcache at Facebook</a></p></li><li><p><a href="https://www.youtube.com/watch?v=UH7wkvcf0ys">Facebook and Memcached</a></p></li><li><p><a href="https://pdos.csail.mit.edu/6.824/papers/memcache-faq.txt">Memcache FAQ by MIT</a></p></li><li><p><a href="https://www.ehcache.org/documentation/2.8/recipes/thunderingherd.html">Thundering Herd</a></p></li><li><p><a href="https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside">Cache-Aside Pattern</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p>
]]></content:encoded>
<pubDate>Tue, 14 May 2024 15:30:27 GMT</pubDate>
</item>
<item>
<title>EP111: My Favorite 10 Books for Software Developers</title>
<link>https://blog.bytebytego.com/p/ep111-my-favorite-10-books-for-software</link>
<guid>https://blog.bytebytego.com/p/ep111-my-favorite-10-books-for-software</guid>
<content:encoded><![CDATA[
<div> 编程原则、软件开发书籍、重要论文、实时数据、IPv4 vs. IPv6
编程原则的重要性、软件开发人员必读的经典书籍如《The Pragmatic Programmer》、重要的改变计算机世界的25篇论文、实时数据利用的关键Change Data Capture、IPv4与IPv6的区别。
<br /><br />总结: 本文介绍了编程原则、软件开发书籍、重要论文、实时数据和IPv4与IPv6之间的区别。重点强调编程原则的重要性，推荐了经典的软件开发书籍，列举了改变计算机世界的25篇重要论文，介绍了实时数据利用的关键Change Data Capture以及IPv4和IPv6之间的差异。文章内容涵盖了编程知识、软件开发经验、计算机技术的重要变革和网络协议的演变。 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>10 Coding Principles Explained in 5 Minutes (Youtube video)</p></li><li><p>My Favorite 10 Books for Software Developers </p></li><li><p>25 Papers That Completely Transformed the Computer World</p></li><li><p>Change Data Capture: Key to Leverage Real-time Data</p></li><li><p>IPv4 vs. IPv6, what are the differences? </p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65b29d8d-75dd-4d36-b1af-08b6227f6138_1355x1600.png" title="" width="1355" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</a></p></li><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>10 Coding Principles Explained in 5 Minutes</h2><div class="youtube-wrap" id="youtube2-GmXPwRNIrAU"><div class="youtube-inner"></div></div><div><hr /></div><h2>My Favorite 10 Books for Software Developers </h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1040" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12d664a0-da33-43da-9059-48075c1cad7d_800x1040.gif" title="No alternative text description for this image" width="800" /><div></div></div></a></figure></div><p>General Advice </p><ol><li><p>The Pragmatic Programmer by Andrew Hunt and David Thomas </p></li><li><p>Code Complete by Steve McConnell: Often considered a bible for software developers, this comprehensive book covers all aspects of software development, from design and coding to testing and maintenance. </p></li></ol><p>Coding </p><ol><li><p>Clean Code by Robert C. Martin </p></li><li><p>Refactoring by Martin Fowler </p></li></ol><p>Software Architecture </p><ol><li><p>Designing Data-Intensive Applications by Martin Kleppmann </p></li><li><p>System Design Interview (our own book :)) </p></li></ol><p>Design Patterns </p><ol><li><p>Design Patterns by Eric Gamma and Others </p></li><li><p>Domain-Driven Design by Eric Evans </p></li></ol><p>Data Structures and Algorithms </p><ol><li><p>Introduction to Algorithms by Cormen, Leiserson, Rivest, and Stein </p></li><li><p>Cracking the Coding Interview by Gayle Laakmann McDowell </p></li></ol><p>Over to you: What is your favorite book?</p><div><hr /></div><h2>25 Papers That Completely Transformed the Computer World</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="text" class="sizing-normal" height="1644" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F951c4ad6-986d-490c-a2b7-bfe0d0385a1f_1280x1644.jpeg" title="text" width="1280" /><div></div></div></a></figure></div><ol><li><p><a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo - Amazon&#8217;s Highly Available Key Value Store</a></p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf">Google File System</a>: Insights into a highly scalable file system</p></li><li><p><a href="https://research.facebook.com/file/839620310074473/scaling-memcache-at-facebook.pdf">Scaling Memcached at Facebook</a>: A look at the complexities of Caching</p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf">BigTable</a>: The design principles behind a distributed storage system</p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43438.pdf">Borg - Large Scale Cluster Management at Google</a></p></li><li><p><a href="https://www.cs.cornell.edu/projects/ladis2009/papers/lakshman-ladis2009.pdf">Cassandra</a>: A look at the design and architecture of a distributed NoSQL database</p></li><li><p><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>: Into a new deep learning architecture known as the transformer</p></li><li><p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/09/Kafka.pdf">Kafka</a>: Internals of the distributed messaging platform</p></li><li><p><a href="https://www.foundationdb.org/files/fdb-paper.pdf">FoundationDB</a>: A look at how a distributed database</p></li><li><p><a href="https://web.stanford.edu/class/cs245/readings/aurora.pdf">Amazon Aurora</a>: To learn how Amazon provides high-availability and performance</p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf">Spanner</a>: Design and architecture of Google&#8217;s globally distributed databas</p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/16cb30b4b92fd4989b8619a61752a2387c6dd474.pdf">MapReduce</a>: A detailed look at how MapReduce enables parallel processing of massive volumes of data</p></li><li><p><a href="https://dl.acm.org/doi/pdf/10.1145/3477132.3483546">Shard Manager</a>: Understanding the generic shard management framework</p></li><li><p><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/papers/dapper-2010-1.pdf">Dapper</a>: Insights into Google&#8217;s distributed systems tracing infrastructure</p></li><li><p><a href="https://www.researchgate.net/publication/308993790_Apache_Flink_Stream_and_Batch_Processing_in_a_Single_Engine">Flink</a>: A detailed look at the uni&#64257;ed architecture of stream and batch processing</p></li><li><p><a href="https://arxiv.org/pdf/2310.11703.pdf">A Comprehensive Survey on Vector Databases</a></p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/10683a8987dbf0c6d4edcafb9b4f05cc9de5974a.pdf">Zanzibar</a>: A look at the design, implementation and deployment of a global system for managing access control lists at Google&nbsp;</p></li><li><p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/d84ab6c93881af998de877d0070a706de7bec6d8.pdf">Monarch</a>: Architecture of Google&#8217;s in-memory time series database&nbsp;</p></li><li><p><a href="https://thrift.apache.org/static/files/thrift-20070401.pdf">Thrift</a>: Explore the design choices behind Facebook&#8217;s code-generation tool</p></li><li><p><a href="https://bitcoin.org/bitcoin.pdf">Bitcoin</a>: The ground-breaking introduction to the peer-to-peer electronic cash system</p></li><li><p><a href="https://web.stanford.edu/~rezab/papers/wtf_overview.pdf">WTF - Who to Follow Service at Twitter</a>: Twitter&#8217;s (now X) user recommendation system</p></li><li><p><a href="https://www.vldb.org/pvldb/vol13/p3217-matsunobu.pdf">MyRocks: LSM-Tree Database Storage Engine</a></p></li><li><p><a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">GoTo Considered Harmful</a></p></li><li><p><a href="https://raft.github.io/raft.pdf">Raft Consensus Algorithm</a>: To learn about the more understandable consensus algorithm</p></li><li><p><a href="https://lamport.azurewebsites.net/pubs/time-clocks.pdf">Time Clocks and Ordering of Events</a>: The extremely important paper that explains the concept of time and event ordering in a distributed system&nbsp;</p></li></ol><p>Over to you: I&#8217;m sure we missed many important papers. Which ones do you think should be included?</p><div><hr /></div><h2>Change Data Capture: Key to Leverage Real-time Data</h2><p>90% of the world&#8217;s data was created in the last two years and this growth will only get faster. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface" class="sizing-normal" height="1557" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc324fb65-98cb-44b4-878f-f56d1bd432a1_1280x1557.gif" title="graphical user interface" width="1280" /><div></div></div></a></figure></div><p><br /> <br />However, the biggest challenge is to leverage this data in real-time. Constant data changes make databases, data lakes, and data warehouses out of sync. <br /> <br />CDC or Change Data Capture can help you overcome this challenge. <br /> <br />CDC identifies and captures changes made to the data in a database, allowing you to replicate and sync data across multiple systems. <br /> <br />So, how does Change Data Capture work? Here's a step-by-step breakdown: <br /> <br />1 - Data Modification: A change is made to the data in the source database. It could be an insert, update, or delete operation on a table. <br /> <br />2 - Change Capture: A CDC tool monitors the database transaction logs to capture the modifications. It uses the source connector to connect to the database and read the logs. <br /> <br />3 - Change Processing: The captured changes are processed and transformed into a format suitable for the downstream systems. <br /> <br />4 - Change Propagation: The processed changes are published to a message queue and propagated to the target systems, such as data warehouses, analytics platforms, distributed caches like Redis, and so on. <br /> <br />5 - Real-Time Integration: The CDC tool uses its sink connector to consume the log and update the target systems. The changes are received in real time, allowing for conflict-free data analysis and decision-making. <br /> <br />Users only need to take care of step 1 while all other steps are transparent. <br /> <br />A popular CDC solution uses Debezium with Kafka Connect to stream data changes from the source to target systems using Kafka as the broker. Debezium has connectors for most databases such as MySQL, PostgreSQL, Oracle, etc. <br /> <br />Over to you: have you leveraged CDC in your application before?</p><div><hr /></div><h2>IPv4 vs. IPv6, what are the differences? </h2><p>The transition from Internet Protocol version 4 (IPv4) to Internet Protocol version 6 (IPv6) is primarily driven by the need for more internet addresses, alongside the desire to streamline certain aspects of network management.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7680062-0800-404d-86bf-ef4237788b2a_1536x1536.gif" title="graphical user interface, application" /><div></div></div></a></figure></div><ul><li><p>Format and Length <br />IPv4 uses a 32-bit address format, which is typically displayed as four decimal numbers separated by dots (e.g., 192.168.0. 12). The 32-bit format allows for approximately 4.3 billion unique addresses, a number that is rapidly proving insufficient due to the explosion of internet-connected devices. <br /> <br />In contrast, IPv6 utilizes a 128-bit address format, represented by eight groups of four hexadecimal digits separated by colons (e.g., 50B3:F200:0211:AB00:0123:4321:6571:B000). This expansion allows for approximately much more addresses, ensuring the internet's growth can continue unabated. </p><p></p></li><li><p>Header <br />The IPv4 header is more complex and includes fields such as the header length, service type, total length, identification, flags, fragment offset, time to live (TTL), protocol, header checksum, source and destination IP addresses, and options. <br /> <br />IPv6 headers are designed to be simpler and more efficient. The fixed header size is 40 bytes and includes less frequently used fields in optional extension headers. The main fields include version, traffic class, flow label, payload length, next header, hop limit, and source and destination addresses. This simplification helps improve packet processing speeds. </p><p></p></li><li><p>Translation between IPv4 and IPv6 <br />As the internet transitions from IPv4 to IPv6, mechanisms to allow these protocols to coexist have become essential: <br /> <br />- Dual Stack: This technique involves running IPv4 and IPv6 simultaneously on the same network devices. It allows seamless communication in both protocols, depending on the destination address availability and compatibility. The dual stack is considered one of the best approaches for the smooth transition from IPv4 to IPv6.</p><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p></p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p></p><p>Space Fills Up Fast - Reserve Today</p><p></p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a></strong></p><div><hr /></div></li></ul>
]]></content:encoded>
<pubDate>Sat, 11 May 2024 15:30:45 GMT</pubDate>
</item>
<item>
<title>HTTP1 vs HTTP2 vs HTTP3 - A Deep Dive</title>
<link>https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive</link>
<guid>https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive</guid>
<content:encoded><![CDATA[
<div> HTTP1, HTTP/1.1, Persistent Connections, Pipelining, Caching and Conditional Requests

总结:<br /><br />HTTP/1是互联网世界增长的推动力之一，HTTP/1.1作为其主要版本，在满足需求和解决问题的基础上，引入了持久连接、管线化、分块传输编码以及缓存和条件请求等重要特性。虽然HTTP/1.1在过去的20多年间发挥了巨大作用，但随着网站规模和资源增加，HTTP/1.1的性能问题也逐渐暴露出来。随着网站越来越大，HTTP1.1的性能问题变得越来越突出。Persistent Connections解决了连接频繁开关的问题，Pipelining提高了性能，Chunked Transfer Encoding改善了页面加载速度，而Caching和Conditional Requests优化了缓存和数据传输，但仍然存在一些问题。(HTTP/1.1 introduced several key features that improved performance, but as websites grew in size, limitations of HTTP/1.1's capabilities started to become apparent.) <div>
<p>What has powered the incredible growth of the World Wide Web?</p><p>There are several factors, but HTTP or Hypertext Transfer Protocol has played a fundamental role.</p><p>Once upon a time, the name may have sounded like a perfect choice. After all, the initial goal of HTTP was to transfer hypertext documents. These are documents that contain links to other documents.</p><p>However, developers soon realized that HTTP can also help transfer other content types, such as images and videos. Over the years, HTTP has become critical to the existence and growth of the web.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7880fc22-160a-4d20-9e74-00f9ded06681_1600x938.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="854" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7880fc22-160a-4d20-9e74-00f9ded06681_1600x938.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In today&#8217;s deep dive, we&#8217;ll unravel the evolution of HTTP, from its humble beginnings with HTTP1 to the latest advancements of HTTP2 and HTTP3. We&#8217;ll look at how each version addressed the limitations of its predecessor, improving performance, security, and user experience.</p><p>By the end of this article, you&#8217;ll have a solid understanding of the key differences between HTTP1, HTTP2, and HTTP3, helping you make informed decisions when designing web applications.</p><h2>HTTP1 - The Foundation</h2><p>HTTP/1 was introduced in 1996. Before that, there was HTTP/0.9, a simple protocol that only supported the GET method and had no headers. Only HTML files were included in HTTP responses. There were no HTTP headers and no HTTP status codes.</p><p>HTTP/1.0 added headers, status codes, and additional methods such as POST and HEAD. However, HTTP/1 still had limitations. For example, each request-response pair needed a new TCP connection&nbsp;</p><p>In 1997, HTTP/1.1 was released to address the limitations of HTTP/1. Generally speaking, HTTP/1.1 is the definitive version of HTTP1. This version powered the growth of the World Wide Web and is still used heavily despite being over 25 years old.</p><p>What contributed to its incredible longevity?</p><p>There were a few important features that made it so successful.</p><h3>1 - Persistent Connections&nbsp;</h3><p>As mentioned, HTTP started as a single request-response protocol.&nbsp;</p><p>A client opens a connection to the server, makes a request, and gets the response. The connection is then closed. If there&#8217;s a second request, the cycle repeats. The same cycle repeats for subsequent requests.</p><p>It&#8217;s like a busy restaurant where a single waiter handles all orders. For each customer, the waiter takes the order, goes to the kitchen, prepares the food, and then delivers it to the customer&#8217;s table. Only then does the waiter move on to the next customer.</p><p>As the web became more media-oriented, closing the connection constantly after every response proved wasteful. If a web page contains multiple resources that have to be fetched, you would have to open and close the connection multiple times.</p><p>Since HTTP/1 was built on top of TCP (Transmission Control Protocol), every new connection meant going through the 3-way handshake process.</p><p>HTTP/1.1 got rid of this extra overhead by supporting persistent connections. It assumed that a TCP connection must be kept open unless directly told to close. This meant:</p><ul><li><p>No closing of the connection after every request</p></li><li><p>No multiple TCP handshakes.</p></li></ul><p>The diagram below shows the difference between multiple connections and persistent connections.</p><h3></h3><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22b23944-a2ab-432e-aad0-0ecfb9ae5144_1600x1018.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="926" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22b23944-a2ab-432e-aad0-0ecfb9ae5144_1600x1018.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>2 - Pipelining</h3><p>HTTP/1.1 also introduced the concept of pipelining.&nbsp;</p><p>The idea was to allow clients to send multiple requests over a single TCP connection without waiting for corresponding responses. For example, when the browser sees that it needs two images to render a web page, it can request them one after the other.</p><p>The below diagram explains the concept of pipelining in more detail.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97c703ce-13e1-4afc-8242-de06e90491cb_1600x1018.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="926" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97c703ce-13e1-4afc-8242-de06e90491cb_1600x1018.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>Pipelining further improved performance by reducing the latency for each response before sending the next request. However, pipelining had some limitations around head-of-line blocking that we will discuss shortly.</p><h3>3 - Chunked Transfer Encoding</h3><p>HTTP/1.1 introduced chunked transfer encoding that allowed servers to send responses in smaller chunks rather than waiting for the entire response to be generated.&nbsp;</p><p>This enabled faster initial page rendering and improved the user experience, particularly for large or dynamically generated content.</p><h3>4 - Caching and Conditional Requests</h3><p>HTTP/1.1 introduced sophisticated caching mechanisms and conditional requests.</p><p>It added headers like Cache-Control and ETag, which allowed clients and servers to better manage cached content and reduce unnecessary data transfers.&nbsp;</p><p>Conditional requests, using headers like If-Modified-Since and If-None-Match, enabled clients to request resources only if they had been modified since a previous request, saving bandwidth and improving performance.</p><h2>The Problem with HTTP/1.1</h2><p>There&#8217;s no doubt that HTTP/1.1 was game-changing and enabled the amazing growth trajectory of the web over the last 20+ years.</p><p>However, the web has also evolved considerably since the time HTTP/1.1 was launched.</p><p>Websites have grown in size, with more resources to download and more data to be transferred over the network. According to the HTTP Archive, the average website these days requests around 80 to 90 resources and downloads nearly 2 MB of data.</p><p>The next graph shows the steady growth of website size over the last 10+ years.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda88ee-86d9-4798-aa45-40d10b1fa4b2_1600x1032.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="939" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bda88ee-86d9-4798-aa45-40d10b1fa4b2_1600x1032.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption"><strong>Source: <a href="https://httparchive.org/reports/state-of-the-web">HTTP Archive State of the Web</a></strong></figcaption></figure></div><p>This growth exposed a fundamental performance problem with HTTP/1.1. </p><p>The diagram below explains the problem visually.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46611727-f8b9-4b47-b1d1-92b6458fd746_1600x1195.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1087" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46611727-f8b9-4b47-b1d1-92b6458fd746_1600x1195.png" title="" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/http1-vs-http2-vs-http3-a-deep-dive">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 09 May 2024 15:30:46 GMT</pubDate>
</item>
<item>
<title>100X Scaling: How Figma Scaled its Databases</title>
<link>https://blog.bytebytego.com/p/100x-scaling-how-figma-scaled-its</link>
<guid>https://blog.bytebytego.com/p/100x-scaling-how-figma-scaled-its</guid>
<content:encoded><![CDATA[
<div> 数据库扩展，垂直分区，水平分片，Figma，DBProxy
<br />
<br />
总结: Figma是一个快速增长的设计平台，面临着数据库规模的迅速增长，通过垂直分区和水平分片的方式来解决数据库扩展的挑战。他们首先进行垂直分区，将高流量的相关表移动到单独的数据库中，然后实施水平分片来将大表跨多个物理数据库分割，通过引入新服务DBProxy来解决路由和查询执行问题。通过这些创新的解决方案，Figma达到了逐步实现数据库横向分片的目标，确保了服务的稳定性和可扩展性。 <div>
<h2><a href="https://bit.ly/QAWolf_050724">&#128536; Kiss bugs goodbye with fully automated end-to-end test coverage (Sponsored)</a></h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/QAWolf_050724" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="752" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F94f074d9-31a4-450a-9b8b-84ea8556f86d_1200x752.png" width="1200" /><div></div></div></a></figure></div><p>Bugs sneak out when less than 80% of user flows are tested before shipping. But getting that kind of coverage &#8212; and staying there &#8212; is hard and pricey for any sized team.</p><p><a href="https://bit.ly/QAWolf_050724">QA Wolf</a> takes testing off your plate:</p><p>&#8594; Get to 80% test coverage in just 4 months.</p><p>&#8594; Stay bug-free with <a href="https://bit.ly/QAWolf_050724">24-hour maintenance</a> and on-demand test creation.</p><p>&#8594; Get <a href="https://bit.ly/QAWolf_050724">unlimited parallel test runs</a></p><p>&#8594; Zero Flakes guaranteed</p><p>QA Wolf has generated <a href="https://bit.ly/QAWolf_050724">amazing results</a> for companies like Salesloft, AutoTrader, Mailchimp, and Bubble.</p><p>&#127775; Rated 4.5/5 on G2</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/QAWolf_050724"><span>Learn more about their 90-day pilot</span></a></p><div><hr /></div><p>Figma, a collaborative design platform, has been on a wild growth ride for the last few years. Its user base has grown by almost 200% since 2018, attracting around 3 million monthly users.</p><p>As more and more users have hopped on board, the infrastructure team found themselves in a spot. They needed a quick way to scale their databases to keep up with the increasing demand.</p><p>The database stack is like the backbone of Figma. It stores and manages all the important metadata, like permissions, file info, and comments. And it ended up growing a whopping 100x since 2020!&nbsp;</p><p>That's a good problem to have, but it also meant the team had to get creative.</p><p>In this article, we'll dive into Figma's database scaling journey. We'll explore the challenges they faced, the decisions they made, and the innovative solutions they came up with. By the end, you'll better understand what it takes to scale databases for a rapidly growing company like Figma.</p><h2>The Initial State of Figma&#8217;s Database Stack</h2><p>In 2020, Figma still used a single, large Amazon RDS database to persist most of the metadata. While it handled things quite well, one machine had its limits.&nbsp;</p><p>During peak traffic, the CPU utilization was above 65% resulting in unpredictable database latencies.</p><p>While complete saturation was far away, the infrastructure team at Figma wanted to proactively identify and fix any scalability issues. They started with a few tactical fixes such as:</p><ul><li><p>Upgrade the database to the largest instance available (from r5.12xlarge to r5.24xlarge).</p></li><li><p>Create multiple read replicas to scale read traffic.</p></li><li><p>Establish new databases for new use cases to limit the growth of the original database.</p></li><li><p>Add PgBouncer as a connection pooler to limit the impact of a growing number of connections.</p></li></ul><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa398da3d-1c1e-46b9-9cff-942a7b6ff403_1600x990.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="901" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa398da3d-1c1e-46b9-9cff-942a7b6ff403_1600x990.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>These fixes gave them an additional year of runway but there were still limitations:</p><ul><li><p>Based on the database traffic, they learned that write operations contributed a major portion of the overall utilization.&nbsp;</p></li><li><p>All read operations could not be moved to replicas because certain use cases were sensitive to the impact of replication lag.</p></li></ul><p>It was clear that they needed a longer-term solution.</p><h2>The First Step: Vertical Partitioning</h2><p>When Figma's infrastructure team realized they needed to scale their databases, they couldn't just shut everything down and start from scratch. They needed a solution to keep Figma running smoothly while they worked on the problem.&nbsp;</p><p>That's where vertical partitioning came in.</p><p>Think of vertical partitioning as reorganizing your wardrobe. Instead of having one big pile of mess, you split things into separate sections. In database terms, it means moving certain tables to separate databases.</p><p>For Figma, vertical partitioning was a lifesaver. It allowed them to move high-traffic, related tables like those for &#8220;Figma Files&#8221; and &#8220;Organizations&#8221; into their separate databases. This provided some much-needed breathing room.</p><p>To identify the tables for partitioning, Figma considered two factors:</p><ol><li><p><strong>Impact: Moving the tables should move a significant portion of the workload.</strong></p></li><li><p><strong>Isolation: The tables should not be strongly connected to other tables.</strong></p></li></ol><p>For measuring impact, they looked at average active sessions (AAS) for queries. This stat describes the average number of active threads dedicated to a given query at a certain point in time.</p><p>Measuring isolation was a little more tricky. They used runtime validators that hooked into ActiveRecord, their Ruby ORM. The validators sent production query and transaction information to Snowflake for analysis, helping them identify tables that were ideal for partitioning based on query patterns and table relationships.</p><p>Once the tables were identified, Figma needed to migrate them between databases without downtime. They set the following goals for their migration solution:</p><ul><li><p>Limit potential availability impact to less than 1 minute.</p></li><li><p>Automate the procedure so it is easily repeatable.</p></li><li><p>Have the ability to undo a recent partition.</p></li></ul><p>Since they couldn&#8217;t find a pre-built solution that could meet these requirements, Figma built an in-house solution. At a high level, it worked as follows:</p><ul><li><p>Prepared client applications to query from multiple database partitions.</p></li><li><p>Replicated tables from the original database to a new database until the replication lag was near 0.</p></li><li><p>Paused activity on the original database.</p></li><li><p>Waited for databases to synchronize.</p></li><li><p>Rerouted query traffic to the new database.</p></li><li><p>Resumed activity.</p></li></ul><p>To make the migration to partitioned databases smoother, they created separate PgBouncer services to split the traffic virtually. Security groups were implemented to ensure that only PgBouncers could directly access the database.</p><p>Partitioning the PgBouncer layer first gave some cushion to the clients to route the queries incorrectly since all PgBouncer instances initially had the same target database. During this time, the team could also detect the routing mismatches and make the necessary corrections.</p><p>The below diagram shows this process of migration.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227d8304-f560-4987-95de-5afcc7b02a86_1244x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F227d8304-f560-4987-95de-5afcc7b02a86_1244x1600.png" width="1244" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="741" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b106e37-e264-4af2-98ce-26cd979aa36f_801x741.png" title="" width="801" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-cicd">A Crash Course in CI/CD</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Implementing Replication</h2><p>Data replication is a great way to scale the read operations for your database. When it came to replicating data for vertical partitioning, Figma had two options in Postgres: streaming replication or logical replication.</p><p>They chose logical replication for 3 main reasons:</p><ul><li><p>Logical replication allowed them to port over a subset of tables so that they could start with a much smaller storage footprint in the destination database.</p></li><li><p>It enabled them to replicate data into a database running a different Postgres major version.</p></li><li><p>Lastly, it allowed them to set up reverse replication to roll back the operation if needed.</p></li></ul><p>However, logical replication was slow. The initial data copy could take days or even weeks to complete.&nbsp;</p><p>Figma desperately wanted to avoid this lengthy process, not only to minimize the window for replication failure but also to reduce the cost of restarting if something went wrong.</p><p>But what made the process so slow?</p><p>The culprit was how Postgres maintains indexes in the destination database. While the replication process copies rows in bulk, it also updates the indexes one row at a time. By removing indexes in the destination database and rebuilding them after the data copy, Figma reduced the copy time to a matter of hours.</p><h2>Need for Horizontal Scaling</h2><p>As Figma's user base and feature set grew, so did the demands on their databases.&nbsp;</p><p>Despite their best efforts, vertical partitioning had limitations, especially for Figma&#8217;s largest tables. Some tables contained several terabytes of data and billions of rows, making them too large for a single database.</p><p>A couple of problems were especially prominent:</p><ul><li><p><strong>Postgres Vacuum Issue: Vacuuming is an essential background process in Postgres that reclaims storage occupied by deleted or obsolete rows. Without regular vacuuming, the database would eventually run out of transaction IDs and grind to a halt. However, vacuuming large tables can be resource-intensive and cause performance issues and downtime.</strong></p></li><li><p><strong>Max IO Operations Per Second: Figma&#8217;s highest write tables were growing so quickly that they would soon exceed the max IOPS limit of Amazon&#8217;s RDS.</strong></p></li></ul><p>For a better perspective, imagine a library with a rapidly growing collection of books. Initially, the library might cope by adding more shelves (vertical partitioning). But eventually, the building itself will run out of space. No matter how efficiently you arrange the shelves, you can&#8217;t fit an infinite number of books in a single building. That&#8217;s when you need to start thinking about opening branch libraries.</p><p>This is the approach of horizontal sharding.</p><p>For Figma, horizontal sharding was a way to split large tables across multiple physical databases, allowing them to scale beyond the limits of a single machine.&nbsp;</p><p>The below diagram shows this approach:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0570f4-0d65-49bd-9cb6-e581e08f4269_1244x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e0570f4-0d65-49bd-9cb6-e581e08f4269_1244x1600.png" width="1244" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>However, horizontal sharding is a complex process that comes with its own set of challenges:</p><ul><li><p>Some SQL queries become inefficient to support.</p></li><li><p>Application code must be updated to route queries efficiently to the correct shard.</p></li><li><p>Schema changes must be coordinated across all shards.&nbsp;</p></li><li><p>Postgres can no longer enforce foreign keys and globally unique indexes.</p></li><li><p>Transactions span multiple shards, which means Postgres cannot be used to enforce transactionality.</p></li></ul><h2>Exploring Alternative Solutions</h2><p>The engineering team at Figma evaluated alternative SQL options such as CockroachDB, TiDB, Spanner, and Vitess as well as NoSQL databases.</p><p>Eventually, however, they decided to build a horizontally sharded solution on top of their existing vertically partitioned RDS Postgres infrastructure.&nbsp;</p><p>There were multiple reasons for taking this decision:</p><ul><li><p>They could leverage their existing expertise with RDS Postgres, which they had been running reliably for years.</p></li><li><p>They could tailor the solution to Figma&#8217;s specific needs, rather than adapting their application to fit a generic sharding solution.</p></li><li><p>In case of any issues, they could easily roll back to their unsharded Postgres databases.</p></li><li><p>They did not need to change their complex relational data model built on top of Postgres architecture to a new approach like NoSQL. This allowed the teams to continue building new features.</p></li></ul><h2>Figma&#8217;s Unique Sharding Implementation</h2><p>Figma&#8217;s approach to horizontal sharding was tailored to their specific needs as well as the existing architecture. They made some unusual design choices that set their implementation apart from other common solutions.</p><p>Let&#8217;s look at the key components of Figma&#8217;s sharding approach:</p><h3>Colos (Colocations) for Grouping Related Tables</h3><p>Figma introduced the concept of &#8220;colos&#8221; or colocations, which are a group of related tables that share the same sharding key and physical sharding layout.&nbsp;</p><p>To create the colos, they selected a handful of sharding keys like UserId, FileId, or OrgID. Almost every table at Figma could be sharded using one of these keys.</p><p>This provides a friendly abstraction for developers to interact with horizontally sharded tables.&nbsp;</p><p>Tables within a colo support cross-table joins and full transactions when restricted to a single sharding key. Most application code already interacted with the database in a similar way, which minimized the work required by applications to make a table ready for horizontal sharding.</p><p>The below diagram shows the concept of colos:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F991f6f8e-c62a-4071-bf54-7bfdac7e9e95_1600x1087.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="989" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F991f6f8e-c62a-4071-bf54-7bfdac7e9e95_1600x1087.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h3>Logical Sharding vs Physical Sharding</h3><p>Figma separated the concept of &#8220;logical sharding&#8221; at the application layer from &#8220;physical sharding&#8221; at the Postgres layer.</p><p>Logical sharding involves creating multiple views per table, each corresponding to a subset of data in a given shard. All reads and writes to the table are sent through these views, making the table appear horizontally sharded even though the data is physically located on a single database host.</p><p>This separation allowed Figma to decouple the two parts of their migration and implement them independently. They could perform a safer and lower-risk logical sharding rollout before executing the riskier distributed physical sharding.&nbsp;</p><p>Rolling back logical sharding was a simple configuration change, whereas rolling back physical shard operations would require more complex coordination to ensure data consistency.</p><h3>DBProxy Query Engine for Routing and Query Execution</h3><p>To support horizontal sharding, the Figma engineering team built a new service named DBProxy that sits between the application and connection pooling layers such as the PGBouncer.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b03c9da-f712-44b7-aaa2-386f433ee45f_1600x1188.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1081" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b03c9da-f712-44b7-aaa2-386f433ee45f_1600x1188.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>DBProxy includes a lightweight query engine capable of parsing and executing horizontally sharded queries. It consists of three main components:</p><ol><li><p>A query parser that reads the SQL sent by the application and transforms it into an Abstract Syntax Tree (AST).</p></li><li><p>A logical planner that parses the AST, extracts the query type (insert, update, etc.), and logical shard IDs from the query plan.</p></li><li><p>A physical planner that maps the query from logical shard IDs to physical databases and rewrites queries to execute on the appropriate physical shard.</p></li></ol><p>The below diagram shows the practical use of these three components within the query processing workflow.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa76c90f1-4149-48bd-9615-faa6fd8d0a16_1600x982.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="894" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa76c90f1-4149-48bd-9615-faa6fd8d0a16_1600x982.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>There are always trade-offs when it comes to queries in a horizontally sharded world. Queries for a single shard key are relatively easy to implement. The query engine just needs to extract the shard key and route the query to the appropriate physical database.</p><p>However, if the query does not contain a sharding key, the query engine has to perform a more complex &#8220;scatter-gather&#8221; operation. This operation is similar to a hide-and-seek game where you send the query to every shard (scatter), and then piece together answers from each shard (gather).&nbsp;</p><p>The below diagram shows how single-shard queries work when compared to scatter-gather queries.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b900cff-db00-4b9b-84c4-1bc3abb2d8fd_1373x1600.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="1600" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b900cff-db00-4b9b-84c4-1bc3abb2d8fd_1373x1600.png" width="1373" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>As you can see, this increases the load on the database, and having too many scatter-gather queries can hurt horizontal scalability.</p><p>To manage things better, DBProxy handles load-shedding, transaction support, database topology management, and improved observability.</p><h3>Shadow Application Readiness Framework</h3><p>Figma added a &#8220;shadow application readiness&#8221; framework capable of predicting how live production traffic would behave under different potential sharding keys.&nbsp;</p><p>This framework helped them keep the DBProxy simple while reducing the work required for the application developers in rewriting unsupported queries.&nbsp;</p><p>All the queries and associated plans are logged to a Snowflake database, where they can run offline analysis. Based on the data collected, they were able to pick a query language that supported the most common 90% of queries while avoiding the worst-case complexity in the query engine.</p><h2>Conclusion</h2><p>Figma&#8217;s infrastructure team shipped their first horizontally sharded table in September 2023, marking a significant milestone in their database scaling journey.</p><p>It was a successful implementation with minimal impact on availability. Also, the team observed no regressions in latency or availability after the sharding operation.</p><p>Figma&#8217;s ultimate goal is to horizontally shard every table in their database and achieve near-infinite scalability. They have identified several challenges that need to be solved such as:</p><ul><li><p>Supporting horizontally sharded schema updates</p></li><li><p>Generating globally unique IDs for horizontally sharded primary keys</p></li><li><p>Implementing atomic cross-shard transactions for business-critical use cases.</p></li><li><p>Enabling distributed globally unique indexes.</p></li><li><p>Developing an ORM model to improve developer velocity</p></li><li><p>Automatic reshard operations to enable shard splits at the click of a button.</p></li></ul><p>Lastly, after achieving a sufficient runway, they also plan to reassess their current approach of using in-house RDS horizontal sharding versus switching to an open-source or managed alternative in the future.</p><p><strong>References:</strong></p><ul><li><p><a href="https://www.figma.com/blog/how-figmas-databases-team-lived-to-tell-the-scale/">How Figma&#8217;s databases team lived to tell the scale</a></p></li><li><p><a href="https://www.figma.com/blog/how-figma-scaled-to-multiple-databases/">The growing pains of database architecture</a></p></li><li><p><a href="https://www.pgbouncer.org/features.html">Features of PgBouncer</a></p></li><li><p><a href="https://zipdo.co/statistics/figma-user/">Figma User Statistics</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a>.</strong></p>
]]></content:encoded>
<pubDate>Tue, 07 May 2024 15:30:45 GMT</pubDate>
</item>
<item>
<title>EP110: Top 5 Strategies to Reduce Latency</title>
<link>https://blog.bytebytego.com/p/ep110-top-5-strategies-to-reduce</link>
<guid>https://blog.bytebytego.com/p/ep110-top-5-strategies-to-reduce</guid>
<content:encoded><![CDATA[
<div> Latency, Load Balancer, Data Sharding Algorithms, C++ Use Cases, Apache Kafka

<br />
Latency对于高规模用户系统来说是一项重要影响收入的因素，而减少延迟的策略包括数据库索引、缓存、负载均衡、内容交付网络、异步处理、数据压缩等。负载均衡的实际用例包括故障处理、实例健康检查、SSL终止、跨区负载均衡和用户粘性，能提升系统可靠性。数据分片算法有基于范围、基于哈希、一致性哈希和虚拟桶分片方法。C++的用途广泛，包括嵌入式系统、游戏开发、操作系统、数据库、网络、科学计算等。Apache Kafka是分布式事件流平台，包含broker、topic、partition、producer、consumer和consumer group等重要组件，并可用作消息传递和日志聚合。 

<br /><br />总结: 
- 减少延迟的策略包括数据库索引、缓存、负载均衡、内容交付网络、异步处理、数据压缩
- 负载均衡的实际用例有故障处理、实例健康检查、SSL终止、跨区负载均衡、用户粘性
- 常用数据分片算法有基于范围、基于哈希、一致性哈希、虚拟桶分片方法
- C++适用于嵌入式系统、游戏开发、操作系统、数据库、网络、科学计算等用例
- Apache Kafka作为分布式事件流平台，包含多个关键组件和用途 <div>
<p>This week&#8217;s system design refresher:</p><ul><li><p>Top 5 Strategies to Reduce Latency</p></li><li><p>Load Balancer Realistic Use Cases You May Not Know</p></li><li><p>Top 4 data sharding algorithms explained</p></li><li><p>Top 8 C++ Use Cases</p></li><li><p>Apache Kafka in 100 Seconds</p></li><li><p>SPONSOR US</p></li></ul><div><hr /></div><h2><a href="https://bit.ly/NewRelic_050324">New Relic AI monitoring, the industry&#8217;s first APM for AI, now generally available (Sponsore</a>d)</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://bit.ly/NewRelic_050324" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="630" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6192fcd8-53fc-4461-9e2c-8a73050c1d7c_1200x630.png" width="1200" /><div></div></div></a></figure></div><p>New Relic AI monitoring provides unprecedented visibility and insights to engineers and developers who are modernizing their tech stacks. With New Relic AI monitoring, engineering teams can monitor, alert, debug, and root-cause AI-powered applications.</p><p class="button-wrapper"><a class="button primary" href="https://bit.ly/NewRelic_050324"><span>Get started</span></a></p><div><hr /></div><h2>Top 5 Strategies to Reduce Latency</h2><p>10 years ago, Amazon found that every 100ms of latency cost them 1% in sales. <br /> <br />That&#8217;s a staggering $5.7 billion in today&#8217;s terms. <br /> <br />For high-scale user-facing systems, high latency is a big loss of revenue. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F801df2c4-056a-400c-91cc-8dc09fced890_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><p>Here are the top strategies to reduce latency: </p><ol><li><p>Database Indexing </p></li><li><p>Caching </p></li><li><p>Load Balancing </p></li><li><p>Content Delivery Network </p></li><li><p>Async Processing </p></li><li><p>Data Compression </p></li></ol><p>Over to you: What other strategies to reduce latency have you seen? </p><div><hr /></div><h2>Load Balancer Realistic Use Cases You May Not Know</h2><p>Load balancers are inherently dynamic and adaptable, designed to efficiently address multiple purposes and use cases in network traffic and server workload management. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="No alternative text description for this image" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d1ff6df-980d-43e9-aba9-7498a2ce3237_1280x1664.gif" title="No alternative text description for this image" width="1280" /><div></div></div></a></figure></div><p>Let's explore some of the use cases: </p><ol><li><p>Failure Handling: <br />Automatically redirects traffic away from malfunctioning elements to maintain continuous service and reduce service interruptions. </p></li><li><p>Instance Health Checks: <br />Continuously evaluates the functionality of instances, directing incoming requests exclusively to those that are fully operational and efficient. </p></li><li><p>Platform Specific Routing: <br />Routes requests from different device types (like mobiles, desktops) to specialized backend systems, providing customized responses based on platform. </p></li><li><p>SSL Termination: <br />Handles the encryption and decryption of SSL traffic, reducing the processing burden on backend infrastructure. </p></li><li><p>Cross Zone Load Balancing: <br />Distributes incoming traffic across various geographic or network zones, increasing the system's resilience and capacity for handling large volumes of requests. </p></li><li><p>User Stickiness: <br />Maintains user session integrity and tailored user interactions by consistently directing requests from specific users to designated backend servers. </p></li></ol><p>Over to you: <br />Which of these use cases would you consider adding to your network to enhance system reliability and why?</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="741" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b106e37-e264-4af2-98ce-26cd979aa36f_801x741.png" width="801" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">Unlocking the Power of SQL Queries for Improved Performance</a></p></li><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-cicd">A Crash Course in CI/CD</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>Top 4 Data Sharding Algorithms Explained</h2><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f404d8a-413b-4874-a9f7-90763e635ed9_1280x1664.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><p>We are dealing with massive amounts of data. Often we need to split data into smaller, more manageable pieces, or &#8220;shards&#8221;. Here are some of the top data sharding algorithms commonly used: </p><ul><li><p>Range-Based Sharding <br />This involves partitioning data based on a range of values. For example, customer data can be sharded based on alphabetical order of last names, or transaction data can be sharded based on date ranges. </p></li><li><p>Hash-Based Sharding <br />In this method, a hash function is applied to a shard key chosen from the data (like a customer ID or transaction ID). <br />This tends to distribute data more evenly across shards compared to range-based sharding. However, we need to choose a proper hash function to avoid hash collision. </p></li><li><p>Consistent Hashing <br />This is an extension of hash-based sharding that reduces the impact of adding or removing shards. It distributes data more evenly and minimizes the amount of data that needs to be relocated when shards are added or removed. </p></li><li><p>Virtual Bucket Sharding <br />Data is mapped into virtual buckets, and these buckets are then mapped to physical shards. This two-level mapping allows for more flexible shard management and rebalancing without significant data movement.</p></li></ul><div><hr /></div><h2>Top 8 C++ Use Cases</h2><p>C++ is a highly versatile programming language that is suitable for a wide range of applications. </p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="graphical user interface, application" class="sizing-normal" height="1664" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9dbf2f6-84ed-4533-a681-1ef110eb4084_1280x1664.gif" title="graphical user interface, application" width="1280" /><div></div></div></a></figure></div><ul><li><p>Embedded Systems <br />The language's efficiency and fine control over hardware resources make it excellent for embedded systems development. </p></li><li><p>Game Development <br />C++ is a staple in the game development industry due to its performance and efficiency. </p></li><li><p>Operating Systems <br />C++ provides extensive control over system resources and memory, making it ideal for developing operating systems and low-level system utilities. </p></li><li><p>Databases <br />Many high-performance database systems are implemented in C++ to manage memory efficiently and ensure fast execution of queries. </p></li><li><p>Financial Applications </p></li><li><p>Web Browsers <br />C++ is used in the development of web browsers and their components, such as rendering engines. </p></li><li><p>Networking <br />C++ is often used for developing network devices and simulation tools. </p></li><li><p>Scientific Computing <br />C++ finds extensive use in scientific computing and engineering applications that require high performance and precise control over computational resources. </p></li></ul><p>Over to you - What did we miss? </p><div><hr /></div><h2>Apache Kafka in 100 Seconds</h2><p>This post is written by guest author <a href="https://www.linkedin.com/in/sanazzakeri/">Sanaz Zakeri</a>, who is a Senior Software Engineer @Uber.</p><p>Apache Kafka is a distributed event streaming platform used for building real-time data processing pipelines and streaming applications. It is highly scalable, fault-tolerant, reliable, and can handle large volumes of data.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="Image" class="sizing-normal" height="1066" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F22ade5eb-1223-4cdc-a2ed-dccd1e42dc6e_1202x1066.jpeg" title="Image" width="1202" /><div></div></div></a></figure></div><p>In order to understand Kafka, we need to define two terms:</p><ul><li><p>Events: a log of state of something at a specific point in time</p></li><li><p>Event streams: continuous and unbounded series of events</p></li></ul><p>Kafka can be used as a Messaging in a publish-subscribe model, where producers write event streams, and consumers read the events. This publish-subscribe model enables decoupling of event stream producers and consumers. Also, Kafka can be used as a log aggregation platform, ingesting and storing logs from multiple sources in a durable and fault-tolerant way.</p><ul><li><p><strong>Kafka Components: </strong></p><p>Kafka cluster has multiple key components to provide the distributed infrastructure and reliably capture, store, order and provide event streams to client applications.</p></li><li><p><strong>Brokers: </strong></p><p>At the heart of the Kafka cluster lies the brokers which are physical servers that handle event streams. After events are published by producers, the broker makes the events available to consumers. Brokers bring scalability to Kafka as Kafka clusters can span multiple brokers across a variety of infrastructure setup to handle large volumes of events. They also bring fault tolerance since events can be stored and replicated across multiple brokers.</p></li><li><p><strong>Topics: </strong></p><p>Topic is the subject name of where the events are published by producers. Topics can have zero or more consumers listening to them and processing the events.</p></li><li><p><strong>Partition: </strong></p><p>In a topic, data is organized into partitions which store ordered streams of events. Each event within a partition is assigned a unique sequential identifier called offset that represents its position in the partition. Events are appended&nbsp; continually to the partition. A Topics can have one or more partitions. Having more than one partition in a topic enables parallelism as more consumers can read from the topic.</p><p>Partitions belonging to a topic can be distributed across separate brokers in the cluster, which brings high data availability and scalability. If one broker fails, the partitions on the remaining brokers can continue to serve data, ensuring fault tolerance.</p></li><li><p><strong>Producers: </strong></p><p>Producers are client applications&nbsp; that write events to Kafka topics as a stream of events.</p></li><li><p><strong>Consumers: </strong></p><p>Consumers are the client applications that subscribe to topics and process or store the events coming to the specific topic. Consumers read events in the order they were received within each partition.</p><p>Applications which require real time processing of data will have multiple consumers in a consumer group which can read from partitions on the subscribed topic.</p></li><li><p><strong>Consumer Groups: </strong></p><p>Consumer group is used to organize consumers that are reading a stream of events from one or more topics. Consumer groups enable parallel processing of events and each consumer in the consumer group can read from one partition to enable load balancing on the client application. This functionality not only brings the parallel processing but also brings fault tolerance since if a consumer fails in a consumer group, Partition can be reassigned to another group member.&nbsp;</p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a>.</strong></p>
]]></content:encoded>
<pubDate>Sat, 04 May 2024 15:30:41 GMT</pubDate>
</item>
<item>
<title>Unlocking the Power of SQL Queries for Improved Performance</title>
<link>https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries</link>
<guid>https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries</guid>
<content:encoded><![CDATA[
<div> SQL, 数据管理, 数据库, 查询优化, Explain Plan

总结:<br /><br />SQL是现代数据管理的基础，通过优化查询可以提升数据库性能和降低成本。使用Explain Plan工具可以分析查询执行计划，帮助识别潜在问题。在MySQL中，使用EXPLAIN命令可以获取执行查询的详细信息，包括表、操作、索引等。优化查询时，可以根据EXPLAIN的输出结果找到潜在瓶颈，并进行调整。通过实际示例演示了如何使用EXPLAIN命令来分析查询的执行计划。 <div>
<p>SQL, or Structured Query Language, is the backbone of modern data management. It enables efficient retrieval, manipulation, and management of data in a Database Management System (DBMS). Each SQL command taps into a complex sequence within a database, building on concepts like the connection pool, query cache, command parser, optimizer, and executor, which we covered in our last issue.</p><p>Crafting effective queries is essential. The right SQL can enhance database performance; the wrong one can lead to increased costs and slower responses. In this issue, we focus on strategies such as using the Explain Plan, adding proper indexes, and optimizing commands like COUNT(*) and ORDER BY. We also dive into troubleshooting slow queries.</p><p>While MySQL is our primary example, the techniques and strategies discussed are applicable across various database systems. Join us as we refine SQL queries for better performance and cost efficiency.</p><div><hr /></div><h2>Explain Plan</h2><p>In MySQL, the EXPLAIN command, known as EXPLAIN PLAN in systems like Oracle, is a useful tool for analyzing how queries are executed. By adding EXPLAIN before a SELECT statement, MySQL provides information about how it processes the SQL. This output shows the tables involved, operations performed (such as sort, scan, and join), and the indexes used, among other execution details. This tool is particularly useful for optimizing SQL queries, as it helps developers see the query execution plan and identify potential bottlenecks.</p><p>When an EXPLAIN statement is executed in MySQL, the database engine simulates the query execution. This simulation generates a detailed report without running the actual query. This report includes several important columns:</p><ul><li><p>id: Identifier for each step in the query execution.</p></li><li><p>select_type: The type of SELECT operation, like SIMPLE (a basic SELECT without unions or subqueries), SUBQUERY, or UNION.</p></li><li><p>table: The table involved in a particular part of the query.</p></li><li><p>type: The join type shows how MySQL joins the tables. Common types include ALL (full table scan), index (index scan), range (index range scan), eq_ref (unique index scan), const/system (constant value optimization).</p></li><li><p>possible_keys: Potential indexes that might be used.</p></li><li><p>key: The key (index) chosen by MySQL.</p></li><li><p>key_len: The length of the chosen key.</p></li><li><p>ref: Columns or constants used with the key to select rows.</p></li><li><p>rows: Estimated number of rows MySQL expects to examine when executing the query.</p></li><li><p>Extra: Additional details, such as the use of temporary tables or filesorts.</p></li></ul><p>Let's explore a practical application of the EXPLAIN command using a database table named <em>orders</em>. Suppose we want to select orders with user_id equal to 100.</p><pre><code><strong>SELECT</strong> * <strong>FROM</strong> orders <strong>WHERE</strong> user_id = 100;</code></pre><p>To analyze this query with EXPLAIN, we would use:</p><pre><code><strong>EXPLAIN SELECT</strong> * <strong>FROM</strong> orders <strong>WHERE</strong> user_id = 100;</code></pre><p>The output might look like this:&nbsp;</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d33f7e-6fca-47da-9e4a-04a9e053c2b8_1470x210.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="208" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d33f7e-6fca-47da-9e4a-04a9e053c2b8_1470x210.png" width="1456" /><div></div></div></a></figure></div>
      <p>
          <a href="https://blog.bytebytego.com/p/unlocking-the-power-of-sql-queries">
              Read more
          </a>
      </p>
]]></content:encoded>
<pubDate>Thu, 02 May 2024 15:31:02 GMT</pubDate>
</item>
<item>
<title>How to Execute End-to-End Tests at Scale</title>
<link>https://blog.bytebytego.com/p/how-to-execute-end-to-end-tests-at</link>
<guid>https://blog.bytebytego.com/p/how-to-execute-end-to-end-tests-at</guid>
<content:encoded><![CDATA[
<div> GCP, Argo CD, Kubernetes, Playwright, QA Wolf
总结:<br /><br />文章介绍了QA Wolf公司的专门基础设施，能够在短短几分钟内并发运行数千个端到端测试，满足客户的期望。他们的技术栈包括Google Cloud Platform(GCP)、Argo CD、Kubernetes、Playwright等工具。利用GitOps方法构建基础设施，采用Pulumi作为IaC工具，使用Typescript编写测试，通过运行数据文件执行测试。他们的执行流程由Run Director服务调度，运行Shard集群提供高可用性和更快测试，同时报告测试结果。该基础设施建立在全云原生架构上，支持快速迭代，为客户快速交付提供价值。 <div>
<p></p><p>Running E2E tests reliably and efficiently is a critical piece of the puzzle for any software organization.&nbsp;</p><p>There are mainly two expectations software teams have when it comes to testing:</p><ul><li><p>Ship as fast as possible without introducing (or reintroducing) bugs</p></li><li><p>Run tests as cheaply as possible without compromising on quality.</p></li></ul><p>In today&#8217;s issue, we are fortunate to host guest author John Gluck, Principal Testing Advocate at QA Wolf. He&#8217;ll be sharing insights into QA Wolf&#8217;s specialized infrastructure capable of running thousands of concurrent E2E tests in just a few minutes and meeting the expectations of their customers.</p><p><a href="https://www.qawolf.com/">QA Wolf</a> is a full-service solution for mid-to-large product teams who want to speed up their QA cycles and reduce the cost of building, running, and maintaining comprehensive regression test coverage.&nbsp;&nbsp;</p><p>Also, <a href="https://sched.co/1YeP3">Mufav Onus</a> of QA Wolf spoke at Kubecon 2024 in Paris about how they automatically resume pods on spot instances after unexpected shutdowns. <a href="https://www.youtube.com/watch?v=c2MbSM9-7Xs">Take a look</a>.</p><div><hr /></div><h2>The Challenge of Running E2E Tests</h2><p>Running E2E tests efficiently is challenging for any organization. The runners tend to cause resource spikes, which cause tests and applications to behave unpredictably.&nbsp; That&#8217;s why it&#8217;s fairly common for large product teams to strategically schedule their test runs. As the number of tests and the number of runs increases, the challenges become exponentially more difficult to overcome.&nbsp;&nbsp;</p><p>While the largest companies in the world may run 10,000 end-to-end tests each month, and a handful run 100,000, QA Wolf runs more than 2 million. At our scale, to support the number of customers that we do, our infrastructure has to address three major concerns:&nbsp;</p><ul><li><p><strong>Availability -</strong> Customers can execute their tests at any time with no restrictions on the number or frequency of parallel runs. The system must be highly available. We can&#8217;t use scheduling tricks to solve this.&nbsp;</p></li><li><p><strong>Speed - </strong>Tests need to run fast. DORA recommends 30 minutes as the maximum time for test suite execution, and customers want to follow this principle.</p></li><li><p><strong>Reliability - </strong>&nbsp;Node contention issues, instance hijacking, and test system execution outages (the things in-house test architects deal with on a regular basis) are simply not tolerable when people are paying you to execute their tests.</p></li></ul><p>For better or worse, StackOverflow didn&#8217;t have blueprints for the kind of test-running infrastructure we needed to build. Success came from lots of experimentation and constant refinement.&nbsp;</p><p>In this post, we discuss the problems we faced and the decisions we made so that we could solve them through experimentation.</p><h2>The Tech Stack Breakdown</h2><p></p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5150f81a-b38f-46c8-b7d2-cf27a9e5f84a_2410x896.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="541" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5150f81a-b38f-46c8-b7d2-cf27a9e5f84a_2410x896.png" width="1456" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">The tech stack</figcaption></figure></div><p>To set the stage, we are completely cloud-native and built our infrastructure on the Google Cloud Platform (GCP).&nbsp;</p><p>We went with GCP for its GKE (Kubernetes) implementation and cluster autoscaling capabilities, which are critical for handling the demand for test execution nodes. There are similar tools out there, but our engineers also had previous experience with GCP, which helped us get started.&nbsp;</p><p>We adopted a GitOps approach so we could run lots of configuration experiments on our infrastructure quickly and safely without disrupting ongoing operations.&nbsp;</p><p>Argo CD was a good choice because of its support for GitOps and Kubernetes. A combination of Helm and Argo Workflows helps make the deployment process consistent and organized. We used Argo CD Application Sets and App of Apps patterns which are considered best practices.</p><p>For IaC, we chose Pulumi because it&#8217;s open source, and unlike Terraform, it doesn&#8217;t force developers to adopt another DSL (Domain-Specific Language)</p><p>Lastly, we used Typescript to write the tests. Our customers look at the test code written for them, and Typescript makes it easy to understand. We chose Playwright as the test executor and test framework for multiple reasons, such as:</p><ol><li><p>Playwright can handle the complex tests that customers may need to automate.</p></li><li><p>Simpler APIs and an easier install prevent customers from being locked into our solution.&nbsp;</p></li><li><p>It&#8217;s backed by Microsoft, and more active development is expanding the list of native capabilities.</p></li></ol><h2>The Ecosystem</h2><p>For the infrastructure ecosystem, we went with one VPC and three main application clusters.&nbsp;</p><p>Each of the three clusters has a specific role:</p><ul><li><p>The application cluster</p></li><li><p>The test instance or runner cluster</p></li><li><p>Operations cluster</p></li></ul><p>The operations cluster is the primary cluster and manages the other two clusters. Argo CD runs within this cluster.</p><p>See the diagram below that shows this arrangement.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a34a0b7-6d02-405c-93cd-3341f60efb8a_980x597.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="441.0489795918367" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a34a0b7-6d02-405c-93cd-3341f60efb8a_980x597.png" width="724" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>At the time of startup, the operations cluster creates both the application and runner clusters. It provisions warm nodes on the runner cluster, each containing two pods, and each pod is built on a single container image.&nbsp;</p><p>See the diagram below for reference:</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90386158-64cc-4736-a8b0-3569b3ba7e0d_1600x974.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="435.6978021978022" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90386158-64cc-4736-a8b0-3569b3ba7e0d_1600x974.png" width="716" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>This structure is fully expendable. Our developers can tear down the entire system and rebuild it from scratch with the touch of a button, which increases predictability for developers and is also great for supporting disaster recovery.&nbsp;</p><p>GKE&#8217;s cluster autoscaler scales the warm nodes on the runner cluster up and down based on demand.&nbsp;</p><div><hr /></div><h2>Latest articles</h2><p>If you&#8217;re not a paid subscriber, here&#8217;s what you missed.</p><div class="captioned-image-container"><figure><a class="image-link image2" href="https://blog.bytebytego.com/subscribe" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="662" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbec68d98-d61b-411c-824c-64205354de37_661x662.png" title="" width="661" /><div></div></div></a></figure></div><ol><li><p><a href="https://blog.bytebytego.com/p/what-happens-when-a-sql-is-executed">What Happens When a SQL is Executed?</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-api-versioning">A Crash Course in API Versioning Strategies</a></p></li><li><p><a href="https://blog.bytebytego.com/p/embracing-chaos-to-improve-system">Embracing Chaos to Improve System Resilience: Chaos Engineering</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-cicd">A Crash Course in CI/CD</a></p></li><li><p><a href="https://blog.bytebytego.com/p/a-crash-course-in-ipv4-addressing">A Crash Course in IPv4 Addressing</a></p></li></ol><p>To receive all the full articles and support ByteByteGo, consider subscribing:</p><p class="button-wrapper"><a class="button primary" href="https://blog.bytebytego.com/subscribe"><span>Subscribe now</span></a></p><div><hr /></div><h2>The Customer-Facing Application</h2><p>The customer-facing application is a specialized IDE where our QA engineers can write, run, and maintain Playwright tests. It has views for managing configuration and third-party integrations with visualization dashboards.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1917074-931e-4567-b53d-d4abc6b6dfe9_1600x785.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="351.11538461538464" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1917074-931e-4567-b53d-d4abc6b6dfe9_1600x785.png" width="716" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">QA Wolf&#8217;s Test Editor</figcaption></figure></div><h2>Writing Tests</h2><p>The tests built and maintained by our in-house QA engineers are autonomous, isolated, idempotent, and atomic, so they can run predictably in a fully parallelized context.</p><p>When a QA engineer saves a test, the application persists the code for the test onto GCS with its corresponding helpers and any associated parsed configuration needed to run it in Playwright. This is the Run Data File for the test. In case you don&#8217;t know, GCS is the GCP equivalent of AWS S3.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27e79e48-de79-49d0-924a-48b903a67644_542x701.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="804.4686346863468" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F27e79e48-de79-49d0-924a-48b903a67644_542x701.png" width="622" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><p>In the initial implementation, we tried passing the Run Data File as a payload in HTML, but the payload containing the test code for all tests in a run was too large for Kubernetes etcd. To get around this, we took the path of least resistance by writing all the code to a central file and giving the client a reference to the file location to pass back to the application.</p><h2>The Execution Flow</h2><p>As mentioned earlier, we orchestrate runs with Argo Workflows because it can run on a Kubernetes cluster without external dependencies.</p><p>Customers or QA engineers can use a scheduler in the application or an API call to start a test run. When a test run is triggered, the application gathers the locations of all necessary Run Data Files. It also creates a new database record for each test run, including a unique build number that acts as an identifier for the test run request. The application uses the build number later to associate system logs and video locations.</p><p>Lastly, it passes the Run Data file locations list to the Run Director service.</p><p>The below diagram depicts the entire execution flow at a high level.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a79ebdf-390b-4d61-91e5-ad9337c5c23a_1305x1077.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="590.9057471264368" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2a79ebdf-390b-4d61-91e5-ad9337c5c23a_1305x1077.png" width="716" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a></figure></div><h2>The Run Director</h2><p>The Run Director is a simple, long-living, horizontally-scalable HTTP service.&nbsp;</p><p>When invoked, the Run Director reports the initial test run status to the application via a webhook and the build number. For each location in the list, the Run Director invokes an Argo Workflows template and hydrates it with the Run Data file at that location. By performing both actions simultaneously, individual test runs can be started faster so that all the tests in the run can finish more quickly.</p><p>The Argo Workflow then provisions a Kubernetes pod for each test run requested from the available warm nodes. It attaches the code for each test to a volume on a corresponding container on the pod. This approach allows us to use the same container build for every test execution. If there aren&#8217;t enough pods for the run on warm nodes, GKE uses cluster autoscaling to meet demand.&nbsp;</p><p>Each test runs in its own pod and container, which isolates the tests and makes it easier for the developers to troubleshoot them. Running tests like this also confines resource consumption issues to the node where the specific tests are having trouble.</p><p>The test code runs from the container entry point. Argo Workflow drives the provisioning process and starts each container with the help of Kubernetes</p><p>The application runs all the tests in headed browsers. This is important because the container is destroyed after the test finishes, and the headed browser makes it possible to capture videos of tests. The videos are an essential debugging tool to know about what happened at the moment, especially in cases where it&#8217;s difficult to recreate a particular failure.&nbsp;</p><p>Due to the high standard for test authorship and the infrastructure reliability, the primary cause of test failure is when the system-under-test (SUT) is not optimized for testing. It makes sense when you think about it. The slower the SUT, the more the test is required to poll, increasing the demand on the processor running the test. Though we can&#8217;t tell the customer how to build their application to improve test performance, we can isolate each test&#8217;s resource consumption to prevent it from impacting other tests.&nbsp;</p><h2>The Flake Detection</h2><p>We maintain a very high standard of test authorship, which allows us to make certain assumptions.</p><p>Since the tests are expected to pass, we can safely assume that a test failure or error is due to an anomaly, such as a temporarily unavailable SUT. The application schedules such failures for automatic retry. It flags any other failure &#8211; such as a suspected infrastructure problem &#8211; for investigation and doesn&#8217;t retry. Argo Workflows will attempt to re-run a failed test three times.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faae5939b-9b9a-468f-8f32-86bc55ddbfc0_1600x1124.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="491.8269230769231" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faae5939b-9b9a-468f-8f32-86bc55ddbfc0_1600x1124.png" width="700" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">QA Wolf Flake Detection Process</figcaption></figure></div><p>If the tests pass on retry, the application resumes as usual and assumes the failure was anomalous. In case all retries fail, the system creates a defect report, and a QA engineer investigates to confirm whether the failure is due to a bug in the application or some other issue.</p><h2>The Run Shard Clusters</h2><p>One of the most significant advantages of the Run Director service is the concept of Run Shard Clusters.</p><p>The sharding strategy allows us to spread the various test runs across clusters located worldwide. We have a GCP global VPC with a bunch of different subnets in different regions. This makes it possible to provision sharding clusters in different regions that can be accessed privately via the Run Director service.</p><p>Shard clusters provide several advantages, such as:</p><ul><li><p><strong>Replicated high availability </strong>- If one region goes down, not everything grinds to a halt.</p></li><li><p><strong>Closer-to-home testing</strong> - The ability to run customer tests close to their home region results in a more accurate performance of their applications and systems.</p></li><li><p><strong>Experimentation </strong>-<strong> </strong>We can experiment with different versions of our Argo Workflows implementation or different run engines without cutting overall traffic to the same version. This also allows us to experiment with cost-saving measures such as spot instances.</p></li></ul><h2>Reporting</h2><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ef5006-498e-41f9-9a2c-d7b3f2000dff_1600x769.jpeg" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="338.46153846153845" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17ef5006-498e-41f9-9a2c-d7b3f2000dff_1600x769.jpeg" width="704" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">The QA Wolf Application Dashboard</figcaption></figure></div><p>Of course, our customers also want to see test results, so we needed to create a reliable system that allowed them to do so.</p><p>Once the test finishes running and retrying (if needed), the Argo Workflow template uploads any run artifacts saved by Playwright back to GCS using the build number. Some of this information will be aggregated and appear on our application&#8217;s dashboard.&nbsp; Other pieces of information from these artifacts are displayed at the test level, such as logs and run history.</p><div class="captioned-image-container"><figure><a class="image-link is-viewable-img image2" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20875576-d0ff-42a0-9704-65465133489e_317x494.png" target="_blank"><div class="image2-inset"><source type="image/webp" /><img alt="" class="sizing-normal" height="687.2365930599369" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20875576-d0ff-42a0-9704-65465133489e_317x494.png" width="441" /><div class="image-link-expand"><svg class="lucide lucide-maximize2 " fill="none" height="20" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="20" xmlns="http://www.w3.org/2000/svg"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></a><figcaption class="image-caption">Run History for a QA Wolf test</figcaption></figure></div><p>On the infrastructure side, the Argo Workflow triggers Kubernetes to shut down the container and detach the volume, ensuring that the system doesn&#8217;t leave unnecessary resources running. This helps keep down operational costs.</p><h2>Conclusion</h2><p>Our unique approach was developed to meet customer needs for speed, availability, and reliability. We are one of the few companies running e2e tests at this scale, so we needed to discover how to create a system to support that through trial and error; therefore, we designed our system to also support fast iteration.&nbsp; Our cost-efficient, full parallel test execution is the backbone of our application and we see it delivering value for our customers on a daily basis.</p><div><hr /></div><p>If you&#8217;d like to learn more about QA Wolf&#8217;s test run infrastructure or how it can help you ship faster with fewer escapes, visit their website to <a href="http://www.qawolf.com/?utm_source=bytebytego&amp;utm_medium=newsletter&amp;utm_campaign=bbgnewsletter">schedule a demo</a>.&nbsp;</p><p>Related Links</p><ul><li><p><a href="https://www.qawolf.com/blog/flaky-coverage-is-fake-coverage">Flaky coverage is fake coverage</a></p></li><li><p><a href="https://www.qawolf.com/blog/the-challenges-and-rewards-of-full-test-parallelization">Parallel testing: what it is, why it's hard, and why you should do it</a></p></li><li><p><a href="https://www.qawolf.com/blog/principles-for-writing-parallizable-tests">Three ways to improve your parallelized tests</a></p></li></ul><div><hr /></div><h2><strong>SPONSOR US</strong></h2><p>Get your product in front of more than 500,000 tech professionals.</p><p>Our newsletter puts your products and services directly in front of an audience that matters - hundreds of thousands of engineering leaders and senior engineers - who have influence over significant tech decisions and big purchases.</p><p>Space Fills Up Fast - Reserve Today</p><p>Ad spots typically sell out about 4 weeks in advance. To ensure your ad reaches this influential audience, reserve your space now by emailing <strong><a href="mailto:hi@bytebytego.com">hi@bytebytego.com</a>.</strong></p>
]]></content:encoded>
<pubDate>Tue, 30 Apr 2024 16:24:12 GMT</pubDate>
</item>
</channel>
</rss>